@ARTICLE{Weir_undated-oc,
  title  = "A molecular filter for the cnidarian stinging response",
  author = "Weir, Keiko and Dupre, Christophe and van Giesen, Lena and Lee, Amy
            S Y and Bellono, Nicholas W",
  doi    = "10.1101/2020.04.04.025338"
}

@UNPUBLISHED{Tran2020-yg,
  title    = "Automated curation of {CNMF-E-extracted} {ROI} spatial footprints
              and calcium traces using open-source {AutoML} tools",
  author   = "Tran, L M and Mocle, A J and Ramsaran, A I and Jacob, A D and
              Frankland, P W and Josselyn, S A",
  abstract = "In vivo 1-photon calcium imaging is an increasingly prevalent
              method in behavioural neuroscience. Numerous analysis pipelines
              have been developed to improve the reliability and scalability of
              pre-processing and ROI extraction for these large calcium imaging
              datasets. Despite these advancements in pre-processing methods,
              manual curation of the extracted spatial footprints and calcium
              traces of neurons remains important for quality control. Here, we
              propose an additional semi-automated curation step for sorting
              spatial footprints and calcium traces from putative neurons
              extracted using the popular CNMF-E algorithm. We used the
              automated machine learning tools TPOT and AutoSklearn to generate
              classifiers to curate the extracted ROIs trained on a subset of
              human-labeled data. AutoSklearn produced the best performing
              classifier, achieving an F1 score > 92\% on the ground truth test
              dataset. This automated approach is a useful strategy for
              filtering ROIs with relatively few labeled data points, and can
              be easily added to pre-existing pipelines currently using CNMF-E
              for ROI extraction.",
  journal  = "bioRxiv",
  pages    = "2020.03.13.991216",
  month    =  mar,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.03.13.991216"
}

@ARTICLE{Takakusaki2008-jk,
  title    = "Forebrain control of locomotor behaviors",
  author   = "Takakusaki, Kaoru",
  abstract = "Activation of different areas in the forebrain evokes different
              types of goal directed adaptive behaviors. An important component
              of these different patterns of behavior is the locomotion that
              brings the animal to or away from a particular location. Here I
              review the role of projections from forebrain structures to the
              mesopontine tegmentum of the brainstem where neural mechanisms
              for initiation of locomotion and regulation of postural muscle
              tone are located that are activated during locomotor behavior. It
              is interesting is to understand how signals that converge from
              the forebrain structures to the mesopontine tegmentum control
              locomotor behavior, because the mesopontine tegmentum receives
              inhibitory efferents from the basal ganglia and excitatory
              efferents from the limbic-hypothalamic system and the neocortex.
              Here I hypothesize that the mesopontine tegmentum has functional
              gating mechanisms that determine whether the subject will
              initiate and select volitionally guided or emotionally triggered
              locomotor behaviors, depending on the behavioral context.",
  journal  = "Brain Res. Rev.",
  volume   =  57,
  number   =  1,
  pages    = "192--198",
  month    =  jan,
  year     =  2008,
  keywords = "Locomotion",
  language = "en",
  issn     = "0165-0173",
  pmid     = "17764749",
  doi      = "10.1016/j.brainresrev.2007.06.024"
}

@ARTICLE{Akam2014-ig,
  title    = "When brains flip coins",
  author   = "Akam, Thomas and Costa, Rui M",
  abstract = "In a recent study in the journal Cell, Tervo et al. (2014) show
              that animals can implement stochastic choice policies in
              environments unfavorable to predictive strategies. The shift
              toward stochastic behavior was driven by noradrenergic signaling
              in the anterior cingulate cortex.",
  journal  = "Neuron",
  volume   =  84,
  number   =  1,
  pages    = "9--11",
  month    =  oct,
  year     =  2014,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "25277450",
  doi      = "10.1016/j.neuron.2014.09.025",
  pmc      = "PMC4724885"
}

@ARTICLE{Koechlin2016-yb,
  title    = "Prefrontal executive function and adaptive behavior in complex
              environments",
  author   = "Koechlin, Etienne",
  abstract = "The prefrontal cortex (PFC) subserves higher cognitive abilities
              such as planning, reasoning and creativity. Here we review recent
              findings from both empirical and theoretical studies providing
              new insights about these cognitive abilities and their neural
              underpinnings in the PFC as overcoming key adaptive limitations
              in reinforcement learning. We outline a unified theoretical
              framework describing the PFC function as implementing an
              algorithmic solution approximating statistically optimal, but
              computationally intractable, adaptive processes. The resulting
              PFC functional architecture combines learning, planning,
              reasoning and creativity processes for balancing exploitation and
              exploration behaviors and optimizing behavioral adaptations in
              uncertain, variable and open-ended environments.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  37,
  pages    = "1--6",
  month    =  apr,
  year     =  2016,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "26687618",
  doi      = "10.1016/j.conb.2015.11.004"
}

@ARTICLE{Tervo2014-uw,
  title    = "Behavioral variability through stochastic choice and its gating
              by anterior cingulate cortex",
  author   = "Tervo, Dougal G R and Proskurin, Mikhail and Manakov, Maxim and
              Kabra, Mayank and Vollmer, Alison and Branson, Kristin and
              Karpova, Alla Y",
  abstract = "Behavioral choices that ignore prior experience promote
              exploration and unpredictability but are seemingly at odds with
              the brain's tendency to use experience to optimize behavioral
              choice. Indeed, when faced with virtual competitors, primates
              resort to strategic counter prediction rather than to stochastic
              choice. Here, we show that rats also use history- and model-based
              strategies when faced with similar competitors but can switch to
              a ``stochastic'' mode when challenged with a competitor that they
              cannot defeat by counter prediction. In this mode, outcomes
              associated with an animal's actions are ignored, and normal
              engagement of anterior cingulate cortex (ACC) is suppressed.
              Using circuit perturbations in transgenic rats, we demonstrate
              that switching between strategic and stochastic behavioral modes
              is controlled by locus coeruleus input into ACC. Our findings
              suggest that, under conditions of uncertainty about environmental
              rules, changes in noradrenergic input alter ACC output and
              prevent erroneous beliefs from guiding decisions, thus enabling
              behavioral variation. PAPERCLIP:",
  journal  = "Cell",
  volume   =  159,
  number   =  1,
  pages    = "21--32",
  month    =  sep,
  year     =  2014,
  language = "en",
  issn     = "0092-8674, 1097-4172",
  pmid     = "25259917",
  doi      = "10.1016/j.cell.2014.08.037"
}

@ARTICLE{Caillerie_undated-bp,
  title  = "Geodesic trail formation in a two-dimensional model of foraging
            ants with directed pheromones",
  author = "Caillerie, Nils"
}

@ARTICLE{Lin2007-yy,
  title    = "Neural encoding of the concept of nest in the mouse brain",
  author   = "Lin, Longnian and Chen, Guifen and Kuang, Hui and Wang, Dong and
              Tsien, Joe Z",
  abstract = "As important as memory is to our daily functions, the ability to
              extract fundamental features and commonalities from various
              episodic experiences and to then generalize them into abstract
              concepts is even more crucial for both humans and animals to
              adapt to novel and complex situations. Here, we report the neural
              correlates of the abstract concept of nests or beds in mice.
              Specifically, we find hippocampal neurons that selectively fire
              or cease to fire when the mouse perceives nests or beds,
              regardless of their locations and environments. Parametric
              analyses show that responses of nest cells remain invariant over
              changes in the nests' physical shape, style, color, odor, or
              construction materials; rather, their responses are driven by
              conscious awareness and physical determination of the categorical
              features that would functionally define nests. Such
              functionality-based abstraction and generalization of conceptual
              knowledge, emerging from episodic experiences, suggests that the
              hippocampus is an intrinsic part of the hierarchical structure
              for generating concepts and knowledge in the brain.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  104,
  number   =  14,
  pages    = "6066--6071",
  month    =  apr,
  year     =  2007,
  language = "en",
  issn     = "0027-8424",
  pmid     = "17389405",
  doi      = "10.1073/pnas.0701106104",
  pmc      = "PMC1851617"
}

@ARTICLE{Jaafar2008-us,
  title   = "A Fuzzy Action Selection Method for Virtual Agent Navigation in
             Unknown Virtual Environments",
  author  = "Jaafar, Jafreezal and Mc Kenzie, Eric",
  journal = "Plan. Perspect.",
  volume  =  144,
  pages   = "154",
  year    =  2008,
  issn    = "0266-5433"
}

@UNPUBLISHED{Adam2020-zd,
  title    = "Cortico-subthalamic projections send brief stop signals to halt
              visually-guided locomotion",
  author   = "Adam, Elie M and Johns, Taylor and Sur, Mriganka",
  abstract = "Summary Goal-directed locomotion necessitates control signals
              that propagate from higher-order areas to regulate spinal
              mechanisms. The cortico-subthalamic hyperdirect pathway offers a
              short route for cortical information to reach locomotor centers
              in the brainstem. We developed a task where head-fixed mice run
              to a visual landmark, then stop and wait to collect reward, and
              examined the role of secondary motor cortex (M2) projections to
              the subthalamic nucleus (STN) in controlling locomotion. Our
              modeled behavioral strategy indicates a switching point in
              behavior, suggesting a critical neuronal control signal at stop
              locations. Optogenetic activation of M2 axons in STN leads the
              animal to stop prematurely. By imaging M2 neurons projecting to
              STN, we find neurons that are active at the onset of stops, when
              executed at the landmark but not spontaneously elsewhere. Our
              results suggest that the M2-STN pathway can be recruited during
              visually-guided locomotion to rapidly and precisely control the
              mesencephalic locomotor region through the basal ganglia.",
  journal  = "bioRxiv",
  pages    = "2020.02.05.936443",
  month    =  feb,
  year     =  2020,
  keywords = "Locomotion",
  language = "en",
  doi      = "10.1101/2020.02.05.936443"
}

@UNPUBLISHED{Findling2019-yc,
  title    = "Imprecise neural computations as source of human adaptive
              behavior in volatile environments",
  author   = "Findling, Charles and Chopin, Nicolas and Koechlin, Etienne",
  abstract = "Everyday life features uncertain and ever-changing situations. In
              such environments, optimal adaptive behavior requires
              higher-order inferential capabilities to grasp the volatility of
              external contingencies. These capabilities however involve
              complex and rapidly intractable computations, so that we poorly
              understand how humans develop efficient adaptive behaviors in
              such environments. Here we demonstrate this counterintuitive
              result: simple, low-level inferential processes involving
              imprecise computations conforming to the psychophysical Weber Law
              actually lead to near-optimal adaptive behavior, regardless of
              the environment volatility. Using volatile experimental settings,
              we further show that such imprecise, low-level inferential
              processes accounted for observed human adaptive performances,
              unlike optimal adaptive models involving higher-order inferential
              capabilities, their biologically more plausible, algorithmic
              approximations and non-inferential adaptive models like
              reinforcement learning. Thus, minimal inferential capabilities
              may have evolved along with imprecise neural computations as
              contributing to near-optimal adaptive behavior in real-life
              environments, while leading humans to make suboptimal choices in
              canonical decision-making tasks.",
  journal  = "bioRxiv",
  pages    = "799239",
  month    =  oct,
  year     =  2019,
  language = "en",
  doi      = "10.1101/799239"
}

@UNPUBLISHED{Duan2019-cb,
  title    = "A cortico-collicular pathway for motor planning in a
              memory-dependent perceptual decision task",
  author   = "Duan, Chunyu A and Pan, Yuxin and Ma, Guofen and Zhou, Taotao and
              Zhang, Siyu and Xu, Ning-Long",
  abstract = "ABSTRACT Survival in a dynamic environment requires animals to
              plan future actions based on past sensory evidence. However, the
              neural circuit mechanism underlying this crucial brain function,
              referred to as motor planning, remains unclear. Here, we employ
              projection-specific imaging and perturbation methods to
              investigate the direct pathway linking two key nodes in the motor
              planning network, the secondary motor cortex (M2) and the
              midbrain superior colliculus (SC), in mice performing a
              memory-dependent perceptual decision task. We find dynamic coding
              of choice information in SC-projecting M2 neurons during motor
              planning and execution, and disruption of this information by
              inhibiting M2 terminals in SC selectively impaired decision
              maintenance. Furthermore, cell-type-specific optogenetic circuit
              mapping shows that M2 terminals modulate both excitatory and
              inhibitory SC neurons with balanced synaptic strength. Together,
              our results reveal the dynamic recruitment of the
              premotor-collicular pathway as a circuit mechanism for motor
              planning.",
  journal  = "bioRxiv",
  pages    = "709170",
  month    =  jul,
  year     =  2019,
  language = "en",
  doi      = "10.1101/709170"
}

@MISC{noauthor_undated-oe,
  title    = "418228.full.pdf",
  keywords = "synapses"
}

@ARTICLE{Branco2009-gn,
  title     = "The probability of neurotransmitter release: variability and
               feedback control at single synapses",
  author    = "Branco, Tiago and Staras, Kevin",
  abstract  = "Information transfer at chemical synapses occurs when vesicles
               fuse with the plasma membrane and release neurotransmitter. This
               process is stochastic and its likelihood of occurrence is a
               crucial factor in the regulation of signal propagation in
               neuronal networks. The reliability of neurotransmitter release
               can be highly variable: experimental data from
               electrophysiological, molecular and imaging studies have
               demonstrated that synaptic terminals can individually set their
               neurotransmitter release probability dynamically through local
               feedback regulation. This local tuning of transmission has
               important implications for current models of single-neuron
               computation.",
  journal   = "Nat. Rev. Neurosci.",
  publisher = "nature.com",
  volume    =  10,
  number    =  5,
  pages     = "373--383",
  month     =  may,
  year      =  2009,
  language  = "en",
  issn      = "1471-003X, 1471-0048",
  pmid      = "19377502",
  doi       = "10.1038/nrn2634"
}

@ARTICLE{Rodriguez2014-ux,
  title    = "Machine learning. Clustering by fast search and find of density
              peaks",
  author   = "Rodriguez, Alex and Laio, Alessandro",
  abstract = "Cluster analysis is aimed at classifying elements into categories
              on the basis of their similarity. Its applications range from
              astronomy to bioinformatics, bibliometrics, and pattern
              recognition. We propose an approach based on the idea that
              cluster centers are characterized by a higher density than their
              neighbors and by a relatively large distance from points with
              higher densities. This idea forms the basis of a clustering
              procedure in which the number of clusters arises intuitively,
              outliers are automatically spotted and excluded from the
              analysis, and clusters are recognized regardless of their shape
              and of the dimensionality of the space in which they are
              embedded. We demonstrate the power of the algorithm on several
              test cases.",
  journal  = "Science",
  volume   =  344,
  number   =  6191,
  pages    = "1492--1496",
  month    =  jun,
  year     =  2014,
  language = "en",
  issn     = "0036-8075, 1095-9203",
  pmid     = "24970081",
  doi      = "10.1126/science.1242072"
}

@UNPUBLISHED{Jun2017-ae,
  title    = "Real-time spike sorting platform for high-density extracellular
              probes with ground-truth validation and drift correction",
  author   = "Jun, James J and Mitelut, Catalin and Lai, Chongxi and Gratiy,
              Sergey L and Anastassiou, Costas A and Harris, Timothy D",
  abstract = "Abstract Electrical recordings from a large array of electrodes
              give us access to neural population activity with single-cell,
              single-spike resolution. These recordings contain extracellular
              spikes which must be correctly detected and assigned to
              individual neurons. Despite numerous spike-sorting techniques
              developed in the past, a lack of high-quality ground-truth
              datasets hinders the validation of spike-sorting approaches.
              Furthermore, existing approaches requiring manual corrections are
              not scalable for hours of recordings exceeding 100 channels. To
              address these issues, we built a comprehensive spike-sorting
              pipeline that performs reliably under noise and probe drift by
              incorporating covariance-based features and unsupervised
              clustering based on fast density-peak finding. We validated
              performance of our workflow using multiple ground-truth datasets
              that recently became available. Our software scales linearly and
              processes up to 1000-channel recording in real-time using a
              single workstation. Accurate, real-time spike sorting from large
              recording arrays will enable more precise control of closed-loop
              feedback experiments and brain-computer interfaces.",
  journal  = "bioRxiv",
  pages    = "101030",
  month    =  jan,
  year     =  2017,
  language = "en",
  doi      = "10.1101/101030"
}

@ARTICLE{DePasquale2016-zd,
  title         = "Using {Firing-Rate} Dynamics to Train Recurrent Networks of
                   Spiking Model Neurons",
  author        = "DePasquale, Brian and Churchland, Mark M and Abbott, L F",
  abstract      = "Recurrent neural networks are powerful tools for
                   understanding and modeling computation and representation by
                   populations of neurons. Continuous-variable or ``rate''
                   model networks have been analyzed and applied extensively
                   for these purposes. However, neurons fire action potentials,
                   and the discrete nature of spiking is an important feature
                   of neural circuit dynamics. Despite significant advances,
                   training recurrently connected spiking neural networks
                   remains a challenge. We present a procedure for training
                   recurrently connected spiking networks to generate dynamical
                   patterns autonomously, to produce complex temporal outputs
                   based on integrating network input, and to model
                   physiological data. Our procedure makes use of a
                   continuous-variable network to identify targets for training
                   the inputs to the spiking model neurons. Surprisingly, we
                   are able to construct spiking networks that duplicate tasks
                   performed by continuous-variable networks with only a
                   relatively minor expansion in the number of neurons. Our
                   approach provides a novel view of the significance and
                   appropriate use of ``firing rate'' models, and it is a
                   useful approach for building model spiking networks that can
                   be used to address important questions about representation
                   and computation in neural systems.",
  month         =  jan,
  year          =  2016,
  keywords      = "to\_read\_for\_review",
  archivePrefix = "arXiv",
  eprint        = "1601.07620",
  primaryClass  = "q-bio.NC",
  arxivid       = "1601.07620"
}

@UNPUBLISHED{Shao2022-vi,
  title    = "Relating local connectivity and global dynamics in recurrent
              excitatory-inhibitory networks",
  author   = "Shao, Yuxiu and Ostojic, Srdjan",
  abstract = "How the connectivity of cortical networks determines the neural
              dynamics and the resulting computations is one of the key
              questions in neuroscience. Previous works have pursued two
              complementary strategies to quantify the structure in
              connectivity, by specifying either the local statistics of
              connectivity motifs between small groups of neurons, or by
              defining network-wide low-rank patterns of connectivity that
              determine the resulting low-dimensional dynamics. A direct
              relationship between these two approaches is however currently
              missing, and in particular it remains to be clarified how local
              connectivity statistics are related to the global connectivity
              structure and shape the low-dimensional activity. To bridge this
              gap, here we develop a method for mapping local connectivity
              statistics onto an approximate global low-rank structure. Our
              method rests on approximating the global connectivity matrix
              using dominant eigenvectors, which we compute using perturbation
              theory for random matrices. This approach demonstrates that
              multi-population networks defined from local connectivity
              properties can in general be approximated by low-rank
              connectivity with Gaussian-mixture statistics. We specifically
              apply this method to excitatory-inhibitory networks, and show
              that it leads to accurate predictions for both the
              low-dimensional dynamics, and for the activity of individual
              neurons. Altogether, our approach allows us to disentangle the
              effects of mean connectivity and reciprocal motifs on the global
              recurrent feedback, and provides an intuitive picture of how
              local connectivity shapes global network dynamics. Author summary
              The structure of connections between neurons is believed to
              determine how cortical networks control behaviour. Current
              experimental methods typically measure connections between small
              numbers of simultaneously recorded neurons, and thereby provide
              information on statistics of local connectivity motifs.
              Collective network dynamics are however determined by
              network-wide patterns of connections. How these global patterns
              are related to local connectivity statistics and shape the
              dynamics is an open question that we address in this study.
              Starting from networks defined in terms of local statistics, we
              develop a method for approximating the resulting connectivity by
              global low-rank patterns. We apply this method to classical
              excitatory-inhibitory networks and show that it allows us to
              predict both collective and single-neuron activity. More
              generally, our approach provides a link between local
              connectivity statistics and global network dynamics. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.08.25.505122",
  month    =  aug,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.08.25.505122"
}

@ARTICLE{Pfeiffer2013-un,
  title    = "Hippocampal place-cell sequences depict future paths to
              remembered goals",
  author   = "Pfeiffer, Brad E and Foster, David J",
  abstract = "Effective navigation requires planning extended routes to
              remembered goal locations. Hippocampal place cells have been
              proposed to have a role in navigational planning, but direct
              evidence has been lacking. Here we show that before goal-directed
              navigation in an open arena, the rat hippocampus generates brief
              sequences encoding spatial trajectories strongly biased to
              progress from the subject's current location to a known goal
              location. These sequences predict immediate future behaviour,
              even in cases in which the specific combination of start and goal
              locations is novel. These results indicate that hippocampal
              sequence events characterized previously in linearly constrained
              environments as 'replay' are also capable of supporting a
              goal-directed, trajectory-finding mechanism, which identifies
              important places and relevant behavioural paths, at specific
              times when memory retrieval is required, and in a manner that
              could be used to control subsequent navigational behaviour.",
  journal  = "Nature",
  volume   =  497,
  number   =  7447,
  pages    = "74--79",
  month    =  may,
  year     =  2013,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "23594744",
  doi      = "10.1038/nature12112",
  pmc      = "PMC3990408"
}

@ARTICLE{Zignoli2020-uq,
  title    = "Prediction of pacing and cornering strategies during cycling
              individual time trials with optimal control",
  author   = "Zignoli, Andrea and Biral, Francesco",
  abstract = "A new dynamic model for predicting road cycling individual time
              trials with optimal control was created. The model included both
              lateral and longitudinal bicycle dynamics, 3D road geometry, and
              anaerobic source depletion. The prediction of the individual time
              trial performance was formulated as an optimal control problem
              and solved with an indirect approach to find the pacing and
              cornering strategies in the respect of the physical/physiological
              limits of the system. The model was tested against the velocity
              and power output data collected by professional cyclists in two
              individual time trial Giro d'Italia data sets: the first data set
              (Rovereto, n = 15) was used to adjust the parameters of the model
              and the second data set (Verona, n = 13) was used to test the
              predictive ability of the model. The simulated velocity fell in
              the $$\textbackslashmathrm\{CI\}_\{95\%\}$$of the experimental
              data for 32 and 18\% of the duration of the course for Rovereto
              and Verona stages, respectively. The simulated power output fell
              in the $$\textbackslashmathrm\{CI\}_\{95\%\}$$of the experimental
              data for 50 and 25\% of the duration of the course for Rovereto
              and Verona stages respectively. This framework can be used to
              input rider's physical/physiological characteristics, 3D road
              geometry, and conditions to generate realistic velocity and power
              output predictions in individual time trials. It, therefore,
              constitutes a tool that could be used by coaches and athletes to
              plan the pacing and cornering strategies before the race.",
  journal  = "Sports Eng.",
  volume   =  23,
  number   =  1,
  pages    = "13",
  month    =  jun,
  year     =  2020,
  issn     = "1369-7072, 1460-2687",
  doi      = "10.1007/s12283-020-00326-x"
}

@ARTICLE{Treves1995-zx,
  title     = "The Upward Bias in Measures of Information Derived from Limited
               Data Samples",
  author    = "Treves, Alessandro and Panzeri, Stefano",
  abstract  = "Extracting information measures from limited experimental
               samples, such as those normally available when using data
               recorded in vivo from mammalian cortical neurons, is known to be
               plagued by a systematic error, which tends to bias the estimate
               upward. We calculate here the average of the bias, under certain
               conditions, as an asymptotic expansion in the inverse of the
               size of the data sample. The result agrees with numerical
               simulations, and is applicable, as an additive correction term,
               to measurements obtained under such conditions. Moreover, we
               discuss the implications for measurements obtained through other
               usual procedures.",
  journal   = "Neural Comput.",
  publisher = "MIT Press",
  volume    =  7,
  number    =  2,
  pages     = "399--407",
  month     =  mar,
  year      =  1995,
  issn      = "0899-7667",
  doi       = "10.1162/neco.1995.7.2.399"
}

@ARTICLE{Eilam1989-uk,
  title     = "Home base behavior of rats (Rattus norvegicus) exploring a novel
               environment",
  author    = "Eilam, D and Golani, I",
  abstract  = "When rats are placed in a novel environment, they alternate
               between progression and stopping: in the course of a session
               they stop briefly in many places, but in one or two places they
               also stop for very long periods. The place in which they stay
               for the longest cumulative time is defined as the rat's home
               base. In this place the incidences of grooming and of rearing
               are high and often the highest. In addition, the number of
               visits to the home base is typically the highest. Some rats
               establish a secondary base with similar properties to those of
               the main home base. The location of the base influences the mode
               of progression throughout the environment: progression away from
               base is slower and includes more stops than progression back. It
               is suggested that this paradigm may be used for the analysis of
               the spatial organization of locomotor behavior in neuroscience
               research.",
  journal   = "Behav. Brain Res.",
  publisher = "tau.ac.il",
  volume    =  34,
  number    =  3,
  pages     = "199--211",
  month     =  sep,
  year      =  1989,
  language  = "en",
  issn      = "0166-4328",
  pmid      = "2789700",
  doi       = "10.1016/s0166-4328(89)80102-0"
}

@ARTICLE{Dayan2009-zu,
  title     = "Goal-directed control and its antipodes",
  author    = "Dayan, Peter",
  abstract  = "In instrumental conditioning, there is a rather precise
               definition of goal-directed control, and therefore an acute
               boundary between it and the somewhat more amorphous category
               comprising its opposites. Here, we review this division in terms
               of the various distinctions that accompany it in the fields of
               reinforcement learning and cognitive architectures, considering
               issues such as declarative and procedural control, the effect of
               prior distributions over environments, the neural substrates
               involved, and the differing views about the relative rationality
               of the various forms of control. Our overall aim is to reconnect
               some presently far-flung relations.",
  journal   = "Neural Netw.",
  publisher = "Elsevier",
  volume    =  22,
  number    =  3,
  pages     = "213--219",
  month     =  apr,
  year      =  2009,
  language  = "en",
  issn      = "0893-6080, 1879-2782",
  pmid      = "19362448",
  doi       = "10.1016/j.neunet.2009.03.004"
}

@ARTICLE{Abbott2016-xx,
  title    = "Building functional networks of spiking model neurons",
  author   = "Abbott, L F and DePasquale, Brian and Memmesheimer, Raoul-Martin",
  abstract = "Most of the networks used by computer scientists and many of
              those studied by modelers in neuroscience represent unit
              activities as continuous variables. Neurons, however, communicate
              primarily through discontinuous spiking. We review methods for
              transferring our ability to construct interesting networks that
              perform relevant tasks from the artificial continuous domain to
              more realistic spiking network models. These methods raise a
              number of issues that warrant further theoretical and
              experimental study.",
  journal  = "Nat. Neurosci.",
  volume   =  19,
  number   =  3,
  pages    = "350--355",
  month    =  mar,
  year     =  2016,
  keywords = "to\_read\_for\_review",
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "26906501",
  doi      = "10.1038/nn.4241",
  pmc      = "PMC4928643"
}

@MISC{Valente2007-qx,
  title    = "Analysis of the Trajectory of Drosophila melanogaster in a
              Circular Open Field Arena",
  author   = "Valente, Dan and Golani, Ilan and Mitra, Partha P",
  editor   = "Scalas, Enrico",
  abstract = "BACKGROUND Obtaining a complete phenotypic characterization of a
              freely moving organism is a difficult task, yet such a
              description is desired in many neuroethological studies. Many
              metrics currently used in the literature to describe locomotor
              and exploratory behavior are typically based on average
              quantities or subjectively chosen spatial and temporal
              thresholds. All of these measures are relatively coarse-grained
              in the time domain. It is advantageous, however, to employ
              metrics based on the entire trajectory that an organism takes
              while exploring its environment. METHODOLOGY/PRINCIPAL FINDINGS
              To characterize the locomotor behavior of Drosophila
              melanogaster, we used a video tracking system to record the
              trajectory of a single fly walking in a circular open field
              arena. The fly was tracked for two hours. Here, we present
              techniques with which to analyze the motion of the fly in this
              paradigm, and we discuss the methods of calculation. The measures
              we introduce are based on spatial and temporal probability
              distributions and utilize the entire time-series trajectory of
              the fly, thus emphasizing the dynamic nature of locomotor
              behavior. Marginal and joint probability distributions of speed,
              position, segment duration, path curvature, and reorientation
              angle are examined and related to the observed behavior.
              CONCLUSIONS/SIGNIFICANCE The measures discussed in this paper
              provide a detailed profile of the behavior of a single fly and
              highlight the interaction of the fly with the environment. Such
              measures may serve as useful tools in any behavioral study in
              which the movement of a fly is an important variable and can be
              incorporated easily into many setups, facilitating
              high-throughput phenotypic characterization.",
  month    =  oct,
  year     =  2007,
  doi      = "10.1371/journal.pone.0001083"
}

@ARTICLE{Benjamini2010-cs,
  title    = "Ten ways to improve the quality of descriptions of whole-animal
              movement",
  author   = "Benjamini, Yoav and Lipkind, Dina and Horev, Guy and Fonio, Ehud
              and Kafkafi, Neri and Golani, Ilan",
  abstract = "The demand for replicability of behavioral results across
              laboratories is viewed as a burden in behavior genetics. We
              demonstrate how it can become an asset offering a quantitative
              criterion that guides the design of better ways to describe
              behavior. Passing the high benchmark dictated by the
              replicability demand requires less stressful and less restraining
              experimental setups, less noisy data, individually customized
              cutoff points between the building blocks of movement, and less
              variable yet discriminative dynamic representations that would
              capture more faithfully the nature of the behavior, unmasking
              similarities and differences and revealing novel animal-centered
              measures. Here we review ten tools that enhance replicability
              without compromising discrimination. While we demonstrate the
              usefulness of these tools in the context of inbred mouse
              exploratory behavior they can readily be used in any study
              involving a high-resolution analysis of spatial behavior. Viewing
              replicability as a design concept and using the ten
              methodological improvements may prove useful in many fields not
              necessarily related to spatial behavior.",
  journal  = "Neurosci. Biobehav. Rev.",
  volume   =  34,
  number   =  8,
  pages    = "1351--1365",
  month    =  jul,
  year     =  2010,
  language = "en",
  issn     = "0149-7634, 1873-7528",
  pmid     = "20399806",
  doi      = "10.1016/j.neubiorev.2010.04.004"
}

@ARTICLE{De_Cheveigne2019-ab,
  title    = "Filters: When, Why, and How (Not) to Use Them",
  author   = "de Cheveign{\'e}, Alain and Nelken, Israel",
  abstract = "Filters are commonly used to reduce noise and improve data
              quality. Filter theory is part of a scientist's training, yet the
              impact of filters on interpreting data is not always fully
              appreciated. This paper reviews the issue and explains what a
              filter is, what problems are to be expected when using them, how
              to choose the right filter, and how to avoid filtering by using
              alternative tools. Time-frequency analysis shares some of the
              same problems that filters have, particularly in the case of
              wavelet transforms. We recommend reporting filter characteristics
              with sufficient details, including a plot of the impulse or step
              response as an inset.",
  journal  = "Neuron",
  volume   =  102,
  number   =  2,
  pages    = "280--293",
  month    =  apr,
  year     =  2019,
  keywords = "Fourier analysis; causality; distortions; filter; impulse
              response; oscillations; ringing; time-frequency representation",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "30998899",
  doi      = "10.1016/j.neuron.2019.02.039"
}

@UNPUBLISHED{De_Cothi2020-kd,
  title    = "Predictive Maps in Rats and Humans for Spatial Navigation",
  author   = "de Cothi, William and Nyberg, Nils and Griesbauer, Eva-Maria and
              Ghaname, Carole and Zisch, Fiona and Fletcher, Lydia and Newton,
              Charlotte and Renaudineau, Sophie and Bendor, Daniel and Grieves,
              Roddy and Duvelle, Eleonore and Barry, Caswell and Spiers, Hugo J",
  abstract = "Much of our understanding of navigation has come from the study
              of rats, humans and simulated artificial agents. To date little
              attempt has been made to integrate these approaches into a common
              framework to understand mechanisms that may be shared across
              mammals and the extent to which different instantiations of
              agents best capture mammalian navigation behaviour. Here, we
              report a comparison of rats, humans and reinforcement learning
              (RL) agents in a novel open-field navigation task (Tartarus Maze)
              requiring dynamic adaptation (shortcuts and detours) to changing
              obstructions in the path to the goal. We find humans and rats are
              remarkably similar in patterns of choice in the task. The
              patterns in their choices, dwell maps and changes over time
              reveal that both species show the greatest similarity to RL
              agents utilising a predictive map: the successor representation.
              Humans also display trajectory features similar to a model-based
              RL agent. Our findings have implications for models seeking to
              explain mammalian navigation in dynamic environments and
              highlight the utility of modelling the behaviour of different
              species in the same frame-work in comparison to RL agents to
              uncover the potential mechanisms used for behaviour. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  pages    = "2020.09.26.314815",
  month    =  sep,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.09.26.314815"
}

@ARTICLE{Gold2002-rg,
  title    = "Banburismus and the brain: decoding the relationship between
              sensory stimuli, decisions, and reward",
  author   = "Gold, Joshua I and Shadlen, Michael N",
  abstract = "This article relates a theoretical framework developed by British
              codebreakers in World War II to the neural computations thought
              to be responsible for forming categorical decisions about sensory
              stimuli. In both, a weight of evidence is computed and
              accumulated to support or oppose the alternative interpretations.
              A decision is reached when the evidence reaches a threshold
              value. In the codebreaking scheme, the threshold determined the
              speed and accuracy of the decision process. Here we propose that
              in the brain, the threshold may be controlled by neural circuits
              that calculate the rate of reward.",
  journal  = "Neuron",
  volume   =  36,
  number   =  2,
  pages    = "299--308",
  month    =  oct,
  year     =  2002,
  language = "en",
  issn     = "0896-6273",
  pmid     = "12383783",
  doi      = "10.1016/S0896-6273(02)00971-6"
}

@UNPUBLISHED{Benavidez2020-oh,
  title    = "The mouse cortico-tectal projectome",
  author   = "Benavidez, Nora L and Bienkowski, Michael S and Khanjani, Neda
              and Bowman, Ian and Fayzullina, Marina and Garcia, Luis and Gao,
              Lei and Korobkova, Laura and Gou, Lin and Cotter, Kaelan and
              Becerra, Marlene and Aquino, Sarvia and Cao, Chunru and Foster,
              Nicholas N and Song, Monica Y and Zhang, Bin and Yamashita, Seita
              and Zhu, Muye and Lo, Darrick and Boesen, Tyler and Zingg, Brian
              and Santarelli, Anthony and Wickersham, Ian R and Ascoli, Giorgio
              A and Hintiryan, Houri and Dong, Hong-Wei",
  abstract = "The superior colliculus (SC) is a midbrain structure that
              receives diverse and robust cortical inputs to drive a range of
              cognitive and sensorimotor behaviors. However, it remains unclear
              how descending cortical inputs arising from higher-order
              associative areas coordinate with SC sensorimotor networks to
              influence its outputs. In this study, we constructed a
              comprehensive map of all cortico-tectal projections and
              identified four collicular zones with differential cortical
              inputs: medial (SC.m), centromedial (SC.cm), centrolateral
              (SC.cl) and lateral (SC.l). Computational analyses revealed that
              cortico-tectal projections are organized as multiple subnetworks
              that are consistent with previously identified cortico-cortical
              and cortico-striatal subnetworks. Furthermore, we delineated the
              brain-wide input/output organization of each collicular zone and
              described a subset of their constituent neuronal cell types based
              on distinct connectional and morphological features. Altogether,
              this work provides a novel structural foundation for the
              integrative role of the SC in controlling cognition, orientation,
              and other sensorimotor behaviors.",
  journal  = "bioRxiv",
  pages    = "2020.03.24.006775",
  month    =  mar,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.03.24.006775"
}

@ARTICLE{Campbell2018-tx,
  title    = "Principles governing the integration of landmark and self-motion
              cues in entorhinal cortical codes for navigation",
  author   = "Campbell, Malcolm G and Ocko, Samuel A and Mallory, Caitlin S and
              Low, Isabel I C and Ganguli, Surya and Giocomo, Lisa M",
  abstract = "To guide navigation, the nervous system integrates multisensory
              self-motion and landmark information. We dissected how these
              inputs generate spatial representations by recording entorhinal
              grid, border and speed cells in mice navigating virtual
              environments. Manipulating the gain between the animal's
              locomotion and the visual scene revealed that border cells
              responded to landmark cues while grid and speed cells responded
              to combinations of locomotion, optic flow and landmark cues in a
              context-dependent manner, with optic flow becoming more
              influential when it was faster than expected. A network model
              explained these results by revealing a phase transition between
              two regimes in which grid cells remain coherent with or break
              away from the landmark reference frame. Moreover, during
              path-integration-based navigation, mice estimated their position
              following principles predicted by our recordings. Together, these
              results provide a theoretical framework for understanding how
              landmark and self-motion cues combine during navigation to
              generate spatial representations and guide behavior.",
  journal  = "Nat. Neurosci.",
  month    =  jul,
  year     =  2018,
  keywords = "Spatial Navigation",
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "30038279",
  doi      = "10.1038/s41593-018-0189-y"
}

@ARTICLE{Todorov2004-re,
  title    = "Optimality principles in sensorimotor control",
  author   = "Todorov, Emanuel",
  abstract = "The sensorimotor system is a product of evolution, development,
              learning and adaptation-which work on different time scales to
              improve behavioral performance. Consequently, many theories of
              motor function are based on 'optimal performance': they quantify
              task goals as cost functions, and apply the sophisticated tools
              of optimal control theory to obtain detailed behavioral
              predictions. The resulting models, although not without
              limitations, have explained more empirical phenomena than any
              other class. Traditional emphasis has been on optimizing desired
              movement trajectories while ignoring sensory feedback. Recent
              work has redefined optimality in terms of feedback control laws,
              and focused on the mechanisms that generate behavior online. This
              approach has allowed researchers to fit previously unrelated
              concepts and observations into what may become a unified
              theoretical framework for interpreting motor function. At the
              heart of the framework is the relationship between high-level
              goals, and the real-time sensorimotor control strategies most
              suitable for accomplishing those goals.",
  journal  = "Nat. Neurosci.",
  volume   =  7,
  number   =  9,
  pages    = "907--915",
  month    =  sep,
  year     =  2004,
  keywords = "control",
  language = "en",
  issn     = "1097-6256",
  pmid     = "15332089",
  doi      = "10.1038/nn1309",
  pmc      = "PMC1488877"
}

@ARTICLE{Turchin1992-ad,
  title     = "Complex Dynamics in Ecological Time Series",
  author    = "Turchin, Peter and Taylor, Andrew D",
  abstract  = "Although the possibility of complex dynamical behaviors?limit
               cycles, quasiperodic oscillations, and aperiodic chaos?has been
               recognized theoretically, most ecologists are skeptical of their
               importance in nature. In this paper we develop a methodology for
               reconstructing endogenous (or deterministic) dynamics from
               ecological time series. Our method consists of fitting a
               response surface to the yearly population change as a function
               of lagged population densities. Using the version of the model
               that includes two lags, we fitted time?series data for 14 insect
               and 22 vertebrate populations. The 14 insect populations were
               classified as: unregulated (1 case), exponentially stable (three
               cases), damped oscillations (six cases), limit cycles (one
               case), quasiperiodic oscillations (two cases), and chaos (one
               case). The vertebrate examples exhibited a similar spectrum of
               dynamics, although there were no cases of chaos. We tested the
               results of the response?surface methodology by calculating
               autocorrelation functions for each time series. Autocorrelation
               patterns were in agreement with our findings of periodic
               behaviors (damped oscillations, limit cycles, and
               quasiperiodicity). On the basis of these results, we conclude
               that the complete spectrum of dynamical behaviors, ranging from
               exponential stability to chaos, is likely to be found among
               natural populations.",
  journal   = "Ecology",
  publisher = "Wiley Online Library",
  volume    =  73,
  number    =  1,
  pages     = "289--305",
  month     =  feb,
  year      =  1992,
  issn      = "0012-9658",
  doi       = "10.2307/1938740"
}

@UNPUBLISHED{Bagur2018-lr,
  title    = "Dissociation of fear initiation and maintenance by
              breathing-driven prefrontal oscillations",
  author   = "Bagur, Sophie and Lefort, Julie M and Lacroix, Marie M and de
              Lavilleon, Gaetan and Herry, Cyril and Billand, Clara and
              Geoffroy, Helene and Benchenane, Karim",
  abstract = "Does the body play an active role in emotions? Since the original
              James/Cannon controversy this debate has mainly been fueled by
              introspective accounts of human experience. Here, we use the
              animal model to demonstrate a physiological mechanism for bodily
              feedback and its causal role in the stabilization of emotional
              states. We report that during fear-related freezing mice breathe
              at 4Hz and show, using probabilistic modelling, that optogenetic
              perturbation of this feedback specifically reduces freezing
              maintenance without impacting its initiation. This rhythm is
              transmitted by the olfactory bulb to the prefrontal cortex where
              it organizes neural firing and optogenetic probing of the circuit
              demonstrates frequency-specific tuning that maximizes prefrontal
              cortex responsivity at 4Hz, the breathing frequency during
              freezing. These results point to a brain-body-brain loop in which
              the initiation of emotional behavior engenders somatic changes
              which then feedback to the cortex to directly participate in
              sustaining emotional states.",
  journal  = "bioRxiv",
  pages    = "468264",
  month    =  nov,
  year     =  2018,
  language = "en",
  doi      = "10.1101/468264"
}

@ARTICLE{Vander_Weele2018-qt,
  title    = "Dopamine enhances signal-to-noise ratio in cortical-brainstem
              encoding of aversive stimuli",
  author   = "Vander Weele, Caitlin M and Siciliano, Cody A and Matthews,
              Gillian A and Namburi, Praneeth and Izadmehr, Ehsan M and
              Espinel, Isabella C and Nieh, Edward H and Schut, Evelien H S and
              Padilla-Coreano, Nancy and Burgos-Robles, Anthony and Chang,
              Chia-Jung and Kimchi, Eyal Y and Beyeler, Anna and Wichmann, Romy
              and Wildes, Craig P and Tye, Kay M",
  abstract = "Dopamine modulates medial prefrontal cortex (mPFC) activity to
              mediate diverse behavioural functions1,2; however, the precise
              circuit computations remain unknown. One potentially unifying
              model by which dopamine may underlie a diversity of functions is
              by modulating the signal-to-noise ratio in subpopulations of mPFC
              neurons3-6, where neural activity conveying sensory information
              (signal) is amplified relative to spontaneous firing (noise).
              Here we demonstrate that dopamine increases the signal-to-noise
              ratio of responses to aversive stimuli in mPFC neurons projecting
              to the dorsal periaqueductal grey (dPAG). Using an
              electrochemical approach, we reveal the precise time course of
              pinch-evoked dopamine release in the mPFC, and show that mPFC
              dopamine biases behavioural responses to aversive stimuli.
              Activation of mPFC-dPAG neurons is sufficient to drive place
              avoidance and defensive behaviours. mPFC-dPAG neurons display
              robust shock-induced excitations, as visualized by single-cell,
              projection-defined microendoscopic calcium imaging. Finally,
              photostimulation of dopamine terminals in the mPFC reveals an
              increase in the signal-to-noise ratio in mPFC-dPAG responses to
              aversive stimuli. Together, these data highlight how dopamine in
              the mPFC can selectively route sensory information to specific
              downstream circuits, representing a potential circuit mechanism
              for valence processing.",
  journal  = "Nature",
  volume   =  563,
  number   =  7731,
  pages    = "397--401",
  month    =  nov,
  year     =  2018,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "30405240",
  doi      = "10.1038/s41586-018-0682-1"
}

@ARTICLE{Mattar2018-ro,
  title    = "Prioritized memory access explains planning and hippocampal
              replay",
  author   = "Mattar, Marcelo G and Daw, Nathaniel D",
  abstract = "To make decisions, animals must evaluate candidate choices by
              accessing memories of relevant experiences. Yet little is known
              about which experiences are considered or ignored during
              deliberation, which ultimately governs choice. We propose a
              normative theory predicting which memories should be accessed at
              each moment to optimize future decisions. Using nonlocal 'replay'
              of spatial locations in hippocampus as a window into memory
              access, we simulate a spatial navigation task in which an agent
              accesses memories of locations sequentially, ordered by utility:
              how much extra reward would be earned due to better choices. This
              prioritization balances two desiderata: the need to evaluate
              imminent choices versus the gain from propagating newly
              encountered information to preceding locations. Our theory offers
              a simple explanation for numerous findings about place cells;
              unifies seemingly disparate proposed functions of replay
              including planning, learning, and consolidation; and posits a
              mechanism whose dysfunction may underlie pathologies like
              rumination and craving.",
  journal  = "Nat. Neurosci.",
  volume   =  21,
  number   =  11,
  pages    = "1609--1617",
  month    =  nov,
  year     =  2018,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "30349103",
  doi      = "10.1038/s41593-018-0232-z",
  pmc      = "PMC6203620"
}

@ARTICLE{Kepecs2008-ys,
  title    = "Neural correlates, computation and behavioural impact of decision
              confidence",
  author   = "Kepecs, Adam and Uchida, Naoshige and Zariwala, Hatim A and
              Mainen, Zachary F",
  abstract = "Humans and other animals must often make decisions on the basis
              of imperfect evidence. Statisticians use measures such as P
              values to assign degrees of confidence to propositions, but
              little is known about how the brain computes confidence estimates
              about decisions. We explored this issue using behavioural
              analysis and neural recordings in rats in combination with
              computational modelling. Subjects were trained to perform an
              odour categorization task that allowed decision confidence to be
              manipulated by varying the distance of the test stimulus to the
              category boundary. To understand how confidence could be computed
              along with the choice itself, using standard models of
              decision-making, we defined a simple measure that quantified the
              quality of the evidence contributing to a particular decision.
              Here we show that the firing rates of many single neurons in the
              orbitofrontal cortex match closely to the predictions of
              confidence models and cannot be readily explained by alternative
              mechanisms, such as learning stimulus-outcome associations.
              Moreover, when tested using a delayed reward version of the task,
              we found that rats' willingness to wait for rewards increased
              with confidence, as predicted by the theoretical model. These
              results indicate that confidence estimates, previously suggested
              to require 'metacognition' and conscious awareness are available
              even in the rodent brain, can be computed with relatively simple
              operations, and can drive adaptive behaviour. We suggest that
              confidence estimation may be a fundamental and ubiquitous
              component of decision-making.",
  journal  = "Nature",
  volume   =  455,
  number   =  7210,
  pages    = "227--231",
  month    =  sep,
  year     =  2008,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "18690210",
  doi      = "10.1038/nature07200"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Tolman1948-ym,
  title     = "Cognitive maps in rats and men",
  author    = "Tolman, E C",
  abstract  = "This paper is devoted to a description of experiments with rats,
               mostly at the author's laboratory, and to indicating the
               significance of these findings on rats for the clinical behavior
               of men. While all students agree as to the facts reported, they
               disagree on theory and …",
  journal   = "Psychol. Rev.",
  publisher = "psycnet.apa.org",
  volume    =  55,
  number    =  4,
  pages     = "189--208",
  month     =  jul,
  year      =  1948,
  keywords  = "CONDITIONING THERAPY",
  language  = "en",
  issn      = "0033-295X",
  pmid      = "18870876"
}

@ARTICLE{Redish1997-pq,
  title     = "Cognitive maps beyond the hippocampus",
  author    = "Redish, A D and Touretzky, D S",
  abstract  = "We present a conceptual framework for the role of the
               hippocampus and its afferent and efferent structures in rodent
               navigation. Our proposal is compatible with the behavioral,
               neurophysiological, anatomical, and neuropharmacological
               literature, and suggests a number of practical experiments that
               could support or refute it. We begin with a review of place
               cells and how the place code for an environment might be aligned
               with sensory cues and updated by self-motion information. The
               existence of place fields in the dark suggests that location
               information is maintained by path integration, which requires an
               internal representation of direction of motion. This leads to a
               consideration of the organization of the rodent head direction
               system, and thence into a discussion of the computational
               structure and anatomical locus of the path integrator. If the
               place code is used in navigation, there must be a mechanism for
               selecting an action based on this information. We review
               evidence that the nucleus accumbens subserves this function.
               From there, we move to interactions between the hippocampal
               system and the environment, emphasizing mechanisms for learning
               novel environments and for aligning the various subsystems upon
               re-entry into familiar environments. We conclude with a
               discussion of the relationship between navigation and
               declarative memory.",
  journal   = "Hippocampus",
  publisher = "Wiley Online Library",
  volume    =  7,
  number    =  1,
  pages     = "15--35",
  year      =  1997,
  language  = "en",
  issn      = "1050-9631",
  pmid      = "9138665",
  doi       = "10.1002/(SICI)1098-1063(1997)7:1<15::AID-HIPO3>3.0.CO;2-6"
}

@UNPUBLISHED{Tanaka2021-fi,
  title    = "Neural mechanisms to exploit positional geometry for collision
              avoidance",
  author   = "Tanaka, Ryosuke and Clark, Damon A",
  abstract = "Visual motion provides rich geometrical cues about the
              three-dimensional configuration the world. However, how brains
              decode the spatial information carried by motion signals remains
              poorly understood. Here, we study a collision avoidance behavior
              in Drosophila as a simple model of motion-based spatial vision.
              With simulations and psychophysics, we demonstrate that walking
              Drosophila exhibit a pattern of slowing to avoid collisions by
              exploiting the geometry of positional changes of objects on
              near-collision courses. This behavior requires the visual neuron
              LPLC1, whose tuning mirrors the behavior and whose activity
              drives slowing. LPLC1 pools inputs from object- and
              motion-detectors, and spatially biased inhibition tunes it to the
              geometry of collisions. Connectomic analyses identified circuitry
              downstream of LPLC1 that faithfully inherits its response
              properties. Overall, our results reveal how a small neural
              circuit solves a specific spatial vision task by combining
              distinct visual features to exploit universal geometrical
              constraints of the visual world. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.12.11.472218",
  month    =  dec,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.12.11.472218"
}

@ARTICLE{Clark_undated-kw,
  title  = "Putting Brain, Body, and World Together Again",
  author = "Clark, Andy"
}

@ARTICLE{Padoa-Schioppa2006-ps,
  title     = "Neurons in the orbitofrontal cortex encode economic value",
  author    = "Padoa-Schioppa, Camillo and Assad, John A",
  abstract  = "Economic choice is the behaviour observed when individuals
               select one among many available options. There is no
               intrinsically 'correct' answer: economic choice depends on
               subjective preferences. This behaviour is traditionally the
               object of economic analysis and is also of primary interest in
               psychology. However, the underlying mental processes and
               neuronal mechanisms are not well understood. Theories of human
               and animal choice have a cornerstone in the concept of 'value'.
               Consider, for example, a monkey offered one raisin versus one
               piece of apple: behavioural evidence suggests that the animal
               chooses by assigning values to the two options. But where and
               how values are represented in the brain is unclear. Here we show
               that, during economic choice, neurons in the orbitofrontal
               cortex (OFC) encode the value of offered and chosen goods.
               Notably, OFC neurons encode value independently of visuospatial
               factors and motor responses. If a monkey chooses between A and
               B, neurons in the OFC encode the value of the two goods
               independently of whether A is presented on the right and B on
               the left, or vice versa. This trait distinguishes the OFC from
               other brain areas in which value modulates activity related to
               sensory or motor processes. Our results have broad implications
               for possible psychological models, suggesting that economic
               choice is essentially choice between goods rather than choice
               between actions. In this framework, neurons in the OFC seem to
               be a good candidate network for value assignment underlying
               economic choice.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  441,
  number    =  7090,
  pages     = "223--226",
  month     =  may,
  year      =  2006,
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "16633341",
  doi       = "10.1038/nature04676",
  pmc       = "PMC2630027"
}

@ARTICLE{noauthor_undated-cn,

}

@UNPUBLISHED{Javer2018-js,
  title    = "Powerful and interpretable behavioural features for quantitative
              phenotyping of C. elegans",
  author   = "Javer, Avelino and Ripoll-Sanchez, Lidia and Brown, Andr{\'e} E X",
  abstract = "Behaviour is a sensitive and integrative readout of nervous
              system function and therefore an attractive measure for assessing
              the effects of mutation or drug treatment on animals. Video data
              provides a rich but high-dimensional representation of behaviour
              and so the first step of analysis is often some form of tracking
              and feature extraction to reduce dimensionality while maintaining
              relevant information. Modern machine learning methods are
              powerful but notoriously difficult to interpret, while
              handcrafted features are interpretable but do not always perform
              as well. Here we report a new set of handcrafted features to
              compactly quantify C. elegans behaviour. The features are
              designed to be interpretable but to capture as much of the
              phenotypic differences between worms as possible. We show that
              the full feature set is more powerful than a previously defined
              feature set in classifying mutant strains. We then use a
              combination of automated and manual feature selection to define a
              core set of interpretable features that still provides sufficient
              power to detect behavioural differences between mutant strains
              and the wild type. Finally, we apply the new features to detect
              time- resolved behavioural differences in a series of optogenetic
              experiments targeting different neural subsets.",
  journal  = "bioRxiv",
  pages    = "389023",
  month    =  aug,
  year     =  2018,
  language = "en",
  doi      = "10.1101/389023"
}

@ARTICLE{Spiro1998-pw,
  title    = "Neuroethology: a meeting of brain and behavior",
  author   = "Spiro, J E and White, S A",
  journal  = "Neuron",
  volume   =  21,
  number   =  5,
  pages    = "981--989",
  month    =  nov,
  year     =  1998,
  language = "en",
  issn     = "0896-6273",
  pmid     = "9856455",
  doi      = "10.1016/s0896-6273(00)80617-0"
}

@ARTICLE{Schacter_Daniel_L2007-rc,
  title     = "The cognitive neuroscience of constructive memory: remembering
               the past and imagining the future",
  author    = "{Schacter Daniel L} and {Addis Donna Rose}",
  journal   = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  publisher = "Royal Society",
  volume    =  362,
  number    =  1481,
  pages     = "773--786",
  month     =  may,
  year      =  2007,
  issn      = "0962-8436",
  doi       = "10.1098/rstb.2007.2087"
}

@ARTICLE{Nitz2006-mn,
  title    = "Tracking route progression in the posterior parietal cortex",
  author   = "Nitz, Douglas A",
  abstract = "Quick and efficient traversal of learned routes is critical to
              the survival of many animals. Routes can be defined by both the
              ordering of navigational epochs, such as continued forward motion
              or execution of a turn, and the distances separating them. The
              neural substrates conferring the ability to fluidly traverse
              complex routes are not well understood, but likely entail
              interactions between frontal, parietal, and rhinal cortices and
              the hippocampus. This paper demonstrates that posterior parietal
              cortical neurons map both individual and multiple navigational
              epochs with respect to their order in a route. In direct contrast
              to spatial firing patterns of hippocampal neurons, parietal
              neurons discharged in a place- and direction-independent fashion.
              Parietal route maps were scalable and versatile in that they were
              independent of the size and spatial configuration of navigational
              epochs. The results provide a framework in which to consider
              parietal function in spatial cognition.",
  journal  = "Neuron",
  volume   =  49,
  number   =  5,
  pages    = "747--756",
  month    =  mar,
  year     =  2006,
  keywords = "navigation;Spatial Navigation;Nitz",
  language = "en",
  issn     = "0896-6273",
  pmid     = "16504949",
  doi      = "10.1016/j.neuron.2006.01.037"
}

@ARTICLE{Nitz2009-vz,
  title    = "Parietal cortex, navigation, and the construction of arbitrary
              reference frames for spatial information",
  author   = "Nitz, Douglas",
  abstract = "The registration of spatial information by neurons of the
              parietal cortex takes on many forms. In most experiments,
              spatially modulated parietal activity patterns are found to take
              as their frame of reference some part of the body such as the
              retina. However, recent findings obtained in single neuron
              recordings from both rat and monkey parietal cortex suggest that
              the frame of reference utilized by parietal cortex may also be
              abstract or arbitrary in nature. Evidence in rats comes from work
              indicating that parietal activity in freely behaving rodents is
              organized according to the space defined by routes taken through
              an environment. In monkeys, evidence for an object-centered frame
              of reference has recently been presented. The present work
              reviews single neuron recording experiments in parietal cortex of
              freely behaving rats and considers the potential contribution of
              parietal cortex in solving navigational tasks. It is proposed
              that parietal cortex, in interaction with the hippocampus, plays
              a critical role in the selection of the most appropriate route
              between two points and, in addition, produces a route-based
              positional signal capable of guiding sensorimotor transitions.",
  journal  = "Neurobiol. Learn. Mem.",
  volume   =  91,
  number   =  2,
  pages    = "179--185",
  month    =  feb,
  year     =  2009,
  keywords = "navigation;Spatial Navigation;Nitz",
  language = "en",
  issn     = "1074-7427, 1095-9564",
  pmid     = "18804545",
  doi      = "10.1016/j.nlm.2008.08.007"
}

@INCOLLECTION{Nitz2014-ca,
  title     = "The Posterior Parietal Cortex: Interface Between Maps of
               External Spaces and the Generation of Action Sequences",
  booktitle = "{Space,Time} and Memory in the Hippocampal Formation",
  author    = "Nitz, Douglas A",
  editor    = "Derdikman, Dori and Knierim, James J",
  abstract  = "In primates as well as rodents, the posterior parietal cortex
               maps spatial relationships having both egocentric and external
               frames of reference. In this chapter, the form in which rat
               posterior parietal cortex neuronal activity maps position within
               trajectories through the environment is considered in detail and
               compared to the forms of spatial mapping observed for neurons of
               the hippocampus and entorhinal cortex. Evidence is presented to
               indicate that posterior parietal neurons simultaneously map
               positions both within and across segments of paths through an
               environment. It is suggested that the specific nature of
               posterior parietal cortex mapping of space serves, in part, to
               transition knowledge of position in the environment, given by
               hippocampus and entorhinal cortex, into efficient path-running
               behavior via projections to primary and secondary sensory and
               motor cortices. Posterior parietal cortex activity is also
               hypothesized to play a role both in driving trajectory
               dependence of hippocampal place cells and in anchoring spatially
               specific hippocampal and entorhinal cortical activity to the
               boundaries of the observable environment.",
  publisher = "Springer Vienna",
  pages     = "27--54",
  year      =  2014,
  address   = "Vienna",
  keywords  = "Spatial Navigation;Nitz",
  isbn      = "9783709112922",
  doi       = "10.1007/978-3-7091-1292-2\_2"
}

@ARTICLE{Skaggs1995-gd,
  title    = "A model of the neural basis of the rat's sense of direction",
  author   = "Skaggs, W E and Knierim, J J and Kudrimoti, H S and McNaughton, B
              L",
  abstract = "In the last decade the outlines of the neural structures
              subserving the sense of direction have begun to emerge. Several
              investigations have shed light on the effects of vestibular input
              and visual input on the head direction representation. In this
              paper, a model is formulated of the neural mechanisms underlying
              the head direction system. The model is built out of simple
              ingredients, depending on nothing more complicated than
              connectional specificity, attractor dynamics, Hebbian learning,
              and sigmoidal nonlinearities, but it behaves in a sophisticated
              way and is consistent with most of the observed properties of
              real head direction cells. In addition it makes a number of
              predictions that ought to be testable by reasonably
              straightforward experiments.",
  journal  = "Adv. Neural Inf. Process. Syst.",
  volume   =  7,
  pages    = "173--180",
  year     =  1995,
  keywords = "Spatial Navigation",
  language = "en",
  issn     = "1049-5258",
  pmid     = "11539168"
}

@ARTICLE{Bianco2015-sb,
  title    = "Visuomotor transformations underlying hunting behavior in
              zebrafish",
  author   = "Bianco, Isaac H and Engert, Florian",
  abstract = "Visuomotor circuits filter visual information and determine
              whether or not to engage downstream motor modules to produce
              behavioral outputs. However, the circuit mechanisms that mediate
              and link perception of salient stimuli to execution of an
              adaptive response are poorly understood. We combined a virtual
              hunting assay for tethered larval zebrafish with two-photon
              functional calcium imaging to simultaneously monitor neuronal
              activity in the optic tectum during naturalistic behavior.
              Hunting responses showed mixed selectivity for combinations of
              visual features, specifically stimulus size, speed, and contrast
              polarity. We identified a subset of tectal neurons with similar
              highly selective tuning, which show non-linear mixed selectivity
              for visual features and are likely to mediate the perceptual
              recognition of prey. By comparing neural dynamics in the optic
              tectum during response versus non-response trials, we discovered
              premotor population activity that specifically preceded
              initiation of hunting behavior and exhibited anatomical
              localization that correlated with motor variables. In summary,
              the optic tectum contains non-linear mixed selectivity neurons
              that are likely to mediate reliable detection of ethologically
              relevant sensory stimuli. Recruitment of small tectal assemblies
              appears to link perception to action by providing the premotor
              commands that release hunting responses. These findings allow us
              to propose a model circuit for the visuomotor transformations
              underlying a natural behavior.",
  journal  = "Curr. Biol.",
  volume   =  25,
  number   =  7,
  pages    = "831--846",
  month    =  mar,
  year     =  2015,
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "25754638",
  doi      = "10.1016/j.cub.2015.01.042",
  pmc      = "PMC4386024"
}

@ARTICLE{Colgin2016-ny,
  title    = "Rhythms of the hippocampal network",
  author   = "Colgin, Laura Lee",
  abstract = "The hippocampal local field potential (LFP) shows three major
              types of rhythms: theta, sharp wave-ripples and gamma. These
              rhythms are defined by their frequencies, they have behavioural
              correlates in several species including rats and humans, and they
              have been proposed to carry out distinct functions in hippocampal
              memory processing. However, recent findings have challenged
              traditional views on these behavioural functions. In this Review,
              I discuss our current understanding of the origins and the
              mnemonic functions of hippocampal theta, sharp wave-ripples and
              gamma rhythms on the basis of findings from rodent studies. In
              addition, I present an updated synthesis of their roles and
              interactions within the hippocampal network.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  17,
  number   =  4,
  pages    = "239--249",
  month    =  apr,
  year     =  2016,
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "26961163",
  doi      = "10.1038/nrn.2016.21",
  pmc      = "PMC4890574"
}

@ARTICLE{Grundemann2015-zj,
  title    = "Ensemble coding in amygdala circuits for associative learning",
  author   = "Gr{\"u}ndemann, Jan and L{\"u}thi, Andreas",
  abstract = "Associative fear learning in the basolateral amygdala (BLA) is
              crucial for an animal's survival upon environmental threats. BLA
              neurons are defined on the basis of their projection target,
              genetic markers, and associated function. BLA principal neuron
              responses to threat signaling stimuli are potentiated upon
              associative fear learning, which is tightly controlled by defined
              interneuron subpopulations. In addition, BLA population activity
              correlates with behavioral states and threat or safety signals.
              BLA neuronal ensembles activated by different behavioral signals
              can be identified using immediate early gene markers. The next
              challenge will be to determine the activity patterns and coding
              properties of defined BLA ensembles in relation to the whole
              neuronal population.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  35,
  pages    = "200--206",
  month    =  dec,
  year     =  2015,
  keywords = "Threat response;Luthi",
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "26531780",
  doi      = "10.1016/j.conb.2015.10.005"
}

@ARTICLE{Robie2017-fu,
  title    = "Mapping the Neural Substrates of Behavior",
  author   = "Robie, Alice A and Hirokawa, Jonathan and Edwards, Austin W and
              Umayam, Lowell A and Lee, Allen and Phillips, Mary L and Card,
              Gwyneth M and Korff, Wyatt and Rubin, Gerald M and Simpson, Julie
              H and Reiser, Michael B and Branson, Kristin",
  abstract = "Assigning behavioral functions to neural structures has long been
              a central goal in neuroscience and is a necessary first step
              toward a circuit-level understanding of how the brain generates
              behavior. Here, we map the neural substrates of locomotion and
              social behaviors for Drosophila melanogaster using automated
              machine-vision and machine-learning techniques. From videos of
              400,000 flies, we quantified the behavioral effects of activating
              2,204 genetically targeted populations of neurons. We combined a
              novel quantification of anatomy with our behavioral analysis to
              create brain-behavior correlation maps, which are shared as
              browsable web pages and interactive software. Based on these
              maps, we generated hypotheses of regions of the brain causally
              related to sensory processing, locomotor control, courtship,
              aggression, and sleep. Our maps directly specify genetic tools to
              target these regions, which we used to identify a small
              population of neurons with a role in the control of walking.",
  journal  = "Cell",
  volume   =  170,
  number   =  2,
  pages    = "393--406.e28",
  month    =  jul,
  year     =  2017,
  keywords = "Drosophila; behavior; computer vision; machine learning; neural
              activation; neural anatomy; neural substrates; neuroscience;
              whole-brain mapping;Analysis/Modelling [Behaviour]",
  language = "en",
  issn     = "0092-8674, 1097-4172",
  pmid     = "28709004",
  doi      = "10.1016/j.cell.2017.06.032"
}

@ARTICLE{Gris2017-ow,
  title    = "Supervised and Unsupervised Learning Technology in the Study of
              Rodent Behavior",
  author   = "Gris, Katsiaryna V and Coutu, Jean-Philippe and Gris, Denis",
  abstract = "Quantifying behavior is a challenge for scientists studying
              neuroscience, ethology, psychology, pathology, etc. Until now,
              behavior was mostly considered as qualitative descriptions of
              postures or labor intensive counting of bouts of individual
              movements. Many prominent behavioral scientists conducted studies
              describing postures of mice and rats, depicting step by step
              eating, grooming, courting, and other behaviors. Automated video
              assessment technologies permit scientists to quantify daily
              behavioral patterns/routines, social interactions, and postural
              changes in an unbiased manner. Here, we extensively reviewed
              published research on the topic of the structural blocks of
              behavior and proposed a structure of behavior based on the latest
              publications. We discuss the importance of defining a clear
              structure of behavior to allow professionals to write viable
              algorithms. We presented a discussion of technologies that are
              used in automated video assessment of behavior in mice and rats.
              We considered advantages and limitations of supervised and
              unsupervised learning. We presented the latest scientific
              discoveries that were made using automated video assessment. In
              conclusion, we proposed that the automated quantitative approach
              to evaluating animal behavior is the future of understanding the
              effect of brain signaling, pathologies, genetic content, and
              environment on behavior.",
  journal  = "Front. Behav. Neurosci.",
  volume   =  11,
  pages    = "141",
  month    =  jul,
  year     =  2017,
  keywords = "animal behavior; automatic analysis; computer learning;
              supervised; unsupervised;Analysis/Modelling [Behaviour]",
  language = "en",
  issn     = "1662-5153",
  pmid     = "28804452",
  doi      = "10.3389/fnbeh.2017.00141",
  pmc      = "PMC5532435"
}

@ARTICLE{Arber2018-kx,
  title    = "Connecting neuronal circuits for movement",
  author   = "Arber, Silvia and Costa, Rui M",
  journal  = "Science",
  volume   =  360,
  number   =  6396,
  pages    = "1403--1404",
  month    =  jun,
  year     =  2018,
  language = "en",
  issn     = "0036-8075, 1095-9203",
  pmid     = "29954969",
  doi      = "10.1126/science.aat5994"
}

@ARTICLE{Floyd2000-rj,
  title    = "Orbitomedial prefrontal cortical projections to distinct
              longitudinal columns of the periaqueductal gray in the rat",
  author   = "Floyd, N S and Price, J L and Ferry, A T and Keay, K A and
              Bandler, R",
  abstract = "We utilised retrograde and anterograde tracing procedures to
              study the origin and termination of prefrontal cortical (PFC)
              projections to the periaqueductal gray (PAG) in the rat. A
              previous study, in the primate, had demonstrated that distinct
              subgroups of PFC areas project to specific PAG columns.
              Retrograde tracing experiments revealed that projections to
              dorsolateral (dlPAG) and ventrolateral (vlPAG) periaqueductal
              gray columns arose from medial PFC, specifically prelimbic,
              infralimbic, and anterior cingulate cortices. Injections made in
              the vlPAG also labeled cells in medial, ventral, and dorsolateral
              orbital cortex and dorsal and posterior agranular insular cortex.
              Other orbital and insular regions, including lateral and
              ventrolateral orbital, ventral agranular insular, and dysgranular
              and granular insular cortex did not give rise to appreciable
              projections to the PAG. Anterograde tracing experiments revealed
              that the projections to different PAG columns arose from specific
              PFC areas. Projections from the caudodorsal medial PFC (caudal
              prelimbic and anterior cingulate cortices) terminated
              predominantly in dlPAG, whereas projections from the
              rostroventral medial PFC (rostral prelimbic cortex) innervated
              predominantly the vlPAG. As well, consistent with the retrograde
              data, projections arising from select orbital and agranular
              insular cortical areas terminated selectively in the vlPAG. The
              results indicate: (1) that rat orbital and medial PFC possesses
              an organisation broadly similar to that of the primate; and (2)
              that subdivisions within the rat orbital and medial PFC can be
              recognised on the basis of projections to distinct PAG columns.",
  journal  = "J. Comp. Neurol.",
  volume   =  422,
  number   =  4,
  pages    = "556--578",
  month    =  jul,
  year     =  2000,
  keywords = "Threat response",
  language = "en",
  issn     = "0021-9967",
  pmid     = "10861526"
}

@ARTICLE{Dunn2016-zt,
  title    = "Neural Circuits Underlying Visually Evoked Escapes in Larval
              Zebrafish",
  author   = "Dunn, Timothy W and Gebhardt, Christoph and Naumann, Eva A and
              Riegler, Clemens and Ahrens, Misha B and Engert, Florian and Del
              Bene, Filippo",
  abstract = "Escape behaviors deliver organisms away from imminent
              catastrophe. Here, we characterize behavioral responses of freely
              swimming larval zebrafish to looming visual stimuli simulating
              predators. We report that the visual system alone can recruit
              lateralized, rapid escape motor programs, similar to those
              elicited by mechanosensory modalities. Two-photon calcium imaging
              of retino-recipient midbrain regions isolated the optic tectum as
              an important center processing looming stimuli, with ensemble
              activity encoding the critical image size determining escape
              latency. Furthermore, we describe activity in retinal ganglion
              cell terminals and superficial inhibitory interneurons in the
              tectum during looming and propose a model for how temporal
              dynamics in tectal periventricular neurons might arise from
              computations between these two fundamental constituents. Finally,
              laser ablations of hindbrain circuitry confirmed that visual and
              mechanosensory modalities share the same premotor output network.
              We establish a circuit for the processing of aversive stimuli in
              the context of an innate visual behavior.",
  journal  = "Neuron",
  volume   =  89,
  number   =  3,
  pages    = "613--628",
  month    =  feb,
  year     =  2016,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "26804997",
  doi      = "10.1016/j.neuron.2015.12.021",
  pmc      = "PMC4742414"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Mimica2018-ls,
  title     = "Efficient cortical coding of {3D} posture in freely behaving
               rats",
  author    = "Mimica, B and Dunn, B A and Tombaz, T and Bojja, V S and
               Whitlock, J R",
  abstract  = "In order to meet physical and behavioural demands of their
               environments animals constantly update their body posture, but
               little is known about the neural signals on which this ability
               depends. To better understand the role of cortex in coordinating
               natural pose and movement, we tracked the heads and backs of
               freely foraging rats in 3D while recording simultaneously from
               posterior parietal cortex (PPC) and frontal motor cortex (M2),
               areas critical for spatial movement planning and navigation.
               Single units in both regions were …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2018,
  keywords  = "Spatial Navigation;Analysis/Modelling [Behaviour]"
}

@ARTICLE{Severi2014-ox,
  title    = "Neural control and modulation of swimming speed in the larval
              zebrafish",
  author   = "Severi, Kristen E and Portugues, Ruben and Marques, Jo{\~a}o C
              and O'Malley, Donald M and Orger, Michael B and Engert, Florian",
  abstract = "Vertebrate locomotion at different speeds is driven by descending
              excitatory connections to central pattern generators in the
              spinal cord. To investigate how these inputs determine locomotor
              kinematics, we used whole-field visual motion to drive zebrafish
              to swim at different speeds. Larvae match the stimulus speed by
              utilizing more locomotor events, or modifying kinematic
              parameters such as the duration and speed of swimming bouts, the
              tail-beat frequency, and the choice of gait. We used laser
              ablations, electrical stimulation, and activity recordings in
              descending neurons of the nucleus of the medial longitudinal
              fasciculus (nMLF) to dissect their contribution to controlling
              forward movement. We found that the activity of single identified
              neurons within the nMLF is correlated with locomotor kinematics,
              and modulates both the duration and oscillation frequency of tail
              movements. By identifying the contribution of individual
              supraspinal circuit elements to locomotion kinematics, we build a
              better understanding of how the brain controls movement.",
  journal  = "Neuron",
  volume   =  83,
  number   =  3,
  pages    = "692--707",
  month    =  aug,
  year     =  2014,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "25066084",
  doi      = "10.1016/j.neuron.2014.06.032",
  pmc      = "PMC4126853"
}

@ARTICLE{Berman2018-xu,
  title    = "Measuring behavior across scales",
  author   = "Berman, Gordon J",
  abstract = "The need for high-throughput, precise, and meaningful methods for
              measuring behavior has been amplified by our recent successes in
              measuring and manipulating neural circuitry. The largest
              challenges associated with moving in this direction, however, are
              not technical but are instead conceptual: what numbers should one
              put on the movements an animal is performing (or not performing)?
              In this review, I will describe how theoretical and data
              analytical ideas are interfacing with recently-developed
              computational and experimental methodologies to answer these
              questions across a variety of contexts, length scales, and time
              scales. I will attempt to highlight commonalities between
              approaches and areas where further advances are necessary to
              place behavior on the same quantitative footing as other
              scientific fields.",
  journal  = "BMC Biol.",
  volume   =  16,
  number   =  1,
  pages    = "23",
  month    =  feb,
  year     =  2018,
  keywords = "Berman;Analysis/Modelling [Behaviour]",
  language = "en",
  issn     = "1741-7007",
  pmid     = "29475451",
  doi      = "10.1186/s12915-018-0494-7",
  pmc      = "PMC5824583"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Patai2018-io,
  title     = "Neural signatures of detours, shortcuts and back-tracking during
               navigation",
  author    = "Patai, E Z and Javadi, A H and Margois, A and Tan, H R and
               Kumaran, D and {others}",
  abstract  = "Central to the concept of the 9cognitive map9 is that it confers
               flexibility in behaviour allowing animals to take efficient
               detours, exploit shortcuts and realise when they need to
               back-track rather than continue on a poorly chosen route.
               Currently the neural underpinnings of such behaviour remains
               unclear. During fMRI we tested human subjects on their ability
               to navigate to a set of goal locations in a virtual desert
               island riven by lava, which occasionally shifted to block
               selected paths (necessitating detours) or receded to …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2018,
  keywords  = "navigation;Spatial Navigation"
}

@ARTICLE{Alexander2017-ho,
  title    = "Spatially Periodic Activation Patterns of Retrosplenial Cortex
              Encode Route Sub-spaces and Distance Traveled",
  author   = "Alexander, Andrew S and Nitz, Douglas A",
  abstract = "Traversal of a complicated route is often facilitated by
              considering it as a set of related sub-spaces. Such
              compartmentalization processes could occur within retrosplenial
              cortex, a structure whose neurons simultaneously encode position
              within routes and other spatial coordinate systems. Here,
              retrosplenial cortex neurons were recorded as rats traversed a
              track having recurrent structure at multiple scales. Consistent
              with a major role in compartmentalization of complex routes,
              individual retrosplenial cortex (RSC) neurons exhibited periodic
              activation patterns that repeated across route segments having
              the same shape. Concurrently, a larger population of RSC neurons
              exhibited single-cycle periodicity over the full route,
              effectively defining a framework for encoding of sub-route
              positions relative to the whole. The same population
              simultaneously provides a novel metric for distance from each
              route position to all others. Together, the findings implicate
              retrosplenial cortex in the extraction of path sub-spaces, the
              encoding of their spatial relationships to each other, and path
              integration.",
  journal  = "Curr. Biol.",
  volume   =  27,
  number   =  11,
  pages    = "1551--1560.e4",
  month    =  jun,
  year     =  2017,
  keywords = "distance; fragmentation; hippocampus; path integration;
              periodicity; retrosplenial cortex; spatial navigation; spatial
              representation; sub-route; sub-space;Spatial Navigation;Nitz",
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "28528904",
  doi      = "10.1016/j.cub.2017.04.036"
}

@ARTICLE{Behrens_undated-kg,
  title    = "What is a cognitive map? Organising knowledge for flexible
              behaviour",
  author   = "Behrens, Timothy E J and Muller, Timothy H and Whittington, James
              C R and Mark, Shirley and Baram, Alon B and Stachenfeld,
              Kimberley L and Kurth-Nelson, Zeb",
  abstract = "It is proposed that a cognitive map encoding the relationships
              between entities in the world supports flexible behaviour, but
              the majority of the neural evidence for such a system comes from
              studies of spatial navigation. Recent work describing neuronal
              parallels between spatial and non-spatial behaviours has
              rekindled the notion of a systematic organisation of knowledge
              across multiple domains. We review experimental evidence and
              theoretical frameworks that point to principles unifying these
              apparently disparate functions. These principles describe how to
              learn and use abstract, generalisable knowledge and suggest
              map-like representations observed in a spatial context may be an
              instance of general coding mechanisms capable of organising
              knowledge of all kinds. We highlight how artificial agents
              endowed with such principles exhibit flexible behaviour and learn
              map-like representations observed in the brain. Finally, we
              speculate on how these principles may offer insight into the
              extreme generalisations, abstractions and inferences that
              characterise human cognition.",
  journal  = "Biorxiv",
  keywords = "Spatial Navigation",
  doi      = "10.1101/365593"
}

@ARTICLE{Tovote2015-ds,
  title    = "Neuronal circuits for fear and anxiety",
  author   = "Tovote, Philip and Fadok, Jonathan Paul and L{\"u}thi, Andreas",
  abstract = "Decades of research has identified the brain areas that are
              involved in fear, fear extinction, anxiety and related defensive
              behaviours. Newly developed genetic and viral tools, optogenetics
              and advanced in vivo imaging techniques have now made it possible
              to characterize the activity, connectivity and function of
              specific cell types within complex neuronal circuits. Recent
              findings that have been made using these tools and techniques
              have provided mechanistic insights into the exquisite
              organization of the circuitry underlying internal defensive
              states. This Review focuses on studies that have used
              circuit-based approaches to gain a more detailed, and also more
              comprehensive and integrated, view on how the brain governs fear
              and anxiety and how it orchestrates adaptive defensive
              behaviours.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  16,
  number   =  6,
  pages    = "317--331",
  month    =  jun,
  year     =  2015,
  keywords = "Threat response",
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "25991441",
  doi      = "10.1038/nrn3945"
}

@ARTICLE{Bassett2018-ni,
  title    = "On the nature and use of models in network neuroscience",
  author   = "Bassett, Danielle S and Zurn, Perry and Gold, Joshua I",
  abstract = "Network theory provides an intuitively appealing framework for
              studying relationships among interconnected brain mechanisms and
              their relevance to behaviour. As the space of its applications
              grows, so does the diversity of meanings of the term network
              model. This diversity can cause confusion, complicate efforts to
              assess model validity and efficacy, and hamper interdisciplinary
              collaboration. In this Review, we examine the field of network
              neuroscience, focusing on organizing principles that can help
              overcome these challenges. First, we describe the fundamental
              goals in constructing network models. Second, we review the most
              common forms of network models, which can be described
              parsimoniously along the following three primary dimensions: from
              data representations to first-principles theory; from biophysical
              realism to functional phenomenology; and from elementary
              descriptions to coarse-grained approximations. Third, we draw on
              biology, philosophy and other disciplines to establish validation
              principles for these models. We close with a discussion of
              opportunities to bridge model types and point to exciting
              frontiers for future pursuits.",
  journal  = "Nat. Rev. Neurosci.",
  month    =  jul,
  year     =  2018,
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "30002509",
  doi      = "10.1038/s41583-018-0038-8"
}

@ARTICLE{Klibaite2017-kd,
  title    = "An unsupervised method for quantifying the behavior of paired
              animals",
  author   = "Klibaite, Ugne and Berman, Gordon J and Cande, Jessica and Stern,
              David L and Shaevitz, Joshua W",
  abstract = "Behaviors involving the interaction of multiple individuals are
              complex and frequently crucial for an animal's survival. These
              interactions, ranging across sensory modalities, length scales,
              and time scales, are often subtle and difficult to characterize.
              Contextual effects on the frequency of behaviors become even more
              difficult to quantify when physical interaction between animals
              interferes with conventional data analysis, e.g. due to visual
              occlusion. We introduce a method for quantifying behavior in
              fruit fly interaction that combines high-throughput video
              acquisition and tracking of individuals with recent unsupervised
              methods for capturing an animal's entire behavioral repertoire.
              We find behavioral differences between solitary flies and those
              paired with an individual of the opposite sex, identifying
              specific behaviors that are affected by social and spatial
              context. Our pipeline allows for a comprehensive description of
              the interaction between two individuals using unsupervised
              machine learning methods, and will be used to answer questions
              about the depth of complexity and variance in fruit fly
              courtship.",
  journal  = "Phys. Biol.",
  volume   =  14,
  number   =  1,
  pages    = "015006",
  month    =  feb,
  year     =  2017,
  keywords = "Berman;Analysis/Modelling [Behaviour]",
  language = "en",
  issn     = "1478-3967, 1478-3975",
  pmid     = "28140374",
  doi      = "10.1088/1478-3975/aa5c50",
  pmc      = "PMC5414632"
}

@ARTICLE{Berman2014-pw,
  title    = "Mapping the stereotyped behaviour of freely moving fruit flies",
  author   = "Berman, Gordon J and Choi, Daniel M and Bialek, William and
              Shaevitz, Joshua W",
  abstract = "A frequent assumption in behavioural science is that most of an
              animal's activities can be described in terms of a small set of
              stereotyped motifs. Here, we introduce a method for mapping an
              animal's actions, relying only upon the underlying structure of
              postural movement data to organize and classify behaviours.
              Applying this method to the ground-based behaviour of the fruit
              fly, Drosophila melanogaster, we find that flies perform
              stereotyped actions roughly 50\% of the time, discovering over
              100 distinguishable, stereotyped behavioural states. These
              include multiple modes of locomotion and grooming. We use the
              resulting measurements as the basis for identifying subtle
              sex-specific behavioural differences and revealing the
              low-dimensional nature of animal motions.",
  journal  = "J. R. Soc. Interface",
  volume   =  11,
  number   =  99,
  month    =  oct,
  year     =  2014,
  keywords = "Drosophila; behaviour; phase reconstruction; stereotypy;
              unsupervised learning;Berman;Analysis/Modelling [Behaviour]",
  language = "en",
  issn     = "1742-5689, 1742-5662",
  pmid     = "25142523",
  doi      = "10.1098/rsif.2014.0672",
  pmc      = "PMC4233753"
}

@ARTICLE{Berman2016-it,
  title    = "Predictability and hierarchy in Drosophila behavior",
  author   = "Berman, Gordon J and Bialek, William and Shaevitz, Joshua W",
  abstract = "Even the simplest of animals exhibit behavioral sequences with
              complex temporal dynamics. Prominent among the proposed
              organizing principles for these dynamics has been the idea of a
              hierarchy, wherein the movements an animal makes can be
              understood as a set of nested subclusters. Although this type of
              organization holds potential advantages in terms of motion
              control and neural circuitry, measurements demonstrating this for
              an animal's entire behavioral repertoire have been limited in
              scope and temporal complexity. Here, we use a recently developed
              unsupervised technique to discover and track the occurrence of
              all stereotyped behaviors performed by fruit flies moving in a
              shallow arena. Calculating the optimally predictive
              representation of the fly's future behaviors, we show that fly
              behavior exhibits multiple time scales and is organized into a
              hierarchical structure that is indicative of its underlying
              behavioral programs and its changing internal states.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  113,
  number   =  42,
  pages    = "11943--11948",
  month    =  oct,
  year     =  2016,
  keywords = "Drosophila; behavior; hierarchy; information bottleneck;Berman",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "27702892",
  doi      = "10.1073/pnas.1607601113",
  pmc      = "PMC5081631"
}

@ARTICLE{Djurdjevic2018-yn,
  title    = "Accuracy of Rats in Discriminating Visual Objects Is Explained by
              the Complexity of Their Perceptual Strategy",
  author   = "Djurdjevic, Vladimir and Ansuini, Alessio and Bertolini, Daniele
              and Macke, Jakob H and Zoccolan, Davide",
  abstract = "Despite their growing popularity as models of visual functions,
              it remains unclear whether rodents are capable of deploying
              advanced shape-processing strategies when engaged in visual
              object recognition. In rats, for instance, pattern vision has
              been reported to range from mere detection of overall object
              luminance to view-invariant processing of discriminative shape
              features. Here we sought to clarify how refined object vision is
              in rodents, and how variable the complexity of their visual
              processing strategy is across individuals. To this aim, we
              measured how well rats could discriminate a reference object from
              11 distractors, which spanned a spectrum of image-level
              similarity to the reference. We also presented the animals with
              random variations of the reference, and processed their responses
              to these stimuli to derive subject-specific models of rat
              perceptual choices. Our models successfully captured the highly
              variable discrimination performance observed across subjects and
              object conditions. In particular, they revealed that the animals
              that succeeded with the most challenging distractors were those
              that integrated the wider variety of discriminative features into
              their perceptual strategies. Critically, these strategies were
              largely preserved when the rats were required to discriminate
              outlined and scaled versions of the stimuli, thus showing that
              rat object vision can be characterized as a
              transformation-tolerant, feature-based filtering process.
              Overall, these findings indicate that rats are capable of
              advanced processing of shape information, and point to the
              rodents as powerful models for investigating the neuronal
              underpinnings of visual object recognition and other high-level
              visual functions.",
  journal  = "Curr. Biol.",
  volume   =  28,
  number   =  7,
  pages    = "1005--1015.e5",
  month    =  apr,
  year     =  2018,
  keywords = "classification; filtering; image; object; perception; processing;
              recognition; rodent; shape; vision",
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "29551414",
  doi      = "10.1016/j.cub.2018.02.037",
  pmc      = "PMC5887110"
}

@ARTICLE{Sweis2018-sg,
  title     = "Sensitivity to ``sunk costs'' in mice, rats, and humans",
  author    = "Sweis, Brian M and Abram, Samantha V and Schmidt, Brandy J and
               Seeland, Kelsey D and MacDonald, Angus W and Thomas, Mark J and
               David Redish, A",
  abstract  = "Sunk costs are irrecoverable investments that should not
               influence decisions, because decisions should be made on the
               basis of expected future consequences. Both human and nonhuman
               animals can show sensitivity to sunk costs, but reports from
               across species are inconsistent. In a temporal context, a
               sensitivity to sunk costs arises when an individual resists
               ending an activity, even if it seems unproductive, because of
               the time already invested. In two parallel foraging tasks that
               we designed, we found that mice, rats, and humans show similar
               sensitivities to sunk costs in their decision-making.
               Unexpectedly, sensitivity to time invested accrued only after an
               initial decision had been made. These findings suggest that
               sensitivity to temporal sunk costs lies in a vulnerability
               distinct from deliberation processes and that this distinction
               is present across species.",
  journal   = "Science",
  publisher = "American Association for the Advancement of Science",
  volume    =  361,
  number    =  6398,
  pages     = "178--181",
  month     =  jul,
  year      =  2018,
  keywords  = "Decision Making",
  language  = "en",
  issn      = "0036-8075, 1095-9203",
  pmid      = "30002252",
  doi       = "10.1126/science.aar8644"
}

@ARTICLE{OConnell2018-st,
  title    = "Bridging Neural and Computational Viewpoints on Perceptual
              {Decision-Making}",
  author   = "O'Connell, Redmond G and Shadlen, Michael N and Wong-Lin,
              Kongfatt and Kelly, Simon P",
  abstract = "Sequential sampling models have provided a dominant theoretical
              framework guiding computational and neurophysiological
              investigations of perceptual decision-making. While these models
              share the basic principle that decisions are formed by
              accumulating sensory evidence to a bound, they come in many forms
              that can make similar predictions of choice behaviour despite
              invoking fundamentally different mechanisms. The identification
              of neural signals that reflect some of the core computations
              underpinning decision formation offers new avenues for
              empirically testing and refining key model assumptions. Here, we
              highlight recent efforts to explore these avenues and, in so
              doing, consider the conceptual and methodological challenges that
              arise when seeking to infer decision computations from complex
              neural data.",
  journal  = "Trends Neurosci.",
  month    =  jul,
  year     =  2018,
  keywords = "computational modelling; lateral intraparietal area (LIP);
              perceptual decision-making; sequential sampling;Decision Making",
  language = "en",
  issn     = "0166-2236, 1878-108X",
  pmid     = "30007746",
  doi      = "10.1016/j.tins.2018.06.005"
}

@UNPUBLISHED{Torok2018-fl,
  title    = "A novel virtual plus-maze for studying electrophysiological
              correlates of spatial reorientation",
  author   = "Torok, Agoston and Kobor, Andrea and Honbolygo, Ferenc and Baker,
              Travis",
  abstract = "Quick reorientation is an essential part of successful
              navigation. Despite growing attention to this ability, little is
              known about how reorientation happens in humans. To this aim, we
              recorded EEG from 34 participants. Participants were navigating a
              simple virtual reality plus-maze where at the beginning of each
              trial they were randomly teleported to either the North or the
              South alley. Results show that the teleportation event caused a
              quick reorientation effect over occipito-parietal areas as early
              as 100 msec; meaning that despite the known stochastic nature of
              the teleportation, participants built up expectations for their
              place of arrival. This result has important consequences for the
              optimal design of virtual reality locomotion.",
  journal  = "bioRxiv",
  pages    = "369207",
  month    =  jul,
  year     =  2018,
  keywords = "Spatial Navigation",
  language = "en",
  doi      = "10.1101/369207"
}

@ARTICLE{Stringer2048-xi,
  title    = "High-dimensional geometry of population responses in visual
              cortex",
  author   = "Stringer, C and Pachitariu, M and Steinmetz, N and Carandini, M
              and Harris, K",
  abstract = "A neuronal population encodes information most efficiently when
              its activity is uncorrelated and high-dimensional, but cor-
              related lower-dimensional codes provide robustness against noise.
              Here, we analyzed the correlation structure of natural image
              coding, in large visual cortical populations recorded from awake
              mice. Evoked population activity was high dimen- sional, with
              correlations obeying an unexpected power-law: the nth principal
              component variance scaled as 1/n. This was not inherited from the
              1/f spectrum of natural images, because it persisted after
              stimulus whitening. We proved mathemat- ically that the variance
              spectrum must decay at least this fast if a population code is
              smooth, i.e. if small changes in input cannot dominate population
              activity. The theory also predicted larger power-law exponents
              for lower-dimensional stimu- lus ensembles, which we validated
              experimentally. These results suggest that coding smoothness
              represents a fundamental constraint governing correlations in
              neural population codes.",
  journal  = "bioRxiv",
  pages    = "374090",
  month    =  jul,
  year     =  2048,
  keywords = "Authors;Harris/Carandini",
  language = "en",
  doi      = "10.1101/374090"
}

@ARTICLE{Tovote2016-of,
  title    = "Midbrain circuits for defensive behaviour",
  author   = "Tovote, Philip and Esposito, Maria Soledad and Botta, Paolo and
              Chaudun, Fabrice and Fadok, Jonathan P and Markovic, Milica and
              Wolff, Steffen B E and Ramakrishnan, Charu and Fenno, Lief and
              Deisseroth, Karl and Herry, Cyril and Arber, Silvia and
              L{\"u}thi, Andreas",
  abstract = "Survival in threatening situations depends on the selection and
              rapid execution of an appropriate active or passive defensive
              response, yet the underlying brain circuitry is not understood.
              Here we use circuit-based optogenetic, in vivo and in vitro
              electrophysiological, and neuroanatomical tracing methods to
              define midbrain periaqueductal grey circuits for specific
              defensive behaviours. We identify an inhibitory pathway from the
              central nucleus of the amygdala to the ventrolateral
              periaqueductal grey that produces freezing by disinhibition of
              ventrolateral periaqueductal grey excitatory outputs to pre-motor
              targets in the magnocellular nucleus of the medulla. In addition,
              we provide evidence for anatomical and functional interaction of
              this freezing pathway with long-range and local circuits
              mediating flight. Our data define the neuronal circuitry
              underlying the execution of freezing, an evolutionarily conserved
              defensive behaviour, which is expressed by many species including
              fish, rodents and primates. In humans, dysregulation of this
              'survival circuit' has been implicated in anxiety-related
              disorders.",
  journal  = "Nature",
  volume   =  534,
  number   =  7606,
  pages    = "206--212",
  month    =  jun,
  year     =  2016,
  keywords = "Threat response",
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "27279213",
  doi      = "10.1038/nature17996"
}

@ARTICLE{Romero-Ferrero2018-dh,
  title    = "idtracker.ai: Tracking all individuals in large collectives of
              unmarked animals",
  author   = "Romero-Ferrero, F and Bergomi, M and Hinz, Robert and Heras, F
              and de Polavieja, G",
  journal  = "bioRxiv",
  month    =  mar,
  year     =  2018,
  keywords = "Analysis/Modelling [Behaviour]",
  doi      = "10.1101/280735"
}

@ARTICLE{Luo2018-cf,
  title    = "A dopaminergic switch for fear to safety transitions",
  author   = "Luo, Ray and Uematsu, Akira and Weitemier, Adam and Aquili, Luca
              and Koivumaa, Jenny and McHugh, Thomas J and Johansen, Joshua P",
  abstract = "Overcoming aversive emotional memories requires neural systems
              that detect when fear responses are no longer appropriate so that
              they can be extinguished. The midbrain ventral tegmental area
              (VTA) dopamine system has been implicated in reward and more
              broadly in signaling when a better-than-expected outcome has
              occurred. This suggests that it may be important in guiding fear
              to safety transitions. We report that when an expected aversive
              outcome does not occur, activity in midbrain dopamine neurons is
              necessary to extinguish behavioral fear responses and engage
              molecular signaling events in extinction learning circuits.
              Furthermore, a specific dopamine projection to the nucleus
              accumbens medial shell is partially responsible for this effect.
              In contrast, a separate dopamine projection to the medial
              prefrontal cortex opposes extinction learning. This demonstrates
              a novel function for the canonical VTA-dopamine reward system and
              reveals opposing behavioral roles for different dopamine neuron
              projections in fear extinction learning.",
  journal  = "Nat. Commun.",
  volume   =  9,
  number   =  1,
  pages    = "2483",
  month    =  jun,
  year     =  2018,
  keywords = "Threat response",
  language = "en",
  issn     = "2041-1723",
  pmid     = "29950562",
  doi      = "10.1038/s41467-018-04784-7",
  pmc      = "PMC6021378"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Horndli2018-ja,
  title     = "Machine Learning Reveals Modules of Economic Behavior from
               Foraging Mice",
  author    = "Horndli, C N S and Wong, E and Ferris, E and Rhodes, A N and
               {others}",
  abstract  = "The mechanisms shaping most ethological behavior patterns are
               elusive because we do not understand how complex patterns are
               constructed. Here, we develop a behavioral paradigm and data
               analysis methods to dissect foraging patterns in mice. We
               uncover discrete behavioral modules linked to round trip
               excursions from the home. Using machine learning, 59 modules are
               revealed across different genetic backgrounds and ages.
               Different modules develop at different ages and are linked to
               different aspects of economic behavior, including …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2018,
  keywords  = "Analysis/Modelling [Behaviour]"
}

@ARTICLE{Gauthier2018-db,
  title    = "A Dedicated Population for Reward Coding in the Hippocampus",
  author   = "Gauthier, Jeffrey L and Tank, David W",
  abstract = "The hippocampus plays a critical role in goal-directed
              navigation. Across different environments, however, hippocampal
              maps are randomized, making it unclear how goal locations could
              be encoded consistently. To address this question, we developed a
              virtual reality task with shifting reward contingencies to
              distinguish place versus reward encoding. In mice performing the
              task, large-scale recordings in CA1 and subiculum revealed a
              small, specialized cell population that was only active near
              reward yet whose activity could not be explained by sensory cues
              or stereotyped reward anticipation behavior. Across different
              virtual environments, most cells remapped randomly, but reward
              encoding consistently arose from a single pool of cells,
              suggesting that they formed a dedicated channel for reward. These
              observations represent a significant departure from the current
              understanding of CA1 as a relatively homogeneous ensemble without
              fixed coding properties and provide a new candidate for the
              cellular basis of goal memory in the hippocampus.",
  journal  = "Neuron",
  volume   =  99,
  number   =  1,
  pages    = "179--193.e7",
  month    =  jul,
  year     =  2018,
  keywords = "CA1; hippocampus; navigation; place cells; place fields; reward;
              subiculum; virtual reality;Spatial Navigation",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "30008297",
  doi      = "10.1016/j.neuron.2018.06.008"
}

@ARTICLE{Grieves2017-ay,
  title     = "The representation of space in the brain",
  author    = "Grieves, Roddy M and Jeffery, Kate J",
  journal   = "Behav. Processes",
  publisher = "Elsevier",
  volume    =  135,
  pages     = "113--131",
  year      =  2017,
  keywords  = "Spatial Navigation",
  issn      = "0376-6357"
}

@ARTICLE{Ainge2007-ue,
  title    = "Hippocampal {CA1} place cells encode intended destination on a
              maze with multiple choice points",
  author   = "Ainge, James A and Tamosiunaite, Minija and Woergoetter,
              Florentin and Dudchenko, Paul A",
  abstract = "The hippocampus encodes both spatial and nonspatial aspects of a
              rat's ongoing behavior at the single-cell level. In this study,
              we examined the encoding of intended destination by hippocampal
              (CA1) place cells during performance of a serial reversal task on
              a double Y-maze. On the maze, rats had to make two choices to
              access one of four possible goal locations, two of which
              contained reward. Reward locations were kept constant within
              blocks of 10 trials but changed between blocks, and the session
              of each day comprised three or more trial blocks. A
              disproportionate number of place fields were observed in the
              start box and beginning stem of the maze, relative to other
              locations on the maze. Forty-six percent of these place fields
              had different firing rates on journeys to different goal boxes.
              Another group of cells had place fields before the second choice
              point, and, of these, 44\% differentiated between journeys to
              specific goal boxes. In a second experiment, we observed that
              rats with hippocampal damage made significantly more errors than
              control rats on the Y-maze when reward locations were reversed.
              Together, these results suggest that, at the start of the maze,
              the hippocampus encodes both current location and the intended
              destination of the rat, and this encoding is necessary for the
              flexible response to changes in reinforcement contingencies.",
  journal  = "J. Neurosci.",
  volume   =  27,
  number   =  36,
  pages    = "9769--9779",
  month    =  sep,
  year     =  2007,
  keywords = "Spatial Navigation;Decision Making",
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "17804637",
  doi      = "10.1523/JNEUROSCI.2011-07.2007"
}

@ARTICLE{Mathis2018-uu,
  title         = "Markerless tracking of user-defined features with deep
                   learning",
  author        = "Mathis, Alexander and Mamidanna, Pranav and Abe, Taiga and
                   Cury, Kevin M and Murthy, Venkatesh N and Mathis, Mackenzie
                   W and Bethge, Matthias",
  abstract      = "Quantifying behavior is crucial for many applications in
                   neuroscience. Videography provides easy methods for the
                   observation and recording of animal behavior in diverse
                   settings, yet extracting particular aspects of a behavior
                   for further analysis can be highly time consuming. In motor
                   control studies, humans or other animals are often marked
                   with reflective markers to assist with computer-based
                   tracking, yet markers are intrusive (especially for smaller
                   animals), and the number and location of the markers must be
                   determined a priori. Here, we present a highly efficient
                   method for markerless tracking based on transfer learning
                   with deep neural networks that achieves excellent results
                   with minimal training data. We demonstrate the versatility
                   of this framework by tracking various body parts in a broad
                   collection of experimental settings: mice odor
                   trail-tracking, egg-laying behavior in drosophila, and mouse
                   hand articulation in a skilled forelimb task. For example,
                   during the skilled reaching behavior, individual joints can
                   be automatically tracked (and a confidence score is
                   reported). Remarkably, even when a small number of frames
                   are labeled ($\approx 200$), the algorithm achieves
                   excellent tracking performance on test frames that is
                   comparable to human accuracy.",
  month         =  apr,
  year          =  2018,
  keywords      = "Analysis/Modelling [Behaviour]",
  archivePrefix = "arXiv",
  eprint        = "1804.03142",
  primaryClass  = "cs.CV",
  arxivid       = "1804.03142"
}

@UNPUBLISHED{Brown2018-bm,
  title    = "Ethology as a physical science",
  author   = "Brown, Andre E X and de Bivort, Benjamin",
  abstract = "Behaviour is the ultimate output of an animal9s nervous system
              and choosing the right action at the right time can be critical
              for survival. The study of the organisation of behaviour in its
              natural context, ethology, has historically been a primarily
              qualitative science. A quantitative theory of behaviour would
              advance research in neuroscience as well as ecology and
              evolution. However, animal posture typically has many degrees of
              freedom and behavioural dynamics vary on timescales ranging from
              milliseconds to years, presenting both technical and conceptual
              challenges. Here we review 1) advances in imaging and computer
              vision that are making it possible to capture increasingly
              complete records of animal motion and 2) new approaches to
              understanding the resulting behavioural data sets. With the right
              analytical approaches, these data are allowing researchers to
              revisit longstanding questions about the structure and
              organisation of animal behaviour and to put unifying principles
              on a quantitative footing. Contributions from both
              experimentalists and theorists are leading to the emergence of a
              physics of behaviour and the prospect of discovering laws and
              developing theories with broad applicability. We believe that
              there now exists an opportunity to develop theories of behaviour
              which can be tested using these data sets leading to a deeper
              understanding of how and why animals behave.",
  journal  = "bioRxiv",
  pages    = "220855",
  month    =  feb,
  year     =  2018,
  keywords = "Analysis/Modelling [Behaviour]",
  language = "en",
  doi      = "10.1101/220855"
}

@ARTICLE{Branco2010-cb,
  title     = "Dendritic discrimination of temporal input sequences in cortical
               neurons",
  author    = "Branco, Tiago and Clark, Beverley A and H{\"a}usser, Michael",
  abstract  = "The detection and discrimination of temporal sequences is
               fundamental to brain function and underlies perception,
               cognition, and motor output. By applying patterned, two-photon
               glutamate uncaging, we found that single dendrites of cortical
               pyramidal neurons exhibit sensitivity to the sequence of
               synaptic activation. This sensitivity is encoded by both local
               dendritic calcium signals and somatic depolarization, leading to
               sequence-selective spike output. The mechanism involves
               dendritic impedance gradients and nonlinear synaptic
               N-methyl-D-aspartate receptor activation and is generalizable to
               dendrites in different neuronal types. This enables
               discrimination of patterns delivered to a single dendrite, as
               well as patterns distributed randomly across the dendritic tree.
               Pyramidal cell dendrites can thus act as processing compartments
               for the detection of synaptic sequences, thereby implementing a
               fundamental cortical computation.",
  journal   = "Science",
  publisher = "science.sciencemag.org",
  volume    =  329,
  number    =  5999,
  pages     = "1671--1675",
  month     =  sep,
  year      =  2010,
  language  = "en",
  issn      = "0036-8075, 1095-9203",
  pmid      = "20705816",
  doi       = "10.1126/science.1189664"
}

@ARTICLE{Evans2018-rs,
  title     = "A synaptic threshold mechanism for computing escape decisions",
  author    = "Evans, Dominic A and Stempel, A Vanessa and Vale, Ruben and
               Ruehle, Sabine and Lefler, Yaara and Branco, Tiago",
  abstract  = "Escaping from imminent danger is an instinctive behaviour that
               is fundamental for survival, and requires the classification of
               sensory stimuli as harmless or threatening. The absence of
               threat enables animals to forage for essential resources, but as
               the level of threat and potential for harm increases, they have
               to decide whether or not to seek safety 1 . Despite previous
               work on instinctive defensive behaviours in rodents2-11, little
               is known about how the brain computes the threat level for
               initiating escape. Here we show that the probability and vigour
               of escape in mice scale with the saliency of innate threats, and
               are well described by a model that computes the distance between
               the threat level and an escape threshold. Calcium imaging and
               optogenetics in the midbrain of freely behaving mice show that
               the activity of excitatory neurons in the deep layers of the
               medial superior colliculus (mSC) represents the saliency of the
               threat stimulus and is predictive of escape, whereas
               glutamatergic neurons of the dorsal periaqueductal grey (dPAG)
               encode exclusively the choice to escape and control escape
               vigour. We demonstrate a feed-forward monosynaptic excitatory
               connection from mSC to dPAG neurons, which is weak and
               unreliable-yet required for escape behaviour-and provides a
               synaptic threshold for dPAG activation and the initiation of
               escape. This threshold can be overcome by high mSC network
               activity because of short-term synaptic facilitation and
               recurrent excitation within the mSC, which amplifies and
               sustains synaptic drive to the dPAG. Therefore, dPAG
               glutamatergic neurons compute escape decisions and escape vigour
               using a synaptic mechanism to threshold threat information
               received from the mSC, and provide a biophysical model of how
               the brain performs a critical behavioural computation.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  558,
  number    =  7711,
  pages     = "590--594",
  month     =  jun,
  year      =  2018,
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "29925954",
  doi       = "10.1038/s41586-018-0244-6"
}

@ARTICLE{Vale2017-cv,
  title     = "Rapid Spatial Learning Controls Instinctive Defensive Behavior
               in Mice",
  author    = "Vale, Ruben and Evans, Dominic A and Branco, Tiago",
  abstract  = "Instinctive defensive behaviors are essential for animal
               survival. Across the animal kingdom, there are sensory stimuli
               that innately represent threat and trigger stereotyped behaviors
               such as escape or freezing [1-4]. While innate behaviors are
               considered to be hard-wired stimulus-responses [5], they act
               within dynamic environments, and factors such as the properties
               of the threat [6-9] and its perceived intensity [1, 10, 11],
               access to food sources [12-14], and expectations from past
               experience [15, 16] have been shown to influence defensive
               behaviors, suggesting that their expression can be modulated.
               However, despite recent work [2, 4, 17-21], little is known
               about how flexible mouse innate defensive behaviors are and how
               quickly they can be modified by experience. To address this, we
               have investigated the dependence of escape behavior on learned
               knowledge about the spatial environment and how the behavior is
               updated when the environment changes acutely. Using behavioral
               assays with innately threatening visual and auditory stimuli, we
               show that the primary goal of escape in mice is to reach a
               previously memorized shelter location. Memory of the escape
               target can be formed in a single shelter visit lasting less than
               20 s, and changes in the spatial environment lead to a rapid
               update of the defensive action, including changing the defensive
               strategy from escape to freezing. Our results show that although
               there are innate links between specific sensory features and
               defensive behavior, instinctive defensive actions are
               surprisingly flexible and can be rapidly updated by experience
               to adapt to changing spatial environments.",
  journal   = "Curr. Biol.",
  publisher = "Elsevier",
  volume    =  27,
  number    =  9,
  pages     = "1342--1349",
  month     =  may,
  year      =  2017,
  keywords  = "defensive behavior; escape; freezing; innate behavior; mouse;
               shelter; spatial learning; spatial memory",
  language  = "en",
  issn      = "0960-9822, 1879-0445",
  pmid      = "28416117",
  doi       = "10.1016/j.cub.2017.03.031",
  pmc       = "PMC5434248"
}

@ARTICLE{De_Franceschi2016-vo,
  title     = "Vision Guides Selection of Freeze or Flight Defense Strategies
               in Mice",
  author    = "De Franceschi, Gioia and Vivattanasarn, Tipok and Saleem, Aman B
               and Solomon, Samuel G",
  abstract  = "In prey species such as mice, avoidance of predators is key to
               survival and drives instinctual behaviors like freeze or flight
               [1, 2]. Sensory signals guide the selection of appropriate
               behavior [3], and for aerial predators only vision provides
               useful information. Surprisingly, there is no evidence that
               vision can guide the selection of escape strategies. Fleeing
               behavior can be readily triggered by a rapidly looming overhead
               stimulus [4]. Freezing behavior, however, has previously been
               induced by real predators or their odors [5]. Here, we discover
               that a small moving disk, simulating the sweep of a predator
               cruising overhead, is sufficient to induce freezing response in
               mice. Looming and sweeping therefore provide visual triggers for
               opposing flight and freeze behaviors and provide evidence that
               mice innately make behavioral choices based on vision alone.
               VIDEO ABSTRACT.",
  journal   = "Curr. Biol.",
  publisher = "Elsevier",
  volume    =  26,
  number    =  16,
  pages     = "2150--2154",
  month     =  aug,
  year      =  2016,
  keywords  = "innate behavior; mouse; predator and prey; visual pathways",
  language  = "en",
  issn      = "0960-9822, 1879-0445",
  pmid      = "27498569",
  doi       = "10.1016/j.cub.2016.06.006"
}

@ARTICLE{Muenzinger1938-ex,
  title     = "Vicarious Trial and Error at a Point of Choice: I. A General
               Survey of its Relation to Learning Efficiency",
  author    = "Muenzinger, Karl F",
  abstract  = "* Received in the Editorial Office on December 7, 1937.",
  journal   = "The Pedagogical Seminary and Journal of Genetic Psychology",
  publisher = "Routledge",
  volume    =  53,
  number    =  1,
  pages     = "75--86",
  month     =  sep,
  year      =  1938,
  keywords  = "Decision Making",
  issn      = "0885-6559",
  doi       = "10.1080/08856559.1938.10533799"
}

@ARTICLE{Hu1995-ip,
  title     = "A simple test of the vicarious trial-and-error hypothesis of
               hippocampal function",
  author    = "Hu, D and Amsel, A",
  abstract  = "Vicarious trial-and-error (VTE) is a term that Muenzinger and
               Tolman used to describe the rat's conflict-like behavior before
               responding to choice. Recently, VTE was proposed as a mechanism
               alternative to the concept of ``cognitive map'' in accounts of
               hippocampal function. That is, many phenomena of impaired
               learning and memory related to hippocampal interventions may be
               explained by behavioral first principles: reduced conflicting,
               incipient, pre-choice tendencies to approach and avoid. The
               nonspatial black-white discrimination learning and VTE behavior
               of the rat were investigated. Hippocampal-lesioned and
               sham-lesioned animals were trained for 25 days (20 trials per
               day) starting at 60 days of age. Each movement of the head from
               one discriminative stimulus to the other was counted as a VTE
               instance. Lesioned rats had fewer VTEs than sham controls, and
               the former learned much more slowly or never learned. After
               learning, VTE frequency declined. Male and female rats showed no
               significant differences in VTE behavior or discrimination
               learning.",
  journal   = "Proc. Natl. Acad. Sci. U. S. A.",
  publisher = "National Acad Sciences",
  volume    =  92,
  number    =  12,
  pages     = "5506--5509",
  month     =  jun,
  year      =  1995,
  keywords  = "Decision Making",
  language  = "en",
  issn      = "0027-8424",
  pmid      = "7777539",
  pmc       = "PMC41724"
}

@ARTICLE{Amsel1993-qk,
  title     = "Hippocampal function in the rat: cognitive mapping or vicarious
               trial and error?",
  author    = "Amsel, A",
  abstract  = "The most prominent hypothesis of hippocampal function likens the
               hippocampus to a ``cognitive map,'' a term used by a famous
               learning theorist, E. C. Tolman, to explain maze learning. The
               usual application of this concept of cognitive map, as it
               applies to the hippocampus, is to what is called spatial
               learning, mainly in the radial-arm maze of Olton and the Morris
               water maze. In a recent Hippocampus Forum, evidence for the
               cognitive map hypothesis was reviewed in a lead article by
               Nadel, followed by a series of commentaries by leading
               investigators of hippocampal function. This speculative
               commentary offers an alternative not represented in the
               forum--that the function of the hippocampus in spatial learning
               is not as a cognitive map, but that it subserves another
               function proposed by Tolman in his work on simple discrimination
               learning, vicarious trial and error, based on incipient,
               conflicting dispositions to approach and avoid.",
  journal   = "Hippocampus",
  publisher = "Wiley Online Library",
  volume    =  3,
  number    =  3,
  pages     = "251--256",
  month     =  jul,
  year      =  1993,
  keywords  = "Decision Making",
  language  = "en",
  issn      = "1050-9631",
  pmid      = "8353608",
  doi       = "10.1002/hipo.450030302"
}

@ARTICLE{Redish2016-id,
  title     = "Vicarious trial and error",
  author    = "Redish, A David",
  abstract  = "When rats come to a decision point, they sometimes pause and
               look back and forth as if deliberating over the choice; at other
               times, they proceed as if they have already made their decision.
               In the 1930s, this pause-and-look behaviour was termed
               'vicarious trial and error' (VTE), with the implication that the
               rat was 'thinking about the future'. The discovery in 2007 that
               the firing of hippocampal place cells gives rise to alternating
               representations of each of the potential path options in a
               serial manner during VTE suggested a possible neural mechanism
               that could underlie the representations of future outcomes.
               More-recent experiments examining VTE in rats suggest that there
               are direct parallels to human processes of deliberative decision
               making, working memory and mental time travel.",
  journal   = "Nat. Rev. Neurosci.",
  publisher = "nature.com",
  volume    =  17,
  number    =  3,
  pages     = "147--159",
  month     =  mar,
  year      =  2016,
  keywords  = "Decision Making",
  language  = "en",
  issn      = "1471-003X, 1471-0048",
  pmid      = "26891625",
  doi       = "10.1038/nrn.2015.30",
  pmc       = "PMC5029271"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Goss1956-dh,
  title     = "Vicarious trial and error and related behavior",
  author    = "Goss, A E and Wischner, G J",
  abstract  = "Empirical material relating to`` vicarious trial -and- error
               ''(VTE) is summarized and evaluated critically in terms of
               criteria for VTE, of antecedents to and response correlates of
               VTE, and of VTE and learning efficiency. It is proposed that the
               criterion for scoring VTE behavior should …",
  journal   = "Psychol. Bull.",
  publisher = "psycnet.apa.org",
  volume    =  53,
  number    =  1,
  pages     = "35--54",
  month     =  jan,
  year      =  1956,
  keywords  = "LEARNING;Decision Making",
  language  = "en",
  issn      = "0033-2909",
  pmid      = "13289965"
}

@ARTICLE{Schmidt2013-bd,
  title     = "Conflict between place and response navigation strategies:
               effects on vicarious trial and error ({VTE}) behaviors",
  author    = "Schmidt, Brandy and Papale, Andrew and Redish, A David and
               Markus, Etan J",
  abstract  = "Navigation can be accomplished through multiple decision-making
               strategies, using different information-processing computations.
               A well-studied dichotomy in these decision-making strategies
               compares hippocampal-dependent ``place'' and dorsal-lateral
               striatal-dependent ``response'' strategies. A place strategy
               depends on the ability to flexibly respond to environmental
               cues, while a response strategy depends on the ability to
               quickly recognize and react to situations with well-learned
               action-outcome relationships. When rats reach decision points,
               they sometimes pause and orient toward the potential routes of
               travel, a process termed vicarious trial and error (VTE). VTE
               co-occurs with neurophysiological information processing,
               including sweeps of representation ahead of the animal in the
               hippocampus and transient representations of reward in the
               ventral striatum and orbitofrontal cortex. To examine the
               relationship between VTE and the place/response strategy
               dichotomy, we analyzed data in which rats were cued to switch
               between place and response strategies on a plus maze. The
               configuration of the maze allowed for place and response
               strategies to work competitively or cooperatively. Animals
               showed increased VTE on trials entailing competition between
               navigational systems, linking VTE with deliberative
               decision-making. Even in a well-learned task, VTE was
               preferentially exhibited when a spatial selection was required,
               further linking VTE behavior with decision-making associated
               with hippocampal processing.",
  journal   = "Learn. Mem.",
  publisher = "learnmem.cshlp.org",
  volume    =  20,
  number    =  3,
  pages     = "130--138",
  month     =  feb,
  year      =  2013,
  keywords  = "Decision Making",
  language  = "en",
  issn      = "1072-0502, 1549-5485",
  pmid      = "23418392",
  doi       = "10.1101/lm.028753.112"
}

@ARTICLE{Wood2018-fu,
  title     = "The honeycomb maze provides a novel test to study
               hippocampal-dependent spatial navigation",
  author    = "Wood, Ruth A and Bauza, Marius and Krupic, Julija and Burton,
               Stephen and Delekate, Andrea and Chan, Dennis and O'Keefe, John",
  abstract  = "Here we describe the honeycomb maze, a behavioural paradigm for
               the study of spatial navigation in rats. The maze consists of 37
               platforms that can be raised or lowered independently. Place
               navigation requires an animal to go to a goal platform from any
               of several start platforms via a series of sequential choices.
               For each, the animal is confined to a raised platform and
               allowed to choose between two of the six adjacent platforms, the
               correct one being the platform with the smallest angle to the
               goal-heading direction. Rats learn rapidly and their choices are
               influenced by three factors: the angle between the two choice
               platforms, the distance from the goal, and the angle between the
               correct platform and the direction of the goal. Rats with
               hippocampal damage are impaired in learning and their
               performance is affected by all three factors. The honeycomb maze
               represents a marked improvement over current spatial navigation
               tests, such as the Morris water maze, because it controls the
               choices of the animal at each point in the maze, provides the
               ability to assess knowledge of the goal direction from any
               location, enables the identification of factors influencing task
               performance and provides the possibility for concomitant
               single-cell recording.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  554,
  number    =  7690,
  pages     = "102--105",
  month     =  feb,
  year      =  2018,
  keywords  = "Spatial Navigation",
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "29364869",
  doi       = "10.1038/nature25433"
}

@ARTICLE{Friston2018-lp,
  title    = "Does predictive coding have a future?",
  author   = "Friston, Karl",
  journal  = "Nat. Neurosci.",
  month    =  jul,
  year     =  2018,
  keywords = "Threat response",
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "30038278",
  doi      = "10.1038/s41593-018-0200-7"
}

@BOOK{McFarland1981-kf,
  title     = "Quantitative Ethology: The State Space Approach",
  author    = "McFarland, David and Houston, Alasdair",
  publisher = "Pitman Advanced Pub. Program",
  year      =  1981,
  language  = "en",
  isbn      = "9780273084174"
}

@ARTICLE{Wiltschko2015-wd,
  title     = "Mapping {Sub-Second} Structure in Mouse Behavior",
  author    = "Wiltschko, Alexander B and Johnson, Matthew J and Iurilli,
               Giuliano and Peterson, Ralph E and Katon, Jesse M and
               Pashkovski, Stan L and Abraira, Victoria E and Adams, Ryan P and
               Datta, Sandeep Robert",
  abstract  = "Complex animal behaviors are likely built from simpler modules,
               but their systematic identification in mammals remains a
               significant challenge. Here we use depth imaging to show that 3D
               mouse pose dynamics are structured at the sub-second timescale.
               Computational modeling of these fast dynamics effectively
               describes mouse behavior as a series of reused and stereotyped
               modules with defined transition probabilities. We demonstrate
               this combined 3D imaging and machine learning method can be used
               to unmask potential strategies employed by the brain to adapt to
               the environment, to capture both predicted and previously hidden
               phenotypes caused by genetic or neural manipulations, and to
               systematically expose the global structure of behavior within an
               experiment. This work reveals that mouse body language is built
               from identifiable components and is organized in a predictable
               fashion; deciphering this language establishes an objective
               framework for characterizing the influence of environmental
               cues, genes and neural activity on behavior.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  88,
  number    =  6,
  pages     = "1121--1135",
  month     =  dec,
  year      =  2015,
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "26687221",
  doi       = "10.1016/j.neuron.2015.11.031",
  pmc       = "PMC4708087"
}

@ARTICLE{Markowitz2018-fk,
  title    = "The Striatum Organizes {3D} Behavior via {Moment-to-Moment}
              Action Selection",
  author   = "Markowitz, Jeffrey E and Gillis, Winthrop F and Beron, Celia C
              and Neufeld, Shay Q and Robertson, Keiramarie and Bhagat, Neha D
              and Peterson, Ralph E and Peterson, Emalee and Hyun, Minsuk and
              Linderman, Scott W and Sabatini, Bernardo L and Datta, Sandeep
              Robert",
  abstract = "Many naturalistic behaviors are built from modular components
              that are expressed sequentially. Although striatal circuits have
              been implicated in action selection and implementation, the
              neural mechanisms that compose behavior in unrestrained animals
              are not well understood. Here, we record bulk and cellular neural
              activity in the direct and indirect pathways of dorsolateral
              striatum (DLS) as mice spontaneously express action sequences.
              These experiments reveal that DLS neurons systematically encode
              information about the identity and ordering of sub-second 3D
              behavioral motifs; this encoding is facilitated by fast-timescale
              decorrelations between the direct and indirect pathways.
              Furthermore, lesioning the DLS prevents appropriate sequence
              assembly during exploratory or odor-evoked behaviors. By
              characterizing naturalistic behavior at neural timescales, these
              experiments identify a code for elemental 3D pose dynamics built
              from complementary pathway dynamics, support a role for DLS in
              constructing meaningful behavioral sequences, and suggest models
              for how actions are sculpted over time.",
  journal  = "Cell",
  volume   =  174,
  number   =  1,
  pages    = "44--58.e17",
  month    =  jun,
  year     =  2018,
  keywords = "basal ganglia; behavior; coding; direct pathway; ethology;
              indirect pathway; machine learning; mouse; photometry; striatum",
  language = "en",
  issn     = "0092-8674, 1097-4172",
  pmid     = "29779950",
  doi      = "10.1016/j.cell.2018.04.019",
  pmc      = "PMC6026065"
}

@ARTICLE{Akam2015-tt,
  title    = "Simple Plans or Sophisticated Habits? State, Transition and
              Learning Interactions in the {Two-Step} Task",
  author   = "Akam, Thomas and Costa, Rui and Dayan, Peter",
  abstract = "The recently developed 'two-step' behavioural task promises to
              differentiate model-based from model-free reinforcement learning,
              while generating neurophysiologically-friendly decision datasets
              with parametric variation of decision variables. These desirable
              features have prompted its widespread adoption. Here, we analyse
              the interactions between a range of different strategies and the
              structure of transitions and outcomes in order to examine
              constraints on what can be learned from behavioural performance.
              The task involves a trade-off between the need for stochasticity,
              to allow strategies to be discriminated, and a need for
              determinism, so that it is worth subjects' investment of effort
              to exploit the contingencies optimally. We show through
              simulation that under certain conditions model-free strategies
              can masquerade as being model-based. We first show that seemingly
              innocuous modifications to the task structure can induce
              correlations between action values at the start of the trial and
              the subsequent trial events in such a way that analysis based on
              comparing successive trials can lead to erroneous conclusions. We
              confirm the power of a suggested correction to the analysis that
              can alleviate this problem. We then consider model-free
              reinforcement learning strategies that exploit correlations
              between where rewards are obtained and which actions have high
              expected value. These generate behaviour that appears model-based
              under these, and also more sophisticated, analyses. Exploiting
              the full potential of the two-step task as a tool for behavioural
              neuroscience requires an understanding of these issues.",
  journal  = "PLoS Comput. Biol.",
  volume   =  11,
  number   =  12,
  pages    = "e1004648",
  month    =  dec,
  year     =  2015,
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "26657806",
  doi      = "10.1371/journal.pcbi.1004648",
  pmc      = "PMC4686094"
}

@UNPUBLISHED{Goode2018-px,
  title    = "Bed nucleus of the stria terminalis mediates fear to ambiguous
              threat signals",
  author   = "Goode, Travis D and Ressler, Reed L and Acca, Gillian M and
              Maren, Stephen",
  abstract = "The bed nucleus of the stria terminalis (BNST) has been
              implicated in fear and anxiety, but the specific factors that
              engage the BNST in defensive behavior are unclear. Here we
              explore the possibility that ambiguous threats recruit the BNST
              during Pavlovian fear conditioning in rats. We arranged a
              conditioned stimulus (CS) to either precede or follow an aversive
              unconditioned stimulus (US), a procedure that established
              reliable (forward) or ambiguous (backward) signals for US onset.
              After conditioning, reversible inactivation of the BNST
              selectively reduced freezing to the backward CS; BNST
              inactivation did not affect freezing to the forward CS even when
              that CS predicted a variable magnitude US. Backward CSs increased
              Fos in the ventral BNST and in BNST-projecting neurons in the
              infralimbic cortex, but not the hippocampus or amygdala. These
              data reveal that BNST circuits process ambiguous threat signals
              central to the etiology and expression of anxiety.",
  journal  = "bioRxiv",
  pages    = "376228",
  month    =  jul,
  year     =  2018,
  keywords = "Threat response",
  language = "en",
  doi      = "10.1101/376228"
}

@ARTICLE{Egnor2016-ix,
  title    = "Computational Analysis of Behavior",
  author   = "Egnor, S E Roian and Branson, Kristin",
  abstract = "In this review, we discuss the emerging field of computational
              behavioral analysis-the use of modern methods from computer
              science and engineering to quantitatively measure animal
              behavior. We discuss aspects of experiment design important to
              both obtaining biologically relevant behavioral data and enabling
              the use of machine vision and learning techniques for automation.
              These two goals are often in conflict. Restraining or restricting
              the environment of the animal can simplify automatic behavior
              quantification, but it can also degrade the quality or alter
              important aspects of behavior. To enable biologists to design
              experiments to obtain better behavioral measurements, and
              computer scientists to pinpoint fruitful directions for algorithm
              improvement, we review known effects of artificial manipulation
              of the animal on behavior. We also review machine vision and
              learning techniques for tracking, feature extraction, automated
              behavior classification, and automated behavior discovery, the
              assumptions they make, and the types of data they work best with.",
  journal  = "Annu. Rev. Neurosci.",
  volume   =  39,
  pages    = "217--236",
  month    =  jul,
  year     =  2016,
  keywords = "animal behavior; automated behavioral analysis; computer vision;
              machine learning; tracking;Analysis/Modelling [Behaviour]",
  language = "en",
  issn     = "0147-006X, 1545-4126",
  pmid     = "27090952",
  doi      = "10.1146/annurev-neuro-070815-013845"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Miller2018-vn,
  title     = "Retrosplenial cortical representations of space and future goal
               locations develop with learning",
  author    = "Miller, A M P and Mau, W and Smith, D M",
  abstract  = "The retrosplenial cortex (RSC) is important for long-term
               contextual memory and spatial navigation, but little is known
               about how RSC neural representations develop with experience. We
               recorded neuronal activity in the RSC of rats as they learned a
               continuous spatial alternation task and found that the RSC
               slowly developed a population-level representation of the rat9s
               spatial location and current trajectory to the goal. After the
               rats reached peak performance, RSC firing patterns became
               predictive of navigation accuracy …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2018,
  keywords  = "Spatial Navigation"
}

@ARTICLE{Todd2017-xy,
  title    = "Systematic exploration of unsupervised methods for mapping
              behavior",
  author   = "Todd, Jeremy G and Kain, Jamey S and de Bivort, Benjamin L",
  abstract = "To fully understand the mechanisms giving rise to behavior, we
              need to be able to precisely measure it. When coupled with large
              behavioral data sets, unsupervised clustering methods offer the
              potential of unbiased mapping of behavioral spaces. However,
              unsupervised techniques to map behavioral spaces are in their
              infancy, and there have been few systematic considerations of all
              the methodological options. We compared the performance of seven
              distinct mapping methods in clustering a wavelet-transformed data
              set consisting of the x- and y-positions of the six legs of
              individual flies. Legs were automatically tracked by small pieces
              of fluorescent dye, while the fly was tethered and walking on an
              air-suspended ball. We find that there is considerable variation
              in the performance of these mapping methods, and that better
              performance is attained when clustering is done in higher
              dimensional spaces (which are otherwise less preferable because
              they are hard to visualize). High dimensionality means that some
              algorithms, including the non-parametric watershed cluster
              assignment algorithm, cannot be used. We developed an alternative
              watershed algorithm which can be used in high-dimensional spaces
              when a probability density estimate can be computed directly.
              With these tools in hand, we examined the behavioral space of fly
              leg postural dynamics and locomotion. We find a striking division
              of behavior into modes involving the fore legs and modes
              involving the hind legs, with few direct transitions between
              them. By computing behavioral clusters using the data from all
              flies simultaneously, we show that this division appears to be
              common to all flies. We also identify individual-to-individual
              differences in behavior and behavioral transitions. Lastly, we
              suggest a computational pipeline that can achieve satisfactory
              levels of performance without the taxing computational demands of
              a systematic combinatorial approach.",
  journal  = "Phys. Biol.",
  volume   =  14,
  number   =  1,
  pages    = "015002",
  month    =  feb,
  year     =  2017,
  keywords = "Analysis/Modelling [Behaviour]",
  language = "en",
  issn     = "1478-3967, 1478-3975",
  pmid     = "28166059",
  doi      = "10.1088/1478-3975/14/1/015002"
}

@ARTICLE{Atiya_undated-kw,
  title    = "Neural Circuit Mechanism of Decision Uncertainty and
              {Change-of-Mind}",
  author   = "Atiya, N and Ra{\~n}{\'o}, I and Prasad, G and Wong-Lin, K",
  journal  = "BiorXiv",
  keywords = "Decision Making;Theoretical",
  doi      = "10.1101/377432"
}

@ARTICLE{Clark_undated-jz,
  title    = "Identifying the cognitive processes underpinning
              hippocampal-dependent tasks",
  author   = "Clark, I and Hotchin, V and Monk, A and Pizzamiglio, G and
              Liefgreen, A and Maguire, E",
  keywords = "Spatial Navigation",
  doi      = "10.1101/377408"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Tolman1939-vg,
  title     = "Prediction of vicarious trial and error by means of the
               schematic sowbug",
  author    = "Tolman, Edward Chace",
  abstract  = "An experiment is described in white-black and white-gray
               discrimination by rats, in which considerable``
               looking-back-and-forth'' or vicarious trial -and- error
               (Muenzinger's terminology), hereafter called VTE behavior,
               occurred. 3 groups of 10 rats each were used …",
  journal   = "Psychol. Rev.",
  publisher = "American Psychological Association",
  volume    =  46,
  number    =  4,
  pages     = "318",
  year      =  1939,
  keywords  = "Decision Making",
  issn      = "0033-295X"
}

@ARTICLE{Poehlmann2018-yj,
  title    = "A unifying model to predict multiple object orienting behaviors
              in tethered flies",
  author   = "Poehlmann, A and Soselisa, S and Fenk, L and Straw, A",
  journal  = "BiorXiv",
  year     =  2018,
  keywords = "Analysis/Modelling [Behaviour]",
  doi      = "10.1101/379651"
}

@ARTICLE{Stephens2008-vt,
  title    = "Dimensionality and dynamics in the behavior of C. elegans",
  author   = "Stephens, Greg J and Johnson-Kerner, Bethany and Bialek, William
              and Ryu, William S",
  abstract = "A major challenge in analyzing animal behavior is to discover
              some underlying simplicity in complex motor actions. Here, we
              show that the space of shapes adopted by the nematode
              Caenorhabditis elegans is low dimensional, with just four
              dimensions accounting for 95\% of the shape variance. These
              dimensions provide a quantitative description of worm behavior,
              and we partially reconstruct ``equations of motion'' for the
              dynamics in this space. These dynamics have multiple attractors,
              and we find that the worm visits these in a rapid and almost
              completely deterministic response to weak thermal stimuli.
              Stimulus-dependent correlations among the different modes suggest
              that one can generate more reliable behaviors by synchronizing
              stimuli to the state of the worm in shape space. We confirm this
              prediction, effectively ``steering'' the worm in real time.",
  journal  = "PLoS Comput. Biol.",
  volume   =  4,
  number   =  4,
  pages    = "e1000028",
  month    =  apr,
  year     =  2008,
  keywords = "Analysis/Modelling [Behaviour]",
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "18389066",
  doi      = "10.1371/journal.pcbi.1000028",
  pmc      = "PMC2276863"
}

@ARTICLE{Stephens2011-ce,
  title    = "Searching for simplicity in the analysis of neurons and behavior",
  author   = "Stephens, Greg J and Osborne, Leslie C and Bialek, William",
  abstract = "What fascinates us about animal behavior is its richness and
              complexity, but understanding behavior and its neural basis
              requires a simpler description. Traditionally, simplification has
              been imposed by training animals to engage in a limited set of
              behaviors, by hand scoring behaviors into discrete classes, or by
              limiting the sensory experience of the organism. An alternative
              is to ask whether we can search through the dynamics of natural
              behaviors to find explicit evidence that these behaviors are
              simpler than they might have been. We review two mathematical
              approaches to simplification, dimensionality reduction and the
              maximum entropy method, and we draw on examples from different
              levels of biological organization, from the crawling behavior of
              Caenorhabditis elegans to the control of smooth pursuit eye
              movements in primates, and from the coding of natural scenes by
              networks of neurons in the retina to the rules of English
              spelling. In each case, we argue that the explicit search for
              simplicity uncovers new and unexpected features of the biological
              system and that the evidence for simplification gives us a
              language with which to phrase new questions for the next
              generation of experiments. The fact that similar mathematical
              structures succeed in taming the complexity of very different
              biological systems hints that there is something more general to
              be discovered.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   = "108 Suppl 3",
  pages    = "15565--15571",
  month    =  sep,
  year     =  2011,
  keywords = "Analysis/Modelling [Behaviour];Theoretical",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "21383186",
  doi      = "10.1073/pnas.1010868108",
  pmc      = "PMC3176616"
}

@ARTICLE{Jovanic2016-ok,
  title    = "Competitive Disinhibition Mediates Behavioral Choice and
              Sequences in Drosophila",
  author   = "Jovanic, Tihana and Schneider-Mizell, Casey Martin and Shao, Mei
              and Masson, Jean-Baptiste and Denisov, Gennady and Fetter,
              Richard Doty and Mensh, Brett Daren and Truman, James William and
              Cardona, Albert and Zlatic, Marta",
  abstract = "Even a simple sensory stimulus can elicit distinct innate
              behaviors and sequences. During sensorimotor decisions,
              competitive interactions among neurons that promote distinct
              behaviors must ensure the selection and maintenance of one
              behavior, while suppressing others. The circuit implementation of
              these competitive interactions is still an open question. By
              combining comprehensive electron microscopy reconstruction of
              inhibitory interneuron networks, modeling, electrophysiology, and
              behavioral studies, we determined the circuit mechanisms that
              contribute to the Drosophila larval sensorimotor decision to
              startle, explore, or perform a sequence of the two in response to
              a mechanosensory stimulus. Together, these studies reveal that,
              early in sensory processing, (1) reciprocally connected
              feedforward inhibitory interneurons implement behavioral choice,
              (2) local feedback disinhibition provides positive feedback that
              consolidates and maintains the chosen behavior, and (3) lateral
              disinhibition promotes sequence transitions. The combination of
              these interconnected circuit motifs can implement both behavior
              selection and the serial organization of behaviors into a
              sequence.",
  journal  = "Cell",
  volume   =  167,
  number   =  3,
  pages    = "858--870.e19",
  month    =  oct,
  year     =  2016,
  keywords = "Drosophila; EM connectome; behavioral choice; behavioral
              sequences; disinihibition; recurrent inhibition; sensory
              processing",
  language = "en",
  issn     = "0092-8674, 1097-4172",
  pmid     = "27720450",
  doi      = "10.1016/j.cell.2016.09.009"
}

@ARTICLE{Krakauer2017-va,
  title    = "Neuroscience Needs Behavior: Correcting a Reductionist Bias",
  author   = "Krakauer, John W and Ghazanfar, Asif A and Gomez-Marin, Alex and
              MacIver, Malcolm A and Poeppel, David",
  abstract = "There are ever more compelling tools available for neuroscience
              research, ranging from selective genetic targeting to optogenetic
              circuit control to mapping whole connectomes. These approaches
              are coupled with a deep-seated, often tacit, belief in the
              reductionist program for understanding the link between the brain
              and behavior. The aim of this program is causal explanation
              through neural manipulations that allow testing of necessity and
              sufficiency claims. We argue, however, that another equally
              important approach seeks an alternative form of understanding
              through careful theoretical and experimental decomposition of
              behavior. Specifically, the detailed analysis of tasks and of the
              behavior they elicit is best suited for discovering component
              processes and their underlying algorithms. In most cases, we
              argue that study of the neural implementation of behavior is best
              investigated after such behavioral work. Thus, we advocate a more
              pluralistic notion of neuroscience when it comes to the
              brain-behavior relationship: behavioral work provides
              understanding, whereas neural interventions test causality.",
  journal  = "Neuron",
  volume   =  93,
  number   =  3,
  pages    = "480--490",
  month    =  feb,
  year     =  2017,
  keywords = "Theoretical",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "28182904",
  doi      = "10.1016/j.neuron.2016.12.041"
}

@ARTICLE{Fetsch2016-zu,
  title    = "The importance of task design and behavioral control for
              understanding the neural basis of cognitive functions",
  author   = "Fetsch, Christopher R",
  abstract = "The success of systems neuroscience depends on the ability to
              forge quantitative links between neural activity and behavior.
              Traditionally, this process has benefited from the rigorous
              development and testing of hypotheses using tools derived from
              classical psychophysics and computational motor control. As our
              capacity for measuring neural activity improves, accompanied by
              powerful new analysis strategies, it seems prudent to remember
              what these traditional approaches have to offer. Here I present a
              perspective on the merits of principled task design and tight
              behavioral control, along with some words of caution about
              interpretation in unguided, large-scale neural recording studies.
              I argue that a judicious combination of new and old approaches is
              the best way to advance our understanding of higher brain
              function in health and disease.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  37,
  pages    = "16--22",
  month    =  apr,
  year     =  2016,
  keywords = "Theoretical",
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "26774692",
  doi      = "10.1016/j.conb.2015.12.002",
  pmc      = "PMC5191893"
}

@ARTICLE{Brody2016-ud,
  title    = "Neural underpinnings of the evidence accumulator",
  author   = "Brody, Carlos D and Hanks, Timothy D",
  abstract = "Gradual accumulation of evidence favoring one or another choice
              is considered a core component of many different types of
              decisions, and has been the subject of many neurophysiological
              studies in non-human primates. But its neural circuit mechanisms
              remain mysterious. Investigating it in rodents has recently
              become possible, facilitating perturbation experiments to
              delineate the relevant causal circuit, as well as the application
              of other tools more readily available in rodents. In addition,
              advances in stimulus design and analysis have aided studying the
              relevant neural encoding. In complement to ongoing non-human
              primate studies, these newly available model systems and tools
              place the field at an exciting time that suggests that the
              dynamical circuit mechanisms underlying accumulation of evidence
              could soon be revealed.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  37,
  pages    = "149--157",
  month    =  apr,
  year     =  2016,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "26878969",
  doi      = "10.1016/j.conb.2016.01.003",
  pmc      = "PMC5777584"
}

@ARTICLE{Dudman2016-gy,
  title    = "The basal ganglia: from motor commands to the control of vigor",
  author   = "Dudman, Joshua T and Krakauer, John W",
  abstract = "Vertebrates are remarkable for their ability to select and
              execute goal-directed actions: motor skills critical for thriving
              in complex, competitive environments. A key aspect of a motor
              skill is the ability to execute its component movements over a
              range of speeds, amplitudes and frequencies (vigor). Recent work
              has indicated that a subcortical circuit, the basal ganglia, is a
              critical determinant of movement vigor in rodents and primates.
              We propose that the basal ganglia evolved from a circuit that in
              lower vertebrates and some mammals is sufficient to directly
              command simple or stereotyped movements to one that indirectly
              controls the vigor of goal-directed movements. The implications
              of a dual role of the basal ganglia in the control of vigor and
              response to reward are also discussed.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  37,
  pages    = "158--166",
  month    =  apr,
  year     =  2016,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "27012960",
  doi      = "10.1016/j.conb.2016.02.005"
}

@ARTICLE{Spratling2017-te,
  title    = "A review of predictive coding algorithms",
  author   = "Spratling, M W",
  abstract = "Predictive coding is a leading theory of how the brain performs
              probabilistic inference. However, there are a number of distinct
              algorithms which are described by the term ``predictive coding''.
              This article provides a concise review of these different
              predictive coding algorithms, highlighting their similarities and
              differences. Five algorithms are covered: linear predictive
              coding which has a long and influential history in the signal
              processing literature; the first neuroscience-related application
              of predictive coding to explaining the function of the retina;
              and three versions of predictive coding that have been proposed
              to model cortical function. While all these algorithms aim to fit
              a generative model to sensory data, they differ in the type of
              generative model they employ, in the process used to optimise the
              fit between the model and sensory data, and in the way that they
              are related to neurobiology.",
  journal  = "Brain Cogn.",
  volume   =  112,
  pages    = "92--97",
  month    =  mar,
  year     =  2017,
  keywords = "Cortex; Free energy; Neural networks; Predictive coding; Retina;
              Signal processing;Theoretical",
  language = "en",
  issn     = "0278-2626, 1090-2147",
  pmid     = "26809759",
  doi      = "10.1016/j.bandc.2015.11.003"
}

@ARTICLE{Bastos2012-fc,
  title    = "Canonical microcircuits for predictive coding",
  author   = "Bastos, Andre M and Usrey, W Martin and Adams, Rick A and Mangun,
              George R and Fries, Pascal and Friston, Karl J",
  abstract = "This Perspective considers the influential notion of a canonical
              (cortical) microcircuit in light of recent theories about
              neuronal processing. Specifically, we conciliate quantitative
              studies of microcircuitry and the functional logic of neuronal
              computations. We revisit the established idea that message
              passing among hierarchical cortical areas implements a form of
              Bayesian inference-paying careful attention to the implications
              for intrinsic connections among neuronal populations. By deriving
              canonical forms for these computations, one can associate
              specific neuronal populations with specific computational roles.
              This analysis discloses a remarkable correspondence between the
              microcircuitry of the cortical column and the connectivity
              implied by predictive coding. Furthermore, it provides some
              intuitive insights into the functional asymmetries between
              feedforward and feedback connections and the characteristic
              frequencies over which they operate.",
  journal  = "Neuron",
  volume   =  76,
  number   =  4,
  pages    = "695--711",
  month    =  nov,
  year     =  2012,
  keywords = "Theoretical",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "23177956",
  doi      = "10.1016/j.neuron.2012.10.038",
  pmc      = "PMC3777738"
}

@ARTICLE{DeCharms2000-ng,
  title     = "Neural representation and the cortical code",
  author    = "deCharms, R C and Zador, A",
  abstract  = "The principle function of the central nervous system is to
               represent and transform information and thereby mediate
               appropriate decisions and behaviors. The cerebral cortex is one
               of the primary seats of the internal representations maintained
               and used in perception, memory, decision making, motor control,
               and subjective experience, but the basic coding scheme by which
               this information is carried and transformed by neurons is not
               yet fully understood. This article defines and reviews how
               information is represented in the firing rates and temporal
               patterns of populations of cortical neurons, with a particular
               emphasis on how this information mediates behavior and
               experience.",
  journal   = "Annu. Rev. Neurosci.",
  publisher = "annualreviews.org",
  volume    =  23,
  pages     = "613--647",
  year      =  2000,
  keywords  = "Theoretical",
  language  = "en",
  issn      = "0147-006X",
  pmid      = "10845077",
  doi       = "10.1146/annurev.neuro.23.1.613"
}

@ARTICLE{Shadlen2013-hz,
  title     = "Decision making as a window on cognition",
  author    = "Shadlen, Michael N and Kiani, Roozbeh",
  abstract  = "A decision is a commitment to a proposition or plan of action
               based on information and values associated with the possible
               outcomes. The process operates in a flexible timeframe that is
               free from the immediacy of evidence acquisition and the real
               time demands of action itself. Thus, it involves deliberation,
               planning, and strategizing. This Perspective focuses on
               perceptual decision making in nonhuman primates and the
               discovery of neural mechanisms that support accuracy, speed, and
               confidence in a decision. We suggest that these mechanisms
               expose principles of cognitive function in general, and we
               speculate about the challenges and directions before the field.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  80,
  number    =  3,
  pages     = "791--806",
  month     =  oct,
  year      =  2013,
  keywords  = "Decision Making",
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "24183028",
  doi       = "10.1016/j.neuron.2013.10.047",
  pmc       = "PMC3852636"
}

@ARTICLE{Carandini2013-hh,
  title     = "Probing perceptual decisions in rodents",
  author    = "Carandini, Matteo and Churchland, Anne K",
  abstract  = "The study of perceptual decision-making offers insight into how
               the brain uses complex, sometimes ambiguous information to guide
               actions. Understanding the underlying processes and their neural
               bases requires that one pair recordings and manipulations of
               neural activity with rigorous psychophysics. Though this
               research has been traditionally performed in primates, it seems
               increasingly promising to pursue it at least partly in mice and
               rats. However, rigorous psychophysical methods are not yet as
               developed for these rodents as they are for primates. Here we
               give a brief overview of the sensory capabilities of rodents and
               of their cortical areas devoted to sensation and decision. We
               then review methods of psychophysics, focusing on the technical
               issues that arise in their implementation in rodents. These
               methods represent a rich set of challenges and opportunities.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  16,
  number    =  7,
  pages     = "824--831",
  month     =  jul,
  year      =  2013,
  keywords  = "Decision Making",
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "23799475",
  doi       = "10.1038/nn.3410",
  pmc       = "PMC4105200"
}

@ARTICLE{Sejnowski2014-rn,
  title     = "Putting big data to good use in neuroscience",
  author    = "Sejnowski, Terrence J and Churchland, Patricia S and Movshon, J
               Anthony",
  abstract  = "Big data has transformed fields such as physics and genomics.
               Neuroscience is set to collect its own big data sets, but to
               exploit its full potential, there need to be ways to
               standardize, integrate and synthesize diverse types of data from
               different levels of analysis and across species. This will
               require a cultural shift in sharing data across labs, as well as
               to a central role for theorists in neuroscience research.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  17,
  number    =  11,
  pages     = "1440--1441",
  month     =  nov,
  year      =  2014,
  keywords  = "Theoretical",
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "25349909",
  doi       = "10.1038/nn.3839",
  pmc       = "PMC4224030"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Meyer2018-ex,
  title     = "An ultralight head-mounted camera system integrates detailed
               behavioral monitoring with multichannel electrophysiology in
               freely moving mice",
  author    = "Meyer, A F and Poort, J and O'Keefe, J and Sahani, M and Linden,
               J F",
  abstract  = "Breakthroughs in understanding the neural basis of natural
               behavior require neural recording and intervention to be paired
               with high-fidelity multimodal behavioral monitoring. An
               extensive genetic toolkit for neural circuit dissection, and
               well-developed neural recording technology, make the mouse a
               powerful model organism for systems neuroscience. However,
               methods for high-bandwidth acquisition of behavioral signals in
               mice remain limited to fixed-position cameras and other
               off-animal devices, complicating the …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2018,
  keywords  = "Analysis/Modelling [Behaviour]"
}

@ARTICLE{Juavinett2018-al,
  title    = "Decision-making behaviors: weighing ethology, complexity, and
              sensorimotor compatibility",
  author   = "Juavinett, Ashley L and Erlich, Jeffrey C and Churchland, Anne K",
  abstract = "Rodent decision-making research aims to uncover the neural
              circuitry underlying the ability to evaluate alternatives and
              select appropriate actions. Designing behavioral paradigms that
              provide a solid foundation to ask questions about decision-making
              computations and mechanisms is a difficult and often
              underestimated challenge. Here, we propose three dimensions on
              which we can consider rodent decision-making tasks: ethological
              validity, task complexity, and stimulus-response compatibility.
              We review recent research through this lens, and provide
              practical guidance for researchers in the decision-making field.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  49,
  pages    = "42--50",
  month    =  apr,
  year     =  2018,
  keywords = "Decision Making",
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "29179005",
  doi      = "10.1016/j.conb.2017.11.001",
  pmc      = "PMC5889959"
}

@UNPUBLISHED{Genewsky2018-bj,
  title    = "How much fear is in anxiety?",
  author   = "Genewsky, Andreas and Albrecht, Nina and Bura, Simona A and
              Kaplick, Paul M and Heinz, Daniel E and Nu{\ss}baumer, Markus and
              Engel, Mareen and Gr{\"u}necker, Barbara and Kaltwasser,
              Sebastian F and Riebe, Caitlin J and Bedenk, Benedikt T and
              Czisch, Michael and Wotjak, Carsten T",
  abstract = "The selective breeding for extreme behavior on the elevated
              plus-maze (EPM) resulted in two mouse lines namely high-anxiety
              behaving (HAB) and low-anxiety behaving (LAB) mice. Using novel
              behavioral tests we demonstrate that HAB animals additionally
              exhibit maladaptive escape behavior and defensive vocalizations,
              whereas LAB mice show profound deficits in escaping from
              approaching threats which partially results from sensory
              deficits. We could relate these behavioral distortions to tonic
              changes in brain activity within the periaqueductal gray (PAG) in
              HAB mice and the superior colliculus (SC) in LAB mice, using in
              vivo manganese-enhanced MRI (MEMRI) followed by pharmacological
              or chemogenetic interventions. Therefore, midbrain-tectal
              structures govern the expression of both anxiety-like behavior
              and defensive responses. Our results challenge the uncritical use
              of the anthropomorphic terms anxiety or anxiety-like for the
              description of mouse behavior, as they imply higher cognitive
              processes, which are not necessarily in place.",
  journal  = "bioRxiv",
  pages    = "385823",
  month    =  aug,
  year     =  2018,
  keywords = "Threat response",
  language = "en",
  doi      = "10.1101/385823"
}

@UNPUBLISHED{George2018-aw,
  title    = "Cortical Microcircuits from a Generative Vision Model",
  author   = "George, Dileep and Lavin, Alexander and Swaroop Guntupalli, J and
              Mely, David and Hay, Nick and Lazaro-Gredilla, Miguel",
  abstract = "Understanding the information processing roles of cortical
              circuits is an outstanding problem in neuroscience and artificial
              intelligence. The theoretical setting of Bayesian inference has
              been suggested as a framework for understanding cortical
              computation. Based on a recently published generative model for
              visual inference (George et al., 2017), we derive a family of
              anatomically instantiated and functional cortical circuit models.
              In contrast to simplistic models of Bayesian inference, the
              underlying generative model9s representational choices are
              validated with real-world tasks that required efficient inference
              and strong generalization. The cortical circuit model is derived
              by systematically comparing the computational requirements of
              this model with known anatomical constraints. The derived model
              suggests precise functional roles for the feedforward, feedback
              and lateral connections observed in different laminae and
              columns, and assigns a computational role for the path through
              the thalamus.",
  journal  = "bioRxiv",
  pages    = "379313",
  month    =  aug,
  year     =  2018,
  language = "en",
  doi      = "10.1101/379313"
}

@ARTICLE{Kaplan2011-vm,
  title     = "Explanation and description in computational neuroscience",
  author    = "Kaplan, David Michael",
  abstract  = "The central aim of this paper is to shed light on the nature of
               explanation in computational neuroscience. I argue that
               computational models in this domain possess explanatory force to
               the extent that they describe the mechanisms responsible for
               producing a given phenomenon---paralleling how other mechanistic
               models explain. Conceiving computational explanation as a
               species of mechanistic explanation affords an important
               distinction between computational models that play genuine
               explanatory roles and those that merely provide accurate
               descriptions or predictions of phenomena. It also serves to
               clarify the pattern of model refinement and elaboration
               undertaken by computational neuroscientists.",
  journal   = "Synthese",
  publisher = "Springer Netherlands",
  volume    =  183,
  number    =  3,
  pages     = "339",
  month     =  dec,
  year      =  2011,
  keywords  = "Theoretical",
  language  = "en",
  issn      = "0039-7857, 1573-0964",
  doi       = "10.1007/s11229-011-9970-0"
}

@UNPUBLISHED{Slezak2018-ix,
  title    = "Astrocytes integrate local sensory and brain-wide neuromodulatory
              signals",
  author   = "Slezak, Michal and Kandler, Steffen and Van Veldhoven, Paul P and
              Bonin, Vincent and Holt, Matthew G",
  abstract = "Astrocytes play multiple functions in the central nervous system,
              from control of blood flow through to modulation of synaptic
              activity. Transient increases in intracellular Ca2+ are thought
              to control these activities. The prevailing concept is that these
              Ca2+ transients are triggered by distinct pathways, with little
              mechanistic and functional overlap. Here we demonstrate that
              astrocytes in visual cortex of mice encode local visual signals
              in conjunction with arousal state, functioning as multi-modal
              integrators. Such activity adds an additional layer of complexity
              to astrocyte function and may enable astrocytes to specifically
              and subtly regulate local network activity and plasticity.",
  journal  = "bioRxiv",
  pages    = "381434",
  month    =  jul,
  year     =  2018,
  language = "en",
  doi      = "10.1101/381434"
}

@ARTICLE{Jazayeri2017-on,
  title    = "Navigating the Neural Space in Search of the Neural Code",
  author   = "Jazayeri, Mehrdad and Afraz, Arash",
  abstract = "The advent of powerful perturbation tools, such as optogenetics,
              has created new frontiers for probing causal dependencies in
              neural and behavioral states. These approaches have significantly
              enhanced the ability to characterize the contribution of
              different cells and circuits to neural function in health and
              disease. They have shifted the emphasis of research toward causal
              interrogations and increased the demand for more precise and
              powerful tools to control and manipulate neural activity. Here,
              we clarify the conditions under which measurements and
              perturbations support causal inferences. We note that the brain
              functions at multiple scales and that causal dependencies may be
              best inferred with perturbation tools that interface with the
              system at the appropriate scale. Finally, we develop a geometric
              framework to facilitate the interpretation of causal experiments
              when brain perturbations do or do not respect the intrinsic
              patterns of brain activity. We describe the challenges and
              opportunities of applying perturbations in the presence of
              dynamics, and we close with a general perspective on navigating
              the activity space of neurons in the search for neural codes.",
  journal  = "Neuron",
  volume   =  93,
  number   =  5,
  pages    = "1003--1014",
  month    =  mar,
  year     =  2017,
  keywords = "behavior; causation; correlation; neural code; neural manifold;
              perturbation;Theoretical",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "28279349",
  doi      = "10.1016/j.neuron.2017.02.019"
}

@ARTICLE{Huxter2003-tz,
  title    = "Independent rate and temporal coding in hippocampal pyramidal
              cells",
  author   = "Huxter, John and Burgess, Neil and O'Keefe, John",
  abstract = "In the brain, hippocampal pyramidal cells use temporal as well as
              rate coding to signal spatial aspects of the animal's environment
              or behaviour. The temporal code takes the form of a phase
              relationship to the concurrent cycle of the hippocampal
              electroencephalogram theta rhythm. These two codes could each
              represent a different variable. However, this requires the rate
              and phase to vary independently, in contrast to recent
              suggestions that they are tightly coupled, both reflecting the
              amplitude of the cell's input. Here we show that the time of
              firing and firing rate are dissociable, and can represent two
              independent variables: respectively the animal's location within
              the place field, and its speed of movement through the field.
              Independent encoding of location together with actions and
              stimuli occurring there may help to explain the dual roles of the
              hippocampus in spatial and episodic memory, or may indicate a
              more general role of the hippocampus in relational/declarative
              memory.",
  journal  = "Nature",
  volume   =  425,
  number   =  6960,
  pages    = "828--832",
  month    =  oct,
  year     =  2003,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "14574410",
  doi      = "10.1038/nature02058",
  pmc      = "PMC2677642"
}

@ARTICLE{Frigg2009-bp,
  title     = "The philosophy of simulation: hot new issues or same old stew?",
  author    = "Frigg, Roman and Reiss, Julian",
  abstract  = "Computer simulations are an exciting tool that plays important
               roles in many scientific disciplines. This has attracted the
               attention of a number of philosophers of science. The main tenor
               in this literature is that computer simulations not only
               constitute interesting and powerful new science, but that they
               also raise a host of new philosophical issues. The protagonists
               in this debate claim no less than that simulations call into
               question our philosophical understanding of scientific ontology,
               the epistemology and semantics of models and theories, and the
               relation between experimentation and theorising, and submit that
               simulations demand a fundamentally new philosophy of science in
               many respects. The aim of this paper is to critically evaluate
               these claims. Our conclusion will be sober. We argue that these
               claims are overblown and that simulations, far from demanding a
               new metaphysics, epistemology, semantics and methodology, raise
               few if any new philosophical problems. The philosophical
               problems that do come up in connection with simulations are not
               specific to simulations and most of them are variants of
               problems that have been discussed in other contexts before.",
  journal   = "Synthese",
  publisher = "Springer Netherlands",
  volume    =  169,
  number    =  3,
  pages     = "593--613",
  month     =  aug,
  year      =  2009,
  keywords  = "Theoretical",
  language  = "en",
  issn      = "0039-7857, 1573-0964",
  doi       = "10.1007/s11229-008-9438-z"
}

@INCOLLECTION{Guala2002-ap,
  title     = "Models, Simulations, and Experiments",
  booktitle = "{Model-Based} Reasoning: Science, Technology, Values",
  author    = "Guala, Francesco",
  editor    = "Magnani, Lorenzo and Nersessian, Nancy J",
  abstract  = "I discuss the difference between models, simulations, and
               experiments from an epistemological and an ontological
               perspective. I first distinguish between ``static'' models (like
               a map) and ``dynamic'' models endowed with the capacity to
               generate processes. Only the latter can be used to simulate. I
               then criticize the view according to which the difference
               between models/simulations and experiments is fundamentally
               epistemic in character. Following Herbert Simon, I argue that
               the difference is ontological. Simulations merely require the
               existence of an abstract correspondence between the simulating
               and the simulated system. In experiments, in contrast, the
               causal relations governing the experimental and the target
               systems are grounded in the same material. Simulations can
               produce new knowledge just as experiments do, but the prior
               knowledge needed to run a good simulation is not the same as
               that needed to run a good experiment. I conclude by discussing
               ``hybrid'' cases of ``experimental simulations'' or ``simulating
               experiments''.",
  publisher = "Springer US",
  pages     = "59--74",
  year      =  2002,
  address   = "Boston, MA",
  keywords  = "Theoretical",
  isbn      = "9781461506058",
  doi       = "10.1007/978-1-4615-0605-8\_4"
}

@ARTICLE{Peschard2011-sz,
  title    = "Is Simulation an Epistemic Substitute for Experimentation?",
  author   = "Peschard, Isabelle",
  abstract = "It is sometimes said that simulation can serve as epistemic
              substitute for experimentation. Such a claim might be suggested
              by the fast-spreading use of computer simulation to investigate
              phenomena not accessible to experimentation (in astrophysics,
              ecology, economics, climatology, etc.). But what does that mean?
              The paper starts with a clarification of the terms of the issue
              and then focuses on two powerful arguments for the view that
              simulation and experimentation are `epistemically on a par'. One
              is based on the claim that, in experimentation, no less than in
              simulation, it is not the system under study that is manipulated
              but a system that `stands-in' for it. The other one highlights
              the pervasive use of models in experimentation. It will be argued
              that these arguments, as compelling as they might seem, are each
              based on a mistaken interpretation of experimentation and that,
              far from simulation and experimentation being epistemically on a
              par, they do not have the same epistemic function, do not produce
              the same kind of epistemic results.",
  month    =  aug,
  year     =  2011,
  keywords = "simulation, experiment, experimentation, substitute, modeling,
              target system, surrogate.;Theoretical",
  language = "en"
}

@INCOLLECTION{Peschard2013-ga,
  title     = "Modeling and experimenting",
  booktitle = "Models, simulations, and representations",
  author    = "Peschard, Isabelle",
  publisher = "Routledge",
  pages     = "60--79",
  year      =  2013,
  keywords  = "Theoretical"
}

@ARTICLE{Kastner2013-gi,
  title    = "When can a Computer Simulation act as Substitute for an
              Experiment? A {Case-Study} from Chemisty",
  author   = "K{\"a}stner, Johannes and Arnold, Eckhart",
  year     =  2013,
  keywords = "Theoretical"
}

@ARTICLE{Hasz2018-hy,
  title    = "Deliberation and Procedural Automation on a {Two-Step} Task for
              Rats",
  author   = "Hasz, Brendan M and Redish, A David",
  abstract = "Current theories suggest that decision-making arises from
              multiple systems. Human studies dissociate model-based and
              model-free systems, while rodent studies dissociate deliberation
              and habit. However, the relationship between these constructs
              remains unresolved. We adapted for rats a two-step task which has
              been used to dissociate model based from model-free decisions in
              humans. We found that an uncertainty-based algorithm predicted
              rats' choices on the maze better than an algorithm with a
              constant weighting between systems, supporting theoretical work
              suggesting decision-making systems are more likely to be used
              when their valuation is less uncertain. We also found that path
              stereotypy, a measure of behavioral consistency associated with
              procedural learning, was correlated with model-free certainty,
              while vicarious trial and error, a deliberative behavior, was
              increased during model-free uncertainty.",
  journal  = "Front. Integr. Neurosci.",
  volume   =  12,
  pages    = "30",
  year     =  2018,
  issn     = "1662-5145",
  doi      = "10.3389/fnint.2018.00030"
}

@ARTICLE{Gardner2013-bg,
  title    = "A secondary working memory challenge preserves primary place
              strategies despite overtraining",
  author   = "Gardner, Robert S and Uttaro, Michael R and Fleming, Samantha E
              and Suarez, Daniel F and Ascoli, Giorgio A and Dumas, Theodore C",
  abstract = "Learning by repetition engages distinct cognitive strategies
              whose contributions are adjusted with experience. Early in
              learning, performance relies upon flexible, attentive strategies.
              With extended practice, inflexible, automatic strategies emerge.
              This transition is thought fundamental to habit formation and
              applies to human and animal cognition. In the context of spatial
              navigation, place strategies are flexible, typically employed
              early in training, and rely on the spatial arrangement of
              landmarks to locate a goal. Response strategies are inflexible,
              become dominant after overtraining, and utilize fixed motor
              sequences. Although these strategies can operate independently,
              they have also been shown to interact. However, since previous
              work has focused on single-choice learning, if and how these
              strategies interact across sequential choices remains unclear. To
              test strategy interactions across sequential choices, we utilized
              various two-choice spatial navigation tasks administered on the
              Opposing Ts maze, an apparatus for rodents that permits
              experimental control over strategy recruitment. We found that
              when a second choice required spatial working memory, the
              transition to response navigation on the first choice was
              blocked. Control experiments specified this effect to the
              cognitive aspects of the secondary task. In addition, response
              navigation, once established on a single choice, was not reversed
              by subsequent introduction of a secondary choice reliant on
              spatial working memory. These results demonstrate that
              performance strategies interact across choices, highlighting the
              sensitivity of strategy use to the cognitive demands of
              subsequent actions, an influence from which overtrained rigid
              actions may be protected.",
  journal  = "Learn. Mem.",
  volume   =  20,
  number   =  11,
  pages    = "648--656",
  month    =  oct,
  year     =  2013,
  language = "en",
  issn     = "1072-0502, 1549-5485",
  pmid     = "24136182",
  doi      = "10.1101/lm.031336.113"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Van_der_Meer2012-lh,
  title     = "Information processing in decision-making systems",
  author    = "van der Meer, M and Kurth-Nelson, Z and {others}",
  abstract  = "Decisions result from an interaction between multiple functional
               systems acting in parallel to process information in very
               different ways, each with strengths and weaknesses. In this
               review, the authors address three action-selection components of
               decision-making: The Pavlovian system releases an action from a
               limited repertoire of potential actions, such as approaching
               learned stimuli. Like the Pavlovian system, the habit system is
               computationally fast but, unlike the Pavlovian system permits
               arbitrary stimulus-action pairings. These …",
  journal   = "The",
  publisher = "journals.sagepub.com",
  year      =  2012,
  pmc       = "PMC4428660"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Niv2006-yu,
  title     = "A normative perspective on motivation",
  author    = "Niv, Y and Joel, D and Dayan, P",
  abstract  = "Understanding the effects of motivation on instrumental action
               selection, and specifically on its two main forms, goal-directed
               and habitual control, is fundamental to the study of decision
               making. Motivational states have been shown to
               'direct'goal-directed behavior rather straightforwardly towards
               more valuable outcomes. However, how motivational states can
               influence outcome-insensitive habitual behavior is more
               mysterious. We adopt a normative perspective, assuming that
               animals seek to maximize the utilities they achieve, and viewing
               …",
  journal   = "Trends Cogn. Sci.",
  publisher = "Elsevier",
  year      =  2006,
  issn      = "1364-6613"
}

@ARTICLE{Anderson2014-hr,
  title    = "Toward a science of computational ethology",
  author   = "Anderson, David J and Perona, Pietro",
  abstract = "The new field of ``Computational Ethology'' is made possible by
              advances in technology, mathematics, and engineering that allow
              scientists to automate the measurement and the analysis of animal
              behavior. We explore the opportunities and long-term directions
              of research in this area.",
  journal  = "Neuron",
  volume   =  84,
  number   =  1,
  pages    = "18--31",
  month    =  oct,
  year     =  2014,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "25277452",
  doi      = "10.1016/j.neuron.2014.09.005"
}

@ARTICLE{Felsen2012-ng,
  title    = "Midbrain contributions to sensorimotor decision making",
  author   = "Felsen, Gidon and Mainen, Zachary F",
  abstract = "Making decisions about future actions is a fundamental function
              of the nervous system. Classical theories hold that separate sets
              of brain regions are responsible for selecting and implementing
              an action. Traditionally, action selection has been considered
              the domain of high-level regions, such as the prefrontal cortex,
              whereas action generation is thought to be carried out by
              dedicated cortical and subcortical motor regions. However,
              increasing evidence suggests that the activity of individual
              neurons in cortical motor structures reflects abstract properties
              of ``decision variables'' rather than conveying simple motor
              commands. Less is known, though, about the role of subcortical
              structures in decision making. In particular, the superior
              colliculus (SC) is critical for planning and initiating visually
              guided, gaze-displacing movements and selecting visual targets,
              but whether and how it contributes more generally to sensorimotor
              decisions are unclear. Here, we show that the SC is intimately
              involved in orienting decisions based on odor cues, even though
              the SC does not explicitly process olfactory stimuli. Neurons
              were recorded from the intermediate and deep SC layers in rats
              trained to perform a delayed-response, odor-cued spatial choice
              task. SC neurons commonly fired well in advance of movement
              initiation, predicting the chosen direction nearly 1 s before
              movement. Moreover, under conditions of sensory uncertainty, SC
              activity varied with task difficulty and reward outcome,
              reflecting the influence of decision variables on the
              intercollicular competition thought to underlie orienting
              movements. These results indicate that the SC plays a more
              general role in decisions than previously appreciated, extending
              beyond visuomotor functions.",
  journal  = "J. Neurophysiol.",
  volume   =  108,
  number   =  1,
  pages    = "135--147",
  month    =  jul,
  year     =  2012,
  language = "en",
  issn     = "0022-3077, 1522-1598",
  pmid     = "22496524",
  doi      = "10.1152/jn.01181.2011",
  pmc      = "PMC3434602"
}

@ARTICLE{Stern2015-kb,
  title    = "Analyzing animal behavior via classifying each video frame using
              convolutional neural networks",
  author   = "Stern, Ulrich and He, Ruo and Yang, Chung-Hui",
  abstract = "High-throughput analysis of animal behavior requires software to
              analyze videos. Such software analyzes each frame individually,
              detecting animals' body parts. But the image analysis rarely
              attempts to recognize ``behavioral states''-e.g., actions or
              facial expressions-directly from the image instead of using the
              detected body parts. Here, we show that convolutional neural
              networks (CNNs)-a machine learning approach that recently became
              the leading technique for object recognition, human pose
              estimation, and human action recognition-were able to recognize
              directly from images whether Drosophila were ``on'' (standing or
              walking) or ``off'' (not in physical contact with) egg-laying
              substrates for each frame of our videos. We used multiple nets
              and image transformations to optimize accuracy for our
              classification task, achieving a surprisingly low error rate of
              just 0.072\%. Classifying one of our 8 h videos took less than 3
              h using a fast GPU. The approach enabled uncovering a novel
              egg-laying-induced behavior modification in Drosophila.
              Furthermore, it should be readily applicable to other behavior
              analysis tasks.",
  journal  = "Sci. Rep.",
  volume   =  5,
  pages    = "14351",
  month    =  sep,
  year     =  2015,
  keywords = "Analysis/Modelling [Behaviour]",
  language = "en",
  issn     = "2045-2322",
  pmid     = "26394695",
  doi      = "10.1038/srep14351",
  pmc      = "PMC4585819"
}

@ARTICLE{Laubach2018-sh,
  title     = "What, if anything, is rodent prefrontal cortex?",
  author    = "Laubach, Mark and Amarante, Linda and Swanson, Kyra and White,
               Samantha R",
  publisher = "PsyArXiv",
  year      =  2018
}

@ARTICLE{McNaughton2018-bc,
  title    = "Survival circuits and risk assessment",
  author   = "McNaughton, Neil and Corr, Philip J",
  abstract = "Risk assessment (RA) behaviour is unusual in the context of
              survival circuits. An external object elicits eating, mating or
              fleeing; but conflict between internal approach and withdrawal
              tendencies elicits RA-specific behaviour that scans the
              environment for new information to bring closure. Recently rodent
              and human threat responses have been compared using `predators'
              that can be real (e.g. a tarantula), robot, virtual, or symbolic
              (with the last three rendered predatory by the use of shock).
              `Quick and dirty' survival circuits in the periaqueductal grey,
              hypothalamus, and amygdala control external RA behaviour. These
              subcortical circuits activate, and are partially inhibited by,
              higher-order internal RA processes (anxiety, memory scanning,
              evaluation and sometimes---maladaptive rumination) in the ventral
              hippocampus and medial prefrontal cortex.",
  journal  = "Current Opinion in Behavioral Sciences",
  volume   =  24,
  pages    = "14--20",
  month    =  dec,
  year     =  2018,
  issn     = "2352-1546",
  doi      = "10.1016/j.cobeha.2018.01.018"
}

@UNPUBLISHED{Kim2018-uq,
  title    = "Task complexity interacts with state-space uncertainty in the
              arbitration process between model-based and model-free
              reinforcement-learning at both behavioral and neural levels",
  author   = "Kim, Dongjae and Park, Geon Yeong and O'Doherty, John P and Lee,
              Sang Wan",
  abstract = "A major open question concerns how the brain governs the
              allocation of control between two distinct strategies for
              learning from reinforcement: model-based and model-free
              reinforcement learning. While there is evidence to suggest that
              the reliability of the predictions of the two systems is a key
              variable responsible for the arbitration process, another key
              variable has remained relatively unexplored: the role of task
              complexity. By using a combination of novel task design,
              computational modeling, and model-based fMRI analysis, we
              examined the role of task complexity alongside state-space
              uncertainty in the arbitration process between model-based and
              model-free RL. We found evidence to suggest that task complexity
              plays a role in influencing the arbitration process alongside
              state-space uncertainty. Participants tended to increase
              model-based RL control in response to increasing task complexity.
              However, they resorted to model-free RL when both uncertainty and
              task complexity were high, suggesting that these two variables
              interact during the arbitration process. Computational fMRI
              revealed that task complexity interacts with neural
              representations of the reliability of the two systems in the
              inferior prefrontal cortex bilaterally. These findings provide
              insight into how the inferior prefrontal cortex negotiates the
              trade-off between model-based and model-free RL in the presence
              of uncertainty and complexity, and more generally, illustrates
              how the brain resolves uncertainty and complexity in dynamically
              changing environment.",
  journal  = "bioRxiv",
  pages    = "393983",
  month    =  aug,
  year     =  2018,
  language = "en",
  doi      = "10.1101/393983"
}

@UNPUBLISHED{Carrillo-Reid2018-tp,
  title    = "Triggering visually-guided behavior by holographic activation of
              pattern completion neurons in cortical ensembles",
  author   = "Carrillo-Reid, Luis and Han, Shuting and Yang, Weijian and
              Akrouh, Alejandro and Yuste, Rafael",
  abstract = "Neuronal ensembles are building blocks of cortical activity yet
              it is unclear if they have any causal role in behavior. Here we
              tested if the precise activation of neuronal ensembles with
              two-photon holographic optogenetics in mouse primary visual
              cortex alters behavioral performance in a visual task. Disruption
              of behaviorally relevant cortical ensembles by activation of
              non-selective neurons decreased behavioral performance whereas
              optogenetic targeting of as few as two neurons with pattern
              completion capability from behaviorally relevant ensembles
              improved task performance by reliably recalling the whole
              ensemble. Moreover, in some cases, activation of two pattern
              completion neurons, in the absence of visual stimulus, triggered
              correct behavioral responses. Our results demonstrate a causal
              role of neuronal ensembles in a visually guided behavior and
              suggest that ensembles could represent perceptual states.",
  journal  = "bioRxiv",
  pages    = "394999",
  month    =  aug,
  year     =  2018,
  language = "en",
  doi      = "10.1101/394999"
}

@UNPUBLISHED{Karalis2018-wn,
  title    = "Breathing coordinates limbic network dynamics underlying memory
              consolidation",
  author   = "Karalis, Nikolaos and Sirota, Anton",
  abstract = "The coordinated activity between remote brain regions underlies
              cognition and memory function. Although neuronal oscillations
              have been proposed as a mechanistic substrate for the
              coordination of information transfer and memory consolidation
              during sleep, little is known about the mechanisms that support
              the widespread synchronization of brain regions and the
              relationship of neuronal dynamics with other bodily rhythms, such
              as breathing. Here we address this question using large-scale
              recordings from a number of structures, including the medial
              prefrontal cortex, hippocampus, thalamus, amygdala and nucleus
              accumbens in mice. We identify a dual mechanism of respiratory
              entrainment, in the form of an intracerebral corollary discharge
              that acts jointly with an olfactory reafference to coordinate
              limbic network dynamics, such as hippocampal ripples and cortical
              UP and DOWN states, involved in memory consolidation. These
              results highlight breathing, a perennial rhythmic input to the
              brain, as an oscillatory scaffold for the functional coordination
              of the limbic circuit, enabling the segregation and integration
              of information flow across neuronal networks.",
  journal  = "bioRxiv",
  pages    = "392530",
  month    =  aug,
  year     =  2018,
  language = "en",
  doi      = "10.1101/392530"
}

@ARTICLE{Gilad2018-cq,
  title    = "Behavioral Strategy Determines Frontal or Posterior Location of
              {Short-Term} Memory in Neocortex",
  author   = "Gilad, Ariel and Gallero-Salas, Yasir and Groos, Dominik and
              Helmchen, Fritjof",
  abstract = "The location of short-term memory in mammalian neocortex remains
              elusive. Here we show that distinct neocortical areas maintain
              short-term memory depending on behavioral strategy. Using
              wide-field and single-cell calcium imaging, we measured layer 2/3
              neuronal activity in mice performing a whisker-based texture
              discrimination task with delayed response. Mice either deployed
              an active strategy-engaging their body toward the approaching
              texture-or passively awaited the touch. Independent of strategy,
              whisker-related posterior areas encoded choice early after touch.
              During the delay, in contrast, persistent cortical activity was
              located medio-frontally in active trials but in a lateral
              posterior area in passive trials. Perturbing these areas impaired
              performance for the associated strategy and also provoked
              strategy switches. Frontally maintained information related to
              future action, whereas activity in the posterior cortex reflected
              past stimulus identity. Thus, depending on behavioral strategy,
              cortical activity is routed differentially to hold information
              either frontally or posteriorly before converging to similar
              action.",
  journal  = "Neuron",
  month    =  jul,
  year     =  2018,
  keywords = "barrel cortex; calcium imaging; fronto-posterior interactions;
              motor cortex; optogenetics; posterolateral cortex; secondary
              motor cortex; whisker; wide-field imaging; working memory",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "30100254",
  doi      = "10.1016/j.neuron.2018.07.029"
}

@ARTICLE{Gallivan2018-rt,
  title    = "Decision-making in sensorimotor control",
  author   = "Gallivan, Jason P and Chapman, Craig S and Wolpert, Daniel M and
              Flanagan, J Randall",
  abstract = "Skilled sensorimotor interactions with the world result from a
              series of decision-making processes that determine, on the basis
              of information extracted during the unfolding sequence of events,
              which movements to make and when and how to make them. Despite
              this inherent link between decision-making and sensorimotor
              control, research into each of these two areas has largely
              evolved in isolation, and it is only fairly recently that
              researchers have begun investigating how they interact and,
              together, influence behaviour. Here, we review recent
              behavioural, neurophysiological and computational research that
              highlights the role of decision-making processes in the
              selection, planning and control of goal-directed movements in
              humans and nonhuman primates.",
  journal  = "Nat. Rev. Neurosci.",
  month    =  aug,
  year     =  2018,
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "30089888",
  doi      = "10.1038/s41583-018-0045-9"
}

@ARTICLE{Papale2012-xl,
  title     = "Interactions between deliberation and delay-discounting in rats",
  author    = "Papale, Andrew E and Stott, Jeffrey J and Powell, Nathaniel J
               and Regier, Paul S and Redish, A David",
  abstract  = "When faced with decisions, rats sometimes pause and look back
               and forth between possible alternatives, a phenomenon termed
               vicarious trial and error (VTE). When it was first observed in
               the 1930s, VTE was theorized to be a mechanism for exploration.
               Later theories suggested that VTE aided the resolution of
               sensory or neuroeconomic conflict. In contrast, recent
               neurophysiological data suggest that VTE reflects a dynamic
               search and evaluation process. These theories make unique
               predictions about the timing of VTE on behavioral tasks. We
               tested these theories of VTE on a T-maze with return rails,
               where rats were given a choice between a smaller reward
               available after one delay or a larger reward available after an
               adjustable delay. Rats showed three clear phases of behavior on
               this task: investigation, characterized by discovery of task
               parameters; titration, characterized by iterative adjustment of
               the delay to a preferred interval; and exploitation,
               characterized by alternation to hold the delay at the preferred
               interval. We found that VTE events occurred during adjustment
               laps more often than during alternation laps. Results were
               incompatible with theories of VTE as an exploratory behavior, as
               reflecting sensory conflict, or as a simple neuroeconomic
               valuation process. Instead, our results were most consistent
               with VTE as reflecting a search process during deliberative
               decision making. This pattern of VTE that we observed is
               reminiscent of current navigational theories proposing a
               transition from a deliberative to a habitual decision-making
               mechanism.",
  journal   = "Cogn. Affect. Behav. Neurosci.",
  publisher = "Springer",
  volume    =  12,
  number    =  3,
  pages     = "513--526",
  month     =  sep,
  year      =  2012,
  language  = "en",
  issn      = "1530-7026, 1531-135X",
  pmid      = "22588853",
  doi       = "10.3758/s13415-012-0097-7",
  pmc       = "PMC3774285"
}

@ARTICLE{Garrett2018-np,
  title     = "Updating Beliefs Under Perceived Threat",
  author    = "Garrett, Neil and Gonz{\'a}lez-Garz{\'o}n, Ana Mar{\'\i}a and
               Foulkes, Lucy and Levita, Liat and Sharot, Tali",
  abstract  = "Humans are better at integrating desirable information into
               their beliefs than undesirable. This asymmetry poses an
               evolutionary puzzle, as it can lead to an underestimation of
               risk and thus failure to take precautionary action. Here, we
               suggest a mechanism that can speak to this conundrum. In
               particular, we show that the bias vanishes in response to
               perceived threat in the environment. We report that an
               improvement in participants' tendency to incorporate bad news
               into their beliefs is associated with physiological arousal in
               response to threat indexed by galvanic skin response and
               self-reported anxiety. This pattern of results was observed in a
               controlled laboratory setting (Experiment I), where perceived
               threat was manipulated, and in firefighters on duty (Experiment
               II), where it naturally varied. Such flexibility in how
               individuals integrate information may enhance the likelihood of
               responding to warnings with caution in environments rife with
               threat, while maintaining a positivity bias otherwise, a
               strategy that can increase well-being.SIGNIFICANCE STATEMENTThe
               human tendency to be overly optimistic has mystified scholars
               and lay people for decades: how could biased beliefs have been
               selected for over unbiased beliefs? Scholars have suggested that
               while the optimism bias can lead to negative outcomes, including
               financial collapse and war, it can also facilitate health and
               productivity. Here, we demonstrate that a mechanism generating
               the optimism bias, namely asymmetric information integration,
               evaporates under threat. Such flexibility could result in
               enhanced caution in dangerous environments while supporting an
               optimism bias otherwise, potentially increasing well-being.",
  journal   = "J. Neurosci.",
  publisher = "papers.ssrn.com",
  month     =  aug,
  year      =  2018,
  language  = "en",
  issn      = "0270-6474, 1529-2401",
  pmid      = "30082420",
  doi       = "10.1523/JNEUROSCI.0716-18.2018"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Swanson2000-yg,
  title     = "Cerebral hemisphere regulation of motivated behavior",
  author    = "Swanson, Larry W",
  abstract  = "The goals of this article are to suggest a basic wiring diagram
               for the motor neural network that controls motivated behavior,
               and to provide a model for the organization of cerebral
               hemisphere inputs to this network. Cerebral projections mediate
               voluntary regulation of a …",
  journal   = "Brain Res.",
  publisher = "Elsevier",
  volume    =  886,
  number    = "1-2",
  pages     = "113--164",
  year      =  2000,
  issn      = "0006-8993"
}

@UNPUBLISHED{Zhang2018-tv,
  title    = "Modeling {Sensory-Motor} Decisions in Natural Behavior",
  author   = "Zhang, Ruohan and Zhang, Shun and Tong, Matthew H and Cui, Yuchen
              and Rothkopf, Constantin A and Ballard, Dana H and Hayhoe, Mary M",
  abstract = "Although a standard reinforcement learning model can capture many
              aspects of reward-seeking behaviors, it may not be practical for
              modeling human natural behaviors because of the richness of
              dynamic environments and limitations in cognitive resources. We
              propose a modular reinforcement learning model that addresses
              these factors. Based on this model, a modular inverse
              reinforcement learning algorithm is developed to estimate both
              the rewards and discount factors from human behavioral data,
              which allows predictions of human navigation behaviors in virtual
              reality with high accuracy across different subjects and with
              different tasks. Complex human navigation trajectories in novel
              environments can be reproduced by an artificial agent that is
              based on the modular model. This model provides a strategy for
              estimating the subjective value of actions and how they influence
              sensory-motor decisions in natural behavior.",
  journal  = "bioRxiv",
  pages    = "412155",
  month    =  sep,
  year     =  2018,
  language = "en",
  doi      = "10.1101/412155"
}

@ARTICLE{Bicanski2018-jz,
  title    = "A neural-level model of spatial memory and imagery",
  author   = "Bicanski, Andrej and Burgess, Neil",
  abstract = "We present a model of how neural representations of egocentric
              spatial experiences in parietal cortex interface with
              viewpoint-independent representations in medial temporal areas,
              via retrosplenial cortex, to enable many key aspects of spatial
              cognition. This account shows how previously reported neural
              responses (place, head-direction and grid cells, allocentric
              boundary- and object-vector cells, gain-field neurons) can map
              onto higher cognitive function in a modular way, and predicts new
              cell types (egocentric and head-direction-modulated boundary- and
              object-vector cells). The model predicts how these neural
              populations should interact across multiple brain regions to
              support spatial memory, scene construction, novelty-detection,
              'trace cells', and mental navigation. Simulated behavior and
              firing rate maps are compared to experimental data, for example
              showing how object-vector cells allow items to be remembered
              within a contextual representation based on environmental
              boundaries, and how grid cells could update the viewpoint in
              imagery during planning and short-cutting by driving sequential
              place cell activity.",
  journal  = "Elife",
  volume   =  7,
  month    =  sep,
  year     =  2018,
  keywords = "computational model; episodic memory; neuroscience; none; scene
              construction; spatial cognition; spatially selective cells; trace
              cells",
  language = "en",
  issn     = "2050-084X",
  pmid     = "30176988",
  doi      = "10.7554/eLife.33752",
  pmc      = "PMC6122954"
}

@ARTICLE{Huk2018-ng,
  title    = "Beyond {Trial-Based} Paradigms: Continuous Behavior, Ongoing
              Neural Activity, and Natural Stimuli",
  author   = "Huk, Alexander and Bonnen, Kathryn and He, Biyu J",
  abstract = "The vast majority of experiments examining perception and
              behavior are conducted using experimental paradigms that adhere
              to a rigid trial structure: each trial consists of a brief and
              discrete series of events and is regarded as independent from all
              other trials. The assumptions underlying this structure ignore
              the reality that natural behavior is rarely discrete, brain
              activity follows multiple time courses that do not necessarily
              conform to the trial structure, and the natural environment has
              statistical structure and dynamics that exhibit long-range
              temporal correlation. Modern advances in statistical modeling and
              analysis offer tools that make it feasible for experiments to
              move beyond rigid independent and identically distributed trial
              structures. Here we review literature that serves as evidence for
              the feasibility and advantages of moving beyond trial-based
              paradigms to understand the neural basis of perception and
              cognition. Furthermore, we propose a synthesis of these efforts,
              integrating the characterization of natural stimulus properties
              with measurements of continuous neural activity and behavioral
              outputs within the framework of sensory-cognitive-motor loops.
              Such a framework provides a basis for the study of natural
              statistics, naturalistic tasks, and/or slow fluctuations in brain
              activity, which should provide starting points for important
              generalizations of analytical tools in neuroscience and
              subsequent progress in understanding the neural basis of
              perception and cognition.",
  journal  = "J. Neurosci.",
  volume   =  38,
  number   =  35,
  pages    = "7551--7558",
  month    =  aug,
  year     =  2018,
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "30037835",
  doi      = "10.1523/JNEUROSCI.1920-17.2018",
  pmc      = "PMC6113904"
}

@ARTICLE{Yoo2018-fd,
  title    = "Economic Choice as an Untangling of Options into Actions",
  author   = "Yoo, Seng Bum Michael and Hayden, Benjamin Yost",
  abstract = "We propose that economic choice can be understood as a gradual
              transformation from a domain of options to one of the actions. We
              draw an analogy with the idea of untangling information in the
              form vision system and propose that form vision and economic
              choice may be two aspects of a larger process that sculpts
              actions based on sensory inputs. From this viewpoint, choice
              results from the accumulated effect of repetitions of simple
              computations. These may consist primarily of relative valuations
              (evaluations relative to the value of rejection, perhaps in a
              manner akin to divisive normalization) applied to individual
              offers. With regard to economic choice, cortical brain regions
              differ primarily in their position and in what information they
              prioritize, and do not-with a few exceptions-have categorically
              distinct roles. Each region's specific contribution is determined
              largely by its inputs; thus, understanding connectivity is
              crucial for understanding choice. This view suggests that there
              is no single site of choice, that there is no meaningful
              distinction between pre- and post-decisionality, and that there
              is no explicit representation of value in the brain.",
  journal  = "Neuron",
  volume   =  99,
  number   =  3,
  pages    = "434--447",
  month    =  aug,
  year     =  2018,
  keywords = "Untangling; affordance competition; economic choice; functional
              neuroanatomy; value",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "30092213",
  doi      = "10.1016/j.neuron.2018.06.038"
}

@ARTICLE{Tao2014-bv,
  title    = "Flexible stop and double-cascaded stop to improve shock
              reliability of {MEMS} accelerometer",
  author   = "Tao, Yong-Kang and Liu, Yun-Feng and Dong, Jing-Xin",
  abstract = "Flexible stop could provide shock protection for MEMS
              accelerometer. By modeling and simulation, the paper studied the
              response of a closed-loop MEMS accelerometer with stop under
              shock of different amplitudes and pulse width. Contact force
              plays an important role and the shock response shows strong
              nonlinearity due to the contact mechanism. A kind of
              double-cascaded stop is proposed to mitigate high-frequency shock
              failure. MEMS accelerometers with flexible stop and with
              double-cascaded stop are both designed and fabricated based on
              SOG (silicon on glass) technology. Compared with shock tests of
              accelerometers with hard cylinder stop, flexible stop could
              withstand more than 1e4g shock with about 100$\mu$s pulse width.
              Double-cascaded stop is more robust to high frequency shock.",
  journal  = "Microelectron. Reliab.",
  volume   =  54,
  number   =  6,
  pages    = "1328--1337",
  month    =  jun,
  year     =  2014,
  issn     = "0026-2714",
  doi      = "10.1016/j.microrel.2014.02.011"
}

@ARTICLE{Huguenard2000-qu,
  title    = "Reliability of axonal propagation: the spike doesn't stop here",
  author   = "Huguenard, J R",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  97,
  number   =  17,
  pages    = "9349--9350",
  month    =  aug,
  year     =  2000,
  language = "en",
  issn     = "0027-8424",
  pmid     = "10944204",
  pmc      = "PMC34025"
}

@ARTICLE{Cox2000-ax,
  title    = "Action potentials reliably invade axonal arbors of rat
              neocortical neurons",
  author   = "Cox, C L and Denk, W and Tank, D W and Svoboda, K",
  abstract = "Neocortical pyramidal neurons have extensive axonal arborizations
              that make thousands of synapses. Action potentials can invade
              these arbors and cause calcium influx that is required for
              neurotransmitter release and excitation of postsynaptic targets.
              Thus, the regulation of action potential invasion in axonal
              branches might shape the spread of excitation in cortical neural
              networks. To measure the reliability and extent of action
              potential invasion into axonal arbors, we have used two-photon
              excitation laser scanning microscopy to directly image
              action-potential-mediated calcium influx in single varicosities
              of layer 2/3 pyramidal neurons in acute brain slices. Our data
              show that single action potentials or bursts of action potentials
              reliably invade axonal arbors over a range of developmental ages
              (postnatal 10-24 days) and temperatures (24 degrees C-30 degrees
              C). Hyperpolarizing current steps preceding action potential
              initiation, protocols that had previously been observed to
              produce failures of action potential propagation in cultured
              preparations, were ineffective in modulating the spread of action
              potentials in acute slices. Our data show that action potentials
              reliably invade the axonal arbors of neocortical pyramidal
              neurons. Failures in synaptic transmission must therefore
              originate downstream of action potential invasion. We also
              explored the function of modulators that inhibit presynaptic
              calcium influx. Consistent with previous studies, we find that
              adenosine reduces action-potential-mediated calcium influx in
              presynaptic terminals. This reduction was observed in all
              terminals tested, suggesting that some modulatory systems are
              expressed homogeneously in most terminals of the same neuron.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  97,
  number   =  17,
  pages    = "9724--9728",
  month    =  aug,
  year     =  2000,
  keywords = "synapses",
  language = "en",
  issn     = "0027-8424",
  pmid     = "10931955",
  doi      = "10.1073/pnas.170278697",
  pmc      = "PMC16932"
}

@ARTICLE{Brette_undated-lb,
  title    = "Theory of action potentials",
  author   = "Brette, Romain",
  keywords = "synapses"
}

@ARTICLE{Brunet2016-lp,
  title    = "From damage response to action potentials: early evolution of
              neural and contractile modules in stem eukaryotes",
  author   = "Brunet, Thibaut and Arendt, Detlev",
  abstract = "Eukaryotic cells convert external stimuli into membrane
              depolarization, which in turn triggers effector responses such as
              secretion and contraction. Here, we put forward an evolutionary
              hypothesis for the origin of the
              depolarization-contraction-secretion (DCS) coupling, the
              functional core of animal neuromuscular circuits. We propose that
              DCS coupling evolved in unicellular stem eukaryotes as part of an
              'emergency response' to calcium influx upon membrane rupture. We
              detail how this initial response was subsequently modified into
              an ancient mechanosensory-effector arc, present in the last
              eukaryotic common ancestor, which enabled contractile amoeboid
              movement that is widespread in extant eukaryotes. Elaborating on
              calcium-triggered membrane depolarization, we reason that the
              first action potentials evolved alongside the membrane of
              sensory-motile cilia, with the first voltage-sensitive
              sodium/calcium channels (Nav/Cav) enabling a fast and coordinated
              response of the entire cilium to mechanosensory stimuli. From the
              cilium, action potentials then spread across the entire cell,
              enabling global cellular responses such as concerted contraction
              in several independent eukaryote lineages. In animals, this
              process led to the invention of mechanosensory contractile cells.
              These gave rise to mechanosensory receptor cells, neurons and
              muscle cells by division of labour and can be regarded as the
              founder cell type of the nervous system.",
  journal  = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  volume   =  371,
  number   =  1685,
  pages    = "20150043",
  month    =  jan,
  year     =  2016,
  keywords = "action potentials; electrophysiology; evo-devo; evolution;
              musculature; nervous systems;synapses",
  language = "en",
  issn     = "0962-8436, 1471-2970",
  pmid     = "26598726",
  doi      = "10.1098/rstb.2015.0043",
  pmc      = "PMC4685582"
}

@ARTICLE{Burkhardt2017-rp,
  title    = "Evolutionary origin of synapses and neurons - Bridging the gap",
  author   = "Burkhardt, Pawel and Sprecher, Simon G",
  abstract = "The evolutionary origin of synapses and neurons is an enigmatic
              subject that inspires much debate. Non-bilaterian metazoans, both
              with and without neurons and their closest relatives already
              contain many components of the molecular toolkits for synapse
              functions. The origin of these components and their assembly into
              ancient synaptic signaling machineries are particularly important
              in light of recent findings on the phylogeny of non-bilaterian
              metazoans. The evolution of synapses and neurons are often
              discussed only from a metazoan perspective leaving a considerable
              gap in our understanding. By taking an integrative approach we
              highlight the need to consider different, but extremely relevant
              phyla and to include the closest unicellular relatives of
              metazoans, the ichthyosporeans, filastereans and
              choanoflagellates, to fully understand the evolutionary origin of
              synapses and neurons. This approach allows for a detailed
              understanding of when and how the first pre- and postsynaptic
              signaling machineries evolved.",
  journal  = "Bioessays",
  volume   =  39,
  number   =  10,
  month    =  oct,
  year     =  2017,
  keywords = "evolution; neuron; origin; protein-protein interactions;
              synapse;synapses",
  language = "en",
  issn     = "0265-9247, 1521-1878",
  pmid     = "28863228",
  doi      = "10.1002/bies.201700024"
}

@ARTICLE{Emes2012-ea,
  title    = "Evolution of synapse complexity and diversity",
  author   = "Emes, Richard D and Grant, Seth G N",
  abstract = "Proteomic studies of the composition of mammalian synapses have
              revealed a high degree of complexity. The postsynaptic and
              presynaptic terminals are molecular systems with highly organized
              protein networks producing emergent physiological and behavioral
              properties. The major classes of synapse proteins and their
              respective functions in intercellular communication and adaptive
              responses evolved in prokaryotes and eukaryotes prior to the
              origins of neurons in metazoa. In eukaryotes, the organization of
              individual proteins into multiprotein complexes comprising
              scaffold proteins, receptors, and signaling enzymes formed the
              precursor to the core adaptive machinery of the metazoan
              postsynaptic terminal. Multiplicative increases in the complexity
              of this protosynapse machinery secondary to genome duplications
              drove synaptic, neuronal, and behavioral novelty in vertebrates.
              Natural selection has constrained diversification in mammalian
              postsynaptic mechanisms and the repertoire of adaptive and innate
              behaviors. The evolution and organization of synapse proteomes
              underlie the origins and complexity of nervous systems and
              behavior.",
  journal  = "Annu. Rev. Neurosci.",
  volume   =  35,
  pages    = "111--131",
  year     =  2012,
  keywords = "synapses",
  language = "en",
  issn     = "0147-006X, 1545-4126",
  pmid     = "22715880",
  doi      = "10.1146/annurev-neuro-062111-150433"
}

@ARTICLE{Masi2015-wb,
  title    = "Electrical spiking in bacterial biofilms",
  author   = "Masi, Elisa and Ciszak, Marzena and Santopolo, Luisa and
              Frascella, Arcangela and Giovannetti, Luciana and Marchi,
              Emmanuela and Viti, Carlo and Mancuso, Stefano",
  abstract = "In nature, biofilms are the most common form of bacterial growth.
              In biofilms, bacteria display coordinated behaviour to perform
              specific functions. Here, we investigated electrical signalling
              as a possible driver in biofilm sociobiology. Using a
              multi-electrode array system that enables high spatio-temporal
              resolution, we studied the electrical activity in two
              biofilm-forming strains and one non-biofilm-forming strain. The
              action potential rates monitored during biofilm-forming bacterial
              growth exhibited a one-peak maximum with a long tail,
              corresponding to the highest biofilm development. This peak was
              not observed for the non-biofilm-forming strain, demonstrating
              that the intensity of the electrical activity was not linearly
              related to the bacterial density, but was instead correlated with
              biofilm formation. Results obtained indicate that the analysis of
              the spatio-temporal electrical activity of bacteria during
              biofilm formation can open a new frontier in the study of the
              emergence of collective microbial behaviour.",
  journal  = "J. R. Soc. Interface",
  volume   =  12,
  number   =  102,
  pages    = "20141036",
  month    =  jan,
  year     =  2015,
  keywords = "bacteria; biofilm; electrical spiking; multi-electrode array;
              sociobiology;synapses",
  language = "en",
  issn     = "1742-5689, 1742-5662",
  pmid     = "25392401",
  doi      = "10.1098/rsif.2014.1036",
  pmc      = "PMC4277093"
}

@ARTICLE{Ryan2009-qm,
  title    = "The origin and evolution of synapses",
  author   = "Ryan, Tom{\'a}s J and Grant, Seth G N",
  abstract = "Understanding the evolutionary origins of behaviour is a central
              aim in the study of biology and may lead to insights into human
              disorders. Synaptic transmission is observed in a wide range of
              invertebrate and vertebrate organisms and underlies their
              behaviour. Proteomic studies of the molecular components of the
              highly complex mammalian postsynaptic machinery point to an
              ancestral molecular machinery in unicellular organisms--the
              protosynapse--that existed before the evolution of metazoans and
              neurons, and hence challenges existing views on the origins of
              the brain. The phylogeny of the molecular components of the
              synapse provides a new model for studying synapse diversity and
              complexity, and their implications for brain evolution.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  10,
  number   =  10,
  pages    = "701--712",
  month    =  oct,
  year     =  2009,
  keywords = "synapses",
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "19738623",
  doi      = "10.1038/nrn2717"
}

@ARTICLE{Nusbaum2017-sy,
  title    = "Functional consequences of neuropeptide and small-molecule
              co-transmission",
  author   = "Nusbaum, Michael P and Blitz, Dawn M and Marder, Eve",
  abstract = "Colocalization of small-molecule and neuropeptide transmitters is
              common throughout the nervous system of all animals. The
              resulting co-transmission, which provides conjoint ionotropic
              ('classical') and metabotropic ('modulatory') actions, includes
              neuropeptide- specific aspects that are qualitatively different
              from those that result from metabotropic actions of
              small-molecule transmitter release. Here, we focus on the
              flexibility afforded to microcircuits by such co-transmission,
              using examples from various nervous systems. Insights from such
              studies indicate that co-transmission mediated even by a single
              neuron can configure microcircuit activity via an array of
              contributing mechanisms, operating on multiple timescales, to
              enhance both behavioural flexibility and robustness.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  18,
  number   =  7,
  pages    = "389--403",
  month    =  jul,
  year     =  2017,
  keywords = "synapses",
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "28592905",
  doi      = "10.1038/nrn.2017.56",
  pmc      = "PMC5547741"
}

@ARTICLE{Moita2004-fi,
  title     = "Putting fear in its place: remapping of hippocampal place cells
               during fear conditioning",
  author    = "Moita, Marta A P and Rosis, Svetlana and Zhou, Yu and LeDoux,
               Joseph E and Blair, Hugh T",
  abstract  = "We recorded hippocampal place cells in two spatial environments:
               a training environment in which rats underwent fear conditioning
               and a neutral control environment. Fear conditioning caused many
               place cells to alter (or remap) their preferred firing locations
               in the training environment, whereas most cells remained stable
               in the control environment. This finding indicates that aversive
               reinforcement can induce place cell remapping even when the
               environment itself remains unchanged. Furthermore, contextual
               fear conditioning caused significantly more remapping of place
               cells than auditory fear conditioning, suggesting that place
               cell remapping was related to the rat's learned fear of the
               environment. These results suggest that one possible function of
               place cell remapping may be to generate new spatial
               representations of a single environment, which could help the
               animal to discriminate among different motivational contexts
               within that environment.",
  journal   = "J. Neurosci.",
  publisher = "Soc Neuroscience",
  volume    =  24,
  number    =  31,
  pages     = "7015--7023",
  month     =  aug,
  year      =  2004,
  language  = "en",
  issn      = "0270-6474, 1529-2401",
  pmid      = "15295037",
  doi       = "10.1523/JNEUROSCI.5492-03.2004"
}

@ARTICLE{Buzsaki2018-je,
  title    = "Space and Time: The Hippocampus as a Sequence Generator",
  author   = "Buzs{\'a}ki, Gy{\"o}rgy and Tingley, David",
  abstract = "Neural computations are often compared to instrument-measured
              distance or duration, and such relationships are interpreted by a
              human observer. However, neural circuits do not depend on
              human-made instruments but perform computations relative to an
              internally defined rate-of-change. While neuronal correlations
              with external measures, such as distance or duration, can be
              observed in spike rates or other measures of neuronal activity,
              what matters for the brain is how such activity patterns are
              utilized by downstream neural observers. We suggest that
              hippocampal operations can be described by the sequential
              activity of neuronal assemblies and their internally defined rate
              of change without resorting to the concept of space or time.",
  journal  = "Trends Cogn. Sci.",
  volume   =  22,
  number   =  10,
  pages    = "853--869",
  month    =  oct,
  year     =  2018,
  keywords = "place cells; time cells; theta oscillation; phase coding; lateral
              septum",
  issn     = "1364-6613",
  doi      = "10.1016/j.tics.2018.07.006"
}

@UNPUBLISHED{Grundemann2018-yn,
  title    = "Amygdala neuronal ensembles dynamically encode behavioral states",
  author   = "Gr{\"u}ndemann, Jan and Bitterman, Yael and Lu, Tingjia and
              Krabbe, Sabine and Grewe, Benjamin F and Schnitzer, Mark J and
              L{\"u}thi, Andreas",
  abstract = "Internal states, including affective or homeostatic states, are
              important behavioral motivators. The amygdala is a key brain
              region involved in the regulation of motivated behaviors, yet how
              distinct internal states are represented in amygdala circuits is
              not known. Here, by imaging somatic neural calcium dynamics in
              freely moving mice, we demonstrate that changes in the relative
              activity levels of two major, non-overlapping populations of
              principal neurons in the basal nucleus of the amygdala (BA)
              predict switches between exploratory and anxiety-like or
              defensive behavioral states across different environments.
              Moreover, we found that the amygdala widely broadcasts internal
              state information via several output pathways to larger brain
              networks, and that sensory responses in the BA were not
              correlated with behavioral states. Our data indicate that the
              brain processes external stimuli and internal states in an
              orthogonal manner, which may facilitate rapid and flexible
              selection of appropriate, state-dependent behavioral responses.",
  journal  = "bioRxiv",
  pages    = "425736",
  month    =  sep,
  year     =  2018,
  language = "en",
  doi      = "10.1101/425736"
}

@ARTICLE{Han2018-vj,
  title    = "A Neural Circuit for {Gut-Induced} Reward",
  author   = "Han, Wenfei and Tellez, Luis A and Perkins, Matthew H and Perez,
              Isaac O and Qu, Taoran and Ferreira, Jozelia and Ferreira,
              Tatiana L and Quinn, Daniele and Liu, Zhong-Wu and Gao, Xiao-Bing
              and Kaelberer, Melanie M and Boh{\'o}rquez, Diego V and
              Shammah-Lagnado, Sara J and de Lartigue, Guillaume and de Araujo,
              Ivan E",
  abstract = "The gut is now recognized as a major regulator of motivational
              and emotional states. However, the relevant gut-brain neuronal
              circuitry remains unknown. We show that optical activation of
              gut-innervating vagal sensory neurons recapitulates the hallmark
              effects of stimulating brain reward neurons. Specifically, right,
              but not left, vagal sensory ganglion activation sustained
              self-stimulation behavior, conditioned both flavor and place
              preferences, and induced dopamine release from Substantia nigra.
              Cell-specific transneuronal tracing revealed asymmetric ascending
              pathways of vagal origin throughout the CNS. In particular,
              transneuronal labeling identified the glutamatergic neurons of
              the dorsolateral parabrachial region as the obligatory relay
              linking the right vagal sensory ganglion to dopamine cells in
              Substantia nigra. Consistently, optical activation of
              parabrachio-nigral projections replicated the rewarding effects
              of right vagus excitation. Our findings establish the vagal
              gut-to-brain axis as an integral component of the neuronal reward
              pathway. They also suggest novel vagal stimulation approaches to
              affective disorders.",
  journal  = "Cell",
  month    =  sep,
  year     =  2018,
  keywords = "dopamine; gut-brain axis; reward; vagus nerve",
  language = "en",
  issn     = "0092-8674, 1097-4172",
  pmid     = "30245012",
  doi      = "10.1016/j.cell.2018.08.049"
}

@UNPUBLISHED{Ahilan2018-qy,
  title    = "Forgetful inference in a sophisticated world model",
  author   = "Ahilan, Sanjeevan and Solomon, Rebecca B and Breton,
              Yannick-Andr{\'e} and Conover, Kent and Niyogi, Ritwik K and
              Shizgal, Peter and Dayan, Peter",
  abstract = "Humans and other animals are able to discover underlying
              statistical structure in their environments and exploit it to
              achieve efficient and effective performance. However, such
              structure is often difficult to learn and use because it is
              obscure, involving long-range temporal dependencies. Here, we
              analysed behavioural data from an extended experiment with rats,
              showing that the subjects learned the underlying statistical
              structure, albeit suffering at times from immediate inferential
              imperfections as to their current state within it. We accounted
              for their behaviour using a Hidden Markov Model, in which recent
              observations are integrated with the recollections of an
              imperfect memory. We found that over the course of training,
              subjects came to track their progress through the task more
              accurately, a change that our model largely attributed to
              decreased forgetting. This 9learning to remember9 decreased
              reliance on recent observations, which may be misleading, in
              favour of a longer-term memory.",
  journal  = "bioRxiv",
  pages    = "419317",
  month    =  sep,
  year     =  2018,
  language = "en",
  doi      = "10.1101/419317"
}

@ARTICLE{Pandarinath2018-mm,
  title    = "Inferring single-trial neural population dynamics using
              sequential auto-encoders",
  author   = "Pandarinath, Chethan and O'Shea, Daniel J and Collins, Jasmine
              and Jozefowicz, Rafal and Stavisky, Sergey D and Kao, Jonathan C
              and Trautmann, Eric M and Kaufman, Matthew T and Ryu, Stephen I
              and Hochberg, Leigh R and Henderson, Jaimie M and Shenoy, Krishna
              V and Abbott, L F and Sussillo, David",
  abstract = "Neuroscience is experiencing a revolution in which simultaneous
              recording of thousands of neurons is revealing population
              dynamics that are not apparent from single-neuron responses. This
              structure is typically extracted from data averaged across many
              trials, but deeper understanding requires studying phenomena
              detected in single trials, which is challenging due to incomplete
              sampling of the neural population, trial-to-trial variability,
              and fluctuations in action potential timing. We introduce latent
              factor analysis via dynamical systems, a deep learning method to
              infer latent dynamics from single-trial neural spiking data. When
              applied to a variety of macaque and human motor cortical
              datasets, latent factor analysis via dynamical systems accurately
              predicts observed behavioral variables, extracts precise firing
              rate estimates of neural dynamics on single trials, infers
              perturbations to those dynamics that correlate with behavioral
              choices, and combines data from non-overlapping recording
              sessions spanning months to improve inference of underlying
              dynamics.",
  journal  = "Nat. Methods",
  month    =  sep,
  year     =  2018,
  language = "en",
  issn     = "1548-7091, 1548-7105",
  pmid     = "30224673",
  doi      = "10.1038/s41592-018-0109-9"
}

@UNPUBLISHED{Low2018-gr,
  title    = "Probing variability in a cognitive map using manifold inference
              from neural dynamics",
  author   = "Low, Ryan J and Lewallen, Sam and Aronov, Dmitriy and Nevers,
              Rhino and Tank, David W",
  abstract = "Hippocampal neurons fire selectively in local behavioral contexts
              such as the position in an environment or phase of a task, and
              are thought to form a cognitive map of task-relevant variables.
              However, their activity varies over repeated behavioral
              conditions, such as different runs through the same position or
              repeated trials. Although widely observed across the brain, such
              variability is not well understood, and could reflect noise or
              structure, such as the encoding of additional cognitive
              information. Here, we introduce a conceptual model to explain
              variability in terms of underlying, population-level structure in
              single-trial neural activity. To test this model, we developed a
              novel unsupervised learning algorithm incorporating temporal
              dynamics, in order to characterize population activity as a
              trajectory on a nonlinear manifold--a space of possible network
              states. The manifold9s structure captures correlations between
              neurons and temporal relationships between states, constraints
              arising from underlying network architecture and inputs. Using
              measurements of activity over time but no information about
              exogenous behavioral variables, we recovered hippocampal activity
              manifolds during spatial and non-spatial cognitive tasks in rats.
              Manifolds were low dimensional and smoothly encoded task-related
              variables, but contained an extra dimension reflecting
              information beyond the measured behavioral variables. Consistent
              with our model, neurons fired as a function of overall network
              state, and fluctuations in their activity across trials
              corresponded to variation in the underlying trajectory on the
              manifold. In particular, the extra dimension allowed the system
              to take different trajectories despite repeated behavioral
              conditions. Furthermore, the trajectory could temporarily
              decouple from current behavioral conditions and traverse
              neighboring manifold points corresponding to past, future, or
              nearby behavioral states. Our results suggest that trial-to-trial
              variability in the hippocampus is structured, and may reflect the
              operation of internal cognitive processes. The manifold structure
              of population activity is well-suited for organizing information
              to support memory, planning, and reinforcement learning. In
              general, our approach could find broader use in probing the
              organization and computational role of circuit dynamics in other
              brain regions.",
  journal  = "bioRxiv",
  pages    = "418939",
  month    =  sep,
  year     =  2018,
  language = "en",
  doi      = "10.1101/418939"
}

@ARTICLE{Wolff2018-ir,
  title    = "The promise and perils of causal circuit manipulations",
  author   = "Wolff, Steffen Be and {\"O}lveczky, Bence P",
  abstract = "The development of increasingly sophisticated methods for
              recording and manipulating neural activity is revolutionizing
              neuroscience. By probing how activity patterns in different types
              of neurons and circuits contribute to behavior, these tools can
              help inform mechanistic models of brain function and explain the
              roles of distinct circuit elements. However, in systems where
              functions are distributed over large networks, interpreting
              causality experiments can be challenging. Here we review common
              assumptions underlying circuit manipulations in behaving animals
              and discuss the strengths and limitations of different
              approaches.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  49,
  pages    = "84--94",
  month    =  apr,
  year     =  2018,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "29414070",
  doi      = "10.1016/j.conb.2018.01.004",
  pmc      = "PMC5957484"
}

@ARTICLE{Dhawale2017-yp,
  title    = "Automated long-term recording and analysis of neural activity in
              behaving animals",
  author   = "Dhawale, Ashesh K and Poddar, Rajesh and Wolff, Steffen Be and
              Normand, Valentin A and Kopelowitz, Evi and {\"O}lveczky, Bence P",
  abstract = "Addressing how neural circuits underlie behavior is routinely
              done by measuring electrical activity from single neurons in
              experimental sessions. While such recordings yield snapshots of
              neural dynamics during specified tasks, they are ill-suited for
              tracking single-unit activity over longer timescales relevant for
              most developmental and learning processes, or for capturing
              neural dynamics across different behavioral states. Here we
              describe an automated platform for continuous long-term
              recordings of neural activity and behavior in freely moving
              rodents. An unsupervised algorithm identifies and tracks the
              activity of single units over weeks of recording, dramatically
              simplifying the analysis of large datasets. Months-long
              recordings from motor cortex and striatum made and analyzed with
              our system revealed remarkable stability in basic neuronal
              properties, such as firing rates and inter-spike interval
              distributions. Interneuronal correlations and the representation
              of different movements and behaviors were similarly stable. This
              establishes the feasibility of high-throughput long-term
              extracellular recordings in behaving animals.",
  journal  = "Elife",
  volume   =  6,
  month    =  sep,
  year     =  2017,
  keywords = "behavior; neural recordings; neuroscience; rat; systems
              neuroscience",
  language = "en",
  issn     = "2050-084X",
  pmid     = "28885141",
  doi      = "10.7554/eLife.27702",
  pmc      = "PMC5619984"
}

@ARTICLE{Doya2002-bl,
  title     = "Multiple model-based reinforcement learning",
  author    = "Doya, Kenji and Samejima, Kazuyuki and Katagiri, Ken-Ichi and
               Kawato, Mitsuo",
  abstract  = "We propose a modular reinforcement learning architecture for
               nonlinear, nonstationary control tasks, which we call multiple
               model-based reinforcement learning (MMRL). The basic idea is to
               decompose a complex task into multiple domains in space and time
               based on the predictability of the environmental dynamics. The
               system is composed of multiple modules, each of which consists
               of a state prediction model and a reinforcement learning
               controller. The ``responsibility signal,'' which is given by the
               softmax function of the prediction errors, is used to weight the
               outputs of multiple modules, as well as to gate the learning of
               the prediction models and the reinforcement learning
               controllers. We formulate MMRL for both discrete-time,
               finite-state case and continuous-time, continuous-state case.
               The performance of MMRL was demonstrated for discrete case in a
               nonstationary hunting task in a grid world and for continuous
               case in a nonlinear, nonstationary control task of swinging up a
               pendulum with variable physical parameters.",
  journal   = "Neural Comput.",
  publisher = "MIT Press",
  volume    =  14,
  number    =  6,
  pages     = "1347--1369",
  month     =  jun,
  year      =  2002,
  language  = "en",
  issn      = "0899-7667",
  pmid      = "12020450",
  doi       = "10.1162/089976602753712972"
}

@ARTICLE{Daw2005-hs,
  title     = "Uncertainty-based competition between prefrontal and
               dorsolateral striatal systems for behavioral control",
  author    = "Daw, Nathaniel D and Niv, Yael and Dayan, Peter",
  abstract  = "A broad range of neural and behavioral data suggests that the
               brain contains multiple systems for behavioral choice, including
               one associated with prefrontal cortex and another with
               dorsolateral striatum. However, such a surfeit of control raises
               an additional choice problem: how to arbitrate between the
               systems when they disagree. Here, we consider dual-action choice
               systems from a normative perspective, using the computational
               theory of reinforcement learning. We identify a key trade-off
               pitting computational simplicity against the flexible and
               statistically efficient use of experience. The trade-off is
               realized in a competition between the dorsolateral striatal and
               prefrontal systems. We suggest a Bayesian principle of
               arbitration between them according to uncertainty, so each
               controller is deployed when it should be most accurate. This
               provides a unifying account of a wealth of experimental evidence
               about the factors favoring dominance by either system.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  8,
  number    =  12,
  pages     = "1704--1711",
  month     =  dec,
  year      =  2005,
  language  = "en",
  issn      = "1097-6256",
  pmid      = "16286932",
  doi       = "10.1038/nn1560"
}

@ARTICLE{Foster2017-ss,
  title     = "Replay Comes of Age",
  author    = "Foster, David J",
  abstract  = "Hippocampal place cells take part in sequenced patterns of
               reactivation after behavioral experience, known as replay. Since
               replay was first reported, nearly 20 years ago, many new results
               have been found, necessitating revision of the original
               interpretations. We review some of these results with a focus on
               the phenomenology of replay.",
  journal   = "Annu. Rev. Neurosci.",
  publisher = "annualreviews.org",
  volume    =  40,
  pages     = "581--602",
  month     =  jul,
  year      =  2017,
  keywords  = "hippocampus; memory; place cell; replay",
  language  = "en",
  issn      = "0147-006X, 1545-4126",
  pmid      = "28772098",
  doi       = "10.1146/annurev-neuro-072116-031538"
}

@ARTICLE{Barron2013-ho,
  title     = "Online evaluation of novel choices by simultaneous
               representation of multiple memories",
  author    = "Barron, Helen C and Dolan, Raymond J and Behrens, Timothy E J",
  abstract  = "Prior experience is critical for decision-making. It enables
               explicit representation of potential outcomes and provides
               training to valuation mechanisms. However, we can also make
               choices in the absence of prior experience by merely imagining
               the consequences of a new experience. Using functional magnetic
               resonance imaging repetition suppression in humans, we examined
               how neuronal representations of novel rewards can be constructed
               and evaluated. A likely novel experience was constructed by
               invoking multiple independent memories in hippocampus and medial
               prefrontal cortex. This construction persisted for only a short
               time period, during which new associations were observed between
               the memories for component items. Together, these findings
               suggest that, in the absence of direct experience, coactivation
               of multiple relevant memories can provide a training signal to
               the valuation system that allows the consequences of new
               experiences to be imagined and acted on.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  16,
  number    =  10,
  pages     = "1492--1498",
  month     =  oct,
  year      =  2013,
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "24013592",
  doi       = "10.1038/nn.3515",
  pmc       = "PMC4001211"
}

@ARTICLE{Dragoi2011-ty,
  title     = "Preplay of future place cell sequences by hippocampal cellular
               assemblies",
  author    = "Dragoi, George and Tonegawa, Susumu",
  abstract  = "During spatial exploration, hippocampal neurons show a
               sequential firing pattern in which individual neurons fire
               specifically at particular locations along the animal's
               trajectory (place cells). According to the dominant model of
               hippocampal cell assembly activity, place cell firing order is
               established for the first time during exploration, to encode the
               spatial experience, and is subsequently replayed during rest or
               slow-wave sleep for consolidation of the encoded experience.
               Here we report that temporal sequences of firing of place cells
               expressed during a novel spatial experience occurred on a
               significant number of occasions during the resting or sleeping
               period preceding the experience. This phenomenon, which is
               called preplay, occurred in disjunction with sequences of replay
               of a familiar experience. These results suggest that internal
               neuronal dynamics during resting or sleep organize hippocampal
               cellular assemblies into temporal sequences that contribute to
               the encoding of a related novel experience occurring in the
               future.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  469,
  number    =  7330,
  pages     = "397--401",
  month     =  jan,
  year      =  2011,
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "21179088",
  doi       = "10.1038/nature09633",
  pmc       = "PMC3104398"
}

@ARTICLE{Wu2014-ud,
  title    = "Hippocampal replay captures the unique topological structure of a
              novel environment",
  author   = "Wu, Xiaojing and Foster, David J",
  abstract = "Hippocampal place-cell replay has been proposed as a fundamental
              mechanism of learning and memory, which might support
              navigational learning and planning. An important hypothesis of
              relevance to these proposed functions is that the information
              encoded in replay should reflect the topological structure of
              experienced environments; that is, which places in the
              environment are connected with which others. Here we report
              several attributes of replay observed in rats exploring a novel
              forked environment that support the hypothesis. First, we
              observed that overlapping replays depicting divergent
              trajectories through the fork recruited the same population of
              cells with the same firing rates to represent the common portion
              of the trajectories. Second, replay tended to be directional and
              to flip the represented direction at the fork. Third,
              replay-associated sharp-wave-ripple events in the local field
              potential exhibited substructure that mapped onto the maze
              topology. Thus, the spatial complexity of our recording
              environment was accurately captured by replay: the underlying
              neuronal activities reflected the bifurcating shape, and both
              directionality and associated ripple structure reflected the
              segmentation of the maze. Finally, we observed that replays
              occurred rapidly after small numbers of experiences. Our results
              suggest that hippocampal replay captures learned information
              about environmental topology to support a role in navigation.",
  journal  = "J. Neurosci.",
  volume   =  34,
  number   =  19,
  pages    = "6459--6469",
  month    =  may,
  year     =  2014,
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "24806672",
  doi      = "10.1523/JNEUROSCI.3414-13.2014",
  pmc      = "PMC4012305"
}

@ARTICLE{Gupta2010-gx,
  title     = "Hippocampal replay is not a simple function of experience",
  author    = "Gupta, Anoopum S and van der Meer, Matthijs A A and Touretzky,
               David S and Redish, A David",
  abstract  = "Replay of behavioral sequences in the hippocampus during sharp
               wave ripple complexes (SWRs) provides a potential mechanism for
               memory consolidation and the learning of knowledge structures.
               Current hypotheses imply that replay should straightforwardly
               reflect recent experience. However, we find these hypotheses to
               be incompatible with the content of replay on a task with two
               distinct behavioral sequences (A and B). We observed forward and
               backward replay of B even when rats had been performing A for
               >10 min. Furthermore, replay of nonlocal sequence B occurred
               more often when B was infrequently experienced. Neither forward
               nor backward sequences preferentially represented highly
               experienced trajectories within a session. Additionally, we
               observed the construction of never-experienced novel-path
               sequences. These observations challenge the idea that sequence
               activation during SWRs is a simple replay of recent experience.
               Instead, replay reflected all physically available trajectories
               within the environment, suggesting a potential role in active
               learning and maintenance of the cognitive map.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  65,
  number    =  5,
  pages     = "695--705",
  month     =  mar,
  year      =  2010,
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "20223204",
  doi       = "10.1016/j.neuron.2010.01.034",
  pmc       = "PMC4460981"
}

@ARTICLE{Johnson2007-ri,
  title     = "Integrating hippocampus and striatum in decision-making",
  author    = "Johnson, Adam and van der Meer, Matthijs A A and Redish, A David",
  abstract  = "Learning and memory and navigation literatures emphasize
               interactions between multiple memory systems: a flexible,
               planning-based system and a rigid, cached-value system. This has
               profound implications for decision-making. Recent
               conceptualizations of flexible decision-making employ
               prospection and projection arising from a network involving the
               hippocampus. Recent recordings from rodent hippocampus in
               decision-making situations have found transient forward-shifted
               representations. Evaluation of that prediction and subsequent
               action-selection probably occurs downstream (e.g. in
               orbitofrontal cortex, in ventral and dorsomedial striatum).
               Classically, striatum has been identified as a crucial component
               of the less-flexible, incremental system. Current evidence,
               however, suggests that striatum is involved in both flexible and
               stimulus-response decision-making, with dorsolateral striatum
               involved in stimulus-response strategies and ventral and
               dorsomedial striatum involved in goal-directed strategies.",
  journal   = "Curr. Opin. Neurobiol.",
  publisher = "Elsevier",
  volume    =  17,
  number    =  6,
  pages     = "692--697",
  month     =  dec,
  year      =  2007,
  language  = "en",
  issn      = "0959-4388",
  pmid      = "18313289",
  doi       = "10.1016/j.conb.2008.01.003",
  pmc       = "PMC3774291"
}

@MISC{noauthor_undated-zp,
  institution = "bioRxiv",
  doi         = "10.1101/446575"
}

@TECHREPORT{Kahneman1977-iq,
  title     = "Prospect Theory. An Analysis of Decision Making Under Risk",
  author    = "Kahneman, Daniel and Tversky, Amos",
  publisher = "Defense Technical Information Center",
  month     =  apr,
  year      =  1977,
  doi       = "10.21236/ADA045771"
}

@MISC{noauthor_undated-bu,
  institution = "bioRxiv",
  doi         = "10.1101/445643"
}

@ARTICLE{Reiter2018-gu,
  title    = "Elucidating the control and development of skin patterning in
              cuttlefish",
  author   = "Reiter, Sam and H{\"u}lsdunk, Philipp and Woo, Theodosia and
              Lauterbach, Marcel A and Eberle, Jessica S and Akay, Leyla Anne
              and Longo, Amber and Meier-Credo, Jakob and Kretschmer, Friedrich
              and Langer, Julian D and Kaschube, Matthias and Laurent, Gilles",
  abstract = "Few animals provide a readout that is as objective of their
              perceptual state as camouflaging cephalopods. Their skin display
              system includes an extensive array of pigment cells
              (chromatophores), each expandable by radial muscles controlled by
              motor neurons. If one could track the individual expansion states
              of the chromatophores, one would obtain a quantitative
              description-and potentially even a neural description by proxy-of
              the perceptual state of the animal in real time. Here we present
              the use of computational and analytical methods to achieve this
              in behaving animals, quantifying the states of tens of thousands
              of chromatophores at sixty frames per second, at single-cell
              resolution, and over weeks. We infer a statistical hierarchy of
              motor control, reveal an underlying low-dimensional structure to
              pattern dynamics and uncover rules that govern the development of
              skin patterns. This approach provides an objective description of
              complex perceptual behaviour, and a powerful means to uncover the
              organizational principles that underlie the function, dynamics
              and morphogenesis of neural systems.",
  journal  = "Nature",
  volume   =  562,
  number   =  7727,
  pages    = "361--366",
  month    =  oct,
  year     =  2018,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "30333578",
  doi      = "10.1038/s41586-018-0591-3"
}

@ARTICLE{Lee2017-fw,
  title    = "Flexibility to contingency changes distinguishes habitual and
              goal-directed strategies in humans",
  author   = "Lee, Julie J and Keramati, Mehdi",
  abstract = "Decision-making in the real world presents the challenge of
              requiring flexible yet prompt behavior, a balance that has been
              characterized in terms of a trade-off between a slower,
              prospective goal-directed model-based (MB) strategy and a fast,
              retrospective habitual model-free (MF) strategy. Theory predicts
              that flexibility to changes in both reward values and transition
              contingencies can determine the relative influence of the two
              systems in reinforcement learning, but few studies have
              manipulated the latter. Therefore, we developed a novel two-level
              contingency change task in which transition contingencies between
              states change every few trials; MB and MF control predict
              different responses following these contingency changes, allowing
              their relative influence to be inferred. Additionally, we
              manipulated the rate of contingency changes in order to determine
              whether contingency change volatility would play a role in
              shifting subjects between a MB and MF strategy. We found that
              human subjects employed a hybrid MB/MF strategy on the task,
              corroborating the parallel contribution of MB and MF systems in
              reinforcement learning. Further, subjects did not remain at one
              level of MB/MF behaviour but rather displayed a shift towards
              more MB behavior over the first two blocks that was not
              attributable to the rate of contingency changes but rather to the
              extent of training. We demonstrate that flexibility to
              contingency changes can distinguish MB and MF strategies, with
              human subjects utilizing a hybrid strategy that shifts towards
              more MB behavior over blocks, consequently corresponding to a
              higher payoff.",
  journal  = "PLoS Comput. Biol.",
  volume   =  13,
  number   =  9,
  pages    = "e1005753",
  month    =  sep,
  year     =  2017,
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "28957319",
  doi      = "10.1371/journal.pcbi.1005753",
  pmc      = "PMC5634647"
}

@ARTICLE{Najafi2018-vk,
  title     = "Perceptual {Decision-Making}: A Field in the Midst of a
               Transformation",
  author    = "Najafi, Farzaneh and Churchland, Anne K",
  abstract  = "Major changes are underway in the field of perceptual
               decision-making. Single-neuron studies have given way to
               population recordings with identified cell types, traditional
               analyses have been extended to accommodate these large and
               diverse collections of neurons, and novel methods of neural
               disruption have provided insights about causal circuits.
               Further, the field has expanded to include multiple new species:
               rodents and invertebrates, for example, have been instrumental
               in demonstrating the importance of internal state on neural
               responses. Finally, a renewed interest in ethological stimuli
               prompted development of new behaviors, frequently analyzed by
               new, automated movement tracking methods. Taken together, these
               advances constitute a seismic shift in both our approach and
               understanding of how incoming sensory signals are used to guide
               decisions.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  100,
  number    =  2,
  pages     = "453--462",
  month     =  oct,
  year      =  2018,
  keywords  = "decision-making; cognition; mice; imaging; neural data analysis;
               computational models",
  language  = "en",
  issn      = "0896-6273",
  doi       = "10.1016/j.neuron.2018.10.017"
}

@ARTICLE{Yan2017-hj,
  title    = "Network control principles predict neuron function in the
              Caenorhabditis elegans connectome",
  author   = "Yan, Gang and V{\'e}rtes, Petra E and Towlson, Emma K and Chew,
              Yee Lian and Walker, Denise S and Schafer, William R and
              Barab{\'a}si, Albert-L{\'a}szl{\'o}",
  abstract = "Recent studies on the controllability of complex systems offer a
              powerful mathematical framework to systematically explore the
              structure-function relationship in biological, social, and
              technological networks. Despite theoretical advances, we lack
              direct experimental proof of the validity of these widely used
              control principles. Here we fill this gap by applying a control
              framework to the connectome of the nematode Caenorhabditis
              elegans, allowing us to predict the involvement of each C.
              elegans neuron in locomotor behaviours. We predict that control
              of the muscles or motor neurons requires 12 neuronal classes,
              which include neuronal groups previously implicated in locomotion
              by laser ablation, as well as one previously uncharacterized
              neuron, PDB. We validate this prediction experimentally, finding
              that the ablation of PDB leads to a significant loss of
              dorsoventral polarity in large body bends. Importantly, control
              principles also allow us to investigate the involvement of
              individual neurons within each neuronal class. For example, we
              predict that, within the class of DD motor neurons, only three
              (DD04, DD05, or DD06) should affect locomotion when ablated
              individually. This prediction is also confirmed; single cell
              ablations of DD04 or DD05 specifically affect posterior body
              movements, whereas ablations of DD02 or DD03 do not. Our
              predictions are robust to deletions of weak connections, missing
              connections, and rewired connections in the current connectome,
              indicating the potential applicability of this analytical
              framework to larger and less well-characterized connectomes.",
  journal  = "Nature",
  volume   =  550,
  number   =  7677,
  pages    = "519--523",
  month    =  oct,
  year     =  2017,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "29045391",
  doi      = "10.1038/nature24056",
  pmc      = "PMC5710776"
}

@ARTICLE{Webb2009-nq,
  title     = "Animals Versus Animats: Or Why Not Model the Real Iguana?",
  author    = "Webb, Barbara",
  abstract  = "The overlapping fields of adaptive behavior and artificial life
               are often described as novel approaches to biology. They focus
               attention on bottom-up explanations and how lifelike phenomena
               can result from relatively simple systems interacting
               dynamically with their environments. They are also characterized
               by the use of synthetic methodologies, that is, building
               artificial systems as a means of exploring these ideas. Two
               differing approaches can be distinguished: building models of
               specific animal systems and assessing them within complete
               behavior?environment loops; and exploring the behavior of
               invented artificial animals, often called animats, under similar
               conditions. An obvious question about the latter approach is,
               how can we learn about real biology from simulation of
               non-existent animals? In this article I will argue, first, that
               animat research, to the extent that it is relevant to biology,
               should also be considered as model building. Animat simulations
               do, implicitly, represent hypotheses about, and should be
               evaluated by comparison to, animals. Casting this research in
               terms of invented agents serves only to limit the ability to
               draw useful conclusions from it by deflecting or deferring any
               serious comparisons of the model mechanisms and results with
               real biological systems. Claims that animat models are meant to
               be existence proofs, idealizations, or represent general
               problems in biology do not make these models qualitatively
               different from more conventional models of specific animals, nor
               undermine the ultimate requirement to justify this work by
               making concrete comparisons with empirical data. It is thus
               suggested that we will learn more by choosing real, and not
               made-up, targets for our models.",
  journal   = "Adapt. Behav.",
  publisher = "SAGE Publications Ltd STM",
  volume    =  17,
  number    =  4,
  pages     = "269--286",
  month     =  aug,
  year      =  2009,
  issn      = "1059-7123",
  doi       = "10.1177/1059712309339867"
}

@ARTICLE{Webb2001-kg,
  title    = "Can robots make good models of biological behaviour?",
  author   = "Webb, B",
  abstract = "UNLABELLED: How should biological behaviour be modelled? A
              relatively new approach is to investigate problems in
              neuroethology by building physical robot models of biological
              sensorimotor systems. The explication and justification of this
              approach are here placed within a framework for describing and
              comparing models in the behavioural and biological sciences.
              First, simulation models--the representation of a hypothesis
              about a target system--are distinguished from several other
              relationships also termed ``modelling'' in discussions of
              scientific explanation. Seven dimensions on which simulation
              models can differ are defined and distinctions between them
              discussed: 1. RELEVANCE: whether the model tests and generates
              hypotheses applicable to biology. 2. Level: the elemental units
              of the model in the hierarchy from atoms to societies. 3.
              Generality: the range of biological systems the model can
              represent. 4. Abstraction: the complexity, relative to the
              target, or amount of detail included in the model. 5. Structural
              accuracy: how well the model represents the actual mechanisms
              underlying the behaviour. 6. Performance match: to what extent
              the model behaviour matches the target behaviour. 7. Medium: the
              physical basis by which the model is implemented. No specific
              position in the space of models thus defined is the only correct
              one, but a good modelling methodology should be explicit about
              its position and the justification for that position. It is
              argued that in building robot models biological relevance is more
              effective than loose biological inspiration; multiple levels can
              be integrated; that generality cannot be assumed but might emerge
              from studying specific instances; abstraction is better done by
              simplification than idealisation; accuracy can be approached
              through iterations of complete systems; that the model should be
              able to match and predict target behaviour; and that a physical
              medium can have significant advantages. These arguments reflect
              the view that biological behaviour needs to be studied and
              modelled in context, that is, in terms of the real problems faced
              by real animals in real environments.",
  journal  = "Behav. Brain Sci.",
  volume   =  24,
  number   =  6,
  pages    = "1033--50; discussion 1050--94",
  month    =  dec,
  year     =  2001,
  language = "en",
  issn     = "0140-525X",
  pmid     = "12412325"
}

@ARTICLE{Kirk_undated-qt,
  title    = "A {TEST-DRIVEN} {APPROACHPython}",
  author   = "Kirk, Matthew",
  keywords = "Python books"
}

@ARTICLE{By_undated-ov,
  title    = "{ESSENTIAL} {TOOLS} {FOR} {WORKING} {WITH} {DATA}",
  author   = "By, Powered",
  keywords = "Python books"
}

@ARTICLE{Ramalho_undated-wv,
  title    = "{CLEAR}, {CONCISE}, {AND} {EFFECTIVE} {PROGRAMMING}",
  author   = "Ramalho, Luciano",
  keywords = "Python books"
}

@MISC{noauthor_undated-wa,
  title    = "webscrapingwithpython.pdf",
  keywords = "Python books"
}

@MISC{noauthor_undated-pt,
  title    = "twistednetworkprogrammingessentials.pdf",
  keywords = "Python books"
}

@MISC{noauthor_undated-jh,
  title    = "naturallanguageprocessingwithpython.pdf",
  keywords = "Python books"
}

@MISC{noauthor_undated-xv,
  title    = "elegantscipy.pdf",
  keywords = "Python books"
}

@MISC{noauthor_undated-qc,
  title    = "introducingpython.pdf",
  keywords = "Python books"
}

@MISC{noauthor_undated-rx,
  title    = "thinkbayes.pdf",
  keywords = "Python books"
}

@UNPUBLISHED{Jackson2019-yb,
  title    = "Many paths to the same goal: metaheuristic operation of brains
              during natural behavior",
  author   = "Jackson, Brian J and Fatima, Gusti Lulu and Oh, Sujean and Gire,
              David H",
  abstract = "During self-guided behaviors animals rapidly identify the
              constraints of the problems they face and adaptively employ
              appropriate cognitive strategies and heuristics to solve these
              problems[1][1],[2][2]. This ability is currently an area of
              active investigation in artificial intelligence[3][3]. Recent
              work in computer science has suggested that this type of flexible
              problem solving could be achievable with metaheuristic approaches
              in which specific algorithms are selected based upon the
              identified demands of the problem to be
              solved[4][4],[5][5],[6][6],[7][7]. Investigating how animals
              employ such metaheuristics while solving self-guided natural
              problems is a fertile area for biologically inspired algorithm
              development. Here we show that animals adaptively shift cognitive
              resources between sensory and memory systems during natural
              behavior to optimize performance under uncertainty. We
              demonstrate this using a new, laboratory-based discovery method
              to define the strategies used to solve a difficult optimization
              scenario, the stochastic ``traveling salesman''
              problem[5][5],[8][8],[9][9]. Using this system we precisely
              manipulated the strength of prior information available to
              animals as well as the complexity of the problem. We find that
              rats are capable of efficiently solving this problem, even under
              conditions in which prior information is unreliable and the space
              of possible solutions is large. We compared animal performance to
              a Bayesian search and found that performance is consistent with a
              metaheuristic approach that adaptively allocates cognitive
              resources between sensory processing and memory, enhancing
              sensory acuity and reducing memory load under conditions in which
              prior information is unreliable. Our findings set the foundation
              for new approaches to understand the neural substrates of natural
              behavior as well as the rational development of biologically
              inspired metaheuristic approaches for complex real-world
              optimization. [1]: \#ref-1 [2]: \#ref-2 [3]: \#ref-3 [4]: \#ref-4
              [5]: \#ref-5 [6]: \#ref-6 [7]: \#ref-7 [8]: \#ref-8 [9]: \#ref-9",
  journal  = "bioRxiv",
  pages    = "697607",
  month    =  jul,
  year     =  2019,
  language = "en",
  doi      = "10.1101/697607"
}

@ARTICLE{Olafsdottir2015-dj,
  title     = "Hippocampal place cells construct reward related sequences
               through unexplored space",
  author    = "{\'O}lafsd{\'o}ttir, H Freyja and Barry, Caswell and Saleem,
               Aman B and Hassabis, Demis and Spiers, Hugo J",
  abstract  = "Dominant theories of hippocampal function propose that place
               cell representations are formed during an animal's first
               encounter with a novel environment and are subsequently replayed
               during off-line states to support consolidation and future
               behaviour. Here we report that viewing the delivery of food to
               an unvisited portion of an environment leads to off-line
               pre-activation of place cells sequences corresponding to that
               space. Such 'preplay' was not observed for an unrewarded but
               otherwise similar portion of the environment. These results
               suggest that a hippocampal representation of a visible, yet
               unexplored environment can be formed if the environment is of
               motivational relevance to the animal. We hypothesise such
               goal-biased preplay may support preparation for future
               experiences in novel environments.",
  journal   = "Elife",
  publisher = "cdn.elifesciences.org",
  volume    =  4,
  pages     = "e06063",
  month     =  jun,
  year      =  2015,
  keywords  = "consolidation; hippocampus; neuroscience; place cells; preplay;
               rat; replay; spatial memory",
  language  = "en",
  issn      = "2050-084X",
  pmid      = "26112828",
  doi       = "10.7554/eLife.06063",
  pmc       = "PMC4479790"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Tamprateep2017-bd,
  title        = "Of Mice and Man",
  author       = "Tamprateep, V",
  abstract     = "… As mentioned, we considered two datasets, featuring
                  different maze environments, from Jeremy Freeman and Nicholas
                  Sofroniew at Janelia Research Campus. These two datasets
                  consisted of one maze each. To create a discrete task, these
                  mazes were discretized …",
  publisher    = "pdfs.semanticscholar.org",
  year         =  2017,
  howpublished = "\url{https://pdfs.semanticscholar.org/e3a0/b91f0dbf28afcc608ba7190e7bf941693510.pdf}",
  note         = "Accessed: 2018-11-23"
}

@ARTICLE{Daw2018-vt,
  title    = "Are we of two minds?",
  author   = "Daw, Nathaniel D",
  journal  = "Nat. Neurosci.",
  volume   =  21,
  number   =  11,
  pages    = "1497--1499",
  month    =  nov,
  year     =  2018,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "30349102",
  doi      = "10.1038/s41593-018-0258-2"
}

@ARTICLE{Verschure_Paul_F_M_J2014-hg,
  title     = "The why, what, where, when and how of goal-directed choice:
               neuronal and computational principles",
  author    = "{Verschure Paul F. M. J.} and {Pennartz Cyriel M. A.} and
               {Pezzulo Giovanni}",
  journal   = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  publisher = "Royal Society",
  volume    =  369,
  number    =  1655,
  pages     = "20130483",
  month     =  nov,
  year      =  2014,
  issn      = "0962-8436",
  doi       = "10.1098/rstb.2013.0483"
}

@ARTICLE{Pezzulo2014-ph,
  title    = "Internally generated sequences in learning and executing
              goal-directed behavior",
  author   = "Pezzulo, Giovanni and van der Meer, Matthijs A A and Lansink,
              Carien S and Pennartz, Cyriel M A",
  abstract = "A network of brain structures including hippocampus (HC),
              prefrontal cortex, and striatum controls goal-directed behavior
              and decision making. However, the neural mechanisms underlying
              these functions are unknown. Here, we review the role of
              'internally generated sequences': structured, multi-neuron firing
              patterns in the network that are not confined to signaling the
              current state or location of an agent, but are generated on the
              basis of internal brain dynamics. Neurophysiological studies
              suggest that such sequences fulfill functions in memory
              consolidation, augmentation of representations, internal
              simulation, and recombination of acquired information. Using
              computational modeling, we propose that internally generated
              sequences may be productively considered a component of
              goal-directed decision systems, implementing a sampling-based
              inference engine that optimizes goal acquisition at multiple
              timescales of on-line choice, action control, and learning.",
  journal  = "Trends Cogn. Sci.",
  volume   =  18,
  number   =  12,
  pages    = "647--657",
  month    =  dec,
  year     =  2014,
  keywords = "decision making; forward sweep; generative models; hippocampus;
              inference; prospection; reinforcement learning; replay; spatial
              navigation; theta rhythm; ventral striatum",
  language = "en",
  issn     = "1364-6613, 1879-307X",
  pmid     = "25156191",
  doi      = "10.1016/j.tics.2014.06.011"
}

@ARTICLE{Lansink2012-ha,
  title    = "Reward cues in space: commonalities and differences in neural
              coding by hippocampal and ventral striatal ensembles",
  author   = "Lansink, Carien S and Jackson, Jadin C and Lankelma, Jan V and
              Ito, Rutsuko and Robbins, Trevor W and Everitt, Barry J and
              Pennartz, Cyriel M A",
  abstract = "Forming place-reward associations critically depends on the
              integrity of the hippocampal-ventral striatal system. The ventral
              striatum (VS) receives a strong hippocampal input conveying
              spatial-contextual information, but it is unclear how this
              structure integrates this information to invigorate
              reward-directed behavior. Neuronal ensembles in rat hippocampus
              (HC) and VS were simultaneously recorded during a conditioning
              task in which navigation depended on path integration. In
              contrast to HC, ventral striatal neurons showed low spatial
              selectivity, but rather coded behavioral task phases toward
              reaching goal sites. Outcome-predicting cues induced a remapping
              of firing patterns in the HC, consistent with its role in
              episodic memory. VS remapped in conjunction with the HC,
              indicating that remapping can take place in multiple brain
              regions engaged in the same task. Subsets of ventral striatal
              neurons showed a ``flip'' from high activity when cue lights were
              illuminated to low activity in intertrial intervals, or vice
              versa. The cues induced an increase in spatial information
              transmission and sparsity in both structures. These effects were
              paralleled by an enhanced temporal specificity of ensemble coding
              and a more accurate reconstruction of the animal's position from
              population firing patterns. Altogether, the results reveal strong
              differences in spatial processing between hippocampal area CA1
              and VS, but indicate similarities in how discrete cues impact on
              this processing.",
  journal  = "J. Neurosci.",
  volume   =  32,
  number   =  36,
  pages    = "12444--12459",
  month    =  sep,
  year     =  2012,
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "22956836",
  doi      = "10.1523/JNEUROSCI.0593-12.2012",
  pmc      = "PMC3492752"
}

@ARTICLE{Pezzulo2013-jy,
  title    = "The mixed instrumental controller: using value of information to
              combine habitual choice and mental simulation",
  author   = "Pezzulo, Giovanni and Rigoli, Francesco and Chersi, Fabian",
  abstract = "Instrumental behavior depends on both goal-directed and habitual
              mechanisms of choice. Normative views cast these mechanisms in
              terms of model-free and model-based methods of reinforcement
              learning, respectively. An influential proposal hypothesizes that
              model-free and model-based mechanisms coexist and compete in the
              brain according to their relative uncertainty. In this paper we
              propose a novel view in which a single Mixed Instrumental
              Controller produces both goal-directed and habitual behavior by
              flexibly balancing and combining model-based and model-free
              computations. The Mixed Instrumental Controller performs a
              cost-benefits analysis to decide whether to chose an action
              immediately based on the available ``cached'' value of actions
              (linked to model-free mechanisms) or to improve value estimation
              by mentally simulating the expected outcome values (linked to
              model-based mechanisms). Since mental simulation entails
              cognitive effort and increases the reward delay, it is activated
              only when the associated ``Value of Information'' exceeds its
              costs. The model proposes a method to compute the Value of
              Information, based on the uncertainty of action values and on the
              distance of alternative cached action values. Overall, the model
              by default chooses on the basis of lighter model-free estimates,
              and integrates them with costly model-based predictions only when
              useful. Mental simulation uses a sampling method to produce
              reward expectancies, which are used to update the cached value of
              one or more actions; in turn, this updated value is used for the
              choice. The key predictions of the model are tested in different
              settings of a double T-maze scenario. Results are discussed in
              relation with neurobiological evidence on the hippocampus -
              ventral striatum circuit in rodents, which has been linked to
              goal-directed spatial navigation.",
  journal  = "Front. Psychol.",
  volume   =  4,
  pages    = "92",
  month    =  mar,
  year     =  2013,
  keywords = "exploration-exploitation; forward sweeps; goal-directed
              decision-making; hippocampus; model-based reinforcement learning;
              value of information; ventral striatum",
  language = "en",
  issn     = "1664-1078",
  pmid     = "23459512",
  doi      = "10.3389/fpsyg.2013.00092",
  pmc      = "PMC3586710"
}

@UNPUBLISHED{Long2018-zl,
  title    = "A novel somatosensory spatial navigation system outside the
              hippocampal formation",
  author   = "Long, Xiaoyang and Zhang, Sheng-Jia",
  abstract = "The hippocampal-parahippocampal formation has long been regarded
              as the only site for the brain9s navigational system.
              Nevertheless, studies from patients with medial temporal lobe
              (MTL) lesions suggest that the hippocampal formation is not
              essential for space memory, indicating that spatial navigation
              might be computed with another unknown representation system
              outside the MTL. Such an extra-hippocampal navigational system
              has never been identified, however. Here we report the existence,
              in the rat somatosensory cortex only, of a novel navigational
              system, which contains the full spectrum of all distinct spatial
              cell types including place, head-direction, border/boundary,
              conjunctive, speed and grid cells. All somatosensory spatial
              cells show similar firing characteristics to those detected
              previously in the hippocampal-parahippocampal structures. The
              somatosensory navigational system extends the classical theory of
              a cognitive map from two discrete hippocampal-entorhinal regions
              to only one neocortical domain, providing possible alternative
              and more sophisticated computational algorithms for spatial
              memory and cognitive mapping.",
  journal  = "bioRxiv",
  pages    = "473090",
  month    =  nov,
  year     =  2018,
  language = "en",
  doi      = "10.1101/473090"
}

@UNPUBLISHED{Hok2018-di,
  title    = "A spatial code in the dorsal lateral geniculate nucleus",
  author   = "Hok, Vincent and Jacob, Pierre-Yves and Bordiga, Pierrick and
              Truchet, Bruno and Poucet, Bruno and Save, Etienne",
  abstract = "Since their discovery in the early 970s, hippocampal place cells
              have been studied in numerous animal and human spatial memory
              paradigms. These pyramidal cells, along with other spatially
              tuned types of neurons (e.g. grid cells, head direction cells),
              are thought to provide the mammalian brain a unique spatial
              signature characterizing a specific environment, and thereby a
              memory trace of the subject9s place. While grid and head
              direction cells are found in various brain regions, only few
              hippocampal-related structures showing 9place cell9-like neurons
              have been identified, thus reinforcing the central role of the
              hippocampus in spatial memory. Concurrently, it is increasingly
              suggested that visual areas play an important role in spatial
              cognition as recent studies showed a clear spatial selectivity of
              visual cortical (V1) neurons in freely moving rodents. We
              therefore thought to investigate, in the rat, such spatial
              correlates in a thalamic structure located one synapse upstream
              of V1, the dorsal Lateral Geniculate Nucleus (dLGN), and
              discovered that a substantial proportion (ca. 30\%) of neurons
              exhibits spatio-selective activity. We found that dLGN place
              cells maintain their spatial selectivity in the absence of visual
              inputs, presumably relying on odor and locomotor inputs. We also
              found that dLGN place cells maintain their place selectivity
              across sessions in a familiar environment and that contextual
              modifications yield separated representations. Our results show
              that dLGN place cells are likely to participate in spatial
              cognition processes, creating as early as the thalamic stage a
              comprehensive representation of one given environment.",
  journal  = "bioRxiv",
  pages    = "473520",
  month    =  nov,
  year     =  2018,
  language = "en",
  doi      = "10.1101/473520"
}

@UNPUBLISHED{Steinmetz2018-zx,
  title    = "Distributed correlates of visually-guided behavior across the
              mouse brain",
  author   = "Steinmetz, Nicholas and Zatka-Haas, Peter and Carandini, Matteo
              and Harris, Kenneth",
  abstract = "Behavior arises from neuronal activity, but it is not known how
              the active neurons are distributed across brain regions and how
              their activity unfolds in time. Here, we used high-density
              Neuropixels probes to record from ~30,000 neurons in mice
              performing a visual contrast discrimination task. The task
              activated 60\% of the neurons, involving nearly all 42 recorded
              brain regions, well beyond the regions activated by passive
              visual stimulation. However, neurons selective for choice (left
              vs. right) were rare, and found mostly in midbrain, striatum, and
              frontal cortex. Those in midbrain were typically activated prior
              to contralateral choices and suppressed prior to ipsilateral
              choices, consistent with a competitive midbrain circuit for
              adjudicating the subject9s choice. A brain-wide state shift
              distinguished trials in which visual stimuli led to movement.
              These results reveal concurrent representations of movement and
              choice in neurons widely distributed across the brain.",
  journal  = "bioRxiv",
  pages    = "474437",
  month    =  nov,
  year     =  2018,
  language = "en",
  doi      = "10.1101/474437"
}

@ARTICLE{Spiers2015-fh,
  title    = "Solving the detour problem in navigation: a model of prefrontal
              and hippocampal interactions",
  author   = "Spiers, Hugo J and Gilbert, Sam J",
  abstract = "Adapting behavior to accommodate changes in the environment is an
              important function of the nervous system. A universal problem for
              motile animals is the discovery that a learned route is blocked
              and a detour is required. Given the substantial neuroscience
              research on spatial navigation and decision-making it is
              surprising that so little is known about how the brain solves the
              detour problem. Here we review the limited number of relevant
              functional neuroimaging, single unit recording and lesion
              studies. We find that while the prefrontal cortex (PFC)
              consistently responds to detours, the hippocampus does not.
              Recent evidence suggests the hippocampus tracks information about
              the future path distance to the goal. Based on this evidence we
              postulate a conceptual model in which: Lateral PFC provides a
              prediction error signal about the change in the path, frontopolar
              and superior PFC support the re-formulation of the route plan as
              a novel subgoal and the hippocampus simulates the new path. More
              data will be required to validate this model and understand (1)
              how the system processes the different options; and (2) deals
              with situations where a new path becomes available (i.e.,
              shortcuts).",
  journal  = "Front. Hum. Neurosci.",
  volume   =  9,
  pages    = "125",
  month    =  mar,
  year     =  2015,
  keywords = "artificial intelligence; goals; hippocampus; place cells;
              planning; prediction error; reinforcement learning; virtual
              reality",
  language = "en",
  issn     = "1662-5161",
  pmid     = "25852515",
  doi      = "10.3389/fnhum.2015.00125",
  pmc      = "PMC4366647"
}

@ARTICLE{Panzeri2007-vl,
  title     = "Correcting for the sampling bias problem in spike train
               information measures",
  author    = "Panzeri, Stefano and Senatore, Riccardo and Montemurro, Marcelo
               A and Petersen, Rasmus S",
  abstract  = "Information Theory enables the quantification of how much
               information a neuronal response carries about external stimuli
               and is hence a natural analytic framework for studying neural
               coding. The main difficulty in its practical application to
               spike train analysis is that estimates of neuronal information
               from experimental data are prone to a systematic error (called
               ``bias''). This bias is an inevitable consequence of the limited
               number of stimulus-response samples that it is possible to
               record in a real experiment. In this paper, we first explain the
               origin and the implications of the bias problem in spike train
               analysis. We then review and evaluate some recent
               general-purpose methods to correct for sampling bias: the
               Panzeri-Treves, Quadratic Extrapolation, Best Universal Bound,
               Nemenman-Shafee-Bialek procedures, and a recently proposed
               shuffling bias reduction procedure. Finally, we make practical
               recommendations for the accurate computation of information from
               spike trains. Our main recommendation is to estimate information
               using the shuffling bias reduction procedure in combination with
               one of the other four general purpose bias reduction procedures
               mentioned in the preceding text. This provides information
               estimates with acceptable variance and which are unbiased even
               when the number of trials per stimulus is as small as the number
               of possible discrete neuronal responses.",
  journal   = "J. Neurophysiol.",
  publisher = "physiology.org",
  volume    =  98,
  number    =  3,
  pages     = "1064--1072",
  month     =  sep,
  year      =  2007,
  language  = "en",
  issn      = "0022-3077",
  pmid      = "17615128",
  doi       = "10.1152/jn.00559.2007"
}

@ARTICLE{Rangel2008-xe,
  title    = "A framework for studying the neurobiology of value-based decision
              making",
  author   = "Rangel, Antonio and Camerer, Colin and Montague, P Read",
  abstract = "Neuroeconomics is the study of the neurobiological and
              computational basis of value-based decision making. Its goal is
              to provide a biologically based account of human behaviour that
              can be applied in both the natural and the social sciences. This
              Review proposes a framework to investigate different aspects of
              the neurobiology of decision making. The framework allows us to
              bring together recent findings in the field, highlight some of
              the most important outstanding problems, define a common lexicon
              that bridges the different disciplines that inform
              neuroeconomics, and point the way to future applications.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  9,
  number   =  7,
  pages    = "545--556",
  month    =  jul,
  year     =  2008,
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "18545266",
  doi      = "10.1038/nrn2357",
  pmc      = "PMC4332708"
}

@ARTICLE{Evans2003-qh,
  title    = "In two minds: dual-process accounts of reasoning",
  author   = "Evans, Jonathan St B T",
  abstract = "Researchers in thinking and reasoning have proposed recently that
              there are two distinct cognitive systems underlying reasoning.
              System 1 is old in evolutionary terms and shared with other
              animals: it comprises a set of autonomous subsystems that include
              both innate input modules and domain-specific knowledge acquired
              by a domain-general learning mechanism. System 2 is
              evolutionarily recent and distinctively human: it permits
              abstract reasoning and hypothetical thinking, but is constrained
              by working memory capacity and correlated with measures of
              general intelligence. These theories essentially posit two minds
              in one brain with a range of experimental psychological evidence
              showing that the two systems compete for control of our
              inferences and actions.",
  journal  = "Trends Cogn. Sci.",
  volume   =  7,
  number   =  10,
  pages    = "454--459",
  month    =  oct,
  year     =  2003,
  issn     = "1364-6613",
  doi      = "10.1016/j.tics.2003.08.012"
}

@ARTICLE{Schall2001-zu,
  title    = "Neural basis of deciding, choosing and acting",
  author   = "Schall, J D",
  abstract = "The ability and opportunity to make decisions and carry out
              effective actions in pursuit of goals is central to intelligent
              life. Recent research has provided significant new insights into
              how the brain arrives at decisions, makes choices, and produces
              and evaluates the consequences of actions. In fact, by monitoring
              or manipulating specific neurons, certain choices can now be
              predicted or manipulated.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  2,
  number   =  1,
  pages    = "33--42",
  month    =  jan,
  year     =  2001,
  language = "en",
  issn     = "1471-003X",
  pmid     = "11253357",
  doi      = "10.1038/35049054"
}

@ARTICLE{Leon1998-oj,
  title    = "Exploring the neurophysiology of decisions",
  author   = "Leon, M I and Shadlen, M N",
  journal  = "Neuron",
  volume   =  21,
  number   =  4,
  pages    = "669--672",
  month    =  oct,
  year     =  1998,
  language = "en",
  issn     = "0896-6273",
  pmid     = "9808454",
  doi      = "10.1016/S0896-6273(00)80584-X"
}

@ARTICLE{Basso1998-ng,
  title     = "Modulation of neuronal activity in superior colliculus by
               changes in target probability",
  author    = "Basso, M A and Wurtz, R H",
  abstract  = "Complex visual scenes require that a target for an impending
               saccadic eye movement be selected from a larger number of
               possible targets. We investigated whether changing the
               probability that a visual stimulus would be selected as the
               target for a saccade altered activity of monkey superior
               colliculus (SC) neurons in two experiments. First, we changed
               the number of possible targets on each trial. Second, we kept
               the visual display constant and presented a single saccade
               target repeatedly so that target probability was established
               over time. Buildup neurons in the SC, those with delay period
               activity, showed a consistent reduction in activity as the
               probability of the saccade decreased, independent of the visual
               stimulus configuration. Other SC neurons, fixation and burst,
               were largely unaffected by the changes in saccade target
               probability. Because we had monkeys making saccades to many
               locations within the visual field, we could examine activity
               associated with saccades outside of the movement field of
               neurons. We found the activity of buildup neurons to be similar
               across the SC, before the target was identified, and reduced
               when the number of possible targets increased. The results of
               our experiments are consistent with a role for this activity in
               establishing a motor set. We found, consistent with this
               interpretation, that the activity of these neurons was
               predictive of the latency of a saccadic eye movement and not
               other saccade parameters such as end point or peak velocity.",
  journal   = "J. Neurosci.",
  publisher = "Soc Neuroscience",
  volume    =  18,
  number    =  18,
  pages     = "7519--7534",
  month     =  sep,
  year      =  1998,
  language  = "en",
  issn      = "0270-6474",
  pmid      = "9736670"
}

@ARTICLE{Busemeyer1993-qq,
  title     = "Decision field theory: a dynamic-cognitive approach to decision
               making in an uncertain environment",
  author    = "Busemeyer, J R and Townsend, J T",
  abstract  = "Decision field theory provides for a mathematical foundation
               leading to a dynamic, stochastic theory of decision behavior in
               an uncertain environment. This theory is used to explain (a)
               violations of stochastic dominance, (b) violations of strong
               stochastic transitivity, (c) violations of independence between
               alternatives, (d) serial position effects on preference, (e)
               speed-accuracy trade-off effects in decision making, (f) the
               inverse relation between choice probability and decision time,
               (g) changes in the direction of preference under time pressure,
               (h) slower decision times for avoidance as compared with
               approach conflicts, and (i) preference reversals between choice
               and selling price measures of preference. The proposed theory is
               compared with 4 other theories of decision making under
               uncertainty.",
  journal   = "Psychol. Rev.",
  publisher = "doi.apa.org",
  volume    =  100,
  number    =  3,
  pages     = "432--459",
  month     =  jul,
  year      =  1993,
  language  = "en",
  issn      = "0033-295X",
  pmid      = "8356185"
}

@ARTICLE{Klaes2011-hi,
  title    = "Choosing goals, not rules: deciding among rule-based action plans",
  author   = "Klaes, Christian and Westendorff, Stephanie and Chakrabarti,
              Shubhodeep and Gail, Alexander",
  abstract = "In natural situations, movements are often directed toward
              locations different from that of the evoking sensory stimulus.
              Movement goals must then be inferred from the sensory cue based
              on rules. When there is uncertainty about the rule that applies
              for a given cue, planning a movement involves both choosing the
              relevant rule and computing the movement goal based on that rule.
              Under these conditions, it is not clear whether primates compute
              multiple movement goals based on all possible rules before
              choosing an action, or whether they first choose a rule and then
              only represent the movement goal associated with that rule.
              Supporting the former hypothesis, we show that neurons in the
              frontoparietal reach areas of monkeys simultaneously represent
              two different rule-based movement goals, which are biased by the
              monkeys' choice preferences. Apparently, primates choose between
              multiple behavioral options by weighing against each other the
              movement goals associated with each option.",
  journal  = "Neuron",
  volume   =  70,
  number   =  3,
  pages    = "536--548",
  month    =  may,
  year     =  2011,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "21555078",
  doi      = "10.1016/j.neuron.2011.02.053"
}

@ARTICLE{Thura2014-zb,
  title    = "Deliberation and commitment in the premotor and primary motor
              cortex during dynamic decision making",
  author   = "Thura, David and Cisek, Paul",
  abstract = "Neurophysiological studies of decision making have primarily
              focused on decisions about information that is stable over time.
              However, during natural behavior, animals make decisions in a
              constantly changing environment. To investigate the neural
              mechanisms of such dynamic choices, we recorded activity in
              dorsal premotor (PMd) and primary motor cortex (M1) while monkeys
              performed a two-choice reaching task in which sensory information
              about the correct choice was changing within each trial and the
              decision could be made at any time. During deliberation, activity
              in both areas did not integrate sensory information but instead
              tracked it and combined it with a growing urgency signal.
              Approximately 280 ms before movement onset, PMd activity tuned to
              the selected target reached a consistent peak while M1 activity
              tuned to the unselected target was suppressed. We propose that
              this reflects the resolution of a competition between the
              potential responses and constitutes the volitional commitment to
              an action choice.",
  journal  = "Neuron",
  volume   =  81,
  number   =  6,
  pages    = "1401--1416",
  month    =  mar,
  year     =  2014,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "24656257",
  doi      = "10.1016/j.neuron.2014.01.031"
}

@ARTICLE{Chapman2010-dv,
  title    = "Reaching for the unknown: multiple target encoding and real-time
              decision-making in a rapid reach task",
  author   = "Chapman, Craig S and Gallivan, Jason P and Wood, Daniel K and
              Milne, Jennifer L and Culham, Jody C and Goodale, Melvyn A",
  abstract = "Decision-making is central to human cognition. Fundamental to
              every decision is the ability to internally represent the
              available choices and their relative costs and benefits. The most
              basic and frequent decisions we make occur as our motor system
              chooses and executes only those actions that achieve our current
              goals. Although these interactions with the environment may
              appear effortless, this belies what must be incredibly
              sophisticated visuomotor decision-making processes. In order to
              measure how visuomotor decisions unfold in real-time, we used a
              unique reaching paradigm that forced participants to initiate
              rapid hand movements toward multiple potential targets, with only
              one being cued after reach onset. We show across three
              experiments that, in cases of target uncertainty, trajectories
              are spatially sensitive to the probabilistic distribution of
              targets within the display. Specifically, when presented with two
              or three target displays, subjects initiate their reaches toward
              an intermediary or 'averaged' location before correcting their
              trajectory in-flight to the cued target location. A control
              experiment suggests that our effect depends on the targets acting
              as potential reach locations and not as distractors. This study
              is the first to show that the 'averaging' of target-directed
              reaching movements depends not only on the spatial position of
              the targets in the display but also the probability of acting at
              each target location.",
  journal  = "Cognition",
  volume   =  116,
  number   =  2,
  pages    = "168--176",
  month    =  aug,
  year     =  2010,
  language = "en",
  issn     = "0010-0277, 1873-7838",
  pmid     = "20471007",
  doi      = "10.1016/j.cognition.2010.04.008"
}

@ARTICLE{Cisek2012-qy,
  title    = "Making decisions through a distributed consensus",
  author   = "Cisek, Paul",
  abstract = "How does the brain decide between actions? Is it through
              comparisons of abstract representations of outcomes or through a
              competition in a sensorimotor map defining the actions
              themselves? Here, I review strengths and limitations of both of
              these proposals, and suggest that decisions emerge through a
              distributed consensus across many levels of representation.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  22,
  number   =  6,
  pages    = "927--936",
  month    =  dec,
  year     =  2012,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "22683275",
  doi      = "10.1016/j.conb.2012.05.007"
}

@ARTICLE{Dehaene2012-xq,
  title    = "From a single decision to a multi-step algorithm",
  author   = "Dehaene, Stanislas and Sigman, Mariano",
  abstract = "Humans can perform sequential and recursive computations, as when
              calculating 23$\times$74. However, this comes at a cost: flexible
              computations are slow and effortful. We argue that this
              competence involves serial chains of successive decisions, each
              based on the accumulation of evidence up to a threshold and
              forwarding the result to the subsequent step. Such serial
              'programs' require a specific neurobiological architecture,
              approximating the operation of a slow serial Turing machine. We
              review recent progress in understanding how the brain implements
              such multi-step decisions and briefly examine how they might be
              realized in models of primate cortex.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  22,
  number   =  6,
  pages    = "937--945",
  month    =  dec,
  year     =  2012,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "22704054",
  doi      = "10.1016/j.conb.2012.05.006"
}

@ARTICLE{Drugowitsch2012-rd,
  title    = "Probabilistic vs. non-probabilistic approaches to the
              neurobiology of perceptual decision-making",
  author   = "Drugowitsch, Jan and Pouget, Alexandre",
  abstract = "Optimal binary perceptual decision making requires accumulation
              of evidence in the form of a probability distribution that
              specifies the probability of the choices being correct given the
              evidence so far. Reward rates can then be maximized by stopping
              the accumulation when the confidence about either option reaches
              a threshold. Behavioral and neuronal evidence suggests that
              humans and animals follow such a probabilitistic decision
              strategy, although its neural implementation has yet to be fully
              characterized. Here we show that that diffusion decision models
              and attractor network models provide an approximation to the
              optimal strategy only under certain circumstances. In particular,
              neither model type is sufficiently flexible to encode the
              reliability of both the momentary and the accumulated evidence,
              which is a pre-requisite to accumulate evidence of time-varying
              reliability. Probabilistic population codes, by contrast, can
              encode these quantities and, as a consequence, have the potential
              to implement the optimal strategy accurately.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  22,
  number   =  6,
  pages    = "963--969",
  month    =  dec,
  year     =  2012,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "22884815",
  doi      = "10.1016/j.conb.2012.07.007",
  pmc      = "PMC3513621"
}

@ARTICLE{Adams2012-mw,
  title    = "Neuroethology of decision-making",
  author   = "Adams, Geoffrey K and Watson, Karli K and Pearson, John and
              Platt, Michael L",
  abstract = "A neuroethological approach to decision-making considers the
              effect of evolutionary pressures on neural circuits mediating
              choice. In this view, decision systems are expected to enhance
              fitness with respect to the local environment, and particularly
              efficient solutions to specific problems should be conserved,
              expanded, and repurposed to solve other problems. Here, we
              discuss basic prerequisites for a variety of decision systems
              from this viewpoint. We focus on two of the best-studied and most
              widely represented decision problems. First, we examine patch
              leaving, a prototype of environmentally based switching between
              action patterns. Second, we consider social information seeking,
              a process resembling foraging with search costs. We argue that
              while the specific neural solutions to these problems sometimes
              differ across species, both the problems themselves and the
              algorithms instantiated by biological hardware are repeated
              widely throughout nature. The behavioral and mathematical study
              of ubiquitous decision processes like patch leaving and social
              information seeking thus provides a powerful new approach to
              uncovering the fundamental design structure of nervous systems.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  22,
  number   =  6,
  pages    = "982--989",
  month    =  dec,
  year     =  2012,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "22902613",
  doi      = "10.1016/j.conb.2012.07.009",
  pmc      = "PMC3510321"
}

@ARTICLE{Wang2012-ac,
  title    = "Neural dynamics and circuit mechanisms of decision-making",
  author   = "Wang, Xiao-Jing",
  abstract = "In this review, I briefly summarize current neurobiological
              studies of decision-making that bear on two general themes. The
              first focuses on the nature of neural representation and dynamics
              in a decision circuit. Experimental and computational results
              suggest that ramping-to-threshold in the temporal domain and
              trajectory of population activity in the state space represent a
              duality of perspectives on a decision process. Moreover, a
              decision circuit can display several different dynamical regimes,
              such as the ramping mode and the jumping mode with distinct
              defining properties. The second is concerned with the
              relationship between biologically-based mechanistic models and
              normative-type models. A fruitful interplay between experiments
              and these models at different levels of abstraction have enabled
              investigators to pose increasingly refined questions and gain new
              insights into the neural basis of decision-making. In particular,
              recent work on multi-alternative decisions suggests that
              deviations from rational models of choice behavior can be
              explained by established neural mechanisms.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  22,
  number   =  6,
  pages    = "1039--1046",
  month    =  dec,
  year     =  2012,
  issn     = "0959-4388",
  doi      = "10.1016/j.conb.2012.08.006"
}

@ARTICLE{Cain2012-tf,
  title    = "Computational models of decision making: integration, stability,
              and noise",
  author   = "Cain, Nicholas and Shea-Brown, Eric",
  abstract = "Decision making demands the accumulation of sensory evidence over
              time. Questions remain about how this occurs, but recent years
              have seen progress on several fronts. The first concerns when
              optimal accumulation of evidence coincides with the simplest
              method of accumulating neural activity: summation over time. The
              second involves what computations the brain might perform when
              summation is difficult due to imprecision in neural circuits or
              is suboptimal due to uncertainty or variability in how evidence
              arrives. Finally, the third concerns sources of noise in decision
              circuits. Empirical studies have better constrained the extent of
              this noise, and modeling work is helping to clarify its possible
              origins.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  22,
  number   =  6,
  pages    = "1047--1053",
  month    =  dec,
  year     =  2012,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "22591667",
  doi      = "10.1016/j.conb.2012.04.013"
}

@ARTICLE{Churchland2012-kw,
  title    = "New advances in understanding decisions among multiple
              alternatives",
  author   = "Churchland, Anne K and Ditterich, Jochen",
  abstract = "Experimental studies of decision-making have put a strong
              emphasis on choices between two alternatives. However, real-life
              decisions often involve multiple alternatives. This article
              provides an overview of theoretical frameworks that have been
              proposed to account for behavioral data from both economic and
              perceptual multialternative decision-making. We further review
              recent neurophysiological data collected in conjunction with
              decision-making behavior. These neural recordings provide
              constraints on putative models of the decision mechanism. For
              example, the time course of inhibition provides insight into how
              the competition between alternatives is mediated. Furthermore,
              whereas decision-related neural activity seems to reach a common
              threshold at the end of the decision period, the starting point
              tends to depend systematically on the number of alternatives. We
              discuss candidate mechanisms that could drive the reduction in
              firing rates on decisions among multiple alternatives.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  22,
  number   =  6,
  pages    = "920--926",
  month    =  dec,
  year     =  2012,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "22554881",
  doi      = "10.1016/j.conb.2012.04.009",
  pmc      = "PMC3422607"
}

@ARTICLE{Sofroniew2014-mh,
  title    = "Natural whisker-guided behavior by head-fixed mice in tactile
              virtual reality",
  author   = "Sofroniew, Nicholas J and Cohen, Jeremy D and Lee, Albert K and
              Svoboda, Karel",
  abstract = "During many natural behaviors the relevant sensory stimuli and
              motor outputs are difficult to quantify. Furthermore, the high
              dimensionality of the space of possible stimuli and movements
              compounds the problem of experimental control. Head fixation
              facilitates stimulus control and movement tracking, and can be
              combined with techniques for recording and manipulating neural
              activity. However, head-fixed mouse behaviors are typically
              trained through extensive instrumental conditioning. Here we
              present a whisker-based, tactile virtual reality system for
              head-fixed mice running on a spherical treadmill. Head-fixed mice
              displayed natural movements, including running and rhythmic
              whisking at 16 Hz. Whisking was centered on a set point that
              changed in concert with running so that more protracted whisking
              was correlated with faster running. During turning, whiskers
              moved in an asymmetric manner, with more retracted whisker
              positions in the turn direction and protracted whisker movements
              on the other side. Under some conditions, whisker movements were
              phase-coupled to strides. We simulated a virtual reality tactile
              corridor, consisting of two moveable walls controlled in a
              closed-loop by running speed and direction. Mice used their
              whiskers to track the walls of the winding corridor without
              training. Whisker curvature changes, which cause forces in the
              sensory follicles at the base of the whiskers, were tightly
              coupled to distance from the walls. Our behavioral system allows
              for precise control of sensorimotor variables during natural
              tactile navigation.",
  journal  = "J. Neurosci.",
  volume   =  34,
  number   =  29,
  pages    = "9537--9550",
  month    =  jul,
  year     =  2014,
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "25031397",
  doi      = "10.1523/JNEUROSCI.0712-14.2014",
  pmc      = "PMC4099538"
}

@ARTICLE{Oh2014-ws,
  title    = "A mesoscale connectome of the mouse brain",
  author   = "Oh, Seung Wook and Harris, Julie A and Ng, Lydia and Winslow,
              Brent and Cain, Nicholas and Mihalas, Stefan and Wang, Quanxin
              and Lau, Chris and Kuan, Leonard and Henry, Alex M and Mortrud,
              Marty T and Ouellette, Benjamin and Nguyen, Thuc Nghi and
              Sorensen, Staci A and Slaughterbeck, Clifford R and Wakeman,
              Wayne and Li, Yang and Feng, David and Ho, Anh and Nicholas, Eric
              and Hirokawa, Karla E and Bohn, Phillip and Joines, Kevin M and
              Peng, Hanchuan and Hawrylycz, Michael J and Phillips, John W and
              Hohmann, John G and Wohnoutka, Paul and Gerfen, Charles R and
              Koch, Christof and Bernard, Amy and Dang, Chinh and Jones, Allan
              R and Zeng, Hongkui",
  abstract = "Comprehensive knowledge of the brain's wiring diagram is
              fundamental for understanding how the nervous system processes
              information at both local and global scales. However, with the
              singular exception of the C. elegans microscale connectome, there
              are no complete connectivity data sets in other species. Here we
              report a brain-wide, cellular-level, mesoscale connectome for the
              mouse. The Allen Mouse Brain Connectivity Atlas uses enhanced
              green fluorescent protein (EGFP)-expressing adeno-associated
              viral vectors to trace axonal projections from defined regions
              and cell types, and high-throughput serial two-photon tomography
              to image the EGFP-labelled axons throughout the brain. This
              systematic and standardized approach allows spatial registration
              of individual experiments into a common three dimensional (3D)
              reference space, resulting in a whole-brain connectivity matrix.
              A computational model yields insights into connectional strength
              distribution, symmetry and other network properties. Virtual
              tractography illustrates 3D topography among interconnected
              regions. Cortico-thalamic pathway analysis demonstrates
              segregation and integration of parallel pathways. The Allen Mouse
              Brain Connectivity Atlas is a freely available, foundational
              resource for structural and functional investigations into the
              neural circuits that support behavioural and cognitive processes
              in health and disease.",
  journal  = "Nature",
  volume   =  508,
  number   =  7495,
  pages    = "207--214",
  month    =  apr,
  year     =  2014,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "24695228",
  doi      = "10.1038/nature13186",
  pmc      = "PMC5102064"
}

@ARTICLE{Van_Strien2009-yf,
  title    = "The anatomy of memory: an interactive overview of the
              parahippocampal-hippocampal network",
  author   = "van Strien, N M and Cappaert, N L M and Witter, M P",
  abstract = "Converging evidence suggests that each parahippocampal and
              hippocampal subregion contributes uniquely to the encoding,
              consolidation and retrieval of declarative memories, but their
              precise roles remain elusive. Current functional thinking does
              not fully incorporate the intricately connected networks that
              link these subregions, owing to their organizational complexity;
              however, such detailed anatomical knowledge is of pivotal
              importance for comprehending the unique functional contribution
              of each subregion. We have therefore developed an interactive
              diagram with the aim to display all of the currently known
              anatomical connections of the rat parahippocampal-hippocampal
              network. In this Review, we integrate the existing anatomical
              knowledge into a concise description of this network and discuss
              the functional implications of some relatively underexposed
              connections.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  10,
  number   =  4,
  pages    = "272--282",
  month    =  apr,
  year     =  2009,
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "19300446",
  doi      = "10.1038/nrn2614"
}

@ARTICLE{Tolman_undated-yh,
  title  = "Cognitive Critique",
  author = "Tolman, Revisiting and Ries, His Theo"
}

@MISC{John_OKeefe_undated-cu,
  title    = "The hippocampus as a cognitive map",
  author   = "John O'Keefe, Lynn Nadel",
  keywords = "books"
}

@ARTICLE{Keum2019-dz,
  title     = "Neural Basis of Observational Fear Learning: A Potential Model
               of Affective Empathy",
  author    = "Keum, Sehoon and Shin, Hee-Sup",
  abstract  = "Observational fear learning in rodents is a type of
               context-dependent fear conditioning in which an unconditioned
               stimulus (US) is provided vicariously by observing conspecific
               others receiving foot shocks. This suggests the involvement of
               affective empathy, with several recent studies showing many
               similarities between this behavior and human empathy.
               Neurobiologically, it is important to understand the neural
               mechanisms by which the vicarious US activates the fear circuit
               via the affective pain system, obviating the sensory pain
               pathway and eventually leading to fear memory formation. This
               paper reviews current studies on the neural mechanisms
               underlying observational fear learning and provides a
               perspective on future research on this subject.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  104,
  number    =  1,
  pages     = "78--86",
  month     =  oct,
  year      =  2019,
  keywords  = "empathy; observational fear learning; social fear; affective
               pain; and anterior cingulate cortex",
  language  = "en",
  issn      = "0896-6273",
  doi       = "10.1016/j.neuron.2019.09.013"
}

@ARTICLE{Koene2003-ep,
  title    = "Modeling goal-directed spatial navigation in the rat based on
              physiological data from the hippocampal formation",
  author   = "Koene, Randal A and Gorchetchnikov, Anatoli and Cannon, Robert C
              and Hasselmo, Michael E",
  abstract = "We investigated the importance of hippocampal theta oscillations
              and the significance of phase differences of theta modulation in
              the cortical regions that are involved in goal-directed spatial
              navigation. Our models used representations of entorhinal cortex
              layer III (ECIII), hippocampus and prefrontal cortex (PFC) to
              guide movements of a virtual rat in a virtual environment. The
              model encoded representations of the environment through
              long-term potentiation of excitatory recurrent connections
              between sequentially spiking place cells in ECIII and CA3. This
              encoding required buffering of place cell activity, which was
              achieved by a short-term memory (STM) in EC that was regulated by
              theta modulation and allowed synchronized reactivation with
              encoding phases in ECIII and CA3. Inhibition at a specific theta
              phase deactivated the oldest item in the buffer when new input
              was presented to a full STM buffer. A 180 degrees phase
              difference separated retrieval and encoding in ECIII and CA3,
              which enabled us to simulate data on theta phase precession of
              place cells. Retrieval of known paths was elicited in ECIII by
              input at the retrieval phase from PFC working memory for goal
              location, requiring strict theta phase relationships with PFC.
              Known locations adjacent to the virtual rat were retrieved in
              CA3. Together, input from ECIII and CA3 activated predictive
              spiking in cells in CA1 for the next desired place on a shortest
              path to a goal. Consistent with data, place cell activity in CA1
              and CA3 showed smaller place fields than in ECIII.",
  journal  = "Neural Netw.",
  volume   =  16,
  number   = "5-6",
  pages    = "577--584",
  month    =  jun,
  year     =  2003,
  language = "en",
  issn     = "0893-6080",
  pmid     = "12850010",
  doi      = "10.1016/S0893-6080(03)00106-0"
}

@ARTICLE{Cisek2010-ke,
  title    = "Neural mechanisms for interacting with a world full of action
              choices",
  author   = "Cisek, Paul and Kalaska, John F",
  abstract = "The neural bases of behavior are often discussed in terms of
              perceptual, cognitive, and motor stages, defined within an
              information processing framework that was originally inspired by
              models of human abstract problem solving. Here, we review a
              growing body of neurophysiological data that is difficult to
              reconcile with this influential theoretical perspective. As an
              alternative foundation for interpreting neural data, we consider
              frameworks borrowed from ethology, which emphasize the kinds of
              real-time interactive behaviors that animals have engaged in for
              millions of years. In particular, we discuss an
              ethologically-inspired view of interactive behavior as
              simultaneous processes that specify potential motor actions and
              select between them. We review how recent neurophysiological data
              from diverse cortical and subcortical regions appear more
              compatible with this parallel view than with the classical view
              of serial information processing stages.",
  journal  = "Annu. Rev. Neurosci.",
  volume   =  33,
  pages    = "269--298",
  year     =  2010,
  language = "en",
  issn     = "0147-006X, 1545-4126",
  pmid     = "20345247",
  doi      = "10.1146/annurev.neuro.051508.135409"
}

@ARTICLE{Mysore2011-fr,
  title    = "The role of a midbrain network in competitive stimulus selection",
  author   = "Mysore, Shreesh P and Knudsen, Eric I",
  abstract = "A midbrain network interacts with the well-known frontoparietal
              forebrain network to select stimuli for gaze and spatial
              attention. The midbrain network, containing the superior
              colliculus (SC; optic tectum, OT, in non-mammalian vertebrates)
              and the isthmic nuclei, helps evaluate the relative priorities of
              competing stimuli and encodes them in a topographic map of space.
              Behavioral experiments in monkeys demonstrate an essential
              contribution of the SC to stimulus selection when the relative
              priorities of competing stimuli are similar. Neurophysiological
              results from the owl OT demonstrate a neural correlate of this
              essential contribution of the SC/OT. The multi-layered,
              spatiotopic organization of the midbrain network lends itself to
              the analysis and modeling of the mechanisms underlying stimulus
              selection for gaze and spatial attention.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  21,
  number   =  4,
  pages    = "653--660",
  month    =  aug,
  year     =  2011,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "21696945",
  doi      = "10.1016/j.conb.2011.05.024",
  pmc      = "PMC3177965"
}

@ARTICLE{Johnson2009-bx,
  title    = "Looking for cognition in the structure within the noise",
  author   = "Johnson, Adam and Fenton, Andr{\'e} A and Kentros, Cliff and
              Redish, A David",
  abstract = "Neural activity in the mammalian CNS is determined by both
              observable processes, such as sensory stimuli or motor output,
              and covert, internal cognitive processes that cannot be directly
              observed. We propose methods to identify these cognitive
              processes by examining the covert structure within the apparent
              'noise' in spike trains. Contemporary analyses of neural codes
              include encoding (tuning curves derived from spike trains and
              behavioral, sensory or motor variables), decoding (reconstructing
              behavioral, sensory or motor variables from spike trains and
              hypothesized tuning curves) and generative models (predicting the
              spike trains from hypothesized encoding models and decoded
              variables). We review examples of each of these processes in
              hippocampal activity, and propose a general methodology to
              examine cognitive processes via the identification of dynamic
              changes in covert variables.",
  journal  = "Trends Cogn. Sci.",
  volume   =  13,
  number   =  2,
  pages    = "55--64",
  month    =  feb,
  year     =  2009,
  language = "en",
  issn     = "1364-6613",
  pmid     = "19135406",
  doi      = "10.1016/j.tics.2008.11.005",
  pmc      = "PMC3774297"
}

@ARTICLE{Geva-Sagiv2015-cl,
  title    = "Spatial cognition in bats and rats: from sensory acquisition to
              multiscale maps and navigation",
  author   = "Geva-Sagiv, Maya and Las, Liora and Yovel, Yossi and Ulanovsky,
              Nachum",
  abstract = "Spatial orientation and navigation rely on the acquisition of
              several types of sensory information. This information is then
              transformed into a neural code for space in the hippocampal
              formation through the activity of place cells, grid cells and
              head-direction cells. These spatial representations, in turn, are
              thought to guide long-range navigation. But how the
              representations encoded by these different cell types are
              integrated in the brain to form a neural 'map and compass' is
              largely unknown. Here, we discuss this problem in the context of
              spatial navigation by bats and rats. We review the experimental
              findings and theoretical models that provide insight into the
              mechanisms that link sensory systems to spatial representations
              and to large-scale natural navigation.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  16,
  number   =  2,
  pages    = "94--108",
  month    =  feb,
  year     =  2015,
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "25601780",
  doi      = "10.1038/nrn3888"
}

@ARTICLE{Phelps2014-qu,
  title    = "Emotion and decision making: multiple modulatory neural circuits",
  author   = "Phelps, Elizabeth A and Lempert, Karolina M and Sokol-Hessner,
              Peter",
  abstract = "Although the prevalent view of emotion and decision making is
              derived from the notion that there are dual systems of emotion
              and reason, a modulatory relationship more accurately reflects
              the current research in affective neuroscience and
              neuroeconomics. Studies show two potential mechanisms for
              affect's modulation of the computation of subjective value and
              decisions. Incidental affective states may carry over to the
              assessment of subjective value and the decision, and emotional
              reactions to the choice may be incorporated into the value
              calculation. In addition, this modulatory relationship is
              reciprocal: Changing emotion can change choices. This research
              suggests that the neural mechanisms mediating the relation
              between affect and choice vary depending on which affective
              component is engaged and which decision variables are assessed.
              We suggest that a detailed and nuanced understanding of emotion
              and decision making requires characterizing the multiple
              modulatory neural circuits underlying the different means by
              which emotion and affect can influence choices.",
  journal  = "Annu. Rev. Neurosci.",
  volume   =  37,
  pages    = "263--287",
  month    =  may,
  year     =  2014,
  keywords = "amygdala; insular cortex; mood; orbitofrontal cortex; stress;
              striatum",
  language = "en",
  issn     = "0147-006X, 1545-4126",
  pmid     = "24905597",
  doi      = "10.1146/annurev-neuro-071013-014119"
}

@ARTICLE{Redish2016-wf,
  title    = "The Computational Complexity of Valuation and Motivational Forces
              in {Decision-Making} Processes",
  author   = "Redish, A David and Schultheiss, Nathan W and Carter, Evan C",
  abstract = "The concept of value is fundamental to most theories of
              motivation and decision making. However, value has to be measured
              experimentally. Different methods of measuring value produce
              incompatible valuation hierarchies. Taking the agent's
              perspective (rather than the experimenter's), we interpret the
              different valuation measurement methods as accessing different
              decision-making systems and show how these different systems
              depend on different information processing algorithms. This
              identifies the translation from these multiple decision-making
              systems into a single action taken by a given agent as one of the
              most important open questions in decision making today. We
              conclude by looking at how these different valuation measures
              accessing different decision-making systems can be used to
              understand and treat decision dysfunction such as in addiction.",
  journal  = "Curr. Top. Behav. Neurosci.",
  volume   =  27,
  pages    = "313--333",
  year     =  2016,
  keywords = "Decision-Making; Multiple Decision Theory; Neuroeconomonics;
              Valuation",
  language = "en",
  issn     = "1866-3370",
  pmid     = "25981912",
  doi      = "10.1007/7854\_2015\_375",
  pmc      = "PMC4937458"
}

@ARTICLE{Steiner2012-xp,
  title    = "The road not taken: neural correlates of decision making in
              orbitofrontal cortex",
  author   = "Steiner, Adam P and Redish, A David",
  abstract = "Empirical research links human orbitofrontal cortex (OFC) to the
              evaluation of outcomes during decision making and the
              representation of alternative (better) outcomes after failures.
              When faced with a difficult decision, rats sometimes pause and
              turn back-and-forth toward goals, until finally orienting toward
              the chosen direction. Neural representations of reward in rodent
              OFC increased immediately following each reorientation, implying
              a transient representation of the expected outcome following
              self-initiated decisions. Upon reaching reward locations and
              finding no reward (having made an error), OFC representations of
              reward decreased locally indicating a disappointment signal that
              then switched to represent the unrewarded, non-local,
              would-have-been rewarded site. These results illustrate that
              following a decision to act, neural ensembles in OFC represent
              reward, and upon the realization of an error, represent the
              reward that could have been.",
  journal  = "Front. Neurosci.",
  volume   =  6,
  pages    = "131",
  month    =  sep,
  year     =  2012,
  keywords = "counterfactual; covert representation of reward; multiple T;
              orbitofrontal cortex; regret; vicarious trial and error",
  language = "en",
  issn     = "1662-4548, 1662-453X",
  pmid     = "22973189",
  doi      = "10.3389/fnins.2012.00131",
  pmc      = "PMC3438732"
}

@ARTICLE{Johnson2007-br,
  title    = "Neural ensembles in {CA3} transiently encode paths forward of the
              animal at a decision point",
  author   = "Johnson, Adam and Redish, A David",
  abstract = "Neural ensembles were recorded from the CA3 region of rats
              running on T-based decision tasks. Examination of neural
              representations of space at fast time scales revealed a transient
              but repeatable phenomenon as rats made a decision: the location
              reconstructed from the neural ensemble swept forward, first down
              one path and then the other. Estimated representations were
              coherent and preferentially swept ahead of the animal rather than
              behind the animal, implying it represented future possibilities
              rather than recently traveled paths. Similar phenomena occurred
              at other important decisions (such as in recovery from an error).
              Local field potentials from these sites contained pronounced
              theta and gamma frequencies, but no sharp wave frequencies.
              Forward-shifted spatial representations were influenced by task
              demands and experience. These data suggest that the hippocampus
              does not represent space as a passive computation, but rather
              that hippocampal spatial processing is an active process likely
              regulated by cognitive mechanisms.",
  journal  = "J. Neurosci.",
  volume   =  27,
  number   =  45,
  pages    = "12176--12189",
  month    =  nov,
  year     =  2007,
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "17989284",
  doi      = "10.1523/JNEUROSCI.3761-07.2007"
}

@ARTICLE{Schmitzer-Torbert2004-tj,
  title    = "Neuronal activity in the rodent dorsal striatum in sequential
              navigation: separation of spatial and reward responses on the
              multiple {T} task",
  author   = "Schmitzer-Torbert, Neil and Redish, A David",
  abstract = "The striatum plays an important role in ``habitual'' learning and
              memory and has been hypothesized to implement a
              reinforcement-learning algorithm to select actions to perform
              given the current sensory input. Many experimental approaches to
              striatal activity have made use of temporally structured tasks,
              which imply that the striatal representation is temporal. To test
              this assumption, we recorded neurons in the dorsal striatum of
              rats running a sequential navigation task: the multiple T maze.
              Rats navigated a sequence of four T maze turns to receive food
              rewards delivered in two locations. The responses of neurons that
              fired phasically were examined. Task-responsive phasic neurons
              were active as rats ran on the maze (maze-responsive) or during
              reward receipt (reward-responsive). Neither maze- nor
              reward-responsive neurons encoded simple motor commands:
              maze-responses were not well correlated with the shape of the
              rat's path and most reward-responsive neurons did not fire at
              similar rates at both food-delivery sites. Maze-responsive
              neurons were active at one or more locations on the maze, but
              these responses did not cluster at spatial landmarks such as
              turns. Across sessions the activity of maze-responsive neurons
              was highly correlated when rats ran the same maze. Maze-responses
              encoded the location of the rat on the maze and imply a spatial
              representation in the striatum in a task with prominent spatial
              demands. Maze-responsive and reward-responsive neurons were two
              separate populations, suggesting a divergence in striatal
              information processing of navigation and reward.",
  journal  = "J. Neurophysiol.",
  volume   =  91,
  number   =  5,
  pages    = "2259--2272",
  month    =  may,
  year     =  2004,
  language = "en",
  issn     = "0022-3077",
  pmid     = "14736863",
  doi      = "10.1152/jn.00687.2003"
}

@ARTICLE{Amemiya2016-fb,
  title    = "Manipulating Decisiveness in Decision Making: Effects of
              Clonidine on Hippocampal Search Strategies",
  author   = "Amemiya, Seiichiro and Redish, A David",
  abstract = "Decisiveness is the ability to commit to a decision quickly and
              efficiently; in contrast, indecision entails the repeated
              consideration of multiple alternative possibilities. In humans,
              the $\alpha$2-adrenergic receptor agonist clonidine increases
              decisiveness in tasks that require planning through unknown
              neural mechanisms. In rats, indecision is manifested as
              reorienting behaviors at choice points (vicarious trial and error
              [VTE]), during which hippocampal representations alternate
              between prospective options. To determine whether the increase in
              decisiveness driven by clonidine also entails changes in
              hippocampal search processes, we compared the effect of clonidine
              on spatial representations in hippocampal neural ensembles as
              rats passed through a T-shaped decision point. Consistent with
              previous experiments, hippocampal representations reflected both
              chosen and unchosen paths during VTE events under saline control
              conditions. Also, consistent with previous experiments,
              hippocampal representations reflected the chosen path more than
              the unchosen path when the animal did not show VTE at the choice
              point. Injection of clonidine suppressed the spatial
              representation of the unchosen path at the choice point on VTE
              laps and hastened the differentiation of spatial representations
              of the chosen path from the unchosen path on non-VTE laps to
              appear before reaching the choice point. These results suggest
              that the decisiveness seen under clonidine is due to limited
              exploration of potential options in hippocampus, and suggest
              novel roles for noradrenaline as a modulator of the hippocampal
              search processes. Significance statement: Clonidine, an
              $\alpha$2-adrenergic receptor agonist, which decreases the level
              of noradrenaline in vivo, has an interesting effect in humans and
              other animals: it makes them more decisive. However, the
              mechanisms by which clonidine makes them more decisive remain
              unknown. Researchers have speculated that clonidine limits the
              amount of mental search that subjects do when planning options.
              We test this hypothesis by measuring the mental search strategy
              in rats through hippocampal recordings. We find that clonidine
              limits the options searched by rats, suggesting that
              noradrenaline also plays a role in balancing exploration and
              exploitation in internally simulated behaviors, similar to its
              role in balancing exploration and exploitation in external
              behaviors.",
  journal  = "J. Neurosci.",
  volume   =  36,
  number   =  3,
  pages    = "814--827",
  month    =  jan,
  year     =  2016,
  keywords = "VTE; hippocampus; noradrenaline; norepinphrine; place field;
              vicarious trial and error",
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "26791212",
  doi      = "10.1523/JNEUROSCI.2595-15.2016",
  pmc      = "PMC4719017"
}

@ARTICLE{Powell2014-iy,
  title    = "Complex neural codes in rat prelimbic cortex are stable across
              days on a spatial decision task",
  author   = "Powell, Nathaniel J and Redish, A David",
  abstract = "The rodent prelimbic cortex has been shown to play an important
              role in cognitive processing, and has been implicated in encoding
              many different parameters relevant to solving decision-making
              tasks. However, it is not known how the prelimbic cortex
              represents all these disparate variables, and if they are
              simultaneously represented when the task requires it. In order to
              investigate this question, we trained rats to run the Multiple-T
              Left Right Alternate (MT-LRA) task and recorded multi-unit
              ensembles from their prelimbic regions. Significant populations
              of cells in the prelimbic cortex represented the strategy
              controlling reward receipt on a given lap, whether the animal
              chose to go right or left on a given lap, and whether the animal
              made a correct decision or an error on a given lap. These
              populations overlapped in the cells recorded, with several cells
              demonstrating differential firing to all three variables. The
              spatial and strategic firing patterns of individual prelimbic
              cells were highly conserved across several days of running this
              task, indicating that each cell encoded the same information
              across days.",
  journal  = "Front. Behav. Neurosci.",
  volume   =  8,
  pages    = "120",
  month    =  apr,
  year     =  2014,
  keywords = "animal; behavior; decision-making; neural ensemble data;
              prefrontal cortex (PFC); prelimbic cortex; rats; tetrode
              recording",
  language = "en",
  issn     = "1662-5153",
  pmid     = "24795579",
  doi      = "10.3389/fnbeh.2014.00120",
  pmc      = "PMC4005964"
}

@ARTICLE{Jones2005-ye,
  title    = "Theta rhythms coordinate hippocampal-prefrontal interactions in a
              spatial memory task",
  author   = "Jones, Matthew W and Wilson, Matthew A",
  abstract = "Decision-making requires the coordinated activity of diverse
              brain structures. For example, in maze-based tasks, the
              prefrontal cortex must integrate spatial information encoded in
              the hippocampus with mnemonic information concerning route and
              task rules in order to direct behavior appropriately. Using
              simultaneous tetrode recordings from CA1 of the rat hippocampus
              and medial prefrontal cortex, we show that correlated firing in
              the two structures is selectively enhanced during behavior that
              recruits spatial working memory, allowing the integration of
              hippocampal spatial information into a broader, decision-making
              network. The increased correlations are paralleled by enhanced
              coupling of the two structures in the 4- to 12-Hz theta-frequency
              range. Thus the coordination of theta rhythms may constitute a
              general mechanism through which the relative timing of disparate
              neural activities can be controlled, allowing specialized brain
              structures to both encode information independently and to
              interact selectively according to current behavioral demands.",
  journal  = "PLoS Biol.",
  volume   =  3,
  number   =  12,
  pages    = "e402",
  month    =  dec,
  year     =  2005,
  language = "en",
  issn     = "1544-9173, 1545-7885",
  pmid     = "16279838",
  doi      = "10.1371/journal.pbio.0030402",
  pmc      = "PMC1283536"
}

@ARTICLE{Stott2014-ac,
  title    = "A functional difference in information processing between
              orbitofrontal cortex and ventral striatum during decision-making
              behaviour",
  author   = "Stott, Jeffrey J and Redish, A David",
  abstract = "Both orbitofrontal cortex (OFC) and ventral striatum (vStr) have
              been identified as key structures that represent information
              about value in decision-making tasks. However, the dynamics of
              how this information is processed are not yet understood. We
              recorded ensembles of cells from OFC and vStr in rats engaged in
              the spatial adjusting delay-discounting task, a decision-making
              task that involves a trade-off between delay to and magnitude of
              reward. Ventral striatal neural activity signalled information
              about reward before the rat's decision, whereas such
              reward-related signals were absent in OFC until after the animal
              had committed to its decision. These data support models in which
              vStr is directly involved in action selection, but OFC processes
              decision-related information afterwards that can be used to
              compare the predicted and actual consequences of behaviour.",
  journal  = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  volume   =  369,
  number   =  1655,
  month    =  nov,
  year     =  2014,
  keywords = "decision-making; neuroeconomics; nucleus accumbens; orbitofrontal
              cortex; vicarious trial and error",
  language = "en",
  issn     = "0962-8436, 1471-2970",
  pmid     = "25267815",
  doi      = "10.1098/rstb.2013.0472",
  pmc      = "PMC4186226"
}

@ARTICLE{Pereira2016-eq,
  title    = "Is there anybody out there? Neural circuits of threat detection
              in vertebrates",
  author   = "Pereira, Ana G and Moita, Marta A",
  abstract = "Avoiding or escaping a predator is arguably one of the most
              important functions of a prey's brain, hence of most animals'
              brains. Studies on fear conditioning have greatly advanced our
              understanding of the circuits that regulate learned defensive
              behaviours. However, animals possess a multitude of threat
              detection mechanisms, from hardwired circuits that ensure innate
              responses to predator cues, to the use of social information.
              Surprisingly, only more recently have these circuits captured the
              attention of a wider range of researchers working on different
              species and behavioural paradigms. These have shed new light into
              the mechanisms of threat detection revealing conservation of the
              kinds of cues animals use and of its underlying detection
              circuits across vertebrates. As most of these studies focus on
              single cues, we argue for the need to study multisensory
              integration, a process that we believe is determinant for the
              prey's defence responses.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  41,
  pages    = "179--187",
  month    =  dec,
  year     =  2016,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "27750206",
  doi      = "10.1016/j.conb.2016.09.011"
}

@ARTICLE{McNaughton2006-by,
  title    = "Path integration and the neural basis of the 'cognitive map'",
  author   = "McNaughton, Bruce L and Battaglia, Francesco P and Jensen, Ole
              and Moser, Edvard I and Moser, May-Britt",
  abstract = "The hippocampal formation can encode relative spatial location,
              without reference to external cues, by the integration of linear
              and angular self-motion (path integration). Theoretical studies,
              in conjunction with recent empirical discoveries, suggest that
              the medial entorhinal cortex (MEC) might perform some of the
              essential underlying computations by means of a unique, periodic
              synaptic matrix that could be self-organized in early development
              through a simple, symmetry-breaking operation. The scale at which
              space is represented increases systematically along the
              dorsoventral axis in both the hippocampus and the MEC, apparently
              because of systematic variation in the gain of a movement-speed
              signal. Convergence of spatially periodic input at multiple
              scales, from so-called grid cells in the entorhinal cortex, might
              result in non-periodic spatial firing patterns (place fields) in
              the hippocampus.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  7,
  number   =  8,
  pages    = "663--678",
  month    =  aug,
  year     =  2006,
  language = "en",
  issn     = "1471-003X",
  pmid     = "16858394",
  doi      = "10.1038/nrn1932"
}

@ARTICLE{Garamszegi2011-vk,
  title    = "Information-theoretic approaches to statistical analysis in
              behavioural ecology: an introduction",
  author   = "Garamszegi, L{\'a}szl{\'o} Zsolt",
  abstract = "Scientific thinking may require the consideration of multiple
              hypotheses, which often call for complex statistical models at
              the level of data analysis. The aim of this introduction is to
              provide a brief overview on how competing hypotheses are
              evaluated statistically in behavioural ecological studies and to
              offer potentially fruitful avenues for future methodological
              developments. Complex models have traditionally been treated by
              model selection approaches using threshold-based removal of
              terms, i.e. stepwise selection. A recently introduced method for
              model selection applies an information-theoretic (IT) approach,
              which simultaneously evaluates hypotheses by balancing between
              model complexity and goodness of fit. The IT method has been
              increasingly propagated in the field of ecology, while a
              literature survey shows that its spread in behavioural ecology
              has been much slower, and model simplification using stepwise
              selection is still more widespread than IT-based model selection.
              Why has the use of IT methods in behavioural ecology lagged
              behind other disciplines? This special issue examines the
              suitability of the IT method for analysing data with multiple
              predictors, which researchers encounter in our field. The volume
              brings together different viewpoints to aid behavioural
              ecologists in understanding the method, with the hope of
              enhancing the statistical integration of our discipline.",
  journal  = "Behav. Ecol. Sociobiol.",
  volume   =  65,
  number   =  1,
  pages    = "1--11",
  month    =  jan,
  year     =  2011,
  issn     = "0340-5443, 1432-0762",
  doi      = "10.1007/s00265-010-1028-7"
}

@ARTICLE{White2019-do,
  title    = "The Future Is Open: {Open-Source} Tools for Behavioral
              Neuroscience Research",
  author   = "White, Samantha R and Amarante, Linda M and Kravitz, Alexxai V
              and Laubach, Mark",
  journal  = "eNeuro",
  volume   =  6,
  number   =  4,
  month    =  aug,
  year     =  2019,
  keywords = "behavior; designs; methods; open source; protocols; tools",
  language = "en",
  issn     = "2373-2822",
  pmid     = "31358510",
  doi      = "10.1523/ENEURO.0223-19.2019",
  pmc      = "PMC6712209"
}

@ARTICLE{Crochet2019-lk,
  title    = "Neural Circuits for {Goal-Directed} Sensorimotor Transformations",
  author   = "Crochet, Sylvain and Lee, Seung-Hee and Petersen, Carl C H",
  abstract = "Precisely wired neuronal circuits process sensory information in
              a learning- and context-dependent manner in order to govern
              behavior. Simple sensory decision-making tasks in rodents are now
              beginning to reveal the contributions of distinct cell types and
              brain regions participating in the conversion of sensory
              information into learned goal-directed motor output. Task
              learning is accompanied by target-specific routing of sensory
              information to specific downstream cortical regions, with
              higher-order cortical regions such as the posterior parietal
              cortex, medial prefrontal cortex, and hippocampus appearing to
              play important roles in learning- and context-dependent
              processing of sensory input. An important challenge for future
              research is to connect cell-type-specific activity in these brain
              regions with motor neurons responsible for action initiation.",
  journal  = "Trends Neurosci.",
  volume   =  42,
  number   =  1,
  pages    = "66--77",
  month    =  jan,
  year     =  2019,
  keywords = "decision-making; neocortex; neuronal cell-types; sensory
              perception",
  language = "en",
  issn     = "0166-2236, 1878-108X",
  pmid     = "30201180",
  doi      = "10.1016/j.tins.2018.08.011"
}

@UNPUBLISHED{Clawson2019-kk,
  title    = "Computing Hubs in the Hippocampus and Cortex",
  author   = "Clawson, Wesley P and Vicente, Ana F and Bernard, Christophe and
              Battaglia, Demian and Quilichini, Pascale P",
  abstract = "Neural computation, which relies on the active storage and
              sharing of information, occurs within large neuron networks in
              the highly dynamic context of varying brain states. Whether such
              functions are performed by specific subsets of neurons and
              whether they occur in specific dynamical regimes remain poorly
              understood. Using high density recordings in the hippocampus,
              medial entorhinal and medial prefrontal cortex of the rat, we
              identify computing microstates, or discreet epochs, in which
              specific computing hub neurons perform well defined storage and
              sharing operations in a brain state-dependent manner. We retrieve
              a multiplicity of distinct computing microstates within each
              global brain state, such as REM and nonREM sleep. Half of
              recorded neurons act as computing hubs in at least one
              microstate, suggesting that functional roles are not firmly
              hardwired but dynamically reassigned at the second timescale. We
              identify sequences of microstates whose temporal organization is
              dynamic and stands between order and disorder. We propose that
              global brain states constrain the language of neuronal
              computations by regulating the syntactic complexity of these
              microstate sequences.",
  journal  = "bioRxiv",
  pages    = "513424",
  month    =  jan,
  year     =  2019,
  language = "en",
  doi      = "10.1101/513424"
}

@ARTICLE{Groman2018-tb,
  title    = "Neurochemical and behavioral dissections of decision-making in a
              rodent multi-stage task",
  author   = "Groman, Stephanie M and Massi, Bart and Mathias, Samuel R and
              Curry, Daniel W and Lee, Daeyeol and Taylor, Jane R",
  abstract = "Flexible decision-making in dynamic environments requires both
              retrospective appraisal of reinforced actions and prospective
              reasoning about the consequences of actions. These complementary
              reinforcement-learning systems can be characterized
              computationally with model-free and model-based algorithms, but
              how these processes interact at a neurobehavioral level in normal
              and pathological states is unknown. Here, we developed a
              translationally analogous multi-stage decision-making task to
              independently quantify model-free and model-based behavioral
              mechanisms in rats. We provide the first direct evidence that
              male rats, similar to humans, use both model-free and model-based
              learning when making value-based choices in the multi-stage
              decision-making task and provide novel analytic approaches for
              independently quantifying these reinforcement-learning
              strategies. Furthermore, we report that ex vivo dopamine tone in
              the ventral striatum and orbitofrontal cortex correlate with
              model-based, but not model-free, strategies indicating that the
              biological mechanisms mediating decision-making in the
              multi-stage task are conserved in rats and humans. This new
              multi-stage task provides a unique behavioral platform for
              conducting systems level analyses of decision-making in normal
              and pathological states.Significance statementDecision-making is
              influenced by both a retrospective ``model free'' system and a
              prospective ``model based'' system in humans, but the
              biobehavioral mechanisms mediating these learning systems in
              normal and disease states are unknown. Here, we describe a
              translationally analogous multi-stage decision-making task to
              provide a behavioral platform for conducting neuroscience studies
              of decision-making in rats. We provide the first evidence that
              choice behavior in rats is influenced by model-free and
              model-based systems and demonstrate that model-based, but not
              model-free, learning is associated with cortico-striatal dopamine
              tone. This novel behavioral paradigm has the potential to yield
              critical insights into the mechanisms mediating decision-making
              alterations in mental disorders.",
  journal  = "J. Neurosci.",
  month    =  nov,
  year     =  2018,
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "30413646",
  doi      = "10.1523/JNEUROSCI.2219-18.2018"
}

@ARTICLE{Lee2012-pe,
  title    = "Neural basis of reinforcement learning and decision making",
  author   = "Lee, Daeyeol and Seo, Hyojung and Jung, Min Whan",
  abstract = "Reinforcement learning is an adaptive process in which an animal
              utilizes its previous experience to improve the outcomes of
              future choices. Computational theories of reinforcement learning
              play a central role in the newly emerging areas of neuroeconomics
              and decision neuroscience. In this framework, actions are chosen
              according to their value functions, which describe how much
              future reward is expected from each action. Value functions can
              be adjusted not only through reward and penalty, but also by the
              animal's knowledge of its current environment. Studies have
              revealed that a large proportion of the brain is involved in
              representing and updating value functions and using them to
              choose an action. However, how the nature of a behavioral task
              affects the neural mechanisms of reinforcement learning remains
              incompletely understood. Future studies should uncover the
              principles by which different computational elements of
              reinforcement learning are dynamically coordinated across the
              entire brain.",
  journal  = "Annu. Rev. Neurosci.",
  volume   =  35,
  pages    = "287--308",
  month    =  mar,
  year     =  2012,
  language = "en",
  issn     = "0147-006X, 1545-4126",
  pmid     = "22462543",
  doi      = "10.1146/annurev-neuro-062111-150512",
  pmc      = "PMC3490621"
}

@UNPUBLISHED{Bernardi2018-ma,
  title    = "The geometry of abstraction in hippocampus and prefrontal cortex",
  author   = "Bernardi, Silvia and Benna, Marcus K and Rigotti, Mattia and
              Munuera, Jerome and Fusi, Stefano and Salzman, Daniel",
  abstract = "Abstraction can be defined as a cognitive process that identifies
              common features - abstract variables, or concepts - shared by
              many examples. Such conceptual knowledge enables subjects to
              generalize upon encountering new examples, an ability that
              supports inferential reasoning and cognitive flexibility. To
              confer the ability to generalize, the brain must represent
              variables in a particular `abstract9 format. Here we show how to
              construct neural representations that encode multiple variables
              in an abstract format simultaneously, and we characterize their
              geometry. Neural representations conforming to this geometry were
              observed in dorsolateral pre-frontal cortex, anterior cingulate
              cortex and the hippocampus in monkeys performing a serial
              reversal-learning task. Similar representations are observed in a
              simulated multi-layer neural network trained with
              back-propagation. These findings provide a novel framework for
              characterizing how different brain areas represent abstract
              variables that are critical for flexible conceptual
              generalization.",
  journal  = "bioRxiv",
  pages    = "408633",
  month    =  dec,
  year     =  2018,
  language = "en",
  doi      = "10.1101/408633"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Penny2012-xo,
  title     = "Bayesian models of brain and behaviour",
  author    = "Penny, William",
  abstract  = "… A readjust- ment at the next level in the hierarchy may
               increase … have multiple hidden variables, for example,
               representing different levels of abstraction in cortical
               hierarchies , and multiple … the applicability of the approach,
               but it is highly efficient for many hierarchical models [21] …",
  journal   = "ISRN Biomathematics",
  publisher = "Hindawi Publishing Corporation",
  volume    =  2012,
  year      =  2012
}

@ARTICLE{Zatka-Haas_undated-ob,
  title  = "Distinct contributions of mouse cortical areas to visual
            discrimination",
  author = "Zatka-Haas, Peter and Steinmetz, Nicholas A and Carandini, Matteo
            and Harris, Kenneth D",
  doi    = "10.1101/501627"
}

@ARTICLE{Lee2011-an,
  title     = "Using hierarchical Bayesian methods to examine the tools of
               decision-making",
  author    = "Lee, Michael D and Newell, Ben R",
  abstract  = "Author(s): Lee, Michael D.; Newell, Ben R. | Abstract:
               Hierarchical Bayesian methods offer a principled and
               comprehensive way to relate psychological models to data. Here
               we use them to model the patterns of information search,
               stopping and deciding in a simulated binary comparison judgment
               task. The simulation involves 20 subjects making 100 forced
               choice comparisons about the relative magnitudes of two objects
               (which of two German cities has more inhabitants). Two
               worked-examples show how hierarchical models can be developed to
               account for and explain the diversity of both search and
               stopping rules seen across the simulated individuals. We discuss
               how the results provide insight into current debates in the
               literature on heuristic decision making and argue that they
               demonstrate the power and flexibility of hierarchical Bayesian
               methods in modeling human decision-making.",
  publisher = "escholarship.org",
  volume    =  6,
  number    =  8,
  pages     = "832--842",
  month     =  dec,
  year      =  2011,
  keywords  = "Social and Behavioral Sciences",
  issn      = "1930-2975"
}

@ARTICLE{Voermans2004-ir,
  title     = "Interaction between the human hippocampus and the caudate
               nucleus during route recognition",
  author    = "Voermans, Nicol C and Petersson, Karl Magnus and Daudey, Leonie
               and Weber, Bernd and Van Spaendonck, Karel P and Kremer,
               Hubertus P H and Fern{\'a}ndez, Guill{\'e}n",
  abstract  = "Navigation through familiar environments can rely upon distinct
               neural representations that are related to different memory
               systems with either the hippocampus or the caudate nucleus at
               their core. However, it is a fundamental question whether and
               how these systems interact during route recognition. To address
               this issue, we combined a functional neuroimaging approach with
               a naturally occurring, well-controlled human model of caudate
               nucleus dysfunction (i.e., preclinical and early-stage
               Huntington's disease). Our results reveal a noncompetitive
               interaction so that the hippocampus compensates for gradual
               caudate nucleus dysfunction with a gradual activity increase,
               maintaining normal behavior. Furthermore, we revealed an
               interaction between medial temporal and caudate activity in
               healthy subjects, which was adaptively modified in Huntington
               patients to allow compensatory hippocampal processing. Thus, the
               two memory systems contribute in a noncompetitive, cooperative
               manner to route recognition, which enables the hippocampus to
               compensate seamlessly for the functional degradation of the
               caudate nucleus.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  43,
  number    =  3,
  pages     = "427--435",
  month     =  aug,
  year      =  2004,
  language  = "en",
  issn      = "0896-6273",
  pmid      = "15294149",
  doi       = "10.1016/j.neuron.2004.07.009"
}

@ARTICLE{Smallwood2015-wd,
  title     = "The science of mind wandering: empirically navigating the stream
               of consciousness",
  author    = "Smallwood, Jonathan and Schooler, Jonathan W",
  abstract  = "Conscious experience is fluid; it rarely remains on one topic
               for an extended period without deviation. Its dynamic nature is
               illustrated by the experience of mind wandering, in which
               attention switches from a current task to unrelated thoughts and
               feelings. Studies exploring the phenomenology of mind wandering
               highlight the importance of its content and relation to
               meta-cognition in determining its functional outcomes.
               Examination of the information-processing demands of the
               mind-wandering state suggests that it involves perceptual
               decoupling to escape the constraints of the moment, its content
               arises from episodic and affective processes, and its regulation
               relies on executive control. Mind wandering also involves a
               complex balance of costs and benefits: Its association with
               various kinds of error underlines its cost, whereas its
               relationship to creativity and future planning suggest its
               potential value. Although essential to the stream of
               consciousness, various strategies may minimize the downsides of
               mind wandering while maintaining its productive aspects.",
  journal   = "Annu. Rev. Psychol.",
  publisher = "annualreviews.org",
  volume    =  66,
  pages     = "487--518",
  month     =  jan,
  year      =  2015,
  keywords  = "default mode network; mental time travel; meta-awareness; mind
               wandering; perceptual decoupling; self-generated thought",
  language  = "en",
  issn      = "0066-4308, 1545-2085",
  pmid      = "25293689",
  doi       = "10.1146/annurev-psych-010814-015331"
}

@ARTICLE{Mullally2014-cr,
  title     = "Memory, Imagination, and Predicting the Future: A Common Brain
               Mechanism?",
  author    = "Mullally, Sin{\'e}ad L and Maguire, Eleanor A",
  abstract  = "On the face of it, memory, imagination, and prediction seem to
               be distinct cognitive functions. However, metacognitive,
               cognitive, neuropsychological, and neuroimaging evidence is
               emerging that they are not, suggesting intimate links in their
               underlying processes. Here, we explore these empirical findings
               and the evolving theoretical frameworks that seek to explain how
               a common neural system supports our recollection of times past,
               imagination, and our attempts to predict the future.",
  journal   = "Neuroscientist",
  publisher = "journals.sagepub.com",
  volume    =  20,
  number    =  3,
  pages     = "220--234",
  month     =  jun,
  year      =  2014,
  keywords  = "amnesia; episodic memory; fMRI; future; hippocampus;
               imagination; navigation; neuropsychology; prediction;
               prospection; scene construction; scenes; simulation",
  language  = "en",
  issn      = "1073-8584",
  pmid      = "23846418",
  doi       = "10.1177/1073858413495091",
  pmc       = "PMC4232337"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Buckner2010-by,
  title     = "The role of the hippocampus in prediction and imagination",
  author    = "Buckner, Randy L",
  abstract  = "Traditionally, the hippocampal system has been studied in
               relation to the goal of retrieving memories about the past.
               Recent work in humans and rodents suggests that the hippocampal
               system may be better understood as a system that facilitates
               predictions about upcoming events. The hippocampus and
               associated cortical structures are active when people envision
               future events, and damage that includes the hippocampal region
               impairs this ability. In rats, hippocampal ensembles preplay and
               replay event sequences in the …",
  journal   = "Annu. Rev. Psychol.",
  publisher = "Annual Reviews",
  volume    =  61,
  pages     = "27--48",
  year      =  2010,
  issn      = "0066-4308"
}

@ARTICLE{Wikenheiser2015-pj,
  title     = "Hippocampal theta sequences reflect current goals",
  author    = "Wikenheiser, Andrew M and Redish, A David",
  abstract  = "Hippocampal information processing is discretized by
               oscillations, and the ensemble activity of place cells is
               organized into temporal sequences bounded by theta cycles. Theta
               sequences represent time-compressed trajectories through space.
               Their forward-directed nature makes them an intuitive candidate
               mechanism for planning future trajectories, but their connection
               to goal-directed behavior remains unclear. As rats performed a
               value-guided decision-making task, the extent to which theta
               sequences projected ahead of the animal's current location
               varied on a moment-by-moment basis depending on the rat's goals.
               Look-ahead extended farther on journeys to distant goals than on
               journeys to more proximal goals and was predictive of the
               animal's destination. On arrival at goals, however, look-ahead
               was similar regardless of where the animal began its journey
               from. Together, these results provide evidence that hippocampal
               theta sequences contain information related to goals or
               intentions, pointing toward a potential spatial basis for
               planning.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  18,
  number    =  2,
  pages     = "289--294",
  month     =  feb,
  year      =  2015,
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "25559082",
  doi       = "10.1038/nn.3909",
  pmc       = "PMC4428659"
}

@ARTICLE{Kloosterman2014-ki,
  title     = "Bayesian decoding using unsorted spikes in the rat hippocampus",
  author    = "Kloosterman, Fabian and Layton, Stuart P and Chen, Zhe and
               Wilson, Matthew A",
  abstract  = "A fundamental task in neuroscience is to understand how neural
               ensembles represent information. Population decoding is a useful
               tool to extract information from neuronal populations based on
               the ensemble spiking activity. We propose a novel Bayesian
               decoding paradigm to decode unsorted spikes in the rat
               hippocampus. Our approach uses a direct mapping between spike
               waveform features and covariates of interest and avoids
               accumulation of spike sorting errors. Our decoding paradigm is
               nonparametric, encoding model-free for representing stimuli, and
               extracts information from all available spikes and their
               waveform features. We apply the proposed Bayesian decoding
               algorithm to a position reconstruction task for freely behaving
               rats based on tetrode recordings of rat hippocampal neuronal
               activity. Our detailed decoding analyses demonstrate that our
               approach is efficient and better utilizes the available
               information in the nonsortable hash than the standard
               sorting-based decoding algorithm. Our approach can be adapted to
               an online encoding/decoding framework for applications that
               require real-time decoding, such as brain-machine interfaces.",
  journal   = "J. Neurophysiol.",
  publisher = "physiology.org",
  volume    =  111,
  number    =  1,
  pages     = "217--227",
  month     =  jan,
  year      =  2014,
  keywords  = "kernel density estimation; neural decoding; population codes;
               spatial-temporal Poisson process; spike sorting",
  language  = "en",
  issn      = "0022-3077, 1522-1598",
  pmid      = "24089403",
  doi       = "10.1152/jn.01046.2012",
  pmc       = "PMC3921373"
}

@ARTICLE{Squire2004-hb,
  title    = "The medial temporal lobe",
  author   = "Squire, Larry R and Stark, Craig E L and Clark, Robert E",
  abstract = "The medial temporal lobe includes a system of anatomically
              related structures that are essential for declarative memory
              (conscious memory for facts and events). The system consists of
              the hippocampal region (CA fields, dentate gyrus, and subicular
              complex) and the adjacent perirhinal, entorhinal, and
              parahippocampal cortices. Here, we review findings from humans,
              monkeys, and rodents that illuminate the function of these
              structures. Our analysis draws on studies of human memory
              impairment and animal models of memory impairment, as well as
              neurophysiological and neuroimaging data, to show that this
              system (a) is principally concerned with memory, (b) operates
              with neocortex to establish and maintain long-term memory, and
              (c) ultimately, through a process of consolidation, becomes
              independent of long-term memory, though questions remain about
              the role of perirhinal and parahippocampal cortices in this
              process and about spatial memory in rodents. Data from
              neurophysiology, neuroimaging, and neuroanatomy point to a
              division of labor within the medial temporal lobe. However, the
              available data do not support simple dichotomies between the
              functions of the hippocampus and the adjacent medial temporal
              cortex, such as associative versus nonassociative memory,
              episodic versus semantic memory, and recollection versus
              familiarity.",
  journal  = "Annu. Rev. Neurosci.",
  volume   =  27,
  pages    = "279--306",
  year     =  2004,
  language = "en",
  issn     = "0147-006X",
  pmid     = "15217334",
  doi      = "10.1146/annurev.neuro.27.070203.144130"
}

@ARTICLE{Moser2008-af,
  title     = "Place cells, grid cells, and the brain's spatial representation
               system",
  author    = "Moser, Edvard I and Kropff, Emilio and Moser, May-Britt",
  abstract  = "More than three decades of research have demonstrated a role for
               hippocampal place cells in representation of the spatial
               environment in the brain. New studies have shown that place
               cells are part of a broader circuit for dynamic representation
               of self-location. A key component of this network is the
               entorhinal grid cells, which, by virtue of their tessellating
               firing fields, may provide the elements of a path
               integration-based neural map. Here we review how place cells and
               grid cells may form the basis for quantitative spatiotemporal
               representation of places, routes, and associated experiences
               during behavior and in memory. Because these cell types have
               some of the most conspicuous behavioral correlates among neurons
               in nonsensory cortical systems, and because their spatial firing
               structure reflects computations internally in the system,
               studies of entorhinal-hippocampal representations may offer
               considerable insight into general principles of cortical network
               dynamics.",
  journal   = "Annu. Rev. Neurosci.",
  publisher = "annualreviews.org",
  volume    =  31,
  pages     = "69--89",
  year      =  2008,
  language  = "en",
  issn      = "0147-006X",
  pmid      = "18284371",
  doi       = "10.1146/annurev.neuro.31.061307.090723"
}

@ARTICLE{Eichenbaum2000-rr,
  title     = "A cortical--hippocampal system for declarative memory",
  author    = "Eichenbaum, Howard",
  abstract  = "Recent neurobiological studies have begun to reveal the
               cognitive and neural coding mechanisms that underlie declarative
               memory --- our ability to recollect everyday events and factual
               knowledge. These studies indicate that the critical circuitry
               involves bidirectional connections between the neocortex, the
               parahippocampal region and the hippocampus. Each of these areas
               makes a unique contribution to memory processing. Widespread
               high-order neocortical areas provide dedicated processors for
               perceptual, motor or cognitive information that is influenced by
               other components of the system. The parahippocampal region
               mediates convergence of this information and extends the
               persistence of neocortical memory representations. The
               hippocampus encodes the sequences of places and events that
               compose episodic memories, and links them together through their
               common elements. Here I describe how these mechanisms work
               together to create and re-create fully networked representations
               of previous experiences and knowledge about the world.",
  journal   = "Nat. Rev. Neurosci.",
  publisher = "Macmillan Magazines Ltd.",
  volume    =  1,
  pages     = "41",
  month     =  oct,
  year      =  2000,
  issn      = "1471-003X",
  doi       = "10.1038/35036213"
}

@ARTICLE{Eichenbaum2009-jb,
  title     = "The neurobiology of memory based predictions",
  author    = "Eichenbaum, Howard and Fortin, Norbert J",
  abstract  = "Recent findings indicate that, in humans, the hippocampal memory
               system is involved in the capacity to imagine the future as well
               as remember the past. Other studies have suggested that animals
               may also have the capacity to recall the past and plan for the
               future. Here, we will consider data that bridge between these
               sets of findings by assessing the role of the hippocampus in
               memory and prediction in rats. We will argue that animals have
               the capacity for recollection and that the hippocampus plays a
               central and selective role in binding information in the service
               of recollective memory. Then we will consider examples of
               transitive inference, a paradigm that requires the integration
               of overlapping memories and flexible use of the resulting
               relational memory networks for generating predictions in novel
               situations. Our data show that animals have the capacity for
               transitive inference and that the hippocampus plays a central
               role in the ability to predict outcomes of events that have not
               yet occurred.",
  journal   = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  publisher = "royalsocietypublishing.org",
  volume    =  364,
  number    =  1521,
  pages     = "1183--1191",
  month     =  may,
  year      =  2009,
  language  = "en",
  issn      = "0962-8436, 1471-2970",
  pmid      = "19527999",
  doi       = "10.1098/rstb.2008.0306",
  pmc       = "PMC2666706"
}

@ARTICLE{Ji2008-cy,
  title     = "Firing rate dynamics in the hippocampus induced by trajectory
               learning",
  author    = "Ji, Daoyun and Wilson, Matthew A",
  abstract  = "The hippocampus is essential for spatial navigation, which may
               involve sequential learning. However, how the hippocampus
               encodes new sequences in familiar environments is unknown. To
               study the impact of novel spatial sequences on the activity of
               hippocampal neurons, we monitored hippocampal ensembles while
               rats learned to switch from two familiar trajectories to a new
               one in a familiar environment. Here, we show that this novel
               spatial experience induces two types of changes in firing rates,
               but not locations of hippocampal place cells. First, place-cell
               firing rates on the two familiar trajectories start to change
               before the actual behavioral switch to the new trajectory.
               Second, repeated exposure on the new trajectory is associated
               with an increased dependence of place-cell firing rates on
               immediate past locations. The result suggests that sequence
               encoding in the hippocampus may involve integration of
               information about the recent past into current state.",
  journal   = "J. Neurosci.",
  publisher = "Soc Neuroscience",
  volume    =  28,
  number    =  18,
  pages     = "4679--4689",
  month     =  apr,
  year      =  2008,
  language  = "en",
  issn      = "0270-6474, 1529-2401",
  pmid      = "18448645",
  doi       = "10.1523/JNEUROSCI.4597-07.2008",
  pmc       = "PMC3844815"
}

@ARTICLE{Lisman2009-tn,
  title     = "Prediction, sequences and the hippocampus",
  author    = "Lisman, John and Redish, A D",
  abstract  = "Recordings of rat hippocampal place cells have provided
               information about how the hippocampus retrieves memory
               sequences. One line of evidence has to do with phase precession,
               a process organized by theta and gamma oscillations. This
               precession can be interpreted as the cued prediction of the
               sequence of upcoming positions. In support of this
               interpretation, experiments in two-dimensional environments and
               on a cue-rich linear track demonstrate that many cells represent
               a position ahead of the animal and that this position is the
               same irrespective of which direction the rat is coming from.
               Other lines of investigation have demonstrated that such
               predictive processes also occur in the non-spatial domain and
               that retrieval can be internally or externally cued. The
               mechanism of sequence retrieval and the usefulness of this
               retrieval to guide behaviour are discussed.",
  journal   = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  publisher = "rstb.royalsocietypublishing.org",
  volume    =  364,
  number    =  1521,
  pages     = "1193--1201",
  month     =  may,
  year      =  2009,
  language  = "en",
  issn      = "0962-8436, 1471-2970",
  pmid      = "19528000",
  doi       = "10.1098/rstb.2008.0316",
  pmc       = "PMC2666714"
}

@ARTICLE{Keinan1987-ci,
  title    = "Decision making under stress: scanning of alternatives under
              controllable and uncontrollable threats",
  author   = "Keinan, G",
  abstract = "This study tested the proposition that deficient decision making
              under stress is due, to a significant extent, to the individual's
              failure to fulfill adequately an elementary requirement of the
              decision-making process, that is, the systematic consideration of
              all relevant alternatives. One hundred one undergraduate students
              (59 women and 42 men), aged 20-40, served as subjects in this
              experiment. They were requested to solve decision problems, using
              an interactive computer paradigm, while being exposed to
              controllable stress, uncontrollable stress, or no stress at all.
              There was no time constraint for the performance of the task. The
              controllability of the stressor was found to have no effect on
              the participants' performance. However, those who were exposed to
              either controllable or uncontrollable stress showed a
              significantly stronger tendency to offer solutions before all
              available alternatives had been considered and to scan their
              alternatives in a nonsystematic fashion than did participants who
              were not exposed to stress. In addition, patterns of alternative
              scanning were found to be correlated with the correctness of
              solutions to decision problems.",
  journal  = "J. Pers. Soc. Psychol.",
  volume   =  52,
  number   =  3,
  pages    = "639--644",
  month    =  mar,
  year     =  1987,
  language = "en",
  issn     = "0022-3514",
  pmid     = "3572731",
  doi      = "10.1037/0022-3514.52.3.639"
}

@ARTICLE{Wolpert1996-cd,
  title     = "The Lack of A Priori Distinctions Between Learning Algorithms",
  author    = "Wolpert, David H",
  abstract  = "This is the first of two papers that use off-training set (OTS)
               error to investigate the assumption-free relationship between
               learning algorithms. This first paper discusses the senses in
               which there are no a priori distinctions between learning
               algorithms. (The second paper discusses the senses in which
               there are such distinctions.) In this first paper it is shown,
               loosely speaking, that for any two algorithms A and B, there are
               ?as many? targets (or priors over targets) for which A has lower
               expected OTS error than B as vice versa, for loss functions like
               zero-one loss. In particular, this is true if A is
               cross-validation and B is ?anti-cross-validation? (choose the
               learning algorithm with largest cross-validation error). This
               paper ends with a discussion of the implications of these
               results for computational learning theory. It is shown that one
               cannot say: if empirical misclassification rate is low, the
               Vapnik-Chervonenkis dimension of your generalizer is small, and
               the training set is large, then with high probability your OTS
               error is small. Other implications for ?membership queries?
               algorithms and ?punting? algorithms are also discussed.",
  journal   = "Neural Comput.",
  publisher = "MIT Press",
  volume    =  8,
  number    =  7,
  pages     = "1341--1390",
  month     =  oct,
  year      =  1996,
  issn      = "0899-7667",
  doi       = "10.1162/neco.1996.8.7.1341"
}

@UNPUBLISHED{Brette2018-gj,
  title    = "Is coding a relevant metaphor for the brain?",
  author   = "Brette, Romain",
  abstract = "``Neural coding'' is a popular metaphor in neuroscience, where
              objective properties of the world are communicated to the brain
              in the form of spikes. Here I argue that this metaphor is often
              inappropriate and misleading. First, when neurons are said to
              encode experimental parameters, the neural code depends on
              experimental details that are not carried by the coding variable.
              Thus, the representational power of neural codes is much more
              limited than generally implied. Second, neural codes carry
              information only by reference to things with known meaning. In
              contrast, perceptual systems must build information from
              relations between sensory signals and actions, forming a
              structured internal model. Neural codes are inadequate for this
              purpose because they are unstructured. Third, coding variables
              are observables tied to the temporality of experiments, while
              spikes are timed actions that mediate coupling in a distributed
              dynamical system. The coding metaphor tries to fit the dynamic,
              circular and distributed causal structure of the brain into a
              linear chain of transformations between observables, but the two
              causal structures are incongruent. I conclude that the neural
              coding metaphor cannot provide a basis for theories of brain
              function, because it is incompatible with both the causal
              structure of the brain and the informational requirements of
              cognition.",
  journal  = "bioRxiv",
  pages    = "168237",
  month    =  jul,
  year     =  2018,
  language = "en",
  doi      = "10.1101/168237"
}

@ARTICLE{Rabinowitz2018-ur,
  title         = "Machine Theory of Mind",
  author        = "Rabinowitz, Neil C and Perbet, Frank and Francis Song, H and
                   Zhang, Chiyuan and Ali Eslami, S M and Botvinick, Matthew",
  abstract      = "Theory of mind (ToM; Premack \& Woodruff, 1978) broadly
                   refers to humans' ability to represent the mental states of
                   others, including their desires, beliefs, and intentions. We
                   propose to train a machine to build such models too. We
                   design a Theory of Mind neural network -- a ToMnet -- which
                   uses meta-learning to build models of the agents it
                   encounters, from observations of their behaviour alone.
                   Through this process, it acquires a strong prior model for
                   agents' behaviour, as well as the ability to bootstrap to
                   richer predictions about agents' characteristics and mental
                   states using only a small number of behavioural
                   observations. We apply the ToMnet to agents behaving in
                   simple gridworld environments, showing that it learns to
                   model random, algorithmic, and deep reinforcement learning
                   agents from varied populations, and that it passes classic
                   ToM tasks such as the ``Sally-Anne'' test (Wimmer \& Perner,
                   1983; Baron-Cohen et al., 1985) of recognising that others
                   can hold false beliefs about the world. We argue that this
                   system -- which autonomously learns how to model other
                   agents in its world -- is an important step forward for
                   developing multi-agent AI systems, for building
                   intermediating technology for machine-human interaction, and
                   for advancing the progress on interpretable AI.",
  month         =  feb,
  year          =  2018,
  archivePrefix = "arXiv",
  eprint        = "1802.07740",
  primaryClass  = "cs.AI",
  arxivid       = "1802.07740"
}

@ARTICLE{Savelli2019-fx,
  title     = "Origin and role of path integration in the cognitive
               representations of the hippocampus: computational insights into
               open questions",
  author    = "Savelli, Francesco and Knierim, James J",
  abstract  = "ABSTRACT Path integration is a straightforward concept with
               varied connotations that are important to different disciplines
               concerned with navigation, such as ethology, cognitive science,
               robotics and neuroscience. In studying the hippocampal
               formation, it is fruitful to think of path integration as a
               computation that transforms a sense of motion into a sense of
               location, continuously integrated with landmark perception.
               Here, we review experimental evidence that path integration is
               intimately involved in fundamental properties of place cells and
               other spatial cells that are thought to support a cognitive
               abstraction of space in this brain system. We discuss hypotheses
               about the anatomical and computational origin of path
               integration in the well-characterized circuits of the rodent
               limbic system. We highlight how computational frameworks for
               map-building in robotics and cognitive science alike suggest an
               essential role for path integration in the creation of a new map
               in unfamiliar territory, and how this very role can help us make
               sense of differences in neurophysiological data from novel
               versus familiar and small versus large environments. Similar
               computational principles could be at work when the hippocampus
               builds certain non-spatial representations, such as time
               intervals or trajectories defined in a sensory stimulus space.",
  journal   = "J. Exp. Biol.",
  publisher = "The Company of Biologists Ltd",
  volume    =  222,
  number    = "Suppl 1",
  pages     = "jeb188912",
  month     =  feb,
  year      =  2019,
  language  = "en",
  issn      = "0022-0949, 1477-9145",
  pmid      = "30728236",
  doi       = "10.1242/jeb.188912"
}

@ARTICLE{Hasselmo2007-mt,
  title    = "Arc length coding by interference of theta frequency oscillations
              may underlie context-dependent hippocampal unit data and episodic
              memory function",
  author   = "Hasselmo, Michael E",
  abstract = "Many memory models focus on encoding of sequences by excitatory
              recurrent synapses in region CA3 of the hippocampus. However,
              data and modeling suggest an alternate mechanism for encoding of
              sequences in which interference between theta frequency
              oscillations encodes the position within a sequence based on
              spatial arc length or time. Arc length can be coded by an
              oscillatory interference model that accounts for many features of
              the context-dependent firing properties of hippocampal neurons
              observed during performance of spatial memory tasks. In
              continuous spatial alternation, many neurons fire selectively
              depending on the direction of prior or future response (left or
              right). In contrast, in delayed non-match to position, most
              neurons fire selectively for task phase (sample vs. choice), with
              less selectivity for left versus right. These seemingly disparate
              results are effectively simulated by the same model, based on
              mechanisms similar to a model of grid cell firing in entorhinal
              cortex. The model also simulates forward shifting of firing over
              trials. Adding effects of persistent firing with reset at reward
              locations addresses changes in context-dependent firing with
              different task designs. Arc length coding could contribute to
              episodic encoding of trajectories as sequences of states and
              actions.",
  journal  = "Learn. Mem.",
  volume   =  14,
  number   =  11,
  pages    = "782--794",
  month    =  nov,
  year     =  2007,
  language = "en",
  issn     = "1072-0502, 1549-5485",
  pmid     = "18007021",
  doi      = "10.1101/lm.686607",
  pmc      = "PMC2080580"
}

@ARTICLE{Frank2009-nv,
  title     = "Multiple Systems in Decision Making: A Neurocomputational
               Perspective",
  author    = "Frank, Michael J and Cohen, Michael X and Sanfey, Alan G",
  abstract  = "Various psychological models posit the existence of two systems
               that contribute to decision making. The first system is
               bottom-up, automatic, intuitive, emotional, and implicit, while
               the second system is top-down, controlled, deliberative, and
               explicit. It has become increasingly evident that this dichotomy
               is both too simplistic and too vague. Here we consider insights
               gained from a different approach, one that considers the
               multiple computational demands of the decision-making system in
               the context of neural mechanisms specialized to accomplish some
               of that system's more basic functions. The use of explicit
               computational models has led to (a) identification of core
               trade-offs imposed by a single-system solution to cognitive
               problems that are solved by having multiple neural systems, and
               (b) novel predictions that can be tested empirically and that
               serve to further refine the models.",
  journal   = "Curr. Dir. Psychol. Sci.",
  publisher = "SAGE Publications Inc",
  volume    =  18,
  number    =  2,
  pages     = "73--77",
  month     =  apr,
  year      =  2009,
  issn      = "0963-7214",
  doi       = "10.1111/j.1467-8721.2009.01612.x"
}

@ARTICLE{Yu2016-ns,
  title    = "Stress potentiates decision biases: A stress induced
              deliberation-to-intuition ({SIDI}) model",
  author   = "Yu, Rongjun",
  abstract = "Humans often make decisions in stressful situations, for example
              when the stakes are high and the potential consequences severe,
              or when the clock is ticking and the task demand is overwhelming.
              In response, a whole train of biological responses to stress has
              evolved to allow organisms to make a fight-or-flight response.
              When under stress, fast and effortless heuristics may dominate
              over slow and demanding deliberation in making decisions under
              uncertainty. Here, I review evidence from behavioral studies and
              neuroimaging research on decision making under stress and propose
              that stress elicits a switch from an analytic reasoning system to
              intuitive processes, and predict that this switch is associated
              with diminished activity in the prefrontal executive control
              regions and exaggerated activity in subcortical reactive emotion
              brain areas. Previous studies have shown that when stressed,
              individuals tend to make more habitual responses than
              goal-directed choices, be less likely to adjust their initial
              judgment, and rely more on gut feelings in social situations. It
              is possible that stress influences the arbitration between the
              emotion responses in subcortical regions and deliberative
              processes in the prefrontal cortex, so that final decisions are
              based on unexamined innate responses. Future research may further
              test this 'stress induced deliberation-to-intuition' (SIDI) model
              and examine its underlying neural mechanisms.",
  journal  = "Neurobiol Stress",
  volume   =  3,
  pages    = "83--95",
  month    =  jun,
  year     =  2016,
  keywords = "Cortisol; Decision making; Stress",
  language = "en",
  issn     = "2352-2895",
  pmid     = "27981181",
  doi      = "10.1016/j.ynstr.2015.12.006",
  pmc      = "PMC5146206"
}

@ARTICLE{Keramati2011-oj,
  title    = "Speed/accuracy trade-off between the habitual and the
              goal-directed processes",
  author   = "Keramati, Mehdi and Dezfouli, Amir and Piray, Payam",
  abstract = "Instrumental responses are hypothesized to be of two kinds:
              habitual and goal-directed, mediated by the sensorimotor and the
              associative cortico-basal ganglia circuits, respectively. The
              existence of the two heterogeneous associative learning
              mechanisms can be hypothesized to arise from the comparative
              advantages that they have at different stages of learning. In
              this paper, we assume that the goal-directed system is
              behaviourally flexible, but slow in choice selection. The
              habitual system, in contrast, is fast in responding, but
              inflexible in adapting its behavioural strategy to new
              conditions. Based on these assumptions and using the
              computational theory of reinforcement learning, we propose a
              normative model for arbitration between the two processes that
              makes an approximately optimal balance between search-time and
              accuracy in decision making. Behaviourally, the model can explain
              experimental evidence on behavioural sensitivity to outcome at
              the early stages of learning, but insensitivity at the later
              stages. It also explains that when two choices with equal
              incentive values are available concurrently, the behaviour
              remains outcome-sensitive, even after extensive training.
              Moreover, the model can explain choice reaction time variations
              during the course of learning, as well as the experimental
              observation that as the number of choices increases, the reaction
              time also increases. Neurobiologically, by assuming that phasic
              and tonic activities of midbrain dopamine neurons carry the
              reward prediction error and the average reward signals used by
              the model, respectively, the model predicts that whereas phasic
              dopamine indirectly affects behaviour through reinforcing
              stimulus-response associations, tonic dopamine can directly
              affect behaviour through manipulating the competition between the
              habitual and the goal-directed systems and thus, affect reaction
              time.",
  journal  = "PLoS Comput. Biol.",
  volume   =  7,
  number   =  5,
  pages    = "e1002055",
  month    =  may,
  year     =  2011,
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "21637741",
  doi      = "10.1371/journal.pcbi.1002055",
  pmc      = "PMC3102758"
}

@ARTICLE{Boureau2015-eo,
  title    = "Deciding How To Decide: {Self-Control} and {Meta-Decision} Making",
  author   = "Boureau, Y-Lan and Sokol-Hessner, Peter and Daw, Nathaniel D",
  abstract = "Many different situations related to self control involve
              competition between two routes to decisions: default and frugal
              versus more resource-intensive. Examples include habits versus
              deliberative decisions, fatigue versus cognitive effort, and
              Pavlovian versus instrumental decision making. We propose that
              these situations are linked by a strikingly similar core dilemma,
              pitting the opportunity costs of monopolizing shared resources
              such as executive functions for some time, against the
              possibility of obtaining a better outcome. We offer a unifying
              normative perspective on this underlying rational
              meta-optimization, review how this may tie together recent
              advances in many separate areas, and connect several independent
              models. Finally, we suggest that the crucial mechanisms and
              meta-decision variables may be shared across domains.",
  journal  = "Trends Cogn. Sci.",
  volume   =  19,
  number   =  11,
  pages    = "700--710",
  month    =  nov,
  year     =  2015,
  language = "en",
  issn     = "1364-6613, 1879-307X",
  pmid     = "26483151",
  doi      = "10.1016/j.tics.2015.08.013"
}

@ARTICLE{Schwabe2011-ko,
  title    = "Stress-induced modulation of instrumental behavior: from
              goal-directed to habitual control of action",
  author   = "Schwabe, Lars and Wolf, Oliver T",
  abstract = "Actions that are directed at achieving pleasant or avoiding
              unpleasant states are referred to as instrumental. The
              acquisition of instrumental actions can be controlled by two
              anatomically and functionally distinct processes: a goal-directed
              process that is based on the prefrontal cortex and dorsomedial
              striatum and encodes the causal relationship between an action
              and the motivational value of the outcome and a dorsolateral
              striatum-based habit process that learns associations between
              actions and antecedent stimuli. Here, we review recent research
              showing that stress modulates the control of instrumental action
              in a manner that favors habitual over goal-directed action. At
              the neuroendocrine level, this stress-induced shift towards habit
              action requires the concerted action of glucocorticoids and
              noradrenergic arousal and is most likely accompanied by opposite
              functional changes in the corticostriatal circuits underlying
              goal-directed and habitual actions. Although generally adaptive,
              these changes in the control of instrumental action under stress
              may promote dysfunctional behaviors and the development of
              psychiatric disorders such as addiction.",
  journal  = "Behav. Brain Res.",
  volume   =  219,
  number   =  2,
  pages    = "321--328",
  month    =  jun,
  year     =  2011,
  language = "en",
  issn     = "0166-4328, 1872-7549",
  pmid     = "21219935",
  doi      = "10.1016/j.bbr.2010.12.038"
}

@ARTICLE{Corbit2018-ep,
  title    = "Understanding the balance between goal-directed and habitual
              behavioral control",
  author   = ". Corbit, Laura H",
  abstract = "Decisions can be reached in different ways. Sometimes they
              involve careful consideration of the expected outcome of our
              behavior. Other times, behavior is generated more automatically
              if a particular response has been repeatedly successful in the
              past. I review animal research into goal-directed and habit
              learning including common training paradigms and studies
              investigating the neural substrates of actions and habits.
              Further, I summarize the wide range of factors (e.g., drugs,
              stress, diet) that promote habitual control. Since habitual
              control is prevalent across a range of neuropsychiatric disorders
              it is important to be able to accurately identify when behavior
              is habitual and better understanding of the behavioral and neural
              determinants of habitual control may enable behavior change when
              needed.",
  journal  = "Current Opinion in Behavioral Sciences",
  volume   =  20,
  pages    = "161--168",
  month    =  apr,
  year     =  2018,
  issn     = "2352-1546",
  doi      = "10.1016/j.cobeha.2018.01.010"
}

@ARTICLE{Wirz2018-zd,
  title    = "Habits under stress: mechanistic insights across different types
              of learning",
  author   = "Wirz, Lisa and Bogdanov, Mario and Schwabe, Lars",
  abstract = "Learning can be controlled by reflective, `cognitive' or
              reflexive, `habitual' systems. An essential question is what
              factors determine which system governs behavior. Here we review
              recent evidence from navigation, classification, and instrumental
              learning, demonstrating that stressful events induce a shift from
              cognitive to habitual control of learning. We propose that this
              shift, mediated by noradrenaline and glucocorticoids acting
              through mineralocorticoid receptors, is orchestrated by the
              amygdala. Although generally adaptive for coping with acute
              stress, the bias toward habits comes at the cost of reduced
              flexibility of learning and may ultimately contribute to
              stress-related psychopathologies.",
  journal  = "Current Opinion in Behavioral Sciences",
  volume   =  20,
  pages    = "9--16",
  month    =  apr,
  year     =  2018,
  issn     = "2352-1546",
  doi      = "10.1016/j.cobeha.2017.08.009"
}

@ARTICLE{Schwabe2013-ka,
  title    = "Stress and multiple memory systems: from 'thinking' to 'doing'",
  author   = "Schwabe, Lars and Wolf, Oliver T",
  abstract = "Although it has been known for decades that stress influences
              memory performance, it was only recently shown that stress may
              alter the contribution of multiple, anatomically and functionally
              distinct memory systems to behavior. Here, we review recent
              animal and human studies demonstrating that stress promotes a
              shift from flexible 'cognitive' to rather rigid 'habit' memory
              systems and discuss, based on recent neuroimaging data in humans,
              the underlying brain mechanisms. We argue that, despite being
              generally adaptive, this stress-induced shift towards 'habit'
              memory may, in vulnerable individuals, be a risk factor for
              psychopathology.",
  journal  = "Trends Cogn. Sci.",
  volume   =  17,
  number   =  2,
  pages    = "60--68",
  month    =  feb,
  year     =  2013,
  language = "en",
  issn     = "1364-6613, 1879-307X",
  pmid     = "23290054",
  doi      = "10.1016/j.tics.2012.12.001"
}

@ARTICLE{Arnsten2009-ow,
  title    = "Stress signalling pathways that impair prefrontal cortex
              structure and function",
  author   = "Arnsten, Amy F T",
  abstract = "The prefrontal cortex (PFC) - the most evolved brain region -
              subserves our highest-order cognitive abilities. However, it is
              also the brain region that is most sensitive to the detrimental
              effects of stress exposure. Even quite mild acute uncontrollable
              stress can cause a rapid and dramatic loss of prefrontal
              cognitive abilities, and more prolonged stress exposure causes
              architectural changes in prefrontal dendrites. Recent research
              has begun to reveal the intracellular signalling pathways that
              mediate the effects of stress on the PFC. This research has
              provided clues as to why genetic or environmental insults that
              disinhibit stress signalling pathways can lead to symptoms of
              profound prefrontal cortical dysfunction in mental illness.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  10,
  number   =  6,
  pages    = "410--422",
  month    =  jun,
  year     =  2009,
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "19455173",
  doi      = "10.1038/nrn2648",
  pmc      = "PMC2907136"
}

@ARTICLE{Balleine2010-es,
  title    = "Human and rodent homologies in action control: corticostriatal
              determinants of goal-directed and habitual action",
  author   = "Balleine, Bernard W and O'Doherty, John P",
  abstract = "Recent behavioral studies in both humans and rodents have found
              evidence that performance in decision-making tasks depends on two
              different learning processes; one encoding the relationship
              between actions and their consequences and a second involving the
              formation of stimulus-response associations. These learning
              processes are thought to govern goal-directed and habitual
              actions, respectively, and have been found to depend on
              homologous corticostriatal networks in these species. Thus,
              recent research using comparable behavioral tasks in both humans
              and rats has implicated homologous regions of cortex (medial
              prefrontal cortex/medial orbital cortex in humans and prelimbic
              cortex in rats) and of dorsal striatum (anterior caudate in
              humans and dorsomedial striatum in rats) in goal-directed action
              and in the control of habitual actions (posterior lateral putamen
              in humans and dorsolateral striatum in rats). These learning
              processes have been argued to be antagonistic or competing
              because their control over performance appears to be all or none.
              Nevertheless, evidence has started to accumulate suggesting that
              they may at times compete and at others cooperate in the
              selection and subsequent evaluation of actions necessary for
              normal choice performance. It appears likely that cooperation or
              competition between these sources of action control depends not
              only on local interactions in dorsal striatum but also on the
              cortico-basal ganglia network within which the striatum is
              embedded and that mediates the integration of learning with basic
              motivational and emotional processes. The neural basis of the
              integration of learning and motivation in choice and
              decision-making is still controversial and we review some recent
              hypotheses relating to this issue.",
  journal  = "Neuropsychopharmacology",
  volume   =  35,
  number   =  1,
  pages    = "48--69",
  month    =  jan,
  year     =  2010,
  language = "en",
  issn     = "0893-133X, 1740-634X",
  pmid     = "19776734",
  doi      = "10.1038/npp.2009.131",
  pmc      = "PMC3055420"
}

@ARTICLE{Dayan2012-jd,
  title    = "How to set the switches on this thing",
  author   = "Dayan, Peter",
  abstract = "Reinforcement learning (RL) has become a dominant computational
              paradigm for modeling psychological and neural aspects of
              affectively charged decision-making tasks. RL is normally
              construed in terms of the interaction between a subject and its
              environment, with the former emitting actions, and the latter
              providing stimuli, and appetitive and aversive reinforcement.
              However, there is recent emphasis on redrawing the boundary
              between the two, with the organism constructing its own notion of
              reward, punishment and state, and with internal actions, such as
              the gating of working memory, being treated on an equal footing
              with external manipulation of the environment. We review recent
              work in this area, focusing on cognitive control.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  22,
  number   =  6,
  pages    = "1068--1074",
  month    =  dec,
  year     =  2012,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "22704797",
  doi      = "10.1016/j.conb.2012.05.011"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Payne1988-pk,
  title     = "Adaptive strategy selection in decision making",
  author    = "Payne, John W and Bettman, James R and Johnson, Eric J",
  abstract  = "The role of effort and accuracy in the adaptive use of decision
               processes is examined. A computer simulation using the concept
               of elementary information processes identified heuristic choice
               strategies that approximate the accuracy of normative procedures
               while saving substantial effort. However, no single heuristic
               did well across all task and context conditions. Of particular
               interest was the finding that under time constraints, several
               heuristics were more accurate than a truncated normative
               procedure. Using a process …",
  journal   = "J. Exp. Psychol. Learn. Mem. Cogn.",
  publisher = "American Psychological Association",
  volume    =  14,
  number    =  3,
  pages     = "534",
  year      =  1988,
  issn      = "0278-7393"
}

@ARTICLE{Seymour2008-vs,
  title    = "Emotion, decision making, and the amygdala",
  author   = "Seymour, Ben and Dolan, Ray",
  abstract = "Emotion plays a critical role in many contemporary accounts of
              decision making, but exactly what underlies its influence and how
              this is mediated in the brain remain far from clear. Here, we
              review behavioral studies that suggest that Pavlovian processes
              can exert an important influence over choice and may account for
              many effects that have traditionally been attributed to emotion.
              We illustrate how recent experiments cast light on the underlying
              structure of Pavlovian control and argue that generally this
              influence makes good computational sense. Corresponding
              neuroscientific data from both animals and humans implicate a
              central role for the amygdala through interactions with other
              brain areas. This yields a neurobiological account of emotion in
              which it may operate, often covertly, to optimize rather than
              corrupt economic choice.",
  journal  = "Neuron",
  volume   =  58,
  number   =  5,
  pages    = "662--671",
  month    =  jun,
  year     =  2008,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "18549779",
  doi      = "10.1016/j.neuron.2008.05.020"
}

@ARTICLE{Viard2011-oi,
  title    = "Anterior hippocampus and goal-directed spatial decision making",
  author   = "Viard, Armelle and Doeller, Christian F and Hartley, Tom and
              Bird, Chris M and Burgess, Neil",
  abstract = "Planning spatial paths through our environment is an important
              part of everyday life and is supported by a neural system
              including the hippocampus and prefrontal cortex. Here we
              investigated the precise functional roles of the components of
              this system in humans by using fMRI as participants performed a
              simple goal-directed route-planning task. Participants had to
              choose the shorter of two routes to a goal in a visual scene that
              might contain a barrier blocking the most direct route, requiring
              a detour, or might be obscured by a curtain, requiring memory for
              the scene. The participant's start position was varied to
              parametrically manipulate their proximity to the goal and the
              difference in length of the two routes. Activity in medial
              prefrontal cortex, precuneus, and left posterior parietal cortex
              was associated with detour planning, regardless of difficulty,
              whereas activity in parahippocampal gyrus was associated with
              remembering the spatial layout of the visual scene. Activity in
              bilateral anterior hippocampal formation showed a strong increase
              the closer the start position was to the goal, together with
              medial prefrontal, medial and posterior parietal cortices. Our
              results are consistent with computational models in which goal
              proximity is used to guide subsequent navigation and with the
              association of anterior hippocampal areas with nonspatial
              functions such as arousal and reward expectancy. They illustrate
              how spatial and nonspatial functions combine within the anterior
              hippocampus, and how these functions interact with
              parahippocampal, parietal, and prefrontal areas in decision
              making and mnemonic function.",
  journal  = "J. Neurosci.",
  volume   =  31,
  number   =  12,
  pages    = "4613--4621",
  month    =  mar,
  year     =  2011,
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "21430161",
  doi      = "10.1523/JNEUROSCI.4640-10.2011"
}

@ARTICLE{Mobbs2015-ag,
  title    = "Neuroethological studies of fear, anxiety, and risky
              decision-making in rodents and humans",
  author   = "Mobbs, Dean and Kim, Jeansok J",
  abstract = "Prey are relentlessly faced with a series of survival problems to
              solve. One enduring problem is predation, where the prey's
              answers rely on the complex interaction between actions
              cultivated during its life course and defense reactions passed
              down by descendants. To understand the proximate neural responses
              to analogous threats, affective neuroscientists have favored
              well-controlled associative learning paradigms, yet researchers
              are now creating semi-realistic environments that examine the
              dynamic flow of decision-making and escape calculations that
              mimic the prey's real world choices. In the context of research
              from the field of ethology and behavioral ecology, we review some
              of the recent literature in rodent and human neuroscience and
              discuss how these studies have the potential to provide new
              insights into the behavioral expression, computations, and the
              neural circuits that underlie healthy and pathological fear and
              anxiety.",
  journal  = "Curr Opin Behav Sci",
  volume   =  5,
  pages    = "8--15",
  month    =  oct,
  year     =  2015,
  language = "en",
  issn     = "2352-1546",
  pmid     = "29984261",
  doi      = "10.1016/j.cobeha.2015.06.005",
  pmc      = "PMC6034691"
}

@ARTICLE{Balleine2015-wp,
  title    = "Hierarchical control of goal-directed action in the
              cortical--basal ganglia network",
  author   = "Balleine, Bernard W and Dezfouli, Amir and Ito, Makato and Doya,
              Kenji",
  abstract = "Goal-directed control depends on constructing a model of the
              world that maps actions onto specific outcomes, allowing choice
              to remain adaptive when the values of outcomes change. In complex
              environments, however, such models can become computationally
              unwieldy. One solution to this problem is to develop a
              hierarchical control structure within which more complex, or
              abstract, actions are built from simpler ones. Here we review
              findings suggesting that the acquisition, evaluation and
              execution of goal-directed actions accords well with predictions
              from hierarchical models. We describe recent evidence that
              hierarchical action control is implemented in a series of
              feedback loops integrating secondary motor areas with the basal
              ganglia and describe how such a structure not only overcomes
              issues of dimensionality, but also helps to explain the formation
              of actions sequences, action chunking and the relationship
              between goal-directed actions and habits.",
  journal  = "Current Opinion in Behavioral Sciences",
  volume   =  5,
  pages    = "1--7",
  month    =  oct,
  year     =  2015,
  issn     = "2352-1546",
  doi      = "10.1016/j.cobeha.2015.06.001"
}

@ARTICLE{Ito2016-tm,
  title    = "The role of the hippocampus in approach-avoidance conflict
              decision-making: Evidence from rodent and human studies",
  author   = "Ito, Rutsuko and Lee, Andy C H",
  abstract = "The hippocampus (HPC) has been traditionally considered to
              subserve mnemonic processing and spatial cognition. Over the past
              decade, however, there has been increasing interest in its
              contributions to processes beyond these two domains. One question
              is whether the HPC plays an important role in decision-making
              under conditions of high approach-avoidance conflict, a scenario
              that arises when a goal stimulus is simultaneously associated
              with reward and punishment. This idea has its origins in rodent
              work conducted in the 1950s and 1960s, and has recently
              experienced a resurgence of interest in the literature. In this
              review, we will first provide an overview of classic rodent
              lesion data that first suggested a role for the HPC in
              approach-avoidance conflict processing and then proceed to
              describe a wide range of more recent evidence from studies
              conducted in rodents and humans. We will demonstrate that there
              is substantial, converging cross-species evidence to support the
              idea that the HPC, in particular the ventral (in
              rodents)/anterior (in humans) portion, contributes to
              approach-avoidance conflict decision making. Furthermore, we
              suggest that the seemingly disparate functions of the HPC (e.g.
              memory, spatial cognition, conflict processing) need not be
              mutually exclusive.",
  journal  = "Behav. Brain Res.",
  volume   =  313,
  pages    = "345--357",
  month    =  oct,
  year     =  2016,
  keywords = "Approach-avoidance; Conflict; Decision-making; Functional
              neuroimaging; Hippocampus; Human; Lesion; Long axis; Memory;
              Rodent; Septotemporal axis; Spatial cognition",
  language = "en",
  issn     = "0166-4328, 1872-7549",
  pmid     = "27457133",
  doi      = "10.1016/j.bbr.2016.07.039"
}

@ARTICLE{Pennartz2011-jd,
  title    = "The hippocampal-striatal axis in learning, prediction and
              goal-directed behavior",
  author   = "Pennartz, C M A and Ito, R and Verschure, P F M J and Battaglia,
              F P and Robbins, T W",
  abstract = "The hippocampal formation and striatum subserve declarative and
              procedural memory, respectively. However, experimental evidence
              suggests that the ventral striatum, as opposed to the dorsal
              striatum, does not lend itself to being part of either system.
              Instead, it may constitute a system integrating inputs from the
              amygdala, prefrontal cortex and hippocampus to generate
              motivational, outcome-predicting signals that invigorate
              goal-directed behaviors. Inspired by reinforcement learning
              models, we suggest an alternative scheme for computational
              functions of the striatum. Dorsal and ventral striatum are
              proposed to compute outcome predictions largely in parallel,
              using different types of information as input. The nature of the
              inputs to striatum is furthermore combinatorial, and the
              specificity of predictions transcends the level of scalar value
              signals, incorporating episodic information.",
  journal  = "Trends Neurosci.",
  volume   =  34,
  number   =  10,
  pages    = "548--559",
  month    =  oct,
  year     =  2011,
  language = "en",
  issn     = "0166-2236, 1878-108X",
  pmid     = "21889806",
  doi      = "10.1016/j.tins.2011.08.001"
}

@ARTICLE{Dezfouli2013-ik,
  title    = "Actions, action sequences and habits: evidence that goal-directed
              and habitual action control are hierarchically organized",
  author   = "Dezfouli, Amir and Balleine, Bernard W",
  abstract = "Behavioral evidence suggests that instrumental conditioning is
              governed by two forms of action control: a goal-directed and a
              habit learning process. Model-based reinforcement learning (RL)
              has been argued to underlie the goal-directed process; however,
              the way in which it interacts with habits and the structure of
              the habitual process has remained unclear. According to a flat
              architecture, the habitual process corresponds to model-free RL,
              and its interaction with the goal-directed process is coordinated
              by an external arbitration mechanism. Alternatively, the
              interaction between these systems has recently been argued to be
              hierarchical, such that the formation of action sequences
              underlies habit learning and a goal-directed process selects
              between goal-directed actions and habitual sequences of actions
              to reach the goal. Here we used a two-stage decision-making task
              to test predictions from these accounts. The hierarchical account
              predicts that, because they are tied to each other as an action
              sequence, selecting a habitual action in the first stage will be
              followed by a habitual action in the second stage, whereas the
              flat account predicts that the statuses of the first and second
              stage actions are independent of each other. We found, based on
              subjects' choices and reaction times, that human subjects
              combined single actions to build action sequences and that the
              formation of such action sequences was sufficient to explain
              habitual actions. Furthermore, based on Bayesian model
              comparison, a family of hierarchical RL models, assuming a
              hierarchical interaction between habit and goal-directed
              processes, provided a better fit of the subjects' behavior than a
              family of flat models. Although these findings do not rule out
              all possible model-free accounts of instrumental conditioning,
              they do show such accounts are not necessary to explain habitual
              actions and provide a new basis for understanding how
              goal-directed and habitual action control interact.",
  journal  = "PLoS Comput. Biol.",
  volume   =  9,
  number   =  12,
  pages    = "e1003364",
  month    =  dec,
  year     =  2013,
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "24339762",
  doi      = "10.1371/journal.pcbi.1003364",
  pmc      = "PMC3854489"
}

@ARTICLE{Botvinick2009-wz,
  title    = "Hierarchically organized behavior and its neural foundations: a
              reinforcement learning perspective",
  author   = "Botvinick, Matthew M and Niv, Yael and Barto, Andrew C",
  abstract = "Research on human and animal behavior has long emphasized its
              hierarchical structure-the divisibility of ongoing behavior into
              discrete tasks, which are comprised of subtask sequences, which
              in turn are built of simple actions. The hierarchical structure
              of behavior has also been of enduring interest within
              neuroscience, where it has been widely considered to reflect
              prefrontal cortical functions. In this paper, we reexamine
              behavioral hierarchy and its neural substrates from the point of
              view of recent developments in computational reinforcement
              learning. Specifically, we consider a set of approaches known
              collectively as hierarchical reinforcement learning, which extend
              the reinforcement learning paradigm by allowing the learning
              agent to aggregate actions into reusable subroutines or skills. A
              close look at the components of hierarchical reinforcement
              learning suggests how they might map onto neural structures, in
              particular regions within the dorsolateral and orbital prefrontal
              cortex. It also suggests specific ways in which hierarchical
              reinforcement learning might provide a complement to existing
              psychological models of hierarchically structured behavior. A
              particularly important question that hierarchical reinforcement
              learning brings to the fore is that of how learning identifies
              new action routines that are likely to provide useful building
              blocks in solving a wide range of future problems. Here and at
              many other points, hierarchical reinforcement learning offers an
              appealing framework for investigating the computational and
              neural underpinnings of hierarchically structured behavior.",
  journal  = "Cognition",
  volume   =  113,
  number   =  3,
  pages    = "262--280",
  month    =  dec,
  year     =  2009,
  language = "en",
  issn     = "0010-0277, 1873-7838",
  pmid     = "18926527",
  doi      = "10.1016/j.cognition.2008.08.011",
  pmc      = "PMC2783353"
}

@ARTICLE{Doya2000-wf,
  title    = "Complementary roles of basal ganglia and cerebellum in learning
              and motor control",
  author   = "Doya, K",
  abstract = "The classical notion that the basal ganglia and the cerebellum
              are dedicated to motor control has been challenged by the
              accumulation of evidence revealing their involvement in
              non-motor, cognitive functions. From a computational viewpoint,
              it has been suggested that the cerebellum, the basal ganglia, and
              the cerebral cortex are specialized for different types of
              learning: namely, supervised learning, reinforcement learning and
              unsupervised learning, respectively. This idea of
              learning-oriented specialization is helpful in understanding the
              complementary roles of the basal ganglia and the cerebellum in
              motor control and cognitive functions.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  10,
  number   =  6,
  pages    = "732--739",
  month    =  dec,
  year     =  2000,
  language = "en",
  issn     = "0959-4388",
  pmid     = "11240282",
  doi      = "10.1016/S0959-4388(00)00153-7"
}

@ARTICLE{Killcross2003-ij,
  title     = "Coordination of actions and habits in the medial prefrontal
               cortex of rats",
  author    = "Killcross, Simon and Coutureau, Etienne",
  abstract  = "As animals learn novel behavioural responses, performance is
               maintained by two dissociable influences. Initial responding is
               goal-directed and under voluntary control, but overtraining of
               the same response routine leads to behavioural autonomy and the
               development of habits that are no longer voluntary or
               goal-directed. Rats normally show goal-directed performance
               after limited training, indexed by sensitivity to changes in the
               value of reward, but this sensitivity to goal value is lost with
               extended training. Rats with selective lesions of the prelimbic
               medial prefrontal cortex showed no sensitivity to goal value
               after either limited or extended training, whereas rats with
               lesions of the infralimbic region of the medial prefrontal
               cortex showed the opposite pattern of deficit, a marked
               sensitivity to goal value after both limited and extended
               training. This double-dissociation suggests that the prelimbic
               region is responsible for voluntary response performance and the
               infralimbic cortex mediates the incremental ability of extended
               training to override this goal-directed behaviour.",
  journal   = "Cereb. Cortex",
  publisher = "academic.oup.com",
  volume    =  13,
  number    =  4,
  pages     = "400--408",
  month     =  apr,
  year      =  2003,
  language  = "en",
  issn      = "1047-3211",
  pmid      = "12631569"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Doya1999-jy,
  title     = "What are the computations of the cerebellum, the basal ganglia
               and the cerebral cortex?",
  author    = "Doya, K",
  abstract  = "The classical notion that the cerebellum and the basal ganglia
               are dedicated to motor control is under dispute given increasing
               evidence of their involvement in non-motor functions. Is it then
               impossible to characterize the functions of the cerebellum, the
               basal ganglia and the cerebral cortex in a simplistic manner?
               This paper presents a novel view that their computational roles
               can be characterized not by asking what are the ``goals'' of
               their computation, such as motor or sensory, but by asking what
               are the ``methods'' of their …",
  journal   = "Neural Netw.",
  publisher = "Elsevier",
  year      =  1999,
  issn      = "0893-6080"
}

@ARTICLE{Battaglia2004-ef,
  title     = "Local sensory cues and place cell directionality: additional
               evidence of prospective coding in the hippocampus",
  author    = "Battaglia, Francesco P and Sutherland, Gary R and McNaughton,
               Bruce L",
  abstract  = "In tasks involving goal-directed, stereotyped trajectories on
               uniform tracks, the spatially selective activity of hippocampal
               principal cells depends on the animal's direction of motion.
               Principal cell ensemble activity while the rat moves in opposite
               directions through a given location is typically uncorrelated.
               It is shown here, with data from three experiments, that
               multimodal, local sensory cues can change the directional
               properties of CA1 pyramidal cells, inducing bidirectionality in
               a significant proportion of place cells. For a majority of these
               bidirectional place cells, place field centers in the two
               directions of motion were displaced relative to one another, as
               would be the case if the cells were representing a position in
               space approximately 5-10 cm ahead of the rat or if place cells
               were subject to strong accommodation or inhibition in the latter
               half of their input fields. However, place field density was not
               affected by the presence of local cues, but in the experimental
               condition with the most salient sensory cues, the CA1 population
               vectors in the ``cue-rich'' condition were sparser and changed
               more quickly in space than in the ``cue-poor'' condition. These
               results suggest that ``view-invariant'' object representations
               are projected to the hippocampus from lower cortical areas and
               can have the effect of increasing the correlation of the
               hippocampal input vectors in the two directions, hence
               decreasing the orthogonality of hippocampal output.",
  journal   = "J. Neurosci.",
  publisher = "Soc Neuroscience",
  volume    =  24,
  number    =  19,
  pages     = "4541--4550",
  month     =  may,
  year      =  2004,
  language  = "en",
  issn      = "0270-6474, 1529-2401",
  pmid      = "15140925",
  doi       = "10.1523/JNEUROSCI.4896-03.2004"
}

@ARTICLE{Zhang2014-nb,
  title     = "Spatial representations of place cells in darkness are supported
               by path integration and border information",
  author    = "Zhang, Sijie and Sch{\"o}nfeld, Fabian and Wiskott, Laurenz and
               Manahan-Vaughan, Denise",
  abstract  = "Effective spatial navigation is enabled by reliable reference
               cues that derive from sensory information from the external
               environment, as well as from internal sources such as the
               vestibular system. The integration of information from these
               sources enables dead reckoning in the form of path integration.
               Navigation in the dark is associated with the accumulation of
               errors in terms of perception of allocentric position and this
               may relate to error accumulation in path integration. We
               assessed this by recording from place cells in the dark under
               circumstances where spatial sensory cues were suppressed.
               Spatial information content, spatial coherence, place field
               size, and peak and infield firing rates decreased whereas
               sparsity increased following exploration in the dark compared to
               the light. Nonetheless it was observed that place field
               stability in darkness was sustained by border information in a
               subset of place cells. To examine the impact of encountering the
               environment's border on navigation, we analyzed the trajectory
               and spiking data gathered during navigation in the dark. Our
               data suggest that although error accumulation in path
               integration drives place field drift in darkness, under
               circumstances where border contact is possible, this information
               is integrated to enable retention of spatial representations.",
  journal   = "Front. Behav. Neurosci.",
  publisher = "frontiersin.org",
  volume    =  8,
  pages     = "222",
  month     =  jun,
  year      =  2014,
  keywords  = "CA1; hippocampus; place cells; sensory",
  language  = "en",
  issn      = "1662-5153",
  pmid      = "25009477",
  doi       = "10.3389/fnbeh.2014.00222",
  pmc       = "PMC4068307"
}

@ARTICLE{Chersi2015-qr,
  title    = "The Cognitive Architecture of Spatial Navigation: Hippocampal and
              Striatal Contributions",
  author   = "Chersi, Fabian and Burgess, Neil",
  abstract = "Spatial navigation can serve as a model system in cognitive
              neuroscience, in which specific neural representations, learning
              rules, and control strategies can be inferred from the vast
              experimental literature that exists across many species,
              including humans. Here, we review this literature, focusing on
              the contributions of hippocampal and striatal systems, and
              attempt to outline a minimal cognitive architecture that is
              consistent with the experimental literature and that synthesizes
              previous related computational modeling. The resulting
              architecture includes striatal reinforcement learning based on
              egocentric representations of sensory states and actions,
              incidental Hebbian association of sensory information with
              allocentric state representations in the hippocampus, and
              arbitration of the outputs of both systems based on
              confidence/uncertainty in medial prefrontal cortex. We discuss
              the relationship between this architecture and learning in
              model-free and model-based systems, episodic memory, imagery, and
              planning, including some open questions and directions for
              further experiments.",
  journal  = "Neuron",
  volume   =  88,
  number   =  1,
  pages    = "64--77",
  month    =  oct,
  year     =  2015,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "26447573",
  doi      = "10.1016/j.neuron.2015.09.021"
}

@ARTICLE{Whitlock2008-wa,
  title     = "Navigating from hippocampus to parietal cortex",
  author    = "Whitlock, Jonathan R and Sutherland, Robert J and Witter, Menno
               P and Moser, May-Britt and Moser, Edvard I",
  abstract  = "The navigational system of the mammalian cortex comprises a
               number of interacting brain regions. Grid cells in the medial
               entorhinal cortex and place cells in the hippocampus are thought
               to participate in the formation of a dynamic representation of
               the animal's current location, and these cells are presumably
               critical for storing the representation in memory. To traverse
               the environment, animals must be able to translate coordinate
               information from spatial maps in the entorhinal cortex and
               hippocampus into body-centered representations that can be used
               to direct locomotion. How this is done remains an enigma. We
               propose that the posterior parietal cortex is critical for this
               transformation.",
  journal   = "Proc. Natl. Acad. Sci. U. S. A.",
  publisher = "National Acad Sciences",
  volume    =  105,
  number    =  39,
  pages     = "14755--14762",
  month     =  sep,
  year      =  2008,
  keywords  = "navigation",
  language  = "en",
  issn      = "0027-8424, 1091-6490",
  pmid      = "18812502",
  doi       = "10.1073/pnas.0804216105",
  pmc       = "PMC2567440"
}

@ARTICLE{Foster2012-lf,
  title     = "Sequence learning and the role of the hippocampus in rodent
               navigation",
  author    = "Foster, David J and Knierim, James J",
  abstract  = "The hippocampus has long been associated with navigation and
               spatial representations, but it has been difficult to link
               directly the neurophysiological correlates of hippocampal place
               cells with navigational planning and action. In recent years,
               large-scale population recordings of place cells have revealed
               that spatial sequences are stored and activated in ways that may
               support navigational strategies. Plasticity mechanisms allow the
               hippocampus to store learned sequences of locations that may
               allow predictions of future locations based on past experience.
               These sequences can also be activated during navigational
               behavior in ways that may allow the animal to learn trajectories
               toward goals. Task-dependent alterations in place cell firing
               patterns may reflect the operation of the hippocampus in
               associating locations with navigationally relevant decision
               variables.",
  journal   = "Curr. Opin. Neurobiol.",
  publisher = "Elsevier",
  volume    =  22,
  number    =  2,
  pages     = "294--300",
  month     =  apr,
  year      =  2012,
  language  = "en",
  issn      = "0959-4388, 1873-6882",
  pmid      = "22226994",
  doi       = "10.1016/j.conb.2011.12.005",
  pmc       = "PMC3338858"
}

@ARTICLE{Cheung2007-hd,
  title     = "Animal navigation: the difficulty of moving in a straight line",
  author    = "Cheung, Allen and Zhang, Shaowu and Stricker, Christian and
               Srinivasan, Mandyam V",
  abstract  = "In principle, there are two strategies for navigating a straight
               course. One is to use an external directional reference and
               continually reorienting with reference to it, while the other is
               to infer body rotations from internal sensory information only.
               We show here that, while the first strategy will enable an
               animal or mobile agent to move arbitrarily far away from its
               starting point, the second strategy will not do so, even after
               an infinite number of steps. Thus, an external directional
               reference-some form of compass-is indispensable for ensuring
               progress away from home. This limitation must place significant
               constraints on the evolution of biological navigation systems.
               Some specific examples are discussed. An important corollary
               arising from the analysis of compassless navigation is that the
               maximum expected displacement represents a robust measure of the
               straightness of a path.",
  journal   = "Biol. Cybern.",
  publisher = "Springer",
  volume    =  97,
  number    =  1,
  pages     = "47--61",
  month     =  jul,
  year      =  2007,
  language  = "en",
  issn      = "0340-1200",
  pmid      = "17520273",
  doi       = "10.1007/s00422-007-0158-0"
}

@ARTICLE{Dosovitskiy2016-au,
  title         = "Learning to Act by Predicting the Future",
  author        = "Dosovitskiy, Alexey and Koltun, Vladlen",
  abstract      = "We present an approach to sensorimotor control in immersive
                   environments. Our approach utilizes a high-dimensional
                   sensory stream and a lower-dimensional measurement stream.
                   The cotemporal structure of these streams provides a rich
                   supervisory signal, which enables training a sensorimotor
                   control model by interacting with the environment. The model
                   is trained using supervised learning techniques, but without
                   extraneous supervision. It learns to act based on raw
                   sensory input from a complex three-dimensional environment.
                   The presented formulation enables learning without a fixed
                   goal at training time, and pursuing dynamically changing
                   goals at test time. We conduct extensive experiments in
                   three-dimensional simulations based on the classical
                   first-person game Doom. The results demonstrate that the
                   presented approach outperforms sophisticated prior
                   formulations, particularly on challenging tasks. The results
                   also show that trained models successfully generalize across
                   environments and goals. A model trained using the presented
                   approach won the Full Deathmatch track of the Visual Doom AI
                   Competition, which was held in previously unseen
                   environments.",
  month         =  nov,
  year          =  2016,
  archivePrefix = "arXiv",
  eprint        = "1611.01779",
  primaryClass  = "cs.LG",
  arxivid       = "1611.01779"
}

@ARTICLE{Botvinick2012-ez,
  title    = "Hierarchical reinforcement learning and decision making",
  author   = "Botvinick, Matthew Michael",
  abstract = "The hierarchical structure of human and animal behavior has been
              of critical interest in neuroscience for many years. Yet
              understanding the neural processes that give rise to such
              structure remains an open challenge. In recent research, a new
              perspective on hierarchical behavior has begun to take shape,
              inspired by ideas from machine learning, and in particular the
              framework of hierarchical reinforcement learning. Hierarchical
              reinforcement learning builds on traditional reinforcement
              learning mechanisms, extending them to accommodate temporally
              extended behaviors or subroutines. The resulting computational
              paradigm has begun to influence both theoretical and empirical
              work in neuroscience, conceptually aligning the study of
              hierarchical behavior with research on other aspects of learning
              and decision making, and giving rise to some thought-provoking
              new findings.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  22,
  number   =  6,
  pages    = "956--962",
  month    =  dec,
  year     =  2012,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "22695048",
  doi      = "10.1016/j.conb.2012.05.008"
}

@ARTICLE{Botvinick2012-ho,
  title    = "Planning as inference",
  author   = "Botvinick, Matthew and Toussaint, Marc",
  abstract = "Recent developments in decision-making research are bringing the
              topic of planning back to center stage in cognitive science. This
              renewed interest reopens an old, but still unanswered question:
              how exactly does planning happen? What are the underlying
              information processing operations and how are they implemented in
              the brain? Although a range of interesting possibilities exists,
              recent work has introduced a potentially transformative new idea,
              according to which planning is accomplished through probabilistic
              inference.",
  journal  = "Trends Cogn. Sci.",
  volume   =  16,
  number   =  10,
  pages    = "485--488",
  month    =  oct,
  year     =  2012,
  language = "en",
  issn     = "1364-6613, 1879-307X",
  pmid     = "22940577",
  doi      = "10.1016/j.tics.2012.08.006"
}

@ARTICLE{Stachenfeld2017-yp,
  title    = "The hippocampus as a predictive map",
  author   = "Stachenfeld, Kimberly L and Botvinick, Matthew M and Gershman,
              Samuel J",
  abstract = "A cognitive map has long been the dominant metaphor for
              hippocampal function, embracing the idea that place cells encode
              a geometric representation of space. However, evidence for
              predictive coding, reward sensitivity and policy dependence in
              place cells suggests that the representation is not purely
              spatial. We approach this puzzle from a reinforcement learning
              perspective: what kind of spatial representation is most useful
              for maximizing future reward? We show that the answer takes the
              form of a predictive representation. This representation captures
              many aspects of place cell responses that fall outside the
              traditional view of a cognitive map. Furthermore, we argue that
              entorhinal grid cells encode a low-dimensionality basis set for
              the predictive representation, useful for suppressing noise in
              predictions and extracting multiscale structure for hierarchical
              planning.",
  journal  = "Nat. Neurosci.",
  volume   =  20,
  number   =  11,
  pages    = "1643--1653",
  month    =  nov,
  year     =  2017,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "28967910",
  doi      = "10.1038/nn.4650"
}

@ARTICLE{Minderer2019-kz,
  title    = "The Spatial Structure of Neural Encoding in Mouse Posterior
              Cortex during Navigation",
  author   = "Minderer, Matthias and Brown, Kristen D and Harvey, Christopher D",
  abstract = "Navigation engages many cortical areas, including visual,
              parietal, and retrosplenial cortices. These regions have been
              mapped anatomically and with sensory stimuli and studied
              individually during behavior. Here, we investigated how
              behaviorally driven neural activity is distributed and combined
              across these regions. We performed dense sampling of
              single-neuron activity across the mouse posterior cortex and
              developed unbiased methods to relate neural activity to behavior
              and anatomical space. Most parts of the posterior cortex encoded
              most behavior-related features. However, the relative strength
              with which features were encoded varied across space. Therefore,
              the posterior cortex could be divided into discriminable areas
              based solely on behaviorally relevant neural activity, revealing
              functional structure in association regions. Multimodal
              representations combining sensory and movement signals were
              strongest in posterior parietal cortex, where gradients of
              single-feature representations spatially overlapped. We propose
              that encoding of behavioral features is not constrained by
              retinotopic borders and instead varies smoothly over space within
              association regions.",
  journal  = "Neuron",
  month    =  feb,
  year     =  2019,
  keywords = "calcium imaging; cortical architecture; mouse cortex; navigation;
              optogenetics; parietal cortex; virtual reality; visual cortex",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "30772081",
  doi      = "10.1016/j.neuron.2019.01.029"
}

@ARTICLE{Jacob2019-iv,
  title     = "Path integration maintains spatial periodicity of grid cell
               firing in a {1D} circular track",
  author    = "Jacob, Pierre-Yves and Capitano, Fabrizio and Poucet, Bruno and
               Save, Etienne and Sargolini, Francesca",
  abstract  = "Entorhinal grid cells are thought to provide a 2D spatial metric
               of the environment. In this study we demonstrate that in a
               familiar 1D circular track (i.e., a continuous space) grid cells
               display a novel 1D equidistant firing pattern based on
               integrated distance rather than travelled distance or time. In
               addition, field spacing is increased compared to a 2D open
               field, probably due to a reduced access to the visual cue in the
               track. This metrical modification is accompanied by a change in
               LFP theta oscillations, but no change in intrinsic grid cell
               rhythmicity, or firing activity of entorhinal speed and
               head-direction cells. These results suggest that in a 1D
               circular space grid cell spatial selectivity is shaped by path
               integration processes, while grid scale relies on external
               information.",
  journal   = "Nat. Commun.",
  publisher = "Nature Publishing Group",
  volume    =  10,
  number    =  1,
  pages     = "840",
  month     =  feb,
  year      =  2019,
  language  = "en",
  issn      = "2041-1723, 2041-1723",
  doi       = "10.1038/s41467-019-08795-w"
}

@ARTICLE{Foster2000-uu,
  title     = "A model of hippocampally dependent navigation, using the
               temporal difference learning rule",
  author    = "Foster, D J and Morris, R G and Dayan, P",
  abstract  = "This paper presents a model of how hippocampal place cells might
               be used for spatial navigation in two watermaze tasks: the
               standard reference memory task and a delayed matching-to-place
               task. In the reference memory task, the escape platform occupies
               a single location and rats gradually learn relatively direct
               paths to the goal over the course of days, in each of which they
               perform a fixed number of trials. In the delayed
               matching-to-place task, the escape platform occupies a novel
               location on each day, and rats gradually acquire one-trial
               learning, i.e., direct paths on the second trial of each day.
               The model uses a local, incremental, and statistically efficient
               connectionist algorithm called temporal difference learning in
               two distinct components. The first is a reinforcement-based
               ``actor-critic'' network that is a general model of classical
               and instrumental conditioning. In this case, it is applied to
               navigation, using place cells to provide information about
               state. By itself, the actor-critic can learn the reference
               memory task, but this learning is inflexible to changes to the
               platform location. We argue that one-trial learning in the
               delayed matching-to-place task demands a goal-independent
               representation of space. This is provided by the second
               component of the model: a network that uses temporal difference
               learning and self-motion information to acquire consistent
               spatial coordinates in the environment. Each component of the
               model is necessary at a different stage of the task; the
               actor-critic provides a way of transferring control to the
               component that performs best. The model successfully captures
               gradual acquisition in both tasks, and, in particular, the
               ultimate development of one-trial learning in the delayed
               matching-to-place task. Place cells report a form of stable,
               allocentric information that is well-suited to the various kinds
               of learning in the model.",
  journal   = "Hippocampus",
  publisher = "Wiley Online Library",
  volume    =  10,
  number    =  1,
  pages     = "1--16",
  year      =  2000,
  language  = "en",
  issn      = "1050-9631",
  pmid      = "10706212",
  doi       = "10.1002/(SICI)1098-1063(2000)10:1<1::AID-HIPO1>3.0.CO;2-1"
}

@ARTICLE{Davidson2009-cn,
  title     = "Hippocampal replay of extended experience",
  author    = "Davidson, Thomas J and Kloosterman, Fabian and Wilson, Matthew A",
  abstract  = "During pauses in exploration, ensembles of place cells in the
               rat hippocampus re-express firing sequences corresponding to
               recent spatial experience. Such ``replay'' co-occurs with ripple
               events: short-lasting (approximately 50-120 ms), high-frequency
               (approximately 200 Hz) oscillations that are associated with
               increased hippocampal-cortical communication. In previous
               studies, rats exploring small environments showed replay
               anchored to the rat's current location and compressed in time
               into a single ripple event. Here, we show, using a neural
               decoding approach, that firing sequences corresponding to long
               runs through a large environment are replayed with high fidelity
               and that such replay can begin at remote locations on the track.
               Extended replay proceeds at a characteristic virtual speed of
               approximately 8 m/s and remains coherent across trains of ripple
               events. These results suggest that extended replay is composed
               of chains of shorter subsequences, which may reflect a strategy
               for the storage and flexible expression of memories of prolonged
               experience.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  63,
  number    =  4,
  pages     = "497--507",
  month     =  aug,
  year      =  2009,
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "19709631",
  doi       = "10.1016/j.neuron.2009.07.027",
  pmc       = "PMC4364032"
}

@ARTICLE{Knierim2016-cx,
  title    = "Tracking the flow of hippocampal computation: Pattern separation,
              pattern completion, and attractor dynamics",
  author   = "Knierim, James J and Neunuebel, Joshua P",
  abstract = "Classic computational theories of the mnemonic functions of the
              hippocampus ascribe the processes of pattern separation to the
              dentate gyrus (DG) and pattern completion to the CA3 region.
              Until the last decade, the large majority of single-unit studies
              of the hippocampus in behaving animals were from the CA1 region.
              The lack of data from the DG, CA3, and the entorhinal inputs to
              the hippocampus severely hampered the ability to test these
              theories with neurophysiological techniques. The past ten years
              have seen a major increase in the recordings from the CA3 region
              and the medial entorhinal cortex (MEC), with an increasing (but
              still limited) number of experiments from the lateral entorhinal
              cortex (LEC) and DG. This paper reviews a series of studies in a
              local-global cue mismatch (double-rotation) experiment in which
              recordings were made from cells in the anterior thalamus, MEC,
              LEC, DG, CA3, and CA1 regions. Compared to the standard cue
              environment, the change in the DG representation of the
              cue-mismatch environment was greater than the changes in its
              entorhinal inputs, providing support for the theory of pattern
              separation in the DG. In contrast, the change in the CA3
              representation of the cue-mismatch environment was less than the
              changes in its entorhinal and DG inputs, providing support for a
              pattern completion/error correction function of CA3. The results
              are interpreted in terms of continuous attractor network models
              of the hippocampus and the relationship of these models to
              pattern separation and pattern completion theories. Whereas DG
              may perform an automatic pattern separation function, the
              attractor dynamics of CA3 allow it to perform a pattern
              separation or pattern completion function, depending on the
              nature of its inputs and the relative strength of the internal
              attractor dynamics.",
  journal  = "Neurobiol. Learn. Mem.",
  volume   =  129,
  pages    = "38--49",
  month    =  mar,
  year     =  2016,
  keywords = "Attractors; CA3; Dentate gyrus; Pattern completion; Pattern
              separation; Place cells",
  language = "en",
  issn     = "1074-7427, 1095-9564",
  pmid     = "26514299",
  doi      = "10.1016/j.nlm.2015.10.008",
  pmc      = "PMC4792674"
}

@ARTICLE{Knierim_James_J2014-wd,
  title     = "Functional correlates of the lateral and medial entorhinal
               cortex: objects, path integration and local--global reference
               frames",
  author    = "{Knierim James J.} and {Neunuebel Joshua P.} and {Deshmukh
               Sachin S.}",
  journal   = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  publisher = "Royal Society",
  volume    =  369,
  number    =  1635,
  pages     = "20130369",
  month     =  feb,
  year      =  2014,
  issn      = "0962-8436",
  doi       = "10.1098/rstb.2013.0369"
}

@ARTICLE{Deshmukh2013-nc,
  title    = "Influence of local objects on hippocampal representations:
              Landmark vectors and memory",
  author   = "Deshmukh, Sachin S and Knierim, James J",
  abstract = "The hippocampus is thought to represent nonspatial information in
              the context of spatial information. An animal can derive both
              spatial information as well as nonspatial information from the
              objects (landmarks) it encounters as it moves around in an
              environment. In this article, correlates of both object-derived
              spatial as well as nonspatial information in the hippocampus of
              rats foraging in the presence of objects are demonstrated. A new
              form of CA1 place cells, called landmark-vector cells, that
              encode spatial locations as a vector relationship to local
              landmarks is described. Such landmark vector relationships can be
              dynamically encoded. Of the 26 CA1 neurons that developed new
              fields in the course of a day's recording sessions, in eight
              cases, the new fields were located at a similar distance and
              direction from a landmark as the initial field was located
              relative to a different landmark. In addition, object-location
              memory in the hippocampus is also described. When objects were
              removed from an environment or moved to new locations, a small
              number of neurons in CA1 and CA3 increased firing at the
              locations where the objects used to be. In some neurons, this
              increase occurred only in one location, indicating object + place
              conjunctive memory; in other neurons, the increase in firing was
              seen at multiple locations where an object used to be. Taken
              together, these results demonstrate that the spatially restricted
              firing of hippocampal neurons encode multiple types of
              information regarding the relationship between an animal's
              location and the location of objects in its environment.",
  journal  = "Hippocampus",
  volume   =  23,
  number   =  4,
  pages    = "253--267",
  month    =  apr,
  year     =  2013,
  keywords = "boundary vector cell; hippocampus; landmark; memory; objects",
  language = "en",
  issn     = "1050-9631, 1098-1063",
  pmid     = "23447419",
  doi      = "10.1002/hipo.22101",
  pmc      = "PMC3869706"
}

@ARTICLE{Knierim2009-ze,
  title    = "Imagining the possibilities: ripples, routes, and reactivation",
  author   = "Knierim, James J",
  abstract = "Hippocampal place cells fire selectively when a rat occupies a
              particular location. Under certain conditions, the cells briefly
              represent trajectories along locations away from the rat's
              current location. New results lend important insight into this
              phenomenon and demonstrate spatiotemporally coherent, cognitive
              representations that are independent of current sensory input.",
  journal  = "Neuron",
  volume   =  63,
  number   =  4,
  pages    = "421--423",
  month    =  aug,
  year     =  2009,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "19709624",
  doi      = "10.1016/j.neuron.2009.08.002"
}

@ARTICLE{Sweis2018-ep,
  title    = "Mice learn to avoid regret",
  author   = "Sweis, Brian M and Thomas, Mark J and Redish, A David",
  abstract = "Regret can be defined as the subjective experience of recognizing
              that one has made a mistake and that a better alternative could
              have been selected. The experience of regret is thought to carry
              negative utility. This typically takes two distinct forms:
              augmenting immediate postregret valuations to make up for losses,
              and augmenting long-term changes in decision-making strategies to
              avoid future instances of regret altogether. While the short-term
              changes in valuation have been studied in human psychology,
              economics, neuroscience, and even recently in nonhuman-primate
              and rodent neurophysiology, the latter long-term process has
              received far less attention, with no reports of regret avoidance
              in nonhuman decision-making paradigms. We trained 31 mice in a
              novel variant of the Restaurant Row economic decision-making
              task, in which mice make decisions of whether to spend time from
              a limited budget to achieve food rewards of varying costs
              (delays). Importantly, we tested mice longitudinally for 70
              consecutive days, during which the task provided their only
              source of food. Thus, decision strategies were interdependent
              across both trials and days. We separated principal commitment
              decisions from secondary reevaluation decisions across space and
              time and found evidence for regret-like behaviors following
              change-of-mind decisions that corrected prior economically
              disadvantageous choices. Immediately following change-of-mind
              events, subsequent decisions appeared to make up for lost effort
              by altering willingness to wait, decision speed, and pellet
              consumption speed, consistent with past reports of regret in
              rodents. As mice were exposed to an increasingly reward-scarce
              environment, we found they adapted and refined distinct economic
              decision-making strategies over the course of weeks to maximize
              reinforcement rate. However, we also found that even without
              changes in reinforcement rate, mice transitioned from an early
              strategy rooted in foraging to a strategy rooted in deliberation
              and planning that prevented future regret-inducing change-of-mind
              episodes from occurring. These data suggest that mice are
              learning to avoid future regret, independent of and separate from
              reinforcement rate maximization.",
  journal  = "PLoS Biol.",
  volume   =  16,
  number   =  6,
  pages    = "e2005853",
  month    =  jun,
  year     =  2018,
  language = "en",
  issn     = "1544-9173, 1545-7885",
  pmid     = "29927938",
  doi      = "10.1371/journal.pbio.2005853",
  pmc      = "PMC6013153"
}

@ARTICLE{Amemiya2018-ym,
  title    = "Hippocampal {Theta-Gamma} Coupling Reflects {State-Dependent}
              Information Processing in Decision Making",
  author   = "Amemiya, Seiichiro and Redish, A David",
  abstract = "During decision making, hippocampal activity encodes information
              sometimes about present and sometimes about potential future
              plans. The mechanisms underlying this transition remain unknown.
              Building on the evidence that gamma oscillations at different
              frequencies (low gamma [LG], 30-55 Hz; high gamma [HG], 60-90 Hz;
              and epsilon, 100-140 Hz) reflect inputs from different circuits,
              we identified how changes in those frequencies reflect different
              information-processing states. Using a unique noradrenergic
              manipulation by clonidine, which shifted both neural
              representations and gamma states, we found that future
              representations depended on gamma components. These changes were
              identifiable on each cycle of theta as asymmetries in the theta
              cycle, which arose from changes within the ratio of LG and HG
              power and the underlying phases of those gamma rhythms within the
              theta cycle. These changes in asymmetry of the theta cycle
              reflected changes in representations of present and future on
              each theta cycle.",
  journal  = "Cell Rep.",
  volume   =  22,
  number   =  12,
  pages    = "3328--3338",
  month    =  mar,
  year     =  2018,
  keywords = "decision making; gamma; hippocampus; local field potential;
              noradrenaline; norepinephrine; place cell; theta; vicarious trial
              and error",
  language = "en",
  issn     = "2211-1247",
  pmid     = "29562187",
  doi      = "10.1016/j.celrep.2018.02.091",
  pmc      = "PMC5929482"
}

@UNPUBLISHED{Zhang2019-bo,
  title    = "A Sequence Learning Model for Decision Making in the Brain",
  author   = "Zhang, Zhewei and Cheng, Huzi and Lin, Zhongqiao and Yang,
              Tianming",
  abstract = "Decision making is often modelled as a competition between
              options. Currently, a great number of popular models to explain
              the accuracy and speed in decision making are based on variations
              of drift diffusion models (DDM), in which the options compete by
              accumulating evidence toward decision bounds. Attractor-based
              recurrent neural networks have been proposed to explain the
              underlying neural mechanism. Yet, it is questionable that either
              the DDM or attractor network is the brain9s general solution for
              decision making. Here, we propose an alternative recurrent neural
              network modeling approach based on gated recurrent units and
              sequence learning. Our network model is trained to learn the
              statistical structure of temporal sequences of sensory events,
              action events, and reward events. We demonstrate its learning
              with a reaction-time version of the weather prediction task
              previously studied in monkey experiments, in which both the
              animals9 behavior and the neuronal responses were consistent with
              the DDM. The network model9s performance is able to reflect the
              accuracy and reaction time pattern of the animals9 choice
              behavior. The analyses of the unit responses in the network
              reveal that they match important experimental findings. Notably,
              we find units encoding the accumulated evidence and the urgency
              signal. We further identify two groups of units based on their
              connection weights to the choice output units. Simulated lesions
              of each group of units produce doubly-dissociable effects on the
              network9s choice and reaction time behavior. Graph analyses
              reveal that these two groups of units belong to one highly
              inter-connected sub-network. Finally, we show that the network is
              capable of making predictions consistent with the predictive
              coding and Bayesian inference framework. Our work offers
              experimentally testable predictions of how decision making is
              achieved in the brain. It provides an approach that may piece
              together experimental findings of decision making, reinforcement
              learning, and predictive coding. In particular, it suggests that
              the DDM may be a manifestation of a more general computational
              mechanism in the brain.",
  journal  = "bioRxiv",
  pages    = "555862",
  month    =  feb,
  year     =  2019,
  language = "en",
  doi      = "10.1101/555862"
}

@ARTICLE{Gershman2014-ll,
  title    = "Retrospective revaluation in sequential decision making: a tale
              of two systems",
  author   = "Gershman, Samuel J and Markman, Arthur B and Otto, A Ross",
  abstract = "Recent computational theories of decision making in humans and
              animals have portrayed 2 systems locked in a battle for control
              of behavior. One system--variously termed model-free or
              habitual--favors actions that have previously led to reward,
              whereas a second--called the model-based or goal-directed
              system--favors actions that causally lead to reward according to
              the agent's internal model of the environment. Some evidence
              suggests that control can be shifted between these systems using
              neural or behavioral manipulations, but other evidence suggests
              that the systems are more intertwined than a competitive account
              would imply. In 4 behavioral experiments, using a retrospective
              revaluation design and a cognitive load manipulation, we show
              that human decisions are more consistent with a cooperative
              architecture in which the model-free system controls behavior,
              whereas the model-based system trains the model-free system by
              replaying and simulating experience.",
  journal  = "J. Exp. Psychol. Gen.",
  volume   =  143,
  number   =  1,
  pages    = "182--194",
  month    =  feb,
  year     =  2014,
  language = "en",
  issn     = "0096-3445",
  pmid     = "23230992",
  doi      = "10.1037/a0030844"
}

@ARTICLE{Jones2012-oh,
  title    = "Orbitofrontal cortex supports behavior and learning using
              inferred but not cached values",
  author   = "Jones, Joshua L and Esber, Guillem R and McDannald, Michael A and
              Gruber, Aaron J and Hernandez, Alex and Mirenzi, Aaron and
              Schoenbaum, Geoffrey",
  abstract = "Computational and learning theory models propose that behavioral
              control reflects value that is both cached (computed and stored
              during previous experience) and inferred (estimated on the fly on
              the basis of knowledge of the causal structure of the
              environment). The latter is thought to depend on the
              orbitofrontal cortex. Yet some accounts propose that the
              orbitofrontal cortex contributes to behavior by signaling
              ``economic'' value, regardless of the associative basis of the
              information. We found that the orbitofrontal cortex is critical
              for both value-based behavior and learning when value must be
              inferred but not when a cached value is sufficient. The
              orbitofrontal cortex is thus fundamental for accessing
              model-based representations of the environment to compute value
              rather than for signaling value per se.",
  journal  = "Science",
  volume   =  338,
  number   =  6109,
  pages    = "953--956",
  month    =  nov,
  year     =  2012,
  language = "en",
  issn     = "0036-8075, 1095-9203",
  pmid     = "23162000",
  doi      = "10.1126/science.1227489",
  pmc      = "PMC3592380"
}

@ARTICLE{Richard_R_Sutton2015-ot,
  title    = "Reinforcement Learning - An introduction",
  author   = "Richard R. Sutton, Andrew G Burton",
  journal  = "The MIT Press",
  year     =  2015,
  keywords = "books"
}

@BOOK{Kass2014-jh,
  title    = "Analysis of Neural Data",
  author   = "Kass, Robert E and Eden, Uri T and Brown, Emery N",
  year     =  2014,
  keywords = "books",
  isbn     = "9781461496014",
  doi      = "10.1007/978-1-4614-9602-1"
}

@ARTICLE{Wallis2011-jp,
  title    = "Cross-species studies of orbitofrontal cortex and value-based
              decision-making",
  author   = "Wallis, Jonathan D",
  abstract = "Recent work has emphasized the role that orbitofrontal cortex
              (OFC) has in value-based decision-making. However, it is also
              clear that a number of discrepancies have arisen when comparing
              the findings from animal models to those from humans. Here, we
              examine several possibilities that might explain these
              discrepancies, including anatomical difference between species,
              the behavioral tasks used to probe decision-making and the
              methodologies used to assess neural function. Understanding how
              these differences affect the interpretation of experimental
              results will help us to better integrate future results from
              animal models. This will enable us to fully realize the benefits
              of using multiple approaches to understand OFC function.",
  journal  = "Nat. Neurosci.",
  volume   =  15,
  number   =  1,
  pages    = "13--19",
  month    =  nov,
  year     =  2011,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "22101646",
  doi      = "10.1038/nn.2956",
  pmc      = "PMC3549638"
}

@ARTICLE{Ernst2005-xn,
  title    = "Neurobiology of decision making: a selective review from a
              neurocognitive and clinical perspective",
  author   = "Ernst, Monique and Paulus, Martin P",
  abstract = "We present a temporal map of key processes that occur during
              decision making, which consists of three stages: 1) formation of
              preferences among options, 2) selection and execution of an
              action, and 3) experience or evaluation of an outcome. This
              framework can be used to integrate findings of traditional choice
              psychology, neuropsychology, brain lesion studies, and functional
              neuroimaging. Decision making is distributed across various brain
              centers, which are differentially active across these stages of
              decision making. This approach can be used to follow
              developmental trajectories of the different stages of decision
              making and to identify unique deficits associated with distinct
              psychiatric disorders.",
  journal  = "Biol. Psychiatry",
  volume   =  58,
  number   =  8,
  pages    = "597--604",
  month    =  oct,
  year     =  2005,
  language = "en",
  issn     = "0006-3223",
  pmid     = "16095567",
  doi      = "10.1016/j.biopsych.2005.06.004"
}

@ARTICLE{Rolls2004-wu,
  title    = "The functions of the orbitofrontal cortex",
  author   = "Rolls, Edmund T",
  abstract = "The orbitofrontal cortex contains the secondary taste cortex, in
              which the reward value of taste is represented. It also contains
              the secondary and tertiary olfactory cortical areas, in which
              information about the identity and also about the reward value of
              odours is represented. The orbitofrontal cortex also receives
              information about the sight of objects from the temporal lobe
              cortical visual areas, and neurons in it learn and reverse the
              visual stimulus to which they respond when the association of the
              visual stimulus with a primary reinforcing stimulus (such as
              taste) is reversed. This is an example of stimulus-reinforcement
              association learning, and is a type of stimulus-stimulus
              association learning. More generally, the stimulus might be a
              visual or olfactory stimulus, and the primary (unlearned)
              positive or negative reinforcer a taste or touch. A somatosensory
              input is revealed by neurons that respond to the texture of food
              in the mouth, including a population that responds to the mouth
              feel of fat. In complementary neuroimaging studies in humans, it
              is being found that areas of the orbitofrontal cortex are
              activated by pleasant touch, by painful touch, by taste, by
              smell, and by more abstract reinforcers such as winning or losing
              money. Damage to the orbitofrontal cortex can impair the learning
              and reversal of stimulus-reinforcement associations, and thus the
              correction of behavioural responses when there are no longer
              appropriate because previous reinforcement contingencies change.
              The information which reaches the orbitofrontal cortex for these
              functions includes information about faces, and damage to the
              orbitofrontal cortex can impair face (and voice) expression
              identification. This evidence thus shows that the orbitofrontal
              cortex is involved in decoding and representing some primary
              reinforcers such as taste and touch; in learning and reversing
              associations of visual and other stimuli to these primary
              reinforcers; and in controlling and correcting reward-related and
              punishment-related behavior, and thus in emotion. The approach
              described here is aimed at providing a fundamental understanding
              of how the orbitofrontal cortex actually functions, and thus in
              how it is involved in motivational behavior such as feeding and
              drinking, in emotional behavior, and in social behavior.",
  journal  = "Brain Cogn.",
  volume   =  55,
  number   =  1,
  pages    = "11--29",
  month    =  jun,
  year     =  2004,
  language = "en",
  issn     = "0278-2626",
  pmid     = "15134840",
  doi      = "10.1016/S0278-2626(03)00277-X"
}

@ARTICLE{Stephenson-Jones2016-wq,
  title    = "A basal ganglia circuit for evaluating action outcomes",
  author   = "Stephenson-Jones, Marcus and Yu, Kai and Ahrens, Sandra and
              Tucciarone, Jason M and van Huijstee, Aile N and Mejia, Luis A
              and Penzo, Mario A and Tai, Lung-Hao and Wilbrecht, Linda and Li,
              Bo",
  abstract = "The basal ganglia, a group of subcortical nuclei, play a crucial
              role in decision-making by selecting actions and evaluating their
              outcomes. While much is known about the function of the basal
              ganglia circuitry in selection, how these nuclei contribute to
              outcome evaluation is less clear. Here we show that neurons in
              the habenula-projecting globus pallidus (GPh) in mice are
              essential for evaluating action outcomes and are regulated by a
              specific set of inputs from the basal ganglia. We find in a
              classical conditioning task that individual mouse GPh neurons
              bidirectionally encode whether an outcome is better or worse than
              expected. Mimicking these evaluation signals with optogenetic
              inhibition or excitation is sufficient to reinforce or discourage
              actions in a decision-making task. Moreover, cell-type-specific
              synaptic manipulations reveal that the inhibitory and excitatory
              inputs to the GPh are necessary for mice to appropriately
              evaluate positive and negative feedback, respectively. Finally,
              using rabies-virus-assisted monosynaptic tracing, we show that
              the GPh is embedded in a basal ganglia circuit wherein it
              receives inhibitory input from both striosomal and matrix
              compartments of the striatum, and excitatory input from the
              'limbic' regions of the subthalamic nucleus. Our results provide
              evidence that information about the selection and evaluation of
              actions is channelled through distinct sets of basal ganglia
              circuits, with the GPh representing a key locus in which
              information of opposing valence is integrated to determine
              whether action outcomes are better or worse than expected.",
  journal  = "Nature",
  volume   =  539,
  number   =  7628,
  pages    = "289--293",
  month    =  nov,
  year     =  2016,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "27652894",
  doi      = "10.1038/nature19845",
  pmc      = "PMC5161609"
}

@ARTICLE{Stella2019-ap,
  title     = "Hippocampal Reactivation of Random Trajectories Resembling
               Brownian Diffusion",
  author    = "Stella, Federico and Baracskay, Peter and O'Neill, Joseph and
               Csicsvari, Jozsef",
  abstract  = "SummaryHippocampal activity patterns representing movement
               trajectories are reactivated in immobility and sleep periods, a
               process associated with memory recall, consolidation, and
               decision making. It is thought that only fixed, behaviorally
               relevant patterns can be reactivated, which are stored across
               hippocampal synaptic connections. To test whether some
               generalized rules govern reactivation, we examined trajectory
               reactivation following non-stereotypical exploration of familiar
               open-field environments. We found that random trajectories of
               varying lengths and timescales were reactivated, resembling that
               of Brownian motion of particles. The animals' behavioral
               trajectory did not follow Brownian diffusion demonstrating that
               the exact behavioral experience is not reactivated. Therefore,
               hippocampal circuits are able to generate random trajectories of
               any recently active map by following diffusion dynamics. This
               ability of hippocampal circuits to generate representations of
               all behavioral outcome combinations, experienced or not, may
               underlie a wide variety of hippocampal-dependent cognitive
               functions such as learning, generalization, and planning.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  0,
  number    =  0,
  month     =  feb,
  year      =  2019,
  language  = "en",
  issn      = "0896-6273",
  doi       = "10.1016/j.neuron.2019.01.052"
}

@BOOK{Pfeifer2006-sa,
  title     = "How the Body Shapes the Way We Think: A New View of Intelligence",
  author    = "Pfeifer, Rolf and Bongard, Josh",
  abstract  = "An exploration of embodied intelligence and its implications
               points toward a theory of intelligence in general; with case
               studies of intelligent systems in ubiquitous computing, business
               and management, human memory, and robotics.How could the body
               influence our thinking when it seems obvious that the brain
               controls the body? In How the Body Shapes the Way We Think, Rolf
               Pfeifer and Josh Bongard demonstrate that thought is not
               independent of the body but is tightly constrained, and at the
               same time enabled, by it. They argue that the kinds of thoughts
               we are capable of have their foundation in our embodiment---in
               our morphology and the material properties of our bodies.This
               crucial notion of embodiment underlies fundamental changes in
               the field of artificial intelligence over the past two decades,
               and Pfeifer and Bongard use the basic methodology of artificial
               intelligence---``understanding by building''---to describe their
               insights. If we understand how to design and build intelligent
               systems, they reason, we will better understand intelligence in
               general. In accessible, nontechnical language, and using many
               examples, they introduce the basic concepts by building on
               recent developments in robotics, biology, neuroscience, and
               psychology to outline a possible theory of intelligence. They
               illustrate applications of such a theory in ubiquitous
               computing, business and management, and the psychology of human
               memory. Embodied intelligence, as described by Pfeifer and
               Bongard, has important implications for our understanding of
               both natural and artificial intelligence.",
  publisher = "MIT Press",
  month     =  oct,
  year      =  2006,
  keywords  = "books",
  language  = "en",
  isbn      = "9780262288521"
}

@ARTICLE{Olafsdottir2018-on,
  title    = "The Role of Hippocampal Replay in Memory and Planning",
  author   = "{\'O}lafsd{\'o}ttir, H Freyja and Bush, Daniel and Barry, Caswell",
  abstract = "The mammalian hippocampus is important for normal memory
              function, particularly memory for places and events. Place cells,
              neurons within the hippocampus that have spatial receptive
              fields, represent information about an animal's position. During
              periods of rest, but also during active task engagement, place
              cells spontaneously recapitulate past trajectories. Such 'replay'
              has been proposed as a mechanism necessary for a range of
              neurobiological functions, including systems memory
              consolidation, recall and spatial working memory, navigational
              planning, and reinforcement learning. Focusing mainly, but not
              exclusively, on work conducted in rodents, we describe the
              methodologies used to analyse replay and review evidence for its
              putative roles. We identify outstanding questions as well as
              apparent inconsistencies in existing data, making suggestions as
              to how these might be resolved. In particular, we find support
              for the involvement of replay in disparate processes, including
              the maintenance of hippocampal memories and decision making. We
              propose that the function of replay changes dynamically according
              to task demands placed on an organism and its current level of
              arousal.",
  journal  = "Curr. Biol.",
  volume   =  28,
  number   =  1,
  pages    = "R37--R50",
  month    =  jan,
  year     =  2018,
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "29316421",
  doi      = "10.1016/j.cub.2017.10.073",
  pmc      = "PMC5847173"
}

@ARTICLE{Trullier1997-gt,
  title    = "Biologically based artificial navigation systems: review and
              prospects",
  author   = "Trullier, O and Wiener, S I and Berthoz, A and Meyer, J A",
  abstract = "Diverse theories of animal navigation aim at explaining how to
              determine and maintain a course from one place to another in the
              environment, although each presents a particular perspective with
              its own terminologies. These vocabularies sometimes overlap, but
              unfortunately with different meanings. This paper attempts to
              define precisely the existing concepts and terminologies, so as
              to describe comprehensively the different theories and models
              within the same unifying framework. We present navigation
              strategies within a four-level hierarchical framework based upon
              levels of complexity of required processing (Guidance, Place
              recognition-triggered Response, Topological navigation, Metric
              navigation). This classification is based upon what information
              is perceived, represented and processed. It contrasts with common
              distinctions based upon the availability of certain sensors or
              cues and rather stresses the information structure and content of
              central processors. We then review computational models of animal
              navigation, i.e. of animats. These are introduced along with the
              underlying conceptual basis in biological data drawn from
              behavioral and physiological experiments, with emphasis on
              theories of ``spatial cognitive maps''. The goal is to aid in
              deriving algorithms based upon insights into these processes,
              algorithms that can be useful both for psychobiologists and
              roboticists. The main observation is, however, that despite the
              fact that all reviewed models claim to have biological
              inspiration and that some of them explicitly use ``Cognitive
              Map''-like mechanisms, they correspond to different levels of our
              proposed hierarchy and that none of them exhibits the main
              capabilities of real ``Cognitive Maps''--in Tolman's sense--that
              is, a robust capacity for detour and shortcut behaviors.",
  journal  = "Prog. Neurobiol.",
  volume   =  51,
  number   =  5,
  pages    = "483--544",
  month    =  apr,
  year     =  1997,
  language = "en",
  issn     = "0301-0082",
  pmid     = "9153072",
  doi      = "10.1016/S0301-0082(96)00060-3"
}

@ARTICLE{Frank2000-xi,
  title    = "Trajectory encoding in the hippocampus and entorhinal cortex",
  author   = "Frank, L M and Brown, E N and Wilson, M",
  abstract = "We recorded from single neurons in the hippocampus and entorhinal
              cortex (EC) of rats to investigate the role of these structures
              in navigation and memory representation. Our results revealed two
              novel phenomena: first, many cells in CA1 and the EC fired at
              significantly different rates when the animal was in the same
              position depending on where the animal had come from or where it
              was going. Second, cells in deep layers of the EC, the targets of
              hippocampal outputs, appeared to represent the similarities
              between locations on spatially distinct trajectories through the
              environment. Our findings suggest that the hippocampus represents
              the animal's position in the context of a trajectory through
              space and that the EC represents regularities across different
              trajectories that could allow for generalization across
              experiences.",
  journal  = "Neuron",
  volume   =  27,
  number   =  1,
  pages    = "169--178",
  month    =  jul,
  year     =  2000,
  keywords = "Non-programmatic",
  language = "en",
  issn     = "0896-6273",
  pmid     = "10939340",
  doi      = "10.1016/S0896-6273(00)00018-0"
}

@ARTICLE{Stoianov2018-og,
  title    = "Model-based spatial navigation in the hippocampus-ventral
              striatum circuit: A computational analysis",
  author   = "Stoianov, Ivilin Peev and Pennartz, Cyriel M A and Lansink,
              Carien S and Pezzulo, Giovani",
  abstract = "While the neurobiology of simple and habitual choices is
              relatively well known, our current understanding of goal-directed
              choices and planning in the brain is still limited. Theoretical
              work suggests that goal-directed computations can be productively
              associated to model-based (reinforcement learning) computations,
              yet a detailed mapping between computational processes and
              neuronal circuits remains to be fully established. Here we report
              a computational analysis that aligns Bayesian nonparametrics and
              model-based reinforcement learning (MB-RL) to the functioning of
              the hippocampus (HC) and the ventral striatum (vStr)-a neuronal
              circuit that increasingly recognized to be an appropriate model
              system to understand goal-directed (spatial) decisions and
              planning mechanisms in the brain. We test the MB-RL agent in a
              contextual conditioning task that depends on intact hippocampus
              and ventral striatal (shell) function and show that it solves the
              task while showing key behavioral and neuronal signatures of the
              HC-vStr circuit. Our simulations also explore the benefits of
              biological forms of look-ahead prediction (forward sweeps) during
              both learning and control. This article thus contributes to fill
              the gap between our current understanding of computational
              algorithms and biological realizations of (model-based)
              reinforcement learning.",
  journal  = "PLoS Comput. Biol.",
  volume   =  14,
  number   =  9,
  pages    = "e1006316",
  month    =  sep,
  year     =  2018,
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "30222746",
  doi      = "10.1371/journal.pcbi.1006316",
  pmc      = "PMC6160242"
}

@ARTICLE{Ha2018-sa,
  title     = "World Models",
  author    = "Ha, David and Schmidhuber, J{\"u}rgen",
  abstract  = "We explore building generative neural network models of popular
               reinforcement learning environments. Our world model can be
               trained quickly in an unsupervised manner to learn a compressed
               spatial and temporal representation of the environment. By using
               features extracted from the world model as inputs to an agent,
               we can train a very compact and simple policy that can solve the
               required task. We can even train our agent entirely inside of
               its own hallucinated dream generated by its world model, and
               transfer this policy back into the actual environment. An
               interactive version of this article is available at
               worldmodels.github.io.",
  publisher = "Zenodo",
  year      =  2018,
  doi       = "10.5281/ZENODO.1207631"
}

@ARTICLE{Madl2015-wd,
  title    = "Computational cognitive models of spatial memory in navigation
              space: a review",
  author   = "Madl, Tamas and Chen, Ke and Montaldi, Daniela and Trappl, Robert",
  abstract = "Spatial memory refers to the part of the memory system that
              encodes, stores, recognizes and recalls spatial information about
              the environment and the agent's orientation within it. Such
              information is required to be able to navigate to goal locations,
              and is vitally important for any embodied agent, or model
              thereof, for reaching goals in a spatially extended environment.
              In this paper, a number of computationally implemented cognitive
              models of spatial memory are reviewed and compared. Three
              categories of models are considered: symbolic models, neural
              network models, and models that are part of a systems-level
              cognitive architecture. Representative models from each category
              are described and compared in a number of dimensions along which
              simulation models can differ (level of modeling, types of
              representation, structural accuracy, generality and abstraction,
              environment complexity), including their possible mapping to the
              underlying neural substrate. Neural mappings are rarely
              explicated in the context of behaviorally validated models, but
              they could be useful to cognitive modeling research by providing
              a new approach for investigating a model's plausibility. Finally,
              suggested experimental neuroscience methods are described for
              verifying the biological plausibility of computational cognitive
              models of spatial memory, and open questions for the field of
              spatial memory modeling are outlined.",
  journal  = "Neural Netw.",
  volume   =  65,
  pages    = "18--43",
  month    =  may,
  year     =  2015,
  keywords = "Computational cognitive modeling; Spatial memory models",
  language = "en",
  issn     = "0893-6080, 1879-2782",
  pmid     = "25659941",
  doi      = "10.1016/j.neunet.2015.01.002"
}

@ARTICLE{Arulkumaran2017-bm,
  title         = "A Brief Survey of Deep Reinforcement Learning",
  author        = "Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage,
                   Miles and Bharath, Anil Anthony",
  abstract      = "Deep reinforcement learning is poised to revolutionise the
                   field of AI and represents a step towards building
                   autonomous systems with a higher level understanding of the
                   visual world. Currently, deep learning is enabling
                   reinforcement learning to scale to problems that were
                   previously intractable, such as learning to play video games
                   directly from pixels. Deep reinforcement learning algorithms
                   are also applied to robotics, allowing control policies for
                   robots to be learned directly from camera inputs in the real
                   world. In this survey, we begin with an introduction to the
                   general field of reinforcement learning, then progress to
                   the main streams of value-based and policy-based methods.
                   Our survey will cover central algorithms in deep
                   reinforcement learning, including the deep $Q$-network,
                   trust region policy optimisation, and asynchronous advantage
                   actor-critic. In parallel, we highlight the unique
                   advantages of deep neural networks, focusing on visual
                   understanding via reinforcement learning. To conclude, we
                   describe several current areas of research within the field.",
  month         =  aug,
  year          =  2017,
  archivePrefix = "arXiv",
  eprint        = "1708.05866",
  primaryClass  = "cs.LG",
  arxivid       = "1708.05866"
}

@ARTICLE{Schmidhuber2015-ym,
  title         = "On Learning to Think: Algorithmic Information Theory for
                   Novel Combinations of Reinforcement Learning Controllers and
                   Recurrent Neural World Models",
  author        = "Schmidhuber, Juergen",
  abstract      = "This paper addresses the general problem of reinforcement
                   learning (RL) in partially observable environments. In 2013,
                   our large RL recurrent neural networks (RNNs) learned from
                   scratch to drive simulated cars from high-dimensional video
                   input. However, real brains are more powerful in many ways.
                   In particular, they learn a predictive model of their
                   initially unknown environment, and somehow use it for
                   abstract (e.g., hierarchical) planning and reasoning. Guided
                   by algorithmic information theory, we describe RNN-based AIs
                   (RNNAIs) designed to do the same. Such an RNNAI can be
                   trained on never-ending sequences of tasks, some of them
                   provided by the user, others invented by the RNNAI itself in
                   a curious, playful fashion, to improve its RNN-based world
                   model. Unlike our previous model-building RNN-based RL
                   machines dating back to 1990, the RNNAI learns to actively
                   query its model for abstract reasoning and planning and
                   decision making, essentially ``learning to think.'' The
                   basic ideas of this report can be applied to many other
                   cases where one RNN-like system exploits the algorithmic
                   information content of another. They are taken from a grant
                   proposal submitted in Fall 2014, and also explain concepts
                   such as ``mirror neurons.'' Experimental results will be
                   described in separate papers.",
  month         =  nov,
  year          =  2015,
  archivePrefix = "arXiv",
  eprint        = "1511.09249",
  primaryClass  = "cs.AI",
  arxivid       = "1511.09249"
}

@ARTICLE{Panov2018-xf,
  title    = "Grid Path Planning with Deep Reinforcement Learning: Preliminary
              Results",
  author   = "Panov, Aleksandr I and Yakovlev, Konstantin S and Suvorov, Roman",
  abstract = "Single-shot grid-based path finding is an important problem with
              the applications in robotics, video games etc. Typically in AI
              community heuristic search methods (based on A* and its
              variations) are used to solve it. In this work we present the
              results of preliminary studies on how neural networks can be
              utilized to path planning on square grids, e.g. how well they can
              cope with path finding tasks by themselves within the well-known
              reinforcement problem statement. Conducted experiments show that
              the agent using neural Q-learning algorithm robustly learns to
              achieve the goal on small maps and demonstrate promising results
              on the maps have ben never seen by him before.",
  journal  = "Procedia Comput. Sci.",
  volume   =  123,
  pages    = "347--353",
  month    =  jan,
  year     =  2018,
  keywords = "path planning; reinforcement learning; neural networks;
              Q-learning; convolution networks; Q-network",
  issn     = "1877-0509",
  doi      = "10.1016/j.procs.2018.01.054"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Darekar2018-xd,
  title    = "Modeling spatial navigation in the presence of dynamic obstacles:
              a differential games approach",
  author   = "Darekar, Anuja and Goussev, Valery and McFadyen, Bradford J and
              Lamontagne, Anouk and Fung, Joyce",
  abstract = "Obstacle circumvention strategies can be shaped by the dynamic
              interaction of an individual (evader) and an obstacle (pursuer).
              We have developed a mathematical model with predictive and
              emergent components, using experimental data from seven healthy
              young adults walking toward a target while avoiding collision
              with a stationary or moving obstacle (approaching head-on, or
              diagonally 30° left or right) in a virtual environment. Two
              linear properties from the predictive component enable the evader
              to predict the minimum distance between itself and the obstacle
              at all times, including the future intersection of trajectories.
              The emergent component uses the classical differential games
              model to solve for an optimal circumvention while reaching the
              target, wherein the locomotor strategy is influenced by the
              obstacle, target, and the evader velocity. Both model components
              were fitted to a different set of experimental data obtained from
              five poststroke and healthy participants to derive the minimum
              predicted distance (predictive component) and obstacle influence
              dimensions (emergent component) during circumvention. Minimum
              predicted distance between evader and pursuer was kept constant
              when the evader was closest to the obstacle in all participants.
              Obstacle influence dimensions varied depending on obstacle
              approach condition and preferred side of circumvention,
              reflecting differences in locomotor strategies between poststroke
              and healthy individuals. Additionally, important associations
              between model outputs and observed experimental outcomes were
              found. The model, supported by experimental data, suggests that
              both predictive and emergent processes can shape obstacle
              circumvention strategies in healthy and poststroke individuals.
              NEW \& NOTEWORTHY Obstacle circumvention during goal-directed
              locomotion is modeled with a new mathematical approach comprising
              both predictive and emergent elements. The major novelty is using
              differential games solutions to illustrate the dynamic
              interactions between the individual as an evader and the
              approaching obstacle as a pursuer. The model is supported by
              experimental evidence that explains the behavior along the
              continuum of locomotor adaptation displayed by healthy subjects
              and individuals with stroke.",
  journal  = "J. Neurophysiol.",
  volume   =  119,
  number   =  3,
  pages    = "990--1004",
  month    =  mar,
  year     =  2018,
  keywords = "collision avoidance; locomotion; modeling; obstacle
              circumvention; stroke;Locomotion",
  language = "en",
  issn     = "0022-3077, 1522-1598",
  pmid     = "29187558",
  doi      = "10.1152/jn.00857.2016"
}

@ARTICLE{Oess2017-fp,
  title    = "A Computational Model for Spatial Navigation Based on Reference
              Frames in the Hippocampus, Retrosplenial Cortex, and Posterior
              Parietal Cortex",
  author   = "Oess, Timo and Krichmar, Jeffrey L and R{\"o}hrbein, Florian",
  abstract = "Behavioral studies for humans, monkeys, and rats have shown that,
              while traversing an environment, these mammals tend to use
              different frames of reference and frequently switch between them.
              These frames represent allocentric, egocentric, or route-centric
              views of the environment. However, combinations of either of them
              are often deployed. Neurophysiological studies on rats have
              indicated that the hippocampus, the retrosplenial cortex, and the
              posterior parietal cortex contribute to the formation of these
              frames and mediate the transformation between those. In this
              paper, we construct a computational model of the posterior
              parietal cortex and the retrosplenial cortex for spatial
              navigation. We demonstrate how the transformation of reference
              frames could be realized in the brain and suggest how different
              brain areas might use these reference frames to form navigational
              strategies and predict under what conditions an animal might use
              a specific type of reference frame. Our simulated navigation
              experiments demonstrate that the model's results closely resemble
              behavioral findings in humans and rats. These results suggest
              that navigation strategies may depend on the animal's reliance in
              a particular reference frame and shows how low confidence in a
              reference frame can lead to fluid adaptation and deployment of
              alternative navigation strategies. Because of its flexibility,
              our biologically inspired navigation system may be applied to
              autonomous robots.",
  journal  = "Front. Neurorobot.",
  volume   =  11,
  pages    = "4",
  month    =  feb,
  year     =  2017,
  keywords = "computational model; frames of reference; hippocampus; posterior
              parietal cortex; retrosplenial cortex; spatial navigation",
  language = "en",
  issn     = "1662-5218",
  pmid     = "28223931",
  doi      = "10.3389/fnbot.2017.00004",
  pmc      = "PMC5293834"
}

@INPROCEEDINGS{Mannucci2016-ja,
  title     = "A hierarchical maze navigation algorithm with Reinforcement
               Learning and mapping",
  booktitle = "2016 {IEEE} Symposium Series on Computational Intelligence
               ({SSCI})",
  author    = "Mannucci, T and van Kampen, E",
  abstract  = "Goal-finding in an unknown maze is a challenging problem for a
               Reinforcement Learning agent, because the corresponding state
               space can be large if not intractable, and the agent does not
               usually have a model of the environment. Hierarchical
               Reinforcement Learning has been shown in the past to improve
               tractability and learning time of complex problems, as well as
               facilitate learning a coherent transition model for the
               environment. Nonetheless, considerable time is still needed to
               learn the transition model, so that initially the agent can
               perform poorly by getting trapped into dead ends and colliding
               with obstacles. This paper proposes a strategy for maze
               exploration that, by means of sequential tasking and off-line
               training on an abstract environment, provides the agent with a
               minimal level of performance from the very beginning of
               exploration. In particular, this approach allows to prevent
               collisions with obstacles, thus enforcing a safety restraint on
               the agent.",
  pages     = "1--8",
  month     =  dec,
  year      =  2016,
  keywords  = "learning (artificial intelligence);safety restraint;off-line
               training;sequential tasking;maze exploration;reinforcement
               learning;hierarchical maze navigation
               algorithm;Trajectory;Navigation;Robot sensing systems;Learning
               (artificial intelligence);Training;Sonar",
  doi       = "10.1109/SSCI.2016.7849365"
}

@ARTICLE{Lei2018-ih,
  title    = "Dynamic Path Planning of Unknown Environment Based on Deep
              Reinforcement Learning",
  author   = "Lei, Xiaoyun and Zhang, Zhian and Dong, Peifang",
  abstract = "PDF | Dynamic path planning of unknown environment has always
              been a challenge for mobile robots. In this paper, we apply
              double Q-network (DDQN) deep reinforcement learning proposed by
              DeepMind in 2016 to dynamic path planning of unknown environment.
              The reward and punishment...",
  journal  = "Journal of Robotics",
  volume   =  2018,
  number   =  12,
  pages    = "1--10",
  month    =  sep,
  year     =  2018,
  issn     = "1687-9600",
  doi      = "10.1155/2018/5781591"
}

@ARTICLE{Barto2003-bz,
  title     = "Recent Advances in Hierarchical Reinforcement Learning",
  author    = "Barto, Andrew G and Mahadevan, Sridhar",
  abstract  = "Reinforcement learning is bedeviled by the curse of
               dimensionality: the number of parameters to be learned grows
               exponentially with the size of any compact encoding of a state.
               Recent attempts to combat the curse of dimensionality have
               turned to principled ways of exploiting temporal abstraction,
               where decisions are not required at each step, but rather invoke
               the execution of temporally-extended activities which follow
               their own policies until termination. This leads naturally to
               hierarchical control architectures and associated learning
               algorithms. We review several approaches to temporal abstraction
               and hierarchical organization that machine learning researchers
               have recently developed. Common to these approaches is a
               reliance on the theory of semi-Markov decision processes, which
               we emphasize in our review. We then discuss extensions of these
               ideas to concurrent activities, multiagent coordination, and
               hierarchical memory for addressing partial observability.
               Concluding remarks address open challenges facing the further
               development of reinforcement learning in a hierarchical setting.",
  journal   = "Discrete Event Dyn. Syst.: Theory Appl.",
  publisher = "Springer",
  volume    =  13,
  number    =  1,
  pages     = "41--77",
  month     =  jan,
  year      =  2003,
  issn      = "0924-6703, 1573-7594",
  doi       = "10.1023/A:1022140919877"
}

@ARTICLE{Hok2007-zu,
  title    = "Goal-related activity in hippocampal place cells",
  author   = "Hok, Vincent and Lenck-Santini, Pierre-Pascal and Roux,
              S{\'e}bastien and Save, Etienne and Muller, Robert U and Poucet,
              Bruno",
  abstract = "Place cells are hippocampal neurons whose discharge is strongly
              related to a rat's location in its environment. The existence of
              place cells has led to the proposal that they are part of an
              integrated neural system dedicated to spatial navigation, an idea
              supported by the discovery of strong relationships between place
              cell activity and spatial problem solving. To further understand
              such relationships, we examined the discharge of place cells
              recorded while rats solved a place navigation task. We report
              that, in addition to having widely distributed firing fields,
              place cells also discharge selectively while the hungry rat waits
              in an unmarked goal location to release a food pellet. Such
              firing is not duplicated in other locations outside the main
              firing field even when the rat's behavior is constrained to be
              extremely similar to the behavior at the goal. We therefore
              propose that place cells provide both a geometric representation
              of the current environment and a reflection of the rat's
              expectancy that it is located correctly at the goal. This on-line
              feedback about a critical aspect of navigational performance is
              proposed to be signaled by the synchronous activity of the large
              fraction of place cells active at the goal. In combination with
              other (prefrontal) cells that provide coarse encoding of goal
              location, hippocampal place cells may therefore participate in a
              neural network allowing the rat to plan accurate trajectories in
              space.",
  journal  = "J. Neurosci.",
  volume   =  27,
  number   =  3,
  pages    = "472--482",
  month    =  jan,
  year     =  2007,
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "17234580",
  doi      = "10.1523/JNEUROSCI.2864-06.2007"
}

@ARTICLE{Nitz2012-rm,
  title    = "Spaces within spaces: rat parietal cortex neurons register
              position across three reference frames",
  author   = "Nitz, Douglas A",
  abstract = "We recorded parietal cortex neurons as rats traversed squared
              spiral tracks. Spatial firing patterns distinguished the
              behaviorally identical track segments composing loops, yet
              recurred with increasing or decreasing amplitude across the five
              loops composing the full track. These results indicate that
              parietal cortex neurons simultaneously respond to spatial
              relationships in multiple external reference frames, a phenomenon
              that may reflect a neural mechanism for relating parts to a
              whole.",
  journal  = "Nat. Neurosci.",
  volume   =  15,
  number   =  10,
  pages    = "1365--1367",
  month    =  oct,
  year     =  2012,
  keywords = "Locomotion",
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "22960933",
  doi      = "10.1038/nn.3213"
}

@ARTICLE{Dolan2013-rb,
  title    = "Goals and habits in the brain",
  author   = "Dolan, Ray J and Dayan, Peter",
  abstract = "An enduring and richly elaborated dichotomy in cognitive
              neuroscience is that of reflective versus reflexive decision
              making and choice. Other literatures refer to the two ends of
              what is likely to be a spectrum with terms such as goal-directed
              versus habitual, model-based versus model-free or prospective
              versus retrospective. One of the most rigorous traditions of
              experimental work in the field started with studies in rodents
              and graduated via human versions and enrichments of those
              experiments to a current state in which new paradigms are probing
              and challenging the very heart of the distinction. We review four
              generations of work in this tradition and provide pointers to the
              forefront of the field's fifth generation.",
  journal  = "Neuron",
  volume   =  80,
  number   =  2,
  pages    = "312--325",
  month    =  oct,
  year     =  2013,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "24139036",
  doi      = "10.1016/j.neuron.2013.09.007",
  pmc      = "PMC3807793"
}

@ARTICLE{Daw2014-nr,
  title     = "The algorithmic anatomy of model-based evaluation",
  author    = "Daw, Nathaniel D and Dayan, Peter",
  abstract  = "Despite many debates in the first half of the twentieth century,
               it is now largely a truism that humans and other animals build
               models of their environments and use them for prediction and
               control. However, model-based (MB) reasoning presents severe
               computational challenges. Alternative, computationally simpler,
               model-free (MF) schemes have been suggested in the reinforcement
               learning literature, and have afforded influential accounts of
               behavioural and neural data. Here, we study the realization of
               MB calculations, and the ways that this might be woven together
               with MF values and evaluation methods. There are as yet mostly
               only hints in the literature as to the resulting tapestry, so we
               offer more preview than review.",
  journal   = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  publisher = "royalsocietypublishing.org",
  volume    =  369,
  number    =  1655,
  month     =  nov,
  year      =  2014,
  keywords  = "Monte Carlo tree search; model-based reasoning; model-free
               reasoning; orbitofrontal cortex; reinforcement learning;
               striatum",
  language  = "en",
  issn      = "0962-8436, 1471-2970",
  pmid      = "25267820",
  doi       = "10.1098/rstb.2013.0478",
  pmc       = "PMC4186231"
}

@UNPUBLISHED{Alvarez2019-gb,
  title    = "Modeling decision-making under uncertainty: a direct comparison
              study between human and mouse gambling data",
  author   = "Alvarez, Lidia Cabeza and Giustiniani, Julie and Chabin, Thibault
              and Ramadan, Bahrie and Joucla, Coralie and Nicolier, Magali and
              Pazart, Lionel and Haffen, Emmanuel and Fellmann, Dominique and
              Gabriel, Damien and Peterschmitt, Yvan",
  abstract = "Decision-making is a conserved evolutionary process enabling to
              choose one option among several alternatives, and relying on
              reward and cognitive control systems. The Iowa Gambling Task
              allows to assess human decision-making under uncertainty by
              presenting four cards decks with various cost-benefit
              probabilities. Participants seek to maximize their monetary gains
              by developing long-term optimal choice strategies. Animal
              versions have been adapted with nutritional rewards but
              interspecies data comparisons are still scarce. Our study
              directly compared physiological decision-making performances
              between humans and wild-type C57BL/6 mice. Human subjects
              fulfilled an electronic Iowa Gambling Task version while mice
              performed a maze-based adaptation with four arms baited in a
              probabilistic way. Our data show closely matching performances
              among species with similar patterns of choice behaviors.
              Moreover, both populations clustered into good, intermediate, and
              poor decision-making categories with similar proportions.
              Remarkably, mice good decision-makers behaved as humans of the
              same category, but slight differences among species have been
              evidenced for the other two subpopulations. Overall, our direct
              comparative study confirms the good face validity of the rodent
              gambling task. Extended behavioral characterization and
              pathological animal models should help strengthen its construct
              validity and disentangle determinants of decision-making in
              animals and humans.",
  journal  = "bioRxiv",
  pages    = "570499",
  month    =  mar,
  year     =  2019,
  language = "en",
  doi      = "10.1101/570499"
}

@ARTICLE{Ito2011-yi,
  title     = "Multiple representations and algorithms for reinforcement
               learning in the cortico-basal ganglia circuit",
  author    = "Ito, Makoto and Doya, Kenji",
  abstract  = "Accumulating evidence shows that the neural network of the
               cerebral cortex and the basal ganglia is critically involved in
               reinforcement learning. Recent studies found functional
               heterogeneity within the cortico-basal ganglia circuit,
               especially in its ventromedial to dorsolateral axis. Here we
               review computational issues in reinforcement learning and
               propose a working hypothesis on how multiple reinforcement
               learning algorithms are implemented in the cortico-basal ganglia
               circuit using different representations of states, values, and
               actions.",
  journal   = "Curr. Opin. Neurobiol.",
  publisher = "Elsevier",
  volume    =  21,
  number    =  3,
  pages     = "368--373",
  month     =  jun,
  year      =  2011,
  language  = "en",
  issn      = "0959-4388, 1873-6882",
  pmid      = "21531544",
  doi       = "10.1016/j.conb.2011.04.001"
}

@ARTICLE{Sul2010-js,
  title     = "Distinct roles of rodent orbitofrontal and medial prefrontal
               cortex in decision making",
  author    = "Sul, Jung Hoon and Kim, Hoseok and Huh, Namjung and Lee, Daeyeol
               and Jung, Min Whan",
  abstract  = "We investigated how different subregions of rodent prefrontal
               cortex contribute to value-based decision making, by comparing
               neural signals related to animal's choice, its outcome, and
               action value in orbitofrontal cortex (OFC) and medial prefrontal
               cortex (mPFC) of rats performing a dynamic two-armed bandit
               task. Neural signals for upcoming action selection arose in the
               mPFC, including the anterior cingulate cortex, only immediately
               before the behavioral manifestation of animal's choice,
               suggesting that rodent prefrontal cortex is not involved in
               advanced action planning. Both OFC and mPFC conveyed signals
               related to the animal's past choices and their outcomes over
               multiple trials, but neural signals for chosen value and reward
               prediction error were more prevalent in the OFC. Our results
               suggest that rodent OFC and mPFC serve distinct roles in
               value-based decision making and that the OFC plays a prominent
               role in updating the values of outcomes expected from chosen
               actions.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  66,
  number    =  3,
  pages     = "449--460",
  month     =  may,
  year      =  2010,
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "20471357",
  doi       = "10.1016/j.neuron.2010.03.033",
  pmc       = "PMC2872629"
}

@UNPUBLISHED{Russek2017-vw,
  title    = "Predictive representations can link model-based reinforcement
              learning to model-free mechanisms",
  author   = "Russek, Evan M and Momennejad, Ida and Botvinick, Matthew M and
              Gershman, Samuel J and Daw, Nathaniel D",
  abstract = "Humans and animals are capable of evaluating actions by
              considering their long-run future rewards through a process
              described using model-based reinforcement learning (RL)
              algorithms. The mechanisms by which neural circuits perform the
              computations prescribed by model-based RL remain largely unknown;
              however, multiple lines of evidence suggest that neural circuits
              supporting model-based behavior are structurally homologous to
              and overlapping with those thought to carry out model-free
              temporal difference (TD) learning. Here, we lay out a family of
              approaches by which model-based computation may be built upon a
              core of TD learning. The foundation of this framework is the
              successor representation, a predictive state representation that,
              when combined with TD learning of value predictions, can produce
              a subset of the behaviors associated with model-based learning at
              a fraction of the computational cost. Using simulations, we
              delineate the precise behavioral capabilities enabled by
              evaluating actions using this approach, and compare them to those
              demonstrated by biological organisms. We then introduce two new
              algorithms that build upon the successor representation while
              progressively mitigating its limitations. Because this framework
              can account for the full range of observed putatively model-based
              behaviors while still utilizing a core TD framework, we suggest
              that it represents a neurally plausible family of mechanisms for
              model-based evaluation.",
  journal  = "bioRxiv",
  pages    = "083857",
  month    =  aug,
  year     =  2017,
  language = "en",
  doi      = "10.1101/083857"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@UNPUBLISHED{Lee2019-qv,
  title    = "The statistical structure of the hippocampal code for space as a
              function of time, context, and value",
  author   = "Lee, Jae Sung and Briguglio, John and Romani, Sandro and Lee,
              Albert K",
  abstract = "Hippocampal activity represents many behaviorally important
              variables, including context, an animal9s location within a given
              environmental context, time, and reward. Here we used
              longitudinal calcium imaging in mice, multiple large virtual
              environments, and differing reward contingencies to derive a
              unified probabilistic model of hippocampal CA1 representations
              centered on a single feature − the field propensity. Each cell9s
              propensity governs how many place fields it has per unit space,
              predicts its reward−related activity, and is preserved across
              distinct environments and over months. The propensity is broadly
              distributed−with many low, and some very high, propensity cells
              −and thus strongly shapes hippocampal representations. The result
              is a range of spatial codes, from sparse to dense. Propensity
              varied ~10−fold between adjacent cells in a salt-and-pepper
              fashion, indicating substantial functional differences within a
              presumed cell type. The stability of each cell9s propensity
              across conditions suggests this fundamental property has
              anatomical, transcriptional, and/or developmental origins.",
  journal  = "bioRxiv",
  pages    = "615203",
  month    =  apr,
  year     =  2019,
  language = "en",
  doi      = "10.1101/615203"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Olson2017-vi,
  title    = "Subiculum neurons map the current axis of travel",
  author   = "Olson, Jacob M and Tongprasearth, Kanyanat and Nitz, Douglas A",
  abstract = "Flexible navigation demands knowledge of boundaries, routes and
              their relationships. Within a multi-path environment, a
              subpopulation of subiculum neurons robustly encoded the axis of
              travel. The firing of axis-tuned neurons peaked bimodally, at
              head orientations 180° apart. Environmental manipulations showed
              these neurons to be anchored to environmental boundaries but to
              lack axis tuning in an open arena. Axis-tuned neurons thus
              provide a powerful mechanism for mapping relationships between
              routes and the larger environmental context.",
  journal  = "Nat. Neurosci.",
  volume   =  20,
  number   =  2,
  pages    = "170--172",
  month    =  feb,
  year     =  2017,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "27991899",
  doi      = "10.1038/nn.4464"
}

@ARTICLE{Spiers2015-fq,
  title    = "Neural systems supporting navigation",
  author   = "Spiers, Hugo J and Barry, Caswell",
  abstract = "Much is known about how neural systems determine current spatial
              position and orientation in the environment. By contrast little
              is understood about how the brain represents future goal
              locations or computes the distance and direction to such goals.
              Recent electrophysiology, computational modelling and
              neuroimaging research have shed new light on how the spatial
              relationship to a goal may be determined and represented during
              navigation. This research suggests that the hippocampus may code
              the path to the goal while the entorhinal cortex represents the
              vector to the goal. It also reveals that the engagement of the
              hippocampus and entorhinal cortex varies across the different
              operational stages of navigation, such as during travel, route
              planning, and decision-making at waypoints.",
  journal  = "Current Opinion in Behavioral Sciences",
  volume   =  1,
  pages    = "47--55",
  month    =  feb,
  year     =  2015,
  issn     = "2352-1546",
  doi      = "10.1016/j.cobeha.2014.08.005"
}

@INCOLLECTION{Lengyel2008-xy,
  title     = "Hippocampal Contributions to Control: The Third Way",
  booktitle = "Advances in Neural Information Processing Systems 20",
  author    = "Lengyel, M{\'a}t{\'e} and Dayan, Peter",
  editor    = "Platt, J C and Koller, D and Singer, Y and Roweis, S T",
  publisher = "Curran Associates, Inc.",
  pages     = "889--896",
  year      =  2008
}

@ARTICLE{Gustafson2011-ua,
  title    = "Grid cells, place cells, and geodesic generalization for spatial
              reinforcement learning",
  author   = "Gustafson, Nicholas J and Daw, Nathaniel D",
  abstract = "Reinforcement learning (RL) provides an influential
              characterization of the brain's mechanisms for learning to make
              advantageous choices. An important problem, though, is how
              complex tasks can be represented in a way that enables efficient
              learning. We consider this problem through the lens of spatial
              navigation, examining how two of the brain's location
              representations--hippocampal place cells and entorhinal grid
              cells--are adapted to serve as basis functions for approximating
              value over space for RL. Although much previous work has focused
              on these systems' roles in combining upstream sensory cues to
              track location, revisiting these representations with a focus on
              how they support this downstream decision function offers
              complementary insights into their characteristics. Rather than
              localization, the key problem in learning is generalization
              between past and present situations, which may not match
              perfectly. Accordingly, although neural populations collectively
              offer a precise representation of position, our simulations of
              navigational tasks verify the suggestion that RL gains efficiency
              from the more diffuse tuning of individual neurons, which allows
              learning about rewards to generalize over longer distances given
              fewer training experiences. However, work on generalization in RL
              suggests the underlying representation should respect the
              environment's layout. In particular, although it is often assumed
              that neurons track location in Euclidean coordinates (that a
              place cell's activity declines ``as the crow flies'' away from
              its peak), the relevant metric for value is geodesic: the
              distance along a path, around any obstacles. We formalize this
              intuition and present simulations showing how Euclidean, but not
              geodesic, representations can interfere with RL by generalizing
              inappropriately across barriers. Our proposal that place and grid
              responses should be modulated by geodesic distances suggests
              novel predictions about how obstacles should affect spatial
              firing fields, which provides a new viewpoint on data concerning
              both spatial codes.",
  journal  = "PLoS Comput. Biol.",
  volume   =  7,
  number   =  10,
  pages    = "e1002235",
  month    =  oct,
  year     =  2011,
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "22046115",
  doi      = "10.1371/journal.pcbi.1002235",
  pmc      = "PMC3203050"
}

@ARTICLE{Bennett1996-wj,
  title    = "Do animals have cognitive maps?",
  author   = "Bennett, A T",
  abstract = "Drawing on studies of humans, rodents, birds and arthropods, I
              show that 'cognitive maps' have been used to describe a wide
              variety of spatial concepts. There are, however, two main
              definitions. One, sensu Tolman, O'Keefe and Nadel, is that a
              cognitive map is a powerful memory of landmarks which allows
              novel short-cutting to occur. The other, sensu Gallistel, is that
              a cognitive map is any representation of space held by an animal.
              Other definitions with quite different meanings are also
              summarised. I argue that no animal has been conclusively shown to
              have a cognitive map, sensu Tolman, O'Keefe and Nadel, because
              simpler explanations of the crucial novel short-cutting results
              are invariably possible. Owing to the repeated inability of
              experimenters to eliminate these simpler explanations over at
              least 15 years, and the confusion caused by the numerous
              contradictory definitions of a cognitive map, I argue that the
              cognitive map is no longer a useful hypothesis for elucidating
              the spatial behaviour of animals and that use of the term should
              be avoided.",
  journal  = "J. Exp. Biol.",
  volume   =  199,
  number   = "Pt 1",
  pages    = "219--224",
  month    =  jan,
  year     =  1996,
  language = "en",
  issn     = "0022-0949",
  pmid     = "8576693"
}

@ARTICLE{Simon2011-ky,
  title     = "Neural correlates of forward planning in a spatial decision task
               in humans",
  author    = "Simon, Dylan Alexander and Daw, Nathaniel D",
  abstract  = "Although reinforcement learning (RL) theories have been
               influential in characterizing the mechanisms for reward-guided
               choice in the brain, the predominant temporal difference (TD)
               algorithm cannot explain many flexible or goal-directed actions
               that have been demonstrated behaviorally. We investigate such
               actions by contrasting an RL algorithm that is model based, in
               that it relies on learning a map or model of the task and
               planning within it, to traditional model-free TD learning. To
               distinguish these approaches in humans, we used functional
               magnetic resonance imaging in a continuous spatial navigation
               task, in which frequent changes to the layout of the maze forced
               subjects continually to relearn their favored routes, thereby
               exposing the RL mechanisms used. We sought evidence for the
               neural substrates of such mechanisms by comparing choice
               behavior and blood oxygen level-dependent (BOLD) signals to
               decision variables extracted from simulations of either
               algorithm. Both choices and value-related BOLD signals in
               striatum, although most often associated with TD learning, were
               better explained by the model-based theory. Furthermore,
               predecessor quantities for the model-based value computation
               were correlated with BOLD signals in the medial temporal lobe
               and frontal cortex. These results point to a significant
               extension of both the computational and anatomical substrates
               for RL in the brain.",
  journal   = "J. Neurosci.",
  publisher = "Soc Neuroscience",
  volume    =  31,
  number    =  14,
  pages     = "5526--5539",
  month     =  apr,
  year      =  2011,
  language  = "en",
  issn      = "0270-6474, 1529-2401",
  pmid      = "21471389",
  doi       = "10.1523/JNEUROSCI.4647-10.2011",
  pmc       = "PMC3108440"
}

@ARTICLE{Alvernhe2011-st,
  title     = "Local remapping of place cell firing in the Tolman detour task",
  author    = "Alvernhe, Alice and Save, Etienne and Poucet, Bruno",
  abstract  = "The existence of place cells, whose discharge is strongly
               related to a rat's location in its environment, has led to the
               proposal that they form part of an integrated neural system
               dedicated to spatial navigation. It has been suggested that this
               system could represent space as a cognitive map, which is
               flexibly used by animals to plan new shortcuts or efficient
               detours. To further understand the relationships between
               hippocampal place cell firing and cognitive maps, we examined
               the discharge of place cells as rats were exposed to a
               Tolman-type detour problem. In specific sessions, a transparent
               barrier was placed onto the maze so as to block the shortest
               central path between the two rewarded end locations of a
               familiar three-way maze. We found that rats rapidly and
               consistently chose the shortest alternative detour. Furthermore,
               both CA1 and CA3 place cells that had a field in the vicinity of
               the barrier displayed local remapping. In contrast, neither CA1
               nor CA3 cells that had a field away from the barrier were
               affected. This finding, at odds with our previous report of
               altered CA3 discharge for distant fields in a shortcut task,
               suggests that the availability of a novel path and the blocking
               of a familiar path are not equivalent and could lead to
               different responses of the CA3 place cell population. Together,
               the two studies point to a specific role of CA3 in the
               representation of spatial connectivity and sequences.",
  journal   = "Eur. J. Neurosci.",
  publisher = "Wiley Online Library",
  volume    =  33,
  number    =  9,
  pages     = "1696--1705",
  month     =  may,
  year      =  2011,
  language  = "en",
  issn      = "0953-816X, 1460-9568",
  pmid      = "21395871",
  doi       = "10.1111/j.1460-9568.2011.07653.x"
}

@ARTICLE{Alvernhe2008-dx,
  title     = "Different {CA1} and {CA3} representations of novel routes in a
               shortcut situation",
  author    = "Alvernhe, Alice and Van Cauter, Tiffany and Save, Etienne and
               Poucet, Bruno",
  abstract  = "Place cells are hippocampal neurons whose discharge is strongly
               related to a rat's location in its environment. The existence of
               place cells has led to the proposal that they are part of an
               integrated neural system dedicated to spatial navigation. To
               further understand the relationships between place cell firing
               and spatial problem solving, we examined the discharge of CA1
               and CA3 place cells as rats were exposed to a shortcut in a
               runway maze. On specific sessions, a wall section of the maze
               was removed so as to open a shorter novel route within the
               otherwise familiar maze. We found that the discharge of both CA1
               and CA3 cells was strongly affected in the vicinity of the
               shortcut region but was much less affected farther away. In
               addition, CA3 fields away from the shortcut were more altered
               than CA1 fields. Thus, place cell firing appears to reflect more
               than just the animal's spatial location and may provide
               additional information about possible motions, or routes, within
               the environment. This kinematic representation appears to be
               spatially more extended in CA3 than in CA1, suggesting
               interesting computational differences between the two
               subregions.",
  journal   = "J. Neurosci.",
  publisher = "Soc Neuroscience",
  volume    =  28,
  number    =  29,
  pages     = "7324--7333",
  month     =  jul,
  year      =  2008,
  language  = "en",
  issn      = "0270-6474, 1529-2401",
  pmid      = "18632936",
  doi       = "10.1523/JNEUROSCI.1909-08.2008"
}

@ARTICLE{Vikbladh2019-qe,
  title     = "Hippocampal Contributions to {Model-Based} Planning and Spatial
               Memory",
  author    = "Vikbladh, Oliver M and Meager, Michael R and King, John and
               Blackmon, Karen and Devinsky, Orrin and Shohamy, Daphna and
               Burgess, Neil and Daw, Nathaniel D",
  abstract  = "SummaryLittle is known about the neural mechanisms that allow
               humans and animals to plan actions using knowledge of task
               contingencies. Emerging theories hypothesize that it involves
               the same hippocampal mechanisms that support self-localization
               and memory for locations. Yet limited direct evidence supports
               the link between planning and the hippocampal place map. We
               addressed this by investigating model-based planning and place
               memory in healthy controls and epilepsy patients treated using
               unilateral anterior temporal lobectomy with hippocampal
               resection. Both functions were impaired in the patient group.
               Specifically, the planning impairment was related to right
               hippocampal lesion size, controlling for overall lesion size.
               Furthermore, although planning and boundary-driven place memory
               covaried in the control group, this relationship was attenuated
               in patients, consistent with both functions relying on the same
               structure in the healthy brain. These findings clarify both the
               neural mechanism of model-based planning and the scope of
               hippocampal contributions to behavior.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  0,
  number    =  0,
  month     =  mar,
  year      =  2019,
  keywords  = "decision-making; model-based; reinforcement learning; planning;
               spatial; memory; human; hippocampus; anterior temporal lobe;
               lesion",
  language  = "en",
  issn      = "0896-6273",
  doi       = "10.1016/j.neuron.2019.02.014"
}

@ARTICLE{Erdem2012-xv,
  title     = "A goal-directed spatial navigation model using forward
               trajectory planning based on grid cells",
  author    = "Erdem, U{\u g}ur M and Hasselmo, Michael",
  abstract  = "A goal-directed navigation model is proposed based on forward
               linear look-ahead probe of trajectories in a network of head
               direction cells, grid cells, place cells and prefrontal cortex
               (PFC) cells. The model allows selection of new goal-directed
               trajectories. In a novel environment, the virtual rat
               incrementally creates a map composed of place cells and PFC
               cells by random exploration. After exploration, the rat
               retrieves memory of the goal location, picks its next movement
               direction by forward linear look-ahead probe of trajectories in
               several candidate directions while stationary in one location,
               and finds the one activating PFC cells with the highest reward
               signal. Each probe direction involves activation of a static
               pattern of head direction cells to drive an interference model
               of grid cells to update their phases in a specific direction.
               The updating of grid cell spiking drives place cells along the
               probed look-ahead trajectory similar to the forward replay
               during waking seen in place cell recordings. Directions are
               probed until the look-ahead trajectory activates the reward
               signal and the corresponding direction is used to guide
               goal-finding behavior. We report simulation results in several
               mazes with and without barriers. Navigation with barriers
               requires a PFC map topology based on the temporal vicinity of
               visited place cells and a reward signal diffusion process. The
               interaction of the forward linear look-ahead trajectory probes
               with the reward diffusion allows discovery of never-before
               experienced shortcuts towards a goal location.",
  journal   = "Eur. J. Neurosci.",
  publisher = "Wiley Online Library",
  volume    =  35,
  number    =  6,
  pages     = "916--931",
  month     =  mar,
  year      =  2012,
  language  = "en",
  issn      = "0953-816X, 1460-9568",
  pmid      = "22393918",
  doi       = "10.1111/j.1460-9568.2012.08015.x",
  pmc       = "PMC3564559"
}

@ARTICLE{noauthor_undated-uu,
  title = "Prefrontal cortex creates novel navigation sequences from
           hippocampal place-cell replay with spatial reward propagation",
  doi   = "10.1101/466920"
}

@ARTICLE{Akrami2018-xc,
  title    = "Posterior parietal cortex represents sensory history and mediates
              its effects on behaviour",
  author   = "Akrami, Athena and Kopec, Charles D and Diamond, Mathew E and
              Brody, Carlos D",
  abstract = "Many models of cognition and of neural computations posit the use
              and estimation of prior stimulus statistics: it has long been
              known that working memory and perception are strongly impacted by
              previous sensory experience, even when that sensory history is
              not relevant to the current task at hand. Nevertheless, the
              neural mechanisms and regions of the brain that are necessary for
              computing and using such prior experience are unknown. Here we
              report that the posterior parietal cortex (PPC) is a critical
              locus for the representation and use of prior stimulus
              information. We trained rats in an auditory parametric working
              memory task, and found that they displayed substantial and
              readily quantifiable behavioural effects of sensory-stimulus
              history, similar to those observed in humans and monkeys. Earlier
              proposals that the PPC supports working memory predict that
              optogenetic silencing of this region would impair behaviour in
              our working memory task. Contrary to this prediction, we found
              that silencing the PPC significantly improved performance.
              Quantitative analyses of behaviour revealed that this improvement
              was due to the selective reduction of the effects of prior
              sensory stimuli. Electrophysiological recordings showed that PPC
              neurons carried far more information about the sensory stimuli of
              previous trials than about the stimuli of the current trial.
              Furthermore, for a given rat, the more information about previous
              trial sensory history in the neural firing rates of the PPC, the
              greater the behavioural effect of sensory history, suggesting a
              tight link between behaviour and PPC representations of stimulus
              history. Our results indicate that the PPC is a central component
              in the processing of sensory-stimulus history, and could enable
              further neurobiological investigation of long-standing questions
              regarding how perception and working memory are affected by prior
              sensory information.",
  journal  = "Nature",
  volume   =  554,
  number   =  7692,
  pages    = "368--372",
  month    =  feb,
  year     =  2018,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "29414944",
  doi      = "10.1038/nature25510"
}

@ARTICLE{OKeefe1996-rj,
  title    = "Geometric determinants of the place fields of hippocampal neurons",
  author   = "O'Keefe, J and Burgess, N",
  abstract = "The human hippocampus has been implicated in memory, in
              particular episodic or declarative memory. In rats, hippocampal
              lesions cause selective spatial deficits, and hippocampal complex
              spike cells (place cells) exhibit spatially localized firing,
              suggesting a role in spatial memory, although broader functions
              have also been suggested. Here we report the identification of
              the environmental features controlling the location and shape of
              the receptive fields (place fields) of the place cells. This was
              done by recording from the same cell in four rectangular boxes
              that differed solely in the length of one or both sides. Most of
              our results are explained by a model in which the place field is
              formed by the summation of gaussian tuning curves, each oriented
              perpendicular to a box wall and peaked at a fixed distance from
              it.",
  journal  = "Nature",
  volume   =  381,
  number   =  6581,
  pages    = "425--428",
  month    =  may,
  year     =  1996,
  language = "en",
  issn     = "0028-0836",
  pmid     = "8632799",
  doi      = "10.1038/381425a0"
}

@ARTICLE{Burgess2007-hn,
  title    = "An oscillatory interference model of grid cell firing",
  author   = "Burgess, Neil and Barry, Caswell and O'Keefe, John",
  abstract = "We expand upon our proposal that the oscillatory interference
              mechanism proposed for the phase precession effect in place cells
              underlies the grid-like firing pattern of dorsomedial entorhinal
              grid cells (O'Keefe and Burgess (2005) Hippocampus 15:853-866).
              The original one-dimensional interference model is generalized to
              an appropriate two-dimensional mechanism. Specifically, dendritic
              subunits of layer II medial entorhinal stellate cells provide
              multiple linear interference patterns along different directions,
              with their product determining the firing of the cell. Connection
              of appropriate speed- and direction-dependent inputs onto
              dendritic subunits could result from an unsupervised learning
              rule which maximizes postsynaptic firing (e.g. competitive
              learning). These inputs cause the intrinsic oscillation of
              subunit membrane potential to increase above theta frequency by
              an amount proportional to the animal's speed of running in the
              ``preferred'' direction. The phase difference between this
              oscillation and a somatic input at theta-frequency essentially
              integrates velocity so that the interference of the two
              oscillations reflects distance traveled in the preferred
              direction. The overall grid pattern is maintained in
              environmental location by phase reset of the grid cell by place
              cells receiving sensory input from the environment, and
              environmental boundaries in particular. We also outline possible
              variations on the basic model, including the generation of
              grid-like firing via the interaction of multiple cells rather
              than via multiple dendritic subunits. Predictions of the
              interference model are given for the frequency composition of EEG
              power spectra and temporal autocorrelograms of grid cell firing
              as functions of the speed and direction of running and the
              novelty of the environment.",
  journal  = "Hippocampus",
  volume   =  17,
  number   =  9,
  pages    = "801--812",
  year     =  2007,
  language = "en",
  issn     = "1050-9631",
  pmid     = "17598147",
  doi      = "10.1002/hipo.20327",
  pmc      = "PMC2678278"
}

@ARTICLE{Cortese2018-hj,
  title         = "The neural and cognitive architecture for learning from a
                   small sample",
  author        = "Cortese, Aurelio and De Martino, Benedetto and Kawato,
                   Mitsuo",
  abstract      = "Artificial intelligence algorithms are capable of fantastic
                   exploits, yet they are still grossly inefficient compared
                   with the brain's ability to learn from few exemplars or
                   solve problems that have not been explicitly defined. What
                   is the secret that the evolution of human intelligence has
                   unlocked? Generalization is one answer, but there is more to
                   it. The brain does not directly solve difficult problems, it
                   is able to recast them into new and more tractable problems.
                   Here we propose a model whereby higher cognitive functions
                   profoundly interact with reinforcement learning to
                   drastically reduce the degrees of freedom of the search
                   space, simplifying complex problems and fostering more
                   efficient learning.",
  month         =  oct,
  year          =  2018,
  archivePrefix = "arXiv",
  eprint        = "1810.02476",
  primaryClass  = "q-bio.NC",
  arxivid       = "1810.02476"
}

@ARTICLE{De_Martino2013-rw,
  title    = "Confidence in value-based choice",
  author   = "De Martino, Benedetto and Fleming, Stephen M and Garrett, Neil
              and Dolan, Raymond J",
  abstract = "Decisions are never perfect, with confidence in one's choices
              fluctuating over time. How subjective confidence and valuation of
              choice options interact at the level of brain and behavior is
              unknown. Using a dynamic model of the decision process, we show
              that confidence reflects the evolution of a decision variable
              over time, explaining the observed relation between confidence,
              value, accuracy and reaction time. As predicted by our dynamic
              model, we show that a functional magnetic resonance imaging
              signal in human ventromedial prefrontal cortex (vmPFC) reflects
              both value comparison and confidence in the value comparison
              process. Crucially, individuals varied in how they related
              confidence to accuracy, allowing us to show that this
              introspective ability is predicted by a measure of functional
              connectivity between vmPFC and rostrolateral prefrontal cortex.
              Our findings provide a mechanistic link between noise in value
              comparison and metacognitive awareness of choice, enabling us
              both to want and to express knowledge of what we want.",
  journal  = "Nat. Neurosci.",
  volume   =  16,
  number   =  1,
  pages    = "105--110",
  month    =  jan,
  year     =  2013,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "23222911",
  doi      = "10.1038/nn.3279",
  pmc      = "PMC3786394"
}

@UNPUBLISHED{Duan2018-yh,
  title    = "Collicular circuits for flexible sensorimotor routing",
  author   = "Duan, Chunyu A and Pagan, Marino and Piet, Alex T and Kopec,
              Charles D and Akrami, Athena and Riordan, Alexander J and Erlich,
              Jeffrey C and Brody, Carlos D",
  abstract = "Flexible and fast sensorimotor routing, based on relevant
              environmental context, is a central component of executive
              control, with prefrontal cortex (PFC) thought of as playing a
              critical role and the midbrain superior colliculus (SC) more
              traditionally viewed as the output of cortical flexible routing.
              Here, using a rat task in which subjects switch rapidly between
              task contexts that demand changes in sensorimotor mappings, we
              report that silencing of the SC during a delay period, during
              which task context is encoded in SC activity, impaired choice
              accuracy. But inactivations during the subsequent choice period,
              during which the subject selects their motor response, did not.
              Furthermore, a defined subset of SC neurons encoded task context
              more strongly than PFC neurons, and encoded the subject9s motor
              output choice faster than PFC neurons or other SC neurons. These
              data suggest cognitive and decision-making roles for the SC. We
              used computational methods to identify different SC circuit
              architectures that could account for these results. We found
              numerous, highly varied SC model circuits that matched our
              experimental data, including circuits without inhibitory
              connections between units representing opposite decision outputs.
              But all successful model circuits had inhibitory connections
              between units on the same side of the brain representing opposite
              contexts. This anatomical feature appears to be a key
              experimental prediction for models in which the SC plays a
              decision-making role during executive control.",
  journal  = "bioRxiv",
  pages    = "245613",
  month    =  jan,
  year     =  2018,
  language = "en",
  doi      = "10.1101/245613"
}

@ARTICLE{Gershman2018-gf,
  title    = "The Successor Representation: Its Computational Logic and Neural
              Substrates",
  author   = "Gershman, Samuel J",
  abstract = "Reinforcement learning is the process by which an agent learns to
              predict long-term future reward. We now understand a great deal
              about the brain's reinforcement learning algorithms, but we know
              considerably less about the representations of states and actions
              over which these algorithms operate. A useful starting point is
              asking what kinds of representations we would want the brain to
              have, given the constraints on its computational architecture.
              Following this logic leads to the idea of the successor
              representation, which encodes states of the environment in terms
              of their predictive relationships with other states. Recent
              behavioral and neural studies have provided evidence for the
              successor representation, and computational studies have explored
              ways to extend the original idea. This paper reviews progress on
              these fronts, organizing them within a broader framework for
              understanding how the brain negotiates tradeoffs between
              efficiency and flexibility for reinforcement learning.",
  journal  = "J. Neurosci.",
  volume   =  38,
  number   =  33,
  pages    = "7193--7200",
  month    =  aug,
  year     =  2018,
  keywords = "cognitive map; dopamine; hippocampus; reinforcement learning;
              reward",
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "30006364",
  doi      = "10.1523/JNEUROSCI.0151-18.2018",
  pmc      = "PMC6096039"
}

@ARTICLE{Saxena2019-it,
  title    = "Towards the neural population doctrine",
  author   = "Saxena, Shreya and Cunningham, John P",
  abstract = "Across neuroscience, large-scale data recording and
              population-level analysis methods have experienced explosive
              growth. While the underlying hardware and computational
              techniques have been well reviewed, we focus here on the novel
              science that these technologies have enabled. We detail four
              areas of the field where the joint analysis of neural populations
              has significantly furthered our understanding of computation in
              the brain: correlated variability, decoding, neural dynamics, and
              artificial neural networks. Together, these findings suggest an
              exciting trend towards a new era where neural populations are
              understood to be the essential unit of computation in many brain
              regions, a classic idea that has been given new life.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  55,
  pages    = "103--111",
  month    =  mar,
  year     =  2019,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "30877963",
  doi      = "10.1016/j.conb.2019.02.002"
}

@ARTICLE{Baluska2016-po,
  title     = "On Having No Head: Cognition throughout Biological Systems",
  author    = "Balu{\v s}ka, Franti{\v s}ek and Levin, Michael",
  abstract  = "The central nervous system (CNS) underlies memory, perception,
               decision-making, and behavior in numerous organisms. However,
               neural networks have no monopoly on the signaling functions that
               implement these remarkable algorithms. It is often forgotten
               that neurons optimized cellular signaling modes that existed
               long before the CNS appeared during evolution, and were used by
               somatic cellular networks to orchestrate physiology, embryonic
               development, and behavior. Many of the key dynamics that enable
               information processing can, in fact, be implemented by different
               biological hardware. This is widely exploited by organisms
               throughout the tree of life. Here, we review data on memory,
               learning, and other aspects of cognition in a range of models,
               including single celled organisms, plants, and tissues in animal
               bodies. We discuss current knowledge of the molecular mechanisms
               at work in these systems, and suggest several hypotheses for
               future investigation. The study of cognitive processes
               implemented in aneural contexts is a fascinating, highly
               interdisciplinary topic that has many implications for
               evolution, cell biology, regenerative medicine, computer
               science, and synthetic bioengineering.",
  journal   = "Front. Psychol.",
  publisher = "frontiersin.org",
  volume    =  7,
  pages     = "902",
  month     =  jun,
  year      =  2016,
  keywords  = "aneural; bioelectric signaling; cognition; computation;
               information; learning; memory; plants",
  language  = "en",
  issn      = "1664-1078",
  pmid      = "27445884",
  doi       = "10.3389/fpsyg.2016.00902",
  pmc       = "PMC4914563"
}

@ARTICLE{Spiers2008-aw,
  title    = "Keeping the goal in mind: prefrontal contributions to spatial
              navigation",
  author   = "Spiers, Hugo J",
  journal  = "Neuropsychologia",
  volume   =  46,
  number   =  7,
  pages    = "2106--2108",
  month    =  feb,
  year     =  2008,
  language = "en",
  issn     = "0028-3932",
  pmid     = "18387640",
  doi      = "10.1016/j.neuropsychologia.2008.01.028",
  pmc      = "PMC2430985"
}

@ARTICLE{Garnier2013-cv,
  title    = "Do ants need to estimate the geometrical properties of trail
              bifurcations to find an efficient route? A swarm robotics test
              bed",
  author   = "Garnier, Simon and Combe, Maud and Jost, Christian and Theraulaz,
              Guy",
  abstract = "Interactions between individuals and the structure of their
              environment play a crucial role in shaping self-organized
              collective behaviors. Recent studies have shown that ants
              crossing asymmetrical bifurcations in a network of galleries tend
              to follow the branch that deviates the least from their incoming
              direction. At the collective level, the combination of this
              tendency and the pheromone-based recruitment results in a greater
              likelihood of selecting the shortest path between the colony's
              nest and a food source in a network containing asymmetrical
              bifurcations. It was not clear however what the origin of this
              behavioral bias is. Here we propose that it results from a simple
              interaction between the behavior of the ants and the geometry of
              the network, and that it does not require the ability to measure
              the angle of the bifurcation. We tested this hypothesis using
              groups of ant-like robots whose perceptual and cognitive
              abilities can be fully specified. We programmed them only to lay
              down and follow light trails, avoid obstacles and move according
              to a correlated random walk, but not to use more sophisticated
              orientation methods. We recorded the behavior of the robots in
              networks of galleries presenting either only symmetrical
              bifurcations or a combination of symmetrical and asymmetrical
              bifurcations. Individual robots displayed the same pattern of
              branch choice as individual ants when crossing a bifurcation,
              suggesting that ants do not actually measure the geometry of the
              bifurcations when travelling along a pheromone trail. Finally at
              the collective level, the group of robots was more likely to
              select one of the possible shorter paths between two designated
              areas when moving in an asymmetrical network, as observed in
              ants. This study reveals the importance of the shape of trail
              networks for foraging in ants and emphasizes the underestimated
              role of the geometrical properties of transportation networks in
              general.",
  journal  = "PLoS Comput. Biol.",
  volume   =  9,
  number   =  3,
  pages    = "e1002903",
  month    =  mar,
  year     =  2013,
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "23555202",
  doi      = "10.1371/journal.pcbi.1002903",
  pmc      = "PMC3610605"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Forster2014-ms,
  title    = "Effect of Trail Bifurcation Asymmetry and Pheromone Presence or
              Absence on Trail Choice by Lasius niger Ants",
  author   = "Forster, Antonia and Czaczkes, Tomer J and Warner, Emma and
              Woodall, Tom and Martin, Emily and Ratnieks, Francis L W and
              Herberstein, M",
  abstract = "During foraging, ant workers are known to make use of multiple
              information sources, such as private information (personal
              memory) and social information (trail pheromones). Environmental
              effects on foraging, and how these interact with other
              information sources, have, however, been little studied. One
              environmental effect is trail bifurcation asymmetry. Ants forage
              on branching trail networks and must often decide which branch to
              take at a junction (bifurcation). This is an important decision,
              as finding food sources relies on making the correct choices at
              bifurcations. Bifurcation angle may provide important information
              when making this choice. We used a Y-maze with a pivoting 90°
              bifurcation to study trail choice of Lasius niger foragers at
              varying branch asymmetries (0°, [both branches 45° from straight
              ahead], 30° [branches at 30° and 60° from straight ahead], 45°,
              60° and 90° [one branch straight ahead, the other at 90°]). The
              experiment was carried out either with equal amounts of trail
              pheromone on both branches of the bifurcation or with pheromone
              present on only one branch. Our results show that with equal
              pheromone, trail asymmetry has a significant effect on trail
              choice. Ants preferentially follow the branch deviating least
              from straight, and this effect increases as asymmetry increases
              (47\% at 0°, 54\% at 30°, 57\% at 45°, 66\% at 60° and 73\% at
              90°). However, when pheromone is only present on one branch, the
              graded effect of asymmetry disappears. Overall, however, there is
              an effect of asymmetry as the preference of ants for the
              pheromone-marked branch over the unmarked branch is reduced from
              65\%, when it is the less deviating branch, to 53\%, when it is
              the more deviating branch. These results demonstrate that trail
              asymmetry influences ant decision-making at bifurcations and that
              this information interacts with trail pheromone presence in a
              non-hierarchical manner.",
  journal  = "Ethology",
  volume   =  120,
  number   =  8,
  pages    = "768--775",
  month    =  aug,
  year     =  2014,
  keywords = "Lasius niger; asymmetry; environmental effects; foraging;
              pheromone; trail choice",
  language = "en",
  issn     = "0179-1613",
  pmid     = "25400307",
  doi      = "10.1111/eth.12248",
  pmc      = "PMC4204274"
}

@ARTICLE{Holcombe2012-qk,
  title    = "Modelling complex biological systems using an agent-based
              approach",
  author   = "Holcombe, Mike and Adra, Salem and Bicak, Mesude and Chin, Shawn
              and Coakley, Simon and Graham, Alison I and Green, Jeffrey and
              Greenough, Chris and Jackson, Duncan and Kiran, Mariam and
              MacNeil, Sheila and Maleki-Dizaji, Afsaneh and McMinn, Phil and
              Pogson, Mark and Poole, Robert and Qwarnstrom, Eva and Ratnieks,
              Francis and Rolfe, Matthew D and Smallwood, Rod and Sun, Tao and
              Worth, David",
  abstract = "Many of the complex systems found in biology are comprised of
              numerous components, where interactions between individual agents
              result in the emergence of structures and function, typically in
              a highly dynamic manner. Often these entities have limited
              lifetimes but their interactions both with each other and their
              environment can have profound biological consequences. We will
              demonstrate how modelling these entities, and their interactions,
              can lead to a new approach to experimental biology bringing new
              insights and a deeper understanding of biological systems.",
  journal  = "Integr. Biol.",
  volume   =  4,
  number   =  1,
  pages    = "53--64",
  month    =  jan,
  year     =  2012,
  language = "en",
  issn     = "1757-9694, 1757-9708",
  pmid     = "22052476",
  doi      = "10.1039/c1ib00042j"
}

@ARTICLE{Ahrlund-Richter2019-ff,
  title    = "A whole-brain atlas of monosynaptic input targeting four
              different cell types in the medial prefrontal cortex of the mouse",
  author   = "{\"A}hrlund-Richter, Sofie and Xuan, Yang and van Lunteren,
              Josina Anna and Kim, Hoseok and Ortiz, Cantin and Pollak Dorocic,
              Iskra and Meletis, Konstantinos and Carl{\'e}n, Marie",
  abstract = "The local and long-range connectivity of cortical neurons are
              considered instrumental to the functional repertoire of the
              cortical region in which they reside. In cortical networks,
              distinct cell types build local circuit structures enabling
              computational operations. Computations in the medial prefrontal
              cortex (mPFC) are thought to be central to cognitive operation,
              including decision-making and memory. We used a retrograde
              trans-synaptic rabies virus system to generate brain-wide maps of
              the input to excitatory neurons as well as three inhibitory
              interneuron subtypes in the mPFC. On the global scale the input
              patterns were found to be mainly cell type independent, with
              quantitative differences in key brain regions, including the
              basal forebrain. Mapping of the local mPFC network revealed high
              connectivity between the different subtypes of interneurons. The
              connectivity mapping gives insight into the information that the
              mPFC processes and the structural architecture underlying the
              mPFC's unique functions.",
  journal  = "Nat. Neurosci.",
  month    =  mar,
  year     =  2019,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "30886408",
  doi      = "10.1038/s41593-019-0354-y"
}

@UNPUBLISHED{Zador2019-fj,
  title    = "A Critique of Pure Learning: What Artificial Neural Networks can
              Learn from Animal Brains",
  author   = "Zador, Anthony",
  abstract = "Over the last decade, artificial neural networks (ANNs), have
              undergone a revolution, catalyzed in large part by better tools
              for supervised learning. However, training such networks requires
              enormous data sets of labeled examples, whereas young animals
              (including humans) typically learn with few or no labeled
              examples. This stark contrast with biological learning has led
              many in the ANN community posit that instead of supervised
              paradigms, animals must rely instead primarily on unsupervised
              learning, leading the search for better unsupervised algorithms.
              Here we argue that much of an animal9s behavioral repertoire is
              not the result of clever learning algorithms--supervised or
              unsupervised--but arises instead from behavior programs already
              present at birth. These programs arise through evolution, are
              encoded in the genome, and emerge as a consequence of wiring up
              the brain. Specifically, animals are born with highly structured
              brain connectivity, which enables them learn very rapidly.
              Recognizing the importance of the highly structured connectivity
              suggests a path toward building ANNs capable of rapid learning.",
  journal  = "bioRxiv",
  pages    = "582643",
  month    =  mar,
  year     =  2019,
  language = "en",
  doi      = "10.1101/582643"
}

@ARTICLE{Evans2019-tq,
  title    = "Cognitive Control of Escape Behaviour",
  author   = "Evans, Dominic A and Stempel, A Vanessa and Vale, Ruben and
              Branco, Tiago",
  abstract = "When faced with potential predators, animals instinctively decide
              whether there is a threat they should escape from, and also when,
              how, and where to take evasive action. While escape is often
              viewed in classical ethology as an action that is released upon
              presentation of specific stimuli, successful and adaptive escape
              behaviour relies on integrating information from sensory systems,
              stored knowledge, and internal states. From a neuroscience
              perspective, escape is an incredibly rich model that provides
              opportunities for investigating processes such as perceptual and
              value-based decision-making, or action selection, in an
              ethological setting. We review recent research from laboratory
              and field studies that explore, at the behavioural and
              mechanistic levels, how elements from multiple information
              streams are integrated to generate flexible escape behaviour.",
  journal  = "Trends Cogn. Sci.",
  volume   =  23,
  number   =  4,
  pages    = "334--348",
  month    =  apr,
  year     =  2019,
  keywords = "behavioural flexibility; defence; instinctive decisions; threat",
  language = "en",
  issn     = "1364-6613, 1879-307X",
  pmid     = "30852123",
  doi      = "10.1016/j.tics.2019.01.012"
}

@ARTICLE{Otto2013-yk,
  title     = "The curse of planning: dissecting multiple
               reinforcement-learning systems by taxing the central executive",
  author    = "Otto, A Ross and Gershman, Samuel J and Markman, Arthur B and
               Daw, Nathaniel D",
  abstract  = "A number of accounts of human and animal behavior posit the
               operation of parallel and competing valuation systems in the
               control of choice behavior. In these accounts, a flexible but
               computationally expensive model-based reinforcement-learning
               system has been contrasted with a less flexible but more
               efficient model-free reinforcement-learning system. The factors
               governing which system controls behavior-and under what
               circumstances-are still unclear. Following the hypothesis that
               model-based reinforcement learning requires cognitive resources,
               we demonstrated that having human decision makers perform a
               demanding secondary task engenders increased reliance on a
               model-free reinforcement-learning strategy. Further, we showed
               that, across trials, people negotiate the trade-off between the
               two systems dynamically as a function of concurrent
               executive-function demands, and people's choice latencies
               reflect the computational expenses of the strategy they employ.
               These results demonstrate that competition between multiple
               learning systems can be controlled on a trial-by-trial basis by
               modulating the availability of cognitive resources.",
  journal   = "Psychol. Sci.",
  publisher = "journals.sagepub.com",
  volume    =  24,
  number    =  5,
  pages     = "751--761",
  month     =  may,
  year      =  2013,
  keywords  = "cognitive neuroscience; decision making",
  language  = "en",
  issn      = "0956-7976, 1467-9280",
  pmid      = "23558545",
  doi       = "10.1177/0956797612463080",
  pmc       = "PMC3843765"
}

@ARTICLE{Doll2009-ki,
  title     = "Instructional control of reinforcement learning: a behavioral
               and neurocomputational investigation",
  author    = "Doll, Bradley B and Jacobs, W Jake and Sanfey, Alan G and Frank,
               Michael J",
  abstract  = "Humans learn how to behave directly through environmental
               experience and indirectly through rules and instructions.
               Behavior analytic research has shown that instructions can
               control behavior, even when such behavior leads to sub-optimal
               outcomes (Hayes, S. (Ed.). 1989. Rule-governed behavior:
               cognition, contingencies, and instructional control. Plenum
               Press.). Here we examine the control of behavior through
               instructions in a reinforcement learning task known to depend on
               striatal dopaminergic function. Participants selected between
               probabilistically reinforced stimuli, and were (incorrectly)
               told that a specific stimulus had the highest (or lowest)
               reinforcement probability. Despite experience to the contrary,
               instructions drove choice behavior. We present neural network
               simulations that capture the interactions between
               instruction-driven and reinforcement-driven behavior via two
               potential neural circuits: one in which the striatum is
               inaccurately trained by instruction representations coming from
               prefrontal cortex/hippocampus (PFC/HC), and another in which the
               striatum learns the environmentally based reinforcement
               contingencies, but is ``overridden'' at decision output. Both
               models capture the core behavioral phenomena but, because they
               differ fundamentally on what is learned, make distinct
               predictions for subsequent behavioral and neuroimaging
               experiments. Finally, we attempt to distinguish between the
               proposed computational mechanisms governing instructed behavior
               by fitting a series of abstract ``Q-learning'' and Bayesian
               models to subject data. The best-fitting model supports one of
               the neural models, suggesting the existence of a ``confirmation
               bias'' in which the PFC/HC system trains the reinforcement
               system by amplifying outcomes that are consistent with
               instructions while diminishing inconsistent outcomes.",
  journal   = "Brain Res.",
  publisher = "Elsevier",
  volume    =  1299,
  pages     = "74--94",
  month     =  nov,
  year      =  2009,
  language  = "en",
  issn      = "0006-8993, 1872-6240",
  pmid      = "19595993",
  doi       = "10.1016/j.brainres.2009.07.007",
  pmc       = "PMC3050481"
}

@ARTICLE{Balleine1998-ur,
  title     = "Goal-directed instrumental action: contingency and incentive
               learning and their cortical substrates",
  author    = "Balleine, B W and Dickinson, A",
  abstract  = "Instrumental behaviour is controlled by two systems: a
               stimulus-response habit mechanism and a goal-directed process
               that involves two forms of learning. The first is learning about
               the instrumental contingency between the response and reward,
               whereas the second consists of the acquisition of incentive
               value by the reward. Evidence for contingency learning comes
               from studies of reward devaluation and from demonstrations that
               instrumental performance is sensitive not only the probability
               of contiguous reward but also to the probability of unpaired
               rewards. The process of incentive learning is evident in the
               acquisition of control over performance by primary motivational
               states. Preliminary lesion studies of the rat suggest that the
               prelimbic area of prefrontal cortex plays a role in the
               contingency learning, whereas the incentive learning for food
               rewards involves the insular cortex.",
  journal   = "Neuropharmacology",
  publisher = "Elsevier",
  volume    =  37,
  number    = "4-5",
  pages     = "407--419",
  month     =  apr,
  year      =  1998,
  language  = "en",
  issn      = "0028-3908",
  pmid      = "9704982"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Tolman1930-yp,
  title     = "Introduction and removal of reward, and maze performance in rats",
  author    = "Tolman, E C and Honzik, C H",
  abstract  = "Two groups of rats, one which ran the maze with reward, and one
               which ran the maze without reward, were tested to determine the
               influence upon the learning curve of a sudden removal, or a
               sudden introduction, of a food reward. The maze was a 14-unit
               T-maze. Reliability coefficients ranged from. 876 to. 965. When
               the food reward was removed from the maze the error scores and
               time scores of the rewarded rats showed a large increase. When
               reward was introduced into the maze the non-rewarded rats showed
               a large decrease …",
  journal   = "Univ. Calif. Publ. Zool.",
  publisher = "psycnet.apa.org",
  year      =  1930,
  issn      = "0068-6506"
}

@ARTICLE{Glascher2010-ne,
  title     = "States versus rewards: dissociable neural prediction error
               signals underlying model-based and model-free reinforcement
               learning",
  author    = "Gl{\"a}scher, Jan and Daw, Nathaniel and Dayan, Peter and
               O'Doherty, John P",
  abstract  = "Reinforcement learning (RL) uses sequential experience with
               situations (``states'') and outcomes to assess actions. Whereas
               model-free RL uses this experience directly, in the form of a
               reward prediction error (RPE), model-based RL uses it
               indirectly, building a model of the state transition and outcome
               structure of the environment, and evaluating actions by
               searching this model. A state prediction error (SPE) plays a
               central role, reporting discrepancies between the current model
               and the observed state transitions. Using functional magnetic
               resonance imaging in humans solving a probabilistic Markov
               decision task, we found the neural signature of an SPE in the
               intraparietal sulcus and lateral prefrontal cortex, in addition
               to the previously well-characterized RPE in the ventral
               striatum. This finding supports the existence of two unique
               forms of learning signal in humans, which may form the basis of
               distinct computational strategies for guiding behavior.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  66,
  number    =  4,
  pages     = "585--595",
  month     =  may,
  year      =  2010,
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "20510862",
  doi       = "10.1016/j.neuron.2010.04.016",
  pmc       = "PMC2895323"
}

@ARTICLE{Ruediger2012-lx,
  title     = "Goal-oriented searching mediated by ventral hippocampus early in
               trial-and-error learning",
  author    = "Ruediger, Sarah and Spirig, Dominique and Donato, Flavio and
               Caroni, Pico",
  abstract  = "Most behavioral learning in biology is trial and error, but how
               these learning processes are influenced by individual brain
               systems is poorly understood. Here we show that
               ventral-to-dorsal hippocampal subdivisions have specific and
               sequential functions in trial-and-error maze navigation, with
               ventral hippocampus (vH) mediating early task-specific
               goal-oriented searching. Although performance and strategy
               deployment progressed continuously at the population level,
               individual mice showed discrete learning phases, each
               characterized by particular search habits. Transitions in
               learning phases reflected feedforward inhibitory connectivity
               (FFI) growth occurring sequentially in ventral, then
               intermediate, then dorsal hippocampal subdivisions. FFI growth
               at vH occurred abruptly upon behavioral learning of goal-task
               relationships. vH lesions or the absence of vH FFI growth
               delayed early learning and disrupted performance consistency.
               Intermediate hippocampus lesions impaired intermediate place
               learning, whereas dorsal hippocampus lesions specifically
               disrupted late spatial learning. Trial-and-error navigational
               learning processes in naive mice thus involve a stereotype
               sequence of increasingly precise subtasks learned through
               distinct hippocampal subdivisions. Because of its unique
               connectivity, vH may relate specific goals to internal states in
               learning under healthy and pathological conditions.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  15,
  number    =  11,
  pages     = "1563--1571",
  month     =  nov,
  year      =  2012,
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "23001061",
  doi       = "10.1038/nn.3224"
}

@ARTICLE{Collins2012-sn,
  title     = "How much of reinforcement learning is working memory, not
               reinforcement learning? A behavioral, computational, and
               neurogenetic analysis",
  author    = "Collins, Anne G E and Frank, Michael J",
  abstract  = "Instrumental learning involves corticostriatal circuitry and the
               dopaminergic system. This system is typically modeled in the
               reinforcement learning (RL) framework by incrementally
               accumulating reward values of states and actions. However, human
               learning also implicates prefrontal cortical mechanisms involved
               in higher level cognitive functions. The interaction of these
               systems remains poorly understood, and models of human behavior
               often ignore working memory (WM) and therefore incorrectly
               assign behavioral variance to the RL system. Here we designed a
               task that highlights the profound entanglement of these two
               processes, even in simple learning problems. By systematically
               varying the size of the learning problem and delay between
               stimulus repetitions, we separately extracted WM-specific
               effects of load and delay on learning. We propose a new
               computational model that accounts for the dynamic integration of
               RL and WM processes observed in subjects' behavior.
               Incorporating capacity-limited WM into the model allowed us to
               capture behavioral variance that could not be captured in a pure
               RL framework even if we (implausibly) allowed separate RL
               systems for each set size. The WM component also allowed for a
               more reasonable estimation of a single RL process. Finally, we
               report effects of two genetic polymorphisms having relative
               specificity for prefrontal and basal ganglia functions. Whereas
               the COMT gene coding for catechol-O-methyl transferase
               selectively influenced model estimates of WM capacity, the GPR6
               gene coding for G-protein-coupled receptor 6 influenced the RL
               learning rate. Thus, this study allowed us to specify distinct
               influences of the high-level and low-level cognitive functions
               on instrumental learning, beyond the possibilities offered by
               simple RL models.",
  journal   = "Eur. J. Neurosci.",
  publisher = "Wiley Online Library",
  volume    =  35,
  number    =  7,
  pages     = "1024--1035",
  month     =  apr,
  year      =  2012,
  language  = "en",
  issn      = "0953-816X, 1460-9568",
  pmid      = "22487033",
  doi       = "10.1111/j.1460-9568.2011.07980.x",
  pmc       = "PMC3390186"
}

@ARTICLE{Huys2012-my,
  title     = "Bonsai trees in your head: how the pavlovian system sculpts
               goal-directed choices by pruning decision trees",
  author    = "Huys, Quentin J M and Eshel, Neir and O'Nions, Elizabeth and
               Sheridan, Luke and Dayan, Peter and Roiser, Jonathan P",
  abstract  = "When planning a series of actions, it is usually infeasible to
               consider all potential future sequences; instead, one must prune
               the decision tree. Provably optimal pruning is, however, still
               computationally ruinous and the specific approximations humans
               employ remain unknown. We designed a new sequential
               reinforcement-based task and showed that human subjects adopted
               a simple pruning strategy: during mental evaluation of a
               sequence of choices, they curtailed any further evaluation of a
               sequence as soon as they encountered a large loss. This pruning
               strategy was Pavlovian: it was reflexively evoked by large
               losses and persisted even when overwhelmingly counterproductive.
               It was also evident above and beyond loss aversion. We found
               that the tendency towards Pavlovian pruning was selectively
               predicted by the degree to which subjects exhibited sub-clinical
               mood disturbance, in accordance with theories that ascribe
               Pavlovian behavioural inhibition, via serotonin, a role in mood
               disorders. We conclude that Pavlovian behavioural inhibition
               shapes highly flexible, goal-directed choices in a manner that
               may be important for theories of decision-making in mood
               disorders.",
  journal   = "PLoS Comput. Biol.",
  publisher = "journals.plos.org",
  volume    =  8,
  number    =  3,
  pages     = "e1002410",
  month     =  mar,
  year      =  2012,
  language  = "en",
  issn      = "1553-734X, 1553-7358",
  pmid      = "22412360",
  doi       = "10.1371/journal.pcbi.1002410",
  pmc       = "PMC3297555"
}

@ARTICLE{Havenith2019-st,
  title    = "The {Virtual-Environment-Foraging} Task enables rapid training
              and single-trial metrics of rule acquisition and reversal in
              head-fixed mice",
  author   = "Havenith, Martha N and Zijderveld, Peter M and van Heukelum,
              Sabrina and Abghari, Shaghayegh and Tiesinga, Paul and Glennon,
              Jeffrey C",
  abstract = "Behavioural flexibility is an essential survival skill, yet our
              understanding of its neuronal substrates is still limited. While
              mouse research offers unique tools to dissect the neuronal
              circuits involved, the measurement of flexible behaviour in mice
              often suffers from long training times, poor experimental
              control, and temporally imprecise binary (hit/miss) performance
              readouts. Here we present a virtual-environment task for mice
              that tackles these limitations. It offers fast training of
              vision-based rule reversals (~100 trials per reversal) with full
              stimulus control and continuous behavioural readouts. By
              generating multiple non-binary performance metrics per trial, it
              provides single-trial estimates not only of response accuracy and
              speed, but also of underlying processes like choice certainty and
              alertness (discussed in detail in a companion paper). Based on
              these metrics, we show that mice can predict new task rules long
              before they are able to execute them, and that this delay varies
              across animals. We also provide and validate single-trial
              estimates of whether an error was committed with or without
              awareness of the task rule. By tracking in unprecedented detail
              the cognitive dynamics underlying flexible behaviour, this task
              enables new investigations into the neuronal interactions that
              shape behavioural flexibility moment by moment.",
  journal  = "Sci. Rep.",
  volume   =  9,
  number   =  1,
  pages    = "4790",
  month    =  mar,
  year     =  2019,
  language = "en",
  issn     = "2045-2322",
  pmid     = "30886236",
  doi      = "10.1038/s41598-019-41250-w"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Friston2012-rd,
  title     = "The history of the future of the Bayesian brain",
  author    = "Friston, Karl",
  abstract  = "The slight perversion of the original title of this piece (The
               Future of the Bayesian Brain ) reflects my attempt to write
               prospectively about 'Science and Stories' over the past 20
               years. I will meet this challenge by dealing with the future and
               then turning to its history. The future of …",
  journal   = "Neuroimage",
  publisher = "Elsevier",
  volume    =  62,
  number    =  2,
  pages     = "1230--1233",
  year      =  2012,
  issn      = "1053-8119"
}

@ARTICLE{Knill2004-uu,
  title    = "The Bayesian brain: the role of uncertainty in neural coding and
              computation",
  author   = "Knill, David C and Pouget, Alexandre",
  abstract = "To use sensory information efficiently to make judgments and
              guide action in the world, the brain must represent and use
              information about uncertainty in its computations for perception
              and action. Bayesian methods have proven successful in building
              computational theories for perception and sensorimotor control,
              and psychophysics is providing a growing body of evidence that
              human perceptual computations are ``Bayes' optimal''. This leads
              to the ``Bayesian coding hypothesis'': that the brain represents
              sensory information probabilistically, in the form of probability
              distributions. Several computational schemes have recently been
              proposed for how this might be achieved in populations of
              neurons. Neurophysiological data on the hypothesis, however, is
              almost non-existent. A major challenge for neuroscientists is to
              test these ideas experimentally, and so determine whether and how
              neurons code information about sensory uncertainty.",
  journal  = "Trends Neurosci.",
  volume   =  27,
  number   =  12,
  pages    = "712--719",
  month    =  dec,
  year     =  2004,
  language = "en",
  issn     = "0166-2236",
  pmid     = "15541511",
  doi      = "10.1016/j.tins.2004.10.007"
}

@BOOK{Kenji_Doya_Shin_Ishii_Alexandre_Pouget_Rajesh_P_N_Rao2006-pc,
  title     = "Bayesian Brain, Probabilistic approaches to neural coding",
  author    = "{Kenji Doya, Shin Ishii, Alexandre Pouget, Rajesh P. N. Rao}",
  publisher = "MIT press",
  year      =  2006,
  keywords  = "books"
}

@ARTICLE{Schmidt2019-gu,
  title    = "Disrupting the medial Prefrontal Cortex Alters Hippocampal
              Sequences during Deliberative {Decision-Making}",
  author   = "Schmidt, Brandy and Duin, Anneke A and Redish, A David",
  abstract = "Current theories of deliberative decision-making suggest that
              deliberative decisions arise from imagined simulations that
              require interactions between the prefrontal cortex and
              hippocampus. In rodent navigation experiments, hippocampal theta
              sequences advance from the location of the rat ahead to the
              subsequent goal. In order to examine the role of the medial
              prefrontal cortex (mPFC) on the hippocampus, we disrupted the
              mPFC with DREADDs (Designer Receptors Exclusively Activated by
              Designer Drugs). Using the Restaurant Row foraging task, we found
              that mPFC disruption resulted in decreased vicarious trial and
              error (VTE) behavior, reduced the number of theta sequences, and
              impaired theta sequences in hippocampus. mPFC disruption led to
              larger changes in the initiation of the hippocampal theta
              sequences that represent the current location of the rat rather
              than to the later portions that represent the future outcomes.
              These data suggest that the mPFC likely provides an important
              component to the initiation of deliberative sequences, and
              provides support for an episodic-future thinking, working memory
              interpretation of deliberation.",
  journal  = "J. Neurophysiol.",
  month    =  mar,
  year     =  2019,
  keywords = "hippocampus; place cell; prelimbic cortex; theta; vicarious trial
              and error",
  language = "en",
  issn     = "0022-3077, 1522-1598",
  pmid     = "30892976",
  doi      = "10.1152/jn.00793.2018"
}

@BOOK{David_Marr2010-uf,
  title    = "Vision a computational investigation",
  author   = "{David\_Marr}",
  year     =  2010,
  keywords = "books"
}

@ARTICLE{Preston2013-qk,
  title     = "Interplay of hippocampus and prefrontal cortex in memory",
  author    = "Preston, Alison R and Eichenbaum, Howard",
  abstract  = "Recent studies on the hippocampus and the prefrontal cortex have
               considerably advanced our understanding of the distinct roles of
               these brain areas in the encoding and retrieval of memories, and
               of how they interact in the prolonged process by which new
               memories are consolidated into our permanent storehouse of
               knowledge. These studies have led to a new model of how the
               hippocampus forms and replays memories and how the prefrontal
               cortex engages representations of the meaningful contexts in
               which related memories occur, as well as how these areas
               interact during memory retrieval. Furthermore, they have
               provided new insights into how interactions between the
               hippocampus and prefrontal cortex support the assimilation of
               new memories into pre-existing networks of knowledge, called
               schemas, and how schemas are modified in this process as the
               foundation of memory consolidation.",
  journal   = "Curr. Biol.",
  publisher = "Elsevier",
  volume    =  23,
  number    =  17,
  pages     = "R764--73",
  month     =  sep,
  year      =  2013,
  language  = "en",
  issn      = "0960-9822, 1879-0445",
  pmid      = "24028960",
  doi       = "10.1016/j.cub.2013.05.041",
  pmc       = "PMC3789138"
}

@ARTICLE{Wang2015-ic,
  title     = "Covert rapid action-memory simulation ({CRAMS)}: A hypothesis of
               hippocampal--prefrontal interactions for adaptive behavior",
  author    = "Wang, Jane X and Cohen, Neal J and Voss, Joel L",
  abstract  = "Effective choices generally require memory, yet little is known
               regarding the cognitive or neural mechanisms that allow memory
               to influence choices. We outline a new framework proposing that
               covert memory processing of hippocampus interacts with
               action-generation processing of prefrontal cortex in order to
               arrive at optimal, memory-guided choices. Covert, rapid
               action-memory simulation (CRAMS) is proposed here as a framework
               for understanding cognitive and/or behavioral choices, whereby
               prefrontal--hippocampal interactions quickly provide multiple
               simulations of potential outcomes used to evaluate the set of
               possible choices. We hypothesize that this CRAMS process is
               automatic, obligatory, and covert, meaning that many cycles of
               action-memory simulation occur in response to choice conflict
               without an individual's necessary intention and generally
               without awareness of the simulations, leading to adaptive
               behavior with little perceived effort. CRAMS is thus distinct
               from influential proposals that adaptive memory-based behavior
               in humans requires consciously experienced memory-based
               construction of possible future scenarios and deliberate
               decisions among possible future constructions. CRAMS provides an
               account of why hippocampus has been shown to make critical
               contributions to the short-term control of behavior, and it
               motivates several new experimental approaches and hypotheses
               that could be used to better understand the ubiquitous role of
               prefrontal--hippocampal interactions in situations that require
               adaptively using memory to guide choices. Importantly, this
               framework provides a perspective that allows for testing
               decision-making mechanisms in a manner that translates well
               across human and nonhuman animal model systems.",
  journal   = "Neurobiol. Learn. Mem.",
  publisher = "Elsevier",
  volume    =  117,
  pages     = "22--33",
  month     =  jan,
  year      =  2015,
  keywords  = "Learning; Memory; Decision-making; Hippocampus; Prefrontal
               cortex; Simulation; Imagination; Adaptive function",
  issn      = "1074-7427",
  doi       = "10.1016/j.nlm.2014.04.003"
}

@ARTICLE{Janabi-Sharifi2000-tj,
  title    = "Discrete-time adaptive windowing for velocity estimation",
  author   = "Janabi-Sharifi, F and Hayward, V and -. J. Chen, C",
  abstract = "We present methods for velocity estimation from discrete and
              quantized position samples using adaptive windowing. Previous
              methods necessitate trade-offs between noise reduction, control
              delay, estimate accuracy, reliability, computational load,
              transient preservation, and difficulties with tuning. In
              contrast, a first-order adaptive windowing method is shown to be
              optimal in the sense that it minimizes the velocity error
              variance while maximizes the accuracy of the estimates, requiring
              no tradeoff. Variants of this method are also discussed. The
              effectiveness of the proposed technique is verified in simulation
              and by experiments on the control of a haptic device.",
  journal  = "IEEE Trans. Control Syst. Technol.",
  volume   =  8,
  number   =  6,
  pages    = "1003--1009",
  month    =  nov,
  year     =  2000,
  keywords = "haptic interfaces;velocity control;adaptive estimation;discrete
              time systems;filtering theory;optimisation;adaptive
              windowing;velocity estimation;discrete-time systems;control
              delay;haptic interface;optimisation;Delay estimation;Finite
              impulse response filter;Noise reduction;Haptic
              interfaces;Velocity control;Filtering;Finite difference
              methods;Intelligent robots;Machine intelligence;Size control",
  issn     = "1063-6536",
  doi      = "10.1109/87.880606"
}

@ARTICLE{Gatto2018-oi,
  title    = "Locomotion Control: Brainstem Circuits Satisfy the Need for Speed",
  author   = "Gatto, Graziana and Goulding, Martyn",
  abstract = "Three new and closely complementary studies have defined the
              architecture of the circuits underlying the descending control of
              locomotion, identifying neurons that drive fast motor responses
              and those that seem to be specialised for exploratory behaviors.",
  journal  = "Curr. Biol.",
  volume   =  28,
  number   =  6,
  pages    = "R256--R259",
  month    =  mar,
  year     =  2018,
  keywords = "Locomotion",
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "29558639",
  doi      = "10.1016/j.cub.2018.01.068",
  pmc      = "PMC5942195"
}

@MISC{Murphy_undated-zd,
  title    = "Machine Learning - A Probabilistic Perspective",
  author   = "{Murphy}",
  keywords = "books"
}

@ARTICLE{Mora2011-th,
  title     = "Are Biological Systems Poised at Criticality?",
  author    = "Mora, Thierry and Bialek, William",
  abstract  = "Many of life's most fascinating phenomena emerge from
               interactions among many elements---many amino acids determine
               the structure of a single protein, many genes determine the fate
               of a cell, many neurons are involved in shaping our thoughts and
               memories. Physicists have long hoped that these collective
               behaviors could be described using the ideas and methods of
               statistical mechanics. In the past few years, new, larger scale
               experiments have made it possible to construct statistical
               mechanics models of biological systems directly from real data.
               We review the surprising successes of this ``inverse'' approach,
               using examples from families of proteins, networks of neurons,
               and flocks of birds. Remarkably, in all these cases the models
               that emerge from the data are poised near a very special point
               in their parameter space---a critical point. This suggests there
               may be some deeper theoretical principle behind the behavior of
               these diverse systems.",
  journal   = "J. Stat. Phys.",
  publisher = "Springer",
  volume    =  144,
  number    =  2,
  pages     = "268--302",
  month     =  jul,
  year      =  2011,
  issn      = "0022-4715, 1572-9613",
  doi       = "10.1007/s10955-011-0229-4"
}

@ARTICLE{Nicolis1999-xi,
  title     = "Emerging patterns and food recruitment in ants: an analytical
               study",
  author    = "Nicolis, S C and Deneubourg, J L",
  abstract  = "A model of food recruitment by social insects accounting for the
               competition between trails in the presence of an arbitrary
               number of sources is developed and analysed in detail. Both the
               case of identical environmental characteristics and the case
               where one source and the corresponding trail are different from
               the others are considered. Different collective responses
               depending on the environmental conditions, and without change of
               individual behaviour, are shown to exist, associated with the
               possibility that the colony may be led to exploit one source or
               a group of sources preferentially. The full bifurcation diagram
               of steady-state solutions is constructed from which the dominant
               exploitation patterns are identified. The biological relevance
               of the results is discussed and suggestions are made for their
               experimental testing in connection with the recruitment behavior
               of species using trail recruitment. The same phenomenological
               model can be used for different trail-laying species since the
               predictions are generic and not restricted to a given species,
               except for the parameter values used. Copyright 1999 Academic
               Press.",
  journal   = "J. Theor. Biol.",
  publisher = "Elsevier",
  volume    =  198,
  number    =  4,
  pages     = "575--592",
  month     =  jun,
  year      =  1999,
  language  = "en",
  issn      = "0022-5193, 1095-8541",
  pmid      = "10373356",
  doi       = "10.1006/jtbi.1999.0934"
}

@UNPUBLISHED{Kay2019-yl,
  title    = "Regular cycling between representations of alternatives in the
              hippocampus",
  author   = "Kay, Kenneth and Chung, Jason E and Sosa, Marielena and Schor,
              Jonathan S and Karlsson, Mattias P and Larkin, Margaret C and
              Liu, Daniel F and Frank, Loren M",
  abstract = "Cognitive faculties such as imagination, planning, and
              decision-making require the ability to represent alternative
              scenarios. In animals, split-second decision-making implies that
              the brain can represent alternatives at a commensurate speed. Yet
              despite this insight, it has remained unknown whether there
              exists neural activity that can consistently represent
              alternatives in",
  journal  = "bioRxiv",
  pages    = "528976",
  month    =  jan,
  year     =  2019,
  language = "en",
  doi      = "10.1101/528976"
}

@ARTICLE{Czaczkes2013-tr,
  title    = "Ant foraging on complex trails: route learning and the role of
              trail pheromones in Lasius niger",
  author   = "Czaczkes, Tomer J and Gr{\"u}ter, Christoph and Ellis, Laura and
              Wood, Elizabeth and Ratnieks, Francis L W",
  abstract = "Ants are central place foragers and use multiple information
              sources to navigate between the nest and feeding sites.
              Individual ants rapidly learn a route, and often prioritize
              memory over pheromone trails when tested on a simple trail with a
              single bifurcation. However, in nature, ants often forage at
              locations that are reached via more complex routes with multiple
              trail bifurcations. Such routes may be more difficult to learn,
              and thus ants would benefit from additional information. We
              hypothesized that trail pheromones play a more significant role
              in ant foraging on complex routes, either by assisting in
              navigation or route learning or both. We studied Lasius niger
              workers foraging on a doubly bifurcating trail with four end
              points. Route learning was slower and errors greater on
              alternating (e.g. left-right) versus repeating routes (e.g.
              left-left), with error rates of 32 and 3\%, respectively.
              However, errors on alternating routes decreased by 30\% when
              trail pheromone was present. Trail pheromones also aid route
              learning, leading to reduced errors in subsequent journeys
              without pheromone. If an experienced forager makes an error when
              returning to a food source, it reacts by increasing pheromone
              deposition on the return journey. In addition, high levels of
              trail pheromone suppress further pheromone deposition. This
              negative feedback mechanism may act to conserve pheromone or to
              regulate recruitment. Taken together, these results demonstrate
              further complexity and sophistication in the foraging system of
              ant colonies, especially in the role of trail pheromones and
              their relationship with learning and the use of private
              information (memory) in a complex environment.",
  journal  = "J. Exp. Biol.",
  volume   =  216,
  number   = "Pt 2",
  pages    = "188--197",
  month    =  jan,
  year     =  2013,
  language = "en",
  issn     = "0022-0949, 1477-9145",
  pmid     = "22972897",
  doi      = "10.1242/jeb.076570"
}

@ARTICLE{Chen_undated-pv,
  title  = "Between-subject prediction reveals a shared representational
            geometry in the rodent hippocampus",
  author = "Chen, Hung-Tu and Manning, Jeremy R and van der Meer, Matthijs A A",
  doi    = "10.1101/2020.01.27.922062"
}

@UNPUBLISHED{Chalk2019-yt,
  title    = "Inferring the function performed by a recurrent neural network",
  author   = "Chalk, Matthew and Tkacik, Gasper and Marre, Olivier",
  abstract = "A central goal in systems neuroscience is to understand the
              functions performed by neural circuits. Previous top-down models
              addressed this question by comparing the behaviour of an ideal
              model circuit, optimised to perform a given function, with neural
              recordings. However, this requires guessing in advance what
              function is being performed, which may not be possible for many
              neural systems. Here, we propose an alternative approach that
              uses recorded neural responses to directly infer the function
              performed by a neural network. We assume that the goal of the
              network can be expressed via a reward function, which describes
              how desirable each state of the network is for carrying out a
              given objective. This allows us to frame the problem of
              optimising each neuron9s responses by viewing neurons as agents
              in a reinforcement learning (RL) paradigm; likewise the problem
              of inferring the reward function from the observed dynamics can
              be treated using inverse RL. Our framework encompasses previous
              influential theories of neural coding, such as efficient coding
              and attractor network models, as special cases, given specific
              choices of reward function. Finally, we can use the reward
              function inferred from recorded neural responses to make testable
              predictions about how the network dynamics will adapt depending
              on contextual changes, such as cell death and/or varying input
              statistics, so as to carry out the same underlying function with
              different constraints.",
  journal  = "bioRxiv",
  pages    = "598086",
  month    =  apr,
  year     =  2019,
  language = "en",
  doi      = "10.1101/598086"
}

@ARTICLE{Lynn2018-pf,
  title         = "The physics of brain network structure, function, and
                   control",
  author        = "Lynn, Christopher W and Bassett, Danielle S",
  abstract      = "The brain is a complex organ characterized by heterogeneous
                   patterns of structural connections supporting unparalleled
                   feats of cognition and a wide range of behaviors. New
                   noninvasive imaging techniques now allow these patterns to
                   be carefully and comprehensively mapped in individual humans
                   and animals. Yet, it remains a fundamental challenge to
                   understand how the brain's structural wiring supports
                   cognitive processes, with major implications for the
                   personalized treatment of mental health disorders. Here, we
                   review recent efforts to meet this challenge that draw on
                   intuitions, models, and theories from physics, spanning the
                   domains of statistical mechanics, information theory, and
                   dynamical systems and control. We begin by considering the
                   organizing principles of brain network architecture
                   instantiated in structural wiring under constraints of
                   symmetry, spatial embedding, and energy minimization. We
                   next consider models of brain network function that
                   stipulate how neural activity propagates along these
                   structural connections, producing the long-range
                   interactions and collective dynamics that support a rich
                   repertoire of system functions. Finally, we consider
                   perturbative experiments and models for brain network
                   control, which leverage the physics of signal transmission
                   along structural wires to infer intrinsic control processes
                   that support goal-directed behavior and to inform
                   stimulation-based therapies for neurological disease and
                   psychiatric disorders. Throughout, we highlight several open
                   questions in the physics of brain network structure,
                   function, and control that will require creative efforts
                   from physicists willing to brave the complexities of living
                   matter.",
  month         =  sep,
  year          =  2018,
  archivePrefix = "arXiv",
  eprint        = "1809.06441",
  primaryClass  = "q-bio.NC",
  arxivid       = "1809.06441"
}

@ARTICLE{Chersi2013-el,
  title     = "Mental imagery in the navigation domain: a computational model
               of sensory-motor simulation mechanisms",
  author    = "Chersi, Fabian and Donnarumma, Francesco and Pezzulo, Giovanni",
  abstract  = "Recent experimental evidence indicates that animals can use
               mental simulation to make decisions about the actions to take
               during goal-directed navigation. The principal brain areas found
               to be active during this process are the hippocampus, the
               ventral striatum and the sensory-motor cortex. In this paper, we
               present a computational model that includes biological aspects
               of this circuit and explains mechanistically how it may be used
               to imagine and evaluate future events. Its most salient
               characteristic is that choices about actions are made by
               simulating movements and their sensory effects using the same
               brain areas that are active during overt execution. More
               precisely, the simulation of an action (e.g., walking) creates a
               new sensory pattern that is evaluated in the same way as real
               inputs. The model is validated in a navigation task in which a
               simulated rat is placed in a complex maze. We show that
               hippocampal and striatal cells are activated to simulate paths,
               to retrieve their estimated value and to make decisions. We link
               these results with a general framework that sees the brain as a
               predictive device that can ?detach? itself from the here-and-now
               of current perception using mechanisms such as episodic
               memories, motor and visual imagery.",
  journal   = "Adapt. Behav.",
  publisher = "SAGE Publications Ltd STM",
  volume    =  21,
  number    =  4,
  pages     = "251--262",
  month     =  aug,
  year      =  2013,
  issn      = "1059-7123",
  doi       = "10.1177/1059712313488789"
}

@ARTICLE{Guazzelli1998-ub,
  title     = "Affordances. Motivations, and the World Graph Theory",
  author    = "Guazzelli, Alex and Bota, Mihail and Corbacho, Fernando J and
               Arbib, Michael A",
  abstract  = "O'Keefe and Nadel (1978) distinguish two paradigms for
               navigation, the ``locale system'' for map-based navigation and
               the ``taxon (behavioral orientation) system'' for route
               navigation. This article models the taxon system, the map-based
               system, and their interaction, and argues that the map-based
               system involves the interaction of hippocampus and other
               systems.We relate taxes to the notion of an affordance. Just as
               a rat may have basic taxes for approaching food or avoiding a
               bright light, so does it have a wider repertoire of affordances
               for possible actions associated with immediate sensing of its
               environment. We propose that affordances are extracted by the
               rat posterior parietal cortex, which guides action selection by
               the premotor cortex and is influenced also by hypothalamic drive
               information.The taxon-affordances model (TAM) for taxon-based
               determination of movement direction is based on models of frog
               detour behavior, with expectations of future reward implemented
               using reinforcement learning. The specification of the direction
               of movement is refined by current affordances and motivational
               information to yield an appropriate course of action.The world
               graph (WG) theory expands the idea of a map by developing the
               hypothesis that cognitive and motivational states interact. This
               article describes an implementation of this theory, the WG
               model. The integrated TAM-WG model then allows us to explain
               data on the behavior of rats with and without fornix lesions,
               which disconnect the hippocampus from other neural systems.",
  journal   = "Adapt. Behav.",
  publisher = "SAGE Publications Ltd STM",
  volume    =  6,
  number    = "3-4",
  pages     = "435--471",
  month     =  jan,
  year      =  1998,
  issn      = "1059-7123",
  doi       = "10.1177/105971239800600305"
}

@ARTICLE{Burton2015-am,
  title    = "From ventral-medial to dorsal-lateral striatum: neural correlates
              of reward-guided decision-making",
  author   = "Burton, Amanda C and Nakamura, Kae and Roesch, Matthew R",
  abstract = "The striatum is critical for reward-guided and habitual behavior.
              Anatomical and interference studies suggest a functional
              heterogeneity within striatum. Medial regions, such as nucleus
              accumbens core and dorsal medial striatum play roles in
              goal-directed behavior, while dorsal lateral striatum is critical
              for control of habitual action. Subdivisions of striatum are
              topographically connected with different cortical and subcortical
              structures forming channels that carry information related to
              limbic, associative, and sensorimotor functions. Here, we
              describe data showing that as one progresses from ventral-medial
              to dorsal-lateral striatum, there is a shift from more prominent
              value encoding to activity more closely related to associative
              and motor aspects of decision-making. In addition, we will
              describe data suggesting that striatal circuits work in parallel
              to control behavior and that regions within striatum can
              compensate for each other when functions are disrupted.",
  journal  = "Neurobiol. Learn. Mem.",
  volume   =  117,
  pages    = "51--59",
  month    =  jan,
  year     =  2015,
  keywords = "Goal; Habit; Monkey; Nucleus accumbens; Rat; Single unit;
              Striatum; Value",
  language = "en",
  issn     = "1074-7427, 1095-9564",
  pmid     = "24858182",
  doi      = "10.1016/j.nlm.2014.05.003",
  pmc      = "PMC4240773"
}

@INCOLLECTION{Choi2011-ua,
  title     = "{MAP} Inference for Bayesian Inverse Reinforcement Learning",
  booktitle = "Advances in Neural Information Processing Systems 24",
  author    = "Choi, Jaedeug and Kim, Kee-Eung",
  editor    = "Shawe-Taylor, J and Zemel, R S and Bartlett, P L and Pereira, F
               and Weinberger, K Q",
  publisher = "Curran Associates, Inc.",
  pages     = "1989--1997",
  year      =  2011
}

@ARTICLE{noauthor_undated-wn,
  title = "icml00-irl.pdf"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ramachandran2007-tz,
  title     = "Bayesian Inverse Reinforcement Learning",
  author    = "Ramachandran, D and Amir, E",
  abstract  = "Abstract Inverse Reinforcement Learning (IRL) is the problem of
               learning the reward function underlying a Markov Decision
               Process given the dynamics of the system and the behaviour of an
               expert. IRL is motivated by situations where knowledge of the
               rewards is a goal by …",
  journal   = "IJCAI",
  publisher = "aaai.org",
  year      =  2007,
  issn      = "1045-0823"
}

@ARTICLE{Dayan1993-rr,
  title     = "Improving Generalization for Temporal Difference Learning: The
               Successor Representation",
  author    = "Dayan, Peter",
  abstract  = "Estimation of returns over time, the focus of temporal
               difference (TD) algorithms, imposes particular constraints on
               good function approximators or representations. Appropriate
               generalization between states is determined by how similar their
               successors are, and representations should follow suit. This
               paper shows how TD machinery can be used to learn such
               representations, and illustrates, using a navigation task, the
               appropriately distributed nature of the result.",
  journal   = "Neural Comput.",
  publisher = "MIT Press",
  volume    =  5,
  number    =  4,
  pages     = "613--624",
  month     =  jul,
  year      =  1993,
  issn      = "0899-7667",
  doi       = "10.1162/neco.1993.5.4.613"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Dickinson1985-pt,
  title     = "Actions and habits: the development of behavioural autonomy",
  author    = "Dickinson, Anthony",
  abstract  = "The study of animal behaviour has been dominated by two general
               models. According to the mechanistic stimulus-response model, a
               particular behaviour is either an innate or an acquired habit
               which is simply triggered by the appropriate stimulus. By
               contrast, the teleological model argues that, at least, some
               activities are purposive actions controlled by the current value
               of their goals through knowledge about the instrumental
               relations between the actions and their consequences. The type
               of control over any particular behaviour can …",
  journal   = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  publisher = "The Royal Society London",
  volume    =  308,
  number    =  1135,
  pages     = "67--78",
  year      =  1985,
  issn      = "0962-8436"
}

@ARTICLE{Dickinson1994-td,
  title     = "Motivational control of goal-directed action",
  author    = "Dickinson, Anthony and Balleine, Bernard",
  abstract  = "The control of goal-directed, instrumental actions by primary
               motivational states, such as hunger and thirst, is mediated by
               two processes. The first is engaged by the Pavlovian association
               between contextual or discriminative stimuli and the outcome or
               reinforcer presented during instrumental training. Such stimuli
               exert a motivational influence on instrumental performance that
               depends upon the relevance of the associated outcome to the
               current motivational state of the agent. Moreover, the
               motivational effects of these stimuli operate in the absence of
               prior experience with the outcome under the relevant
               motivational state. The second, instrumental, process is
               mediated by knowledge of the contingency between the action and
               its outcome and controls the value assigned to this outcome. In
               contrast to the Pavlovian process, motivational states do not
               influence the instrumental process directly; rather, the agent
               has to learn about the value of an outcome in a given
               motivational state by exposure to it while in that state. This
               incentive learning is similar in certain respects to the
               acquisition of ``cathexes'' envisaged by Tolman (1949a, 1949b).",
  journal   = "Anim. Learn. Behav.",
  publisher = "Springer",
  volume    =  22,
  number    =  1,
  pages     = "1--18",
  month     =  mar,
  year      =  1994,
  issn      = "0090-4996, 1532-5830",
  doi       = "10.3758/BF03199951"
}

@MISC{noauthor_undated-il,
  title    = "Numerical Linear Algebra",
  keywords = "books"
}

@ARTICLE{Van_der_Meer2010-ed,
  title     = "Expectancies in decision making, reinforcement learning, and
               ventral striatum",
  author    = "van der Meer, Matthijs A A and Redish, A David",
  abstract  = "Decisions can arise in different ways, such as from a gut
               feeling, doing what worked last time, or planful deliberation.
               Different decision-making systems are dissociable behaviorally,
               map onto distinct brain systems, and have different
               computational demands. For instance, ``model-free'' decision
               strategies use prediction errors to estimate scalar action
               values from previous experience, while ``model-based''
               strategies leverage internal forward models to generate and
               evaluate potentially rich outcome expectancies. Animal learning
               studies indicate that expectancies may arise from different
               sources, including not only forward models but also Pavlovian
               associations, and the flexibility with which such
               representations impact behavior may depend on how they are
               generated. In the light of these considerations, we review the
               results of van der Meer and Redish (2009a), who found that
               ventral striatal neurons that respond to reward delivery can
               also be activated at other points, notably at a decision point
               where hippocampal forward representations were also observed.
               These data suggest the possibility that ventral striatal reward
               representations contribute to model-based expectancies used in
               deliberative decision making.",
  journal   = "Front. Neurosci.",
  publisher = "frontiersin.org",
  volume    =  4,
  pages     = "6",
  month     =  may,
  year      =  2010,
  keywords  = "Pavlovian-instrumental transfer; actor--critic; planning;
               reinforcement learning; reward",
  language  = "en",
  issn      = "1662-4548, 1662-453X",
  pmid      = "21221409",
  doi       = "10.3389/neuro.01.006.2010",
  pmc       = "PMC2891485"
}

@ARTICLE{Papale2016-ml,
  title     = "Interplay between Hippocampal {Sharp-Wave-Ripple} Events and
               Vicarious Trial and Error Behaviors in Decision Making",
  author    = "Papale, Andrew E and Zielinski, Mark C and Frank, Loren M and
               Jadhav, Shantanu P and Redish, A David",
  abstract  = "Current theories posit that memories encoded during experiences
               are subsequently consolidated into longer-term storage.
               Hippocampal sharp-wave-ripple (SWR) events have been linked to
               this consolidation process during sleep, but SWRs also occur
               during awake immobility, where their role remains unclear. We
               report that awake SWR rates at the reward site are inversely
               related to the prevalence of vicarious trial and error (VTE)
               behaviors, thought to be involved in deliberation processes. SWR
               rates were diminished immediately after VTE behaviors and an
               increase in the rate of SWR events at the reward site predicted
               a decrease in subsequent VTE behaviors at the choice point.
               Furthermore, SWR disruptions increased VTE behaviors. These
               results suggest an inverse relationship between SWRs and VTE
               behaviors and suggest that awake SWRs and associated planning
               and memory consolidation mechanisms are engaged specifically in
               the context of higher levels of behavioral certainty.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  92,
  number    =  5,
  pages     = "975--982",
  month     =  dec,
  year      =  2016,
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "27866796",
  doi       = "10.1016/j.neuron.2016.10.028",
  pmc       = "PMC5145752"
}

@ARTICLE{Lee2014-ji,
  title     = "Neural computations underlying arbitration between model-based
               and model-free learning",
  author    = "Lee, Sang Wan and Shimojo, Shinsuke and O'Doherty, John P",
  abstract  = "There is accumulating neural evidence to support the existence
               of two distinct systems for guiding action selection, a
               deliberative ``model-based'' and a reflexive ``model-free''
               system. However, little is known about how the brain determines
               which of these systems controls behavior at one moment in time.
               We provide evidence for an arbitration mechanism that allocates
               the degree of control over behavior by model-based and
               model-free systems as a function of the reliability of their
               respective predictions. We show that the inferior lateral
               prefrontal and frontopolar cortex encode both reliability
               signals and the output of a comparison between those signals,
               implicating these regions in the arbitration process. Moreover,
               connectivity between these regions and model-free valuation
               areas is negatively modulated by the degree of model-based
               control in the arbitrator, suggesting that arbitration may work
               through modulation of the model-free valuation system when the
               arbitrator deems that the model-based system should drive
               behavior.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  81,
  number    =  3,
  pages     = "687--699",
  month     =  feb,
  year      =  2014,
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "24507199",
  doi       = "10.1016/j.neuron.2013.11.028",
  pmc       = "PMC3968946"
}

@ARTICLE{Joel2002-xo,
  title     = "Actor--critic models of the basal ganglia: new anatomical and
               computational perspectives",
  author    = "Joel, Daphna and Niv, Yael and Ruppin, Eytan",
  abstract  = "A large number of computational models of information processing
               in the basal ganglia have been developed in recent years.
               Prominent in these are actor--critic models of basal ganglia
               functioning, which build on the strong resemblance between
               dopamine neuron activity and the temporal difference prediction
               error signal in the critic, and between dopamine-dependent
               long-term synaptic plasticity in the striatum and learning
               guided by a prediction error signal in the actor. We selectively
               review several actor--critic models of the basal ganglia with an
               emphasis on two important aspects: the way in which models of
               the critic reproduce the temporal dynamics of dopamine firing,
               and the extent to which models of the actor take into account
               known basal ganglia anatomy and physiology. To complement the
               efforts to relate basal ganglia mechanisms to reinforcement
               learning (RL), we introduce an alternative approach to modeling
               a critic network, which uses Evolutionary Computation techniques
               to `evolve' an optimal RL mechanism, and relate the evolved
               mechanism to the basic model of the critic. We conclude our
               discussion of models of the critic by a critical discussion of
               the anatomical plausibility of implementations of a critic in
               basal ganglia circuitry, and conclude that such implementations
               build on assumptions that are inconsistent with the known
               anatomy of the basal ganglia. We return to the actor component
               of the actor--critic model, which is usually modeled at the
               striatal level with very little detail. We describe an
               alternative model of the basal ganglia which takes into account
               several important, and previously neglected, anatomical and
               physiological characteristics of basal ganglia--thalamocortical
               connectivity and suggests that the basal ganglia performs
               reinforcement-biased dimensionality reduction of cortical
               inputs. We further suggest that since such selective encoding
               may bias the representation at the level of the frontal cortex
               towards the selection of rewarded plans and actions, the
               reinforcement-driven dimensionality reduction framework may
               serve as a basis for basal ganglia actor models. We conclude
               with a short discussion of the dual role of the dopamine signal
               in RL and in behavioral switching.",
  journal   = "Neural Netw.",
  publisher = "Elsevier",
  volume    =  15,
  number    =  4,
  pages     = "535--547",
  month     =  jun,
  year      =  2002,
  keywords  = "Basal ganglia; Dopamine; Reinforcement learning; Actor--critic;
               Dimensionality reduction; Evolutionary computation; Behavioral
               switching; Striosomes/patches",
  issn      = "0893-6080",
  doi       = "10.1016/S0893-6080(02)00047-3"
}

@ARTICLE{Khamassi2005-rl,
  title     = "{Actor--Critic} Models of Reinforcement Learning in the Basal
               Ganglia: From Natural to Artificial Rats",
  author    = "Khamassi, Mehdi and Lach{\`e}ze, Lo{\"\i}c and Girard,
               Beno{\^\i}t and Berthoz, Alain and Guillot, Agn{\`e}s",
  abstract  = "Since 1995, numerous Actor?Critic architectures for
               reinforcement learning have been proposed as models of
               dopamine-like reinforcement learning mechanisms in the rat?s
               basal ganglia. However, these models were usually tested in
               different tasks, and it is then difficult to compare their
               efficiency for an autonomous animat. We present here the
               comparison of four architectures in an animat as it per forms
               the same reward-seeking task. This will illustrate the
               consequences of different hypotheses about the management of
               different Actor sub-modules and Critic units, and their more or
               less autono mously determined coordination. We show that the
               classical method of coordination of modules by mixture of
               experts, depending on each module?s performance, did not allow
               solving our task. Then we address the question of which
               principle should be applied efficiently to combine these units.
               Improve ments for Critic modeling and accuracy of Actor?Critic
               models for a natural task are finally discussed in the
               perspective of our Psikharpax project?an artificial rat having
               to survive autonomously in unpre dictable environments.",
  journal   = "Adapt. Behav.",
  publisher = "SAGE Publications Ltd STM",
  volume    =  13,
  number    =  2,
  pages     = "131--148",
  month     =  jun,
  year      =  2005,
  issn      = "1059-7123",
  doi       = "10.1177/105971230501300205"
}

@ARTICLE{Louie2014-lo,
  title     = "Dynamic divisive normalization predicts time-varying value
               coding in decision-related circuits",
  author    = "Louie, Kenway and LoFaro, Thomas and Webb, Ryan and Glimcher,
               Paul W",
  abstract  = "Normalization is a widespread neural computation, mediating
               divisive gain control in sensory processing and implementing a
               context-dependent value code in decision-related frontal and
               parietal cortices. Although decision-making is a dynamic process
               with complex temporal characteristics, most models of
               normalization are time-independent and little is known about the
               dynamic interaction of normalization and choice. Here, we show
               that a simple differential equation model of normalization
               explains the characteristic phasic-sustained pattern of cortical
               decision activity and predicts specific normalization dynamics:
               value coding during initial transients, time-varying value
               modulation, and delayed onset of contextual information.
               Empirically, we observe these predicted dynamics in
               saccade-related neurons in monkey lateral intraparietal cortex.
               Furthermore, such models naturally incorporate a time-weighted
               average of past activity, implementing an intrinsic
               reference-dependence in value coding. These results suggest that
               a single network mechanism can explain both transient and
               sustained decision activity, emphasizing the importance of a
               dynamic view of normalization in neural coding.",
  journal   = "J. Neurosci.",
  publisher = "Soc Neuroscience",
  volume    =  34,
  number    =  48,
  pages     = "16046--16057",
  month     =  nov,
  year      =  2014,
  keywords  = "computational modeling; decision-making; divisive normalization;
               dynamical system; reward",
  language  = "en",
  issn      = "0270-6474, 1529-2401",
  pmid      = "25429145",
  doi       = "10.1523/JNEUROSCI.2851-14.2014",
  pmc       = "PMC4244470"
}

@ARTICLE{Churchland2008-av,
  title     = "Decision-making with multiple alternatives",
  author    = "Churchland, Anne K and Kiani, Roozbeh and Shadlen, Michael N",
  abstract  = "Simple perceptual tasks have laid the groundwork for
               understanding the neurobiology of decision-making. Here, we
               examined this foundation to explain how decision-making
               circuitry adjusts in the face of a more difficult task. We
               measured behavioral and physiological responses of monkeys on a
               two- and four-choice direction-discrimination decision task. For
               both tasks, firing rates in the lateral intraparietal area
               appeared to reflect the accumulation of evidence for or against
               each choice. Evidence accumulation began at a lower firing rate
               for the four-choice task, but reached a common level by the end
               of the decision process. The larger excursion suggests that the
               subjects required more evidence before making a choice.
               Furthermore, on both tasks, we observed a time-dependent rise in
               firing rates that may impose a deadline for deciding. These
               physiological observations constitute an effective strategy for
               handling increased task difficulty. The differences appear to
               explain subjects' accuracy and reaction times.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  11,
  number    =  6,
  pages     = "693--702",
  month     =  jun,
  year      =  2008,
  language  = "en",
  issn      = "1097-6256",
  pmid      = "18488024",
  doi       = "10.1038/nn.2123",
  pmc       = "PMC2453226"
}

@ARTICLE{Lintz2019-sx,
  title    = "Spatial Representations in the Superior Colliculus Are Modulated
              by Competition among Targets",
  author   = "Lintz, Mario J and Essig, Jaclyn and Zylberberg, Joel and Felsen,
              Gidon",
  abstract = "Selecting and moving to spatial targets are critical components
              of goal-directed behavior, yet their neural bases are not well
              understood. The superior colliculus (SC) is thought to contain a
              topographic map of contralateral space in which the activity of
              specific neuronal populations corresponds to particular spatial
              locations. However, these spatial representations are modulated
              by several decision-related variables, suggesting that they
              reflect information beyond simply the location of an upcoming
              movement. Here, we examine the extent to which these
              representations arise from competitive spatial choice. We
              recorded SC activity in male mice performing a behavioral task
              requiring orienting movements to targets for a water reward in
              two contexts. In ``competitive'' trials, either the left or right
              target could be rewarded, depending on which stimulus was
              presented at the central port. In ``noncompetitive'' trials, the
              same target (e.g., left) was rewarded throughout an entire block.
              While both trial types required orienting movements to the same
              spatial targets, only in competitive trials do targets compete
              for selection. We found that in competitive trials, pre-movement
              SC activity predicted movement to contralateral targets, as
              expected. However, in noncompetitive trials, some neurons lost
              their spatial selectivity and in others activity predicted
              movement to ipsilateral targets. Consistent with these findings,
              unilateral optogenetic inactivation of pre-movement SC activity
              ipsiversively biased competitive, but not noncompetitive, trials.
              Incorporating these results into an attractor model of SC
              activity points to distinct pathways for orienting movements
              under competitive and noncompetitive conditions, with the SC
              specifically required for selecting among multiple potential
              targets.",
  journal  = "Neuroscience",
  month    =  apr,
  year     =  2019,
  keywords = "Superior colliculus; decision making; freely-moving mice; target
              selection",
  language = "en",
  issn     = "0306-4522, 1873-7544",
  pmid     = "30981865",
  doi      = "10.1016/j.neuroscience.2019.04.002"
}

@ARTICLE{Jiang2019-in,
  title    = "{Short-Term} Influence of Recent Trial History on Perceptual
              Choice Changes with Stimulus Strength",
  author   = "Jiang, Weiqian and Liu, Jing and Zhang, Dinghong and Xie, Taorong
              and Yao, Haishan",
  abstract = "Perceptual decisions, especially for difficult stimuli, can be
              influenced by choices and outcomes in previous trials. However,
              it is not well understood how stimulus strength modulates the
              temporal characteristics as well as the magnitude of trial
              history influence. We addressed this question using a contrast
              detection task in freely moving mice. We found that, at lower as
              compared to higher stimulus contrast, the current choice of the
              mice was more influenced by choices and outcomes in the past
              trials and the influence emerged from a longer history. To
              examine the neural basis of stimulus strength-dependent history
              influence, we recorded from the secondary motor cortex (M2), a
              prefrontal region that plays an important role in cue-guided
              actions and memory-guided behaviors. We found that more M2
              neurons conveyed information about choices on the past two trials
              at lower than at higher contrast. Furthermore, history-trial
              activity in M2 was important for decoding upcoming choice at low
              contrast. Thus, trial history influence of perceptual choice is
              adaptive to the strength of sensory evidence, which may be
              important for action selection in a dynamic environment.",
  journal  = "Neuroscience",
  month    =  apr,
  year     =  2019,
  keywords = "choice history; contrast; decision making; rodent; secondary
              motor cortex",
  language = "en",
  issn     = "0306-4522, 1873-7544",
  pmid     = "30986438",
  doi      = "10.1016/j.neuroscience.2019.04.010"
}

@ARTICLE{Dayan2008-jq,
  title     = "Decision theory, reinforcement learning, and the brain",
  author    = "Dayan, Peter and Daw, Nathaniel D",
  abstract  = "Decision making is a core competence for animals and humans
               acting and surviving in environments they only partially
               comprehend, gaining rewards and punishments for their troubles.
               Decision-theoretic concepts permeate experiments and
               computational models in ethology, psychology, and neuroscience.
               Here, we review a well-known, coherent Bayesian approach to
               decision making, showing how it unifies issues in Markovian
               decision problems, signal detection psychophysics, sequential
               sampling, and optimal exploration and discuss paradigmatic
               psychological and neural examples of each problem. We discuss
               computational issues concerning what subjects know about their
               task and how ambitious they are in seeking optimal solutions; we
               address algorithmic topics concerning model-based and model-free
               methods for making choices; and we highlight key aspects of the
               neural implementation of decision making.",
  journal   = "Cogn. Affect. Behav. Neurosci.",
  publisher = "Springer",
  volume    =  8,
  number    =  4,
  pages     = "429--453",
  month     =  dec,
  year      =  2008,
  language  = "en",
  issn      = "1530-7026",
  pmid      = "19033240",
  doi       = "10.3758/CABN.8.4.429"
}

@ARTICLE{Gottlieb2018-jh,
  title     = "Towards a neuroscience of active sampling and curiosity",
  author    = "Gottlieb, Jacqueline and Oudeyer, Pierre-Yves",
  abstract  = "In natural behaviour, animals actively interrogate their
               environments using endogenously generated 'question-and-answer'
               strategies. However, in laboratory settings participants
               typically engage with externally imposed stimuli and tasks, and
               the mechanisms of active sampling remain poorly understood. We
               review a nascent neuroscientific literature that examines
               active-sampling policies and their relation to attention and
               curiosity. We distinguish between information sampling, in which
               organisms reduce uncertainty relevant to a familiar task, and
               information search, in which they investigate in an open-ended
               fashion to discover new tasks. We review evidence that both
               sampling and search depend on individual preferences over
               cognitive states, including attitudes towards uncertainty,
               learning progress and types of information. We propose that,
               although these preferences are non-instrumental and can on
               occasion interfere with external goals, they are important
               heuristics that allow organisms to cope with the high complexity
               of both sampling and search, and generate curiosity-driven
               investigations in large, open environments in which rewards are
               sparse and ex ante unknown.",
  journal   = "Nat. Rev. Neurosci.",
  publisher = "nature.com",
  volume    =  19,
  number    =  12,
  pages     = "758--770",
  month     =  dec,
  year      =  2018,
  language  = "en",
  issn      = "1471-003X, 1471-0048",
  pmid      = "30397322",
  doi       = "10.1038/s41583-018-0078-0"
}

@ARTICLE{Berridge2004-eo,
  title     = "Motivation concepts in behavioral neuroscience",
  author    = "Berridge, Kent C",
  abstract  = "Concepts of motivation are vital to progress in behavioral
               neuroscience. Motivational concepts help us to understand what
               limbic brain systems are chiefly evolved to do, i.e., to mediate
               psychological processes that guide real behavior. This article
               evaluates some major motivation concepts that have historic
               importance or have influenced the interpretation of behavioral
               neuroscience research. These concepts include homeostasis,
               setpoints and settling points, intervening variables, hydraulic
               drives, drive reduction, appetitive and consummatory behavior,
               opponent processes, hedonic reactions, incentive motivation,
               drive centers, dedicated drive neurons (and drive neuropeptides
               and receptors), neural hierarchies, and new concepts from
               affective neuroscience such as allostasis, cognitive incentives,
               and reward 'liking' versus 'wanting'.",
  journal   = "Physiol. Behav.",
  publisher = "Elsevier",
  volume    =  81,
  number    =  2,
  pages     = "179--209",
  month     =  apr,
  year      =  2004,
  language  = "en",
  issn      = "0031-9384",
  pmid      = "15159167",
  doi       = "10.1016/j.physbeh.2004.02.004"
}

@UNPUBLISHED{Pisupati2019-mc,
  title    = "Lapses in perceptual judgments reflect exploration",
  author   = "Pisupati, Sashank and Chartarifsky-Lynn, Lital and Khanal, Anup
              and Churchland, Anne K",
  abstract = "During perceptual decision making, subjects often display a
              constant rate of errors independent of evidence strength,
              referred to as lapses. Their proper treatment is crucial for
              accurate estimation of perceptual parameters, however they are
              often treated as a nuisance arising from motor errors or
              inattention. Here, we propose that lapses can instead reflect a
              dynamic form of exploration. We demonstrate that perceptual
              uncertainty modulates the probability of lapses both across and
              within modalities on a multisensory discrimination task in rats.
              These effects cannot be accounted for by inattention or motor
              error, however they are concisely explained by uncertainty-guided
              exploration. We confirm the predictions of the exploration model
              by showing that changing the magnitude or probability of reward
              associated with one of the decisions selectively affects the
              lapses associated with that decision in uncertain conditions,
              while leaving sure-bet decisions unchanged, as predicted by the
              model. Finally, we demonstrate that muscimol inactivations of
              secondary motor cortex and posterior striatum affect lapses
              asymmetrically across modalities. The inactivations can be
              captured by a devaluation of actions corresponding to the
              inactivated side, and do not affect sure-bet decisions. Together,
              our results suggest that far from being a nuisance, lapses are
              informative about subjects9 action values, and deficits thereof,
              during perceptual decisions.",
  journal  = "bioRxiv",
  pages    = "613828",
  month    =  apr,
  year     =  2019,
  language = "en",
  doi      = "10.1101/613828"
}

@ARTICLE{Doya2008-qf,
  title    = "Modulators of decision making",
  author   = "Doya, Kenji",
  abstract = "Human and animal decisions are modulated by a variety of
              environmental and intrinsic contexts. Here I consider
              computational factors that can affect decision making and review
              anatomical structures and neurochemical systems that are related
              to contextual modulation of decision making. Expectation of a
              high reward can motivate a subject to go for an action despite a
              large cost, a decision that is influenced by dopamine in the
              anterior cingulate cortex. Uncertainty of action outcomes can
              promote risk taking and exploratory choices, in which
              norepinephrine and the orbitofrontal cortex appear to be
              involved. Predictable environments should facilitate
              consideration of longer-delayed rewards, which depends on
              serotonin in the dorsal striatum and dorsal prefrontal cortex.
              This article aims to sort out factors that affect the process of
              decision making from the viewpoint of reinforcement learning
              theory and to bridge between such computational needs and their
              neurophysiological substrates.",
  journal  = "Nat. Neurosci.",
  volume   =  11,
  number   =  4,
  pages    = "410--416",
  month    =  apr,
  year     =  2008,
  language = "en",
  issn     = "1097-6256",
  pmid     = "18368048",
  doi      = "10.1038/nn2077"
}

@ARTICLE{Solway2012-bf,
  title     = "Goal-directed decision making as probabilistic inference: a
               computational framework and potential neural correlates",
  author    = "Solway, Alec and Botvinick, Matthew M",
  abstract  = "Recent work has given rise to the view that reward-based
               decision making is governed by two key controllers: a habit
               system, which stores stimulus-response associations shaped by
               past reward, and a goal-oriented system that selects actions
               based on their anticipated outcomes. The current literature
               provides a rich body of computational theory addressing habit
               formation, centering on temporal-difference learning mechanisms.
               Less progress has been made toward formalizing the processes
               involved in goal-directed decision making. We draw on recent
               work in cognitive neuroscience, animal conditioning, cognitive
               and developmental psychology, and machine learning to outline a
               new theory of goal-directed decision making. Our basic proposal
               is that the brain, within an identifiable network of cortical
               and subcortical structures, implements a probabilistic
               generative model of reward, and that goal-directed decision
               making is effected through Bayesian inversion of this model. We
               present a set of simulations implementing the account, which
               address benchmark behavioral and neuroscientific findings, and
               give rise to a set of testable predictions. We also discuss the
               relationship between the proposed framework and other models of
               decision making, including recent models of perceptual choice,
               to which our theory bears a direct connection.",
  journal   = "Psychol. Rev.",
  publisher = "psycnet.apa.org",
  volume    =  119,
  number    =  1,
  pages     = "120--154",
  month     =  jan,
  year      =  2012,
  language  = "en",
  issn      = "0033-295X, 1939-1471",
  pmid      = "22229491",
  doi       = "10.1037/a0026435",
  pmc       = "PMC3767755"
}

@ARTICLE{Frank2006-an,
  title    = "Hold your horses: a dynamic computational role for the
              subthalamic nucleus in decision making",
  author   = "Frank, Michael J",
  abstract = "The basal ganglia (BG) coordinate decision making processes by
              facilitating adaptive frontal motor commands while suppressing
              others. In previous work, neural network simulations accounted
              for response selection deficits associated with BG dopamine
              depletion in Parkinson's disease. Novel predictions from this
              model have been subsequently confirmed in Parkinson patients and
              in healthy participants under pharmacological challenge.
              Nevertheless, one clear limitation of that model is in its
              omission of the subthalamic nucleus (STN), a key BG structure
              that participates in both motor and cognitive processes. The
              present model incorporates the STN and shows that by modulating
              when a response is executed, the STN reduces premature responding
              and therefore has substantial effects on which response is
              ultimately selected, particularly when there are multiple
              competing responses. Increased cortical response conflict leads
              to dynamic adjustments in response thresholds via
              cortico-subthalamic-pallidal pathways. The model accurately
              captures the dynamics of activity in various BG areas during
              response selection. Simulated dopamine depletion results in
              emergent oscillatory activity in BG structures, which has been
              linked with Parkinson's tremor. Finally, the model accounts for
              the beneficial effects of STN lesions on these oscillations, but
              suggests that this benefit may come at the expense of impaired
              decision making.",
  journal  = "Neural Netw.",
  volume   =  19,
  number   =  8,
  pages    = "1120--1136",
  month    =  oct,
  year     =  2006,
  language = "en",
  issn     = "0893-6080",
  pmid     = "16945502",
  doi      = "10.1016/j.neunet.2006.03.006"
}

@ARTICLE{Clark2004-oz,
  title    = "The neuropsychology of ventral prefrontal cortex: decision-making
              and reversal learning",
  author   = "Clark, L and Cools, R and Robbins, T W",
  abstract = "Converging evidence from human lesion, animal lesion, and human
              functional neuroimaging studies implicates overlapping neural
              circuitry in ventral prefrontal cortex in decision-making and
              reversal learning. The ascending 5-HT and dopamine
              neurotransmitter systems have a modulatory role in both
              processes. There is accumulating evidence that measures of
              decision-making and reversal learning may be useful as functional
              markers of ventral prefrontal cortex integrity in psychiatric and
              neurological disorders. Whilst existing measures of
              decision-making may have superior sensitivity, reversal learning
              may offer superior selectivity, particularly within prefrontal
              cortex. Effective decision-making on existing measures requires
              the ability to adapt behaviour on the basis of changes in
              emotional significance, and this may underlie the shared neural
              circuitry with reversal learning.",
  journal  = "Brain Cogn.",
  volume   =  55,
  number   =  1,
  pages    = "41--53",
  month    =  jun,
  year     =  2004,
  language = "en",
  issn     = "0278-2626",
  pmid     = "15134842",
  doi      = "10.1016/S0278-2626(03)00284-7"
}

@ARTICLE{Coutlee2012-hy,
  title    = "The functional neuroanatomy of decision making: prefrontal
              control of thought and action",
  author   = "Coutlee, Christopher G and Huettel, Scott A",
  abstract = "Humans exhibit a remarkable capacity for flexible thought and
              action. Despite changing internal needs and external context,
              individuals maintain stable goals and pursue purposeful action.
              Functional neuroimaging research examining the neural
              underpinnings of such behavioral flexibility has progressed
              within several distinct traditions, as evident in the largely
              separate literatures on ``cognitive control'' and on ``decision
              making.'' Both topics investigate the formulation of desires and
              intentions, the integration of knowledge and context, and the
              resolution of conflict and uncertainty. Additionally, each
              recognizes the fundamental role of the prefrontal cortex in
              supporting flexible selection of behavior. But despite this
              notable overlap, neuroimaging studies in cognitive control and
              decision making have exerted only limited influence on each
              other, in part due to differences in their theoretical and
              experimental groundings. Additionally, the precise organization
              of control processing within prefrontal cortex has remained
              unclear, fostering an acceptance of vague descriptions of
              decision making in terms of canonical cognitive control functions
              such as ``inhibition'' or ``self-control.'' We suggest a unifying
              role for models of the hierarchical organization of action
              selection within prefrontal cortex. These models provide an
              important conceptual link between decision-making phenomena and
              cognitive-control processes, potentially facilitating
              cross-fertilization between these topics.",
  journal  = "Brain Res.",
  volume   =  1428,
  pages    = "3--12",
  month    =  jan,
  year     =  2012,
  language = "en",
  issn     = "0006-8993, 1872-6240",
  pmid     = "21676379",
  doi      = "10.1016/j.brainres.2011.05.053",
  pmc      = "PMC3202063"
}

@ARTICLE{Hanks2017-mu,
  title    = "Perceptual Decision Making in Rodents, Monkeys, and Humans",
  author   = "Hanks, Timothy D and Summerfield, Christopher",
  abstract = "Perceptual decision making is the process by which animals
              detect, discriminate, and categorize information from the senses.
              Over the past two decades, understanding how perceptual decisions
              are made has become a central theme in the neurosciences.
              Exceptional progress has been made by recording from single
              neurons in the cortex of the macaque monkey and using
              computational models from mathematical psychology to relate these
              neural data to behavior. More recently, however, the range of
              available techniques and paradigms has dramatically broadened,
              and researchers have begun to harness new approaches to explore
              how rodents and humans make perceptual decisions. The results
              have illustrated some striking convergences with findings from
              the monkey, but also raised new questions and provided new
              theoretical insights. In this review, we summarize key findings,
              and highlight open challenges, for understanding perceptual
              decision making in rodents, monkeys, and humans.",
  journal  = "Neuron",
  volume   =  93,
  number   =  1,
  pages    = "15--31",
  month    =  jan,
  year     =  2017,
  keywords = "confidence; decision making; functional neuroimaging; human;
              non-human primate; parietal cortex; psychophysics; rodent;
              single-cell recordings",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "28056343",
  doi      = "10.1016/j.neuron.2016.12.003"
}

@ARTICLE{Balleine2007-qv,
  title    = "The role of the dorsal striatum in reward and decision-making",
  author   = "Balleine, Bernard W and Delgado, Mauricio R and Hikosaka, Okihide",
  abstract = "Although the involvement in the striatum in the refinement and
              control of motor movement has long been recognized, recent
              description of discrete frontal corticobasal ganglia networks in
              a range of species has focused attention on the role particularly
              of the dorsal striatum in executive functions. Current evidence
              suggests that the dorsal striatum contributes directly to
              decision-making, especially to action selection and initiation,
              through the integration of sensorimotor, cognitive, and
              motivational/emotional information within specific
              corticostriatal circuits involving discrete regions of striatum.
              We review key evidence from recent studies in rodent, nonhuman
              primate, and human subjects.",
  journal  = "J. Neurosci.",
  volume   =  27,
  number   =  31,
  pages    = "8161--8165",
  month    =  aug,
  year     =  2007,
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "17670959",
  doi      = "10.1523/JNEUROSCI.1554-07.2007"
}

@ARTICLE{Hikosaka2010-ql,
  title    = "The habenula: from stress evasion to value-based decision-making",
  author   = "Hikosaka, Okihide",
  abstract = "Surviving in a world with hidden rewards and dangers requires
              choosing the appropriate behaviours. Recent discoveries indicate
              that the habenula plays a prominent part in such behavioural
              choice through its effects on neuromodulator systems, in
              particular the dopamine and serotonin systems. By inhibiting
              dopamine-releasing neurons, habenula activation leads to the
              suppression of motor behaviour when an animal fails to obtain a
              reward or anticipates an aversive outcome. Moreover, the habenula
              is involved in behavioural responses to pain, stress, anxiety,
              sleep and reward, and its dysfunction is associated with
              depression, schizophrenia and drug-induced psychosis. As a highly
              conserved structure in the brain, the habenula provides a
              fundamental mechanism for both survival and decision-making.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  11,
  number   =  7,
  pages    = "503--513",
  month    =  jul,
  year     =  2010,
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "20559337",
  doi      = "10.1038/nrn2866",
  pmc      = "PMC3447364"
}

@ARTICLE{Corrado2007-ds,
  title    = "Understanding neural coding through the model-based analysis of
              decision making",
  author   = "Corrado, Greg and Doya, Kenji",
  abstract = "The study of decision making poses new methodological challenges
              for systems neuroscience. Whereas our traditional approach linked
              neural activity to external variables that the experimenter
              directly observed and manipulated, many of the key elements that
              contribute to decisions are internal to the decider. Variables
              such as subjective value or subjective probability may be
              influenced by experimental conditions and manipulations but can
              neither be directly measured nor precisely controlled. Pioneering
              work on the neural basis of decision circumvented this difficulty
              by studying behavior in static conditions, in which knowledge of
              the average state of these quantities was sufficient. More
              recently, a new wave of studies has confronted the conundrum of
              internal decision variables more directly by leveraging
              quantitative behavioral models. When these behavioral models are
              successful in predicting a subject's choice, the model's internal
              variables may serve as proxies for the unobservable decision
              variables that actually drive behavior. This new methodology has
              allowed researchers to localize neural subsystems that encode
              hidden decision variables related to free choice and to study
              these variables under dynamic conditions.",
  journal  = "J. Neurosci.",
  volume   =  27,
  number   =  31,
  pages    = "8178--8180",
  month    =  aug,
  year     =  2007,
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "17670963",
  doi      = "10.1523/JNEUROSCI.1590-07.2007"
}

@ARTICLE{Dayan1995-ai,
  title     = "The Helmholtz machine",
  author    = "Dayan, P and Hinton, G E and Neal, R M and Zemel, R S",
  abstract  = "Discovering the structure inherent in a set of patterns is a
               fundamental aim of statistical inference or learning. One
               fruitful approach is to build a parameterized stochastic
               generative model, independent draws from which are likely to
               produce the patterns. For all but the simplest generative
               models, each pattern can be generated in exponentially many
               ways. It is thus intractable to adjust the parameters to
               maximize the probability of the observed patterns. We describe a
               way of finessing this combinatorial explosion by maximizing an
               easily computed lower bound on the probability of the
               observations. Our method can be viewed as a form of hierarchical
               self-supervised learning that may relate to the function of
               bottom-up and top-down cortical processing pathways.",
  journal   = "Neural Comput.",
  publisher = "MIT Press",
  volume    =  7,
  number    =  5,
  pages     = "889--904",
  month     =  sep,
  year      =  1995,
  language  = "en",
  issn      = "0899-7667",
  pmid      = "7584891"
}

@ARTICLE{Botvinick2008-sh,
  title     = "Hierarchical models of behavior and prefrontal function",
  author    = "Botvinick, Matthew M",
  abstract  = "The recognition of hierarchical structure in human behavior was
               one of the founding insights of the cognitive revolution.
               Despite decades of research, however, the computational
               mechanisms underlying hierarchically organized behavior are
               still not fully understood. Recent findings from behavioral and
               neuroscientific research have fueled a resurgence of interest in
               the problem, inspiring a new generation of computational models.
               In addition to developing some classic proposals, these models
               also break fresh ground, teasing apart different forms of
               hierarchical structure, placing a new focus on the issue of
               learning and addressing recent findings concerning the
               representation of behavioral hierarchies within the prefrontal
               cortex. In addition to offering explanations for some key
               aspects of behavior and functional neuroanatomy, the latest
               models also pose new questions for empirical research.",
  journal   = "Trends Cogn. Sci.",
  publisher = "Elsevier",
  volume    =  12,
  number    =  5,
  pages     = "201--208",
  month     =  may,
  year      =  2008,
  language  = "en",
  issn      = "1364-6613",
  pmid      = "18420448",
  doi       = "10.1016/j.tics.2008.02.009",
  pmc       = "PMC2957875"
}

@ARTICLE{Botvinick2006-ux,
  title     = "Such stuff as habits are made on: A reply to Cooper and Shallice
               (2006)",
  author    = "Botvinick, Matthew M and Plaut, David C",
  abstract  = "The representations and mechanisms guiding everyday routine
               sequential action remain incompletely understood. In recent
               work, the authors proposed a computational model of routine
               sequential behavior that took the form of a recurrent neural
               network (M. Botvinick \& D. C. Plaut, 2004; see record
               2004-12248-005). Subsequently, R. P. Cooper and T. Shallice
               (2006; see record 2006-12689-008) put forth a detailed critique
               of that work, contrasting it with their own account, which
               assumes a strict hierarchical processing system (R. P. Cooper \&
               T. Shallice, 2000; see record 2000-03986-001). The authors
               respond here to the main points of R. P. Cooper and T.
               Shallice's (2006) critique. Although careful and constructive,
               the arguments offered by R. P. Cooper and T. Shallice (2006)
               mistook several superficial implementational issues for
               fundamental theoretical ones, underestimated the computational
               power of recurrent networks as a class, and in some ways
               mischaracterized the relationship between the accounts they
               compare. In responding to these points, the authors articulate
               several key theoretical choices facing models of routine
               sequential behavior. (PsycINFO Database Record (c) 2016 APA, all
               rights reserved)",
  journal   = "Psychol. Rev.",
  publisher = "psycnet.apa.org",
  volume    =  113,
  number    =  4,
  pages     = "917--927",
  month     =  oct,
  year      =  2006,
  issn      = "0033-295X, 1939-1471",
  doi       = "10.1037/0033-295X.113.4.917"
}

@ARTICLE{Cooper2006-gu,
  title     = "Hierarchical schemas and goals in the control of sequential
               behavior",
  author    = "Cooper, Richard P and Shallice, Tim",
  abstract  = "Traditional accounts of sequential behavior assume that schemas
               and goals play a causal role in the control of behavior. In
               contrast, M. Botvinick and D. C. Plaut argued that, at least in
               routine behavior, schemas and goals are epiphenomenal. The
               authors evaluate the Botvinick and Plaut account by contrasting
               the simple recurrent network model of Botvinick and Plaut with
               their own more traditional hierarchically structured interactive
               activation model (R. P. Cooper \& T. Shallice, 2000). The
               authors present a range of arguments and additional simulations
               that demonstrate theoretical and empirical difficulties for both
               Botvinick and Plaut's model and their theoretical position. The
               authors conclude that explicit hierarchically organized and
               causally efficacious schema and goal representations are
               required to provide an adequate account of the flexibility of
               sequential behavior.",
  journal   = "Psychol. Rev.",
  publisher = "psycnet.apa.org",
  volume    =  113,
  number    =  4,
  pages     = "887--916; discussion 917--31",
  month     =  oct,
  year      =  2006,
  language  = "en",
  issn      = "0033-295X",
  pmid      = "17014307",
  doi       = "10.1037/0033-295X.113.4.887"
}

@ARTICLE{Bornstein2011-xi,
  title    = "Multiplicity of control in the basal ganglia: computational roles
              of striatal subregions",
  author   = "Bornstein, Aaron M and Daw, Nathaniel D",
  abstract = "The basal ganglia, in particular the striatum, are central to
              theories of behavioral control, and often identified as a seat of
              action selection. Reinforcement learning (RL) models--which have
              driven much recent experimental work on this region--cast
              striatum as a dynamic controller, integrating sensory and
              motivational information to construct efficient and enriching
              behavioral policies. Befitting this informationally central role,
              the BG sit at the nexus of multiple anatomical 'loops' of
              synaptic projections, connecting a wide range of cortical and
              subcortical structures. Numerous pioneering anatomical studies
              conducted over the past several decades have meticulously
              catalogued these loops, and labeled them according to the
              inferred functions of the connected regions. The specific
              cotermina of the projections are highly localized to several
              different subregions of the striatum, leading to the suggestion
              that these subregions perform complementary but distinct
              functions. However, until recently, the dominant computational
              framework outlined only a bipartite, dorsal/ventral, division of
              striatum. We review recent computational and experimental
              advances that argue for a more finely fractionated delineation.
              In particular, experimental data provide extensive insight into
              unique functions subserved by the dorsomedial striatum (DMS).
              These functions appear to correspond well with theories of a
              'model-based' RL subunit, and may also shed light on the
              suborganization of ventral striatum. Finally, we discuss the
              limitations of these ideas and how they point the way toward
              future refinements of neurocomputational theories of striatal
              function, bringing them into contact with other areas of
              computational theory and other regions of the brain.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  21,
  number   =  3,
  pages    = "374--380",
  month    =  jun,
  year     =  2011,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "21429734",
  doi      = "10.1016/j.conb.2011.02.009",
  pmc      = "PMC3269306"
}

@ARTICLE{Gruber2012-nm,
  title    = "Context, emotion, and the strategic pursuit of goals:
              interactions among multiple brain systems controlling motivated
              behavior",
  author   = "Gruber, Aaron J and McDonald, Robert J",
  abstract = "Motivated behavior exhibits properties that change with
              experience and partially dissociate among a number of brain
              structures. Here, we review evidence from rodent experiments
              demonstrating that multiple brain systems acquire information in
              parallel and either cooperate or compete for behavioral control.
              We propose a conceptual model of systems interaction wherein a
              ventral emotional memory network involving ventral striatum (VS),
              amygdala, ventral hippocampus, and ventromedial prefrontal cortex
              triages behavioral responding to stimuli according to their
              associated affective outcomes. This system engages autonomic and
              postural responding (avoiding, ignoring, approaching) in
              accordance with associated stimulus valence (negative, neutral,
              positive), but does not engage particular operant responses.
              Rather, this emotional system suppresses or invigorates actions
              that are selected through competition between goal-directed
              control involving dorsomedial striatum (DMS) and habitual control
              involving dorsolateral striatum (DLS). The hippocampus provides
              contextual specificity to the emotional system, and provides an
              information rich input to the goal-directed system for navigation
              and discriminations involving ambiguous contexts, complex sensory
              configurations, or temporal ordering. The rapid acquisition and
              high capacity for episodic associations in the emotional system
              may unburden the more complex goal-directed system and reduce
              interference in the habit system from processing contingencies of
              neutral stimuli. Interactions among these systems likely involve
              inhibitory mechanisms and neuromodulation in the striatum to form
              a dominant response strategy. Innate traits, training methods,
              and task demands contribute to the nature of these interactions,
              which can include incidental learning in non-dominant systems.
              Addition of these features to reinforcement learning models of
              decision-making may better align theoretical predictions with
              behavioral and neural correlates in animals.",
  journal  = "Front. Behav. Neurosci.",
  volume   =  6,
  pages    = "50",
  month    =  aug,
  year     =  2012,
  keywords = "Pavlovian-instrumental transfer; amygdala; dopamine; emotion;
              hippocampus; inhibition; reinforcement learning; striatum",
  language = "en",
  issn     = "1662-5153",
  pmid     = "22876225",
  doi      = "10.3389/fnbeh.2012.00050",
  pmc      = "PMC3411069"
}

@ARTICLE{Smith2012-nb,
  title    = "Reversible online control of habitual behavior by optogenetic
              perturbation of medial prefrontal cortex",
  author   = "Smith, Kyle S and Virkud, Arti and Deisseroth, Karl and Graybiel,
              Ann M",
  abstract = "Habits tend to form slowly but, once formed, can have great
              stability. We probed these temporal characteristics of habitual
              behaviors by intervening optogenetically in forebrain habit
              circuits as rats performed well-ingrained habitual runs in a
              T-maze. We trained rats to perform a maze habit, confirmed the
              habitual behavior by devaluation tests, and then, during the maze
              runs (ca. 3 s), we disrupted population activity in a small
              region in the medial prefrontal cortex, the infralimbic cortex.
              In accordance with evidence that this region is necessary for the
              expression of habits, we found that this cortical disruption
              blocked habitual behavior. Notably, however, this blockade of
              habitual performance occurred on line, within an average of three
              trials (ca. 9 s of inhibition), and as soon as during the first
              trial (<3 s). During subsequent weeks of training, the rats
              acquired a new behavioral pattern. When we again imposed the same
              cortical perturbation, the rats regained the suppressed
              maze-running that typified the original habit, and,
              simultaneously, the more recently acquired habit was blocked.
              These online changes occurred within an average of two trials
              (ca. 6 s of infralimbic inhibition). Measured changes in
              generalized performance ability and motivation to consume reward
              were unaffected. This immediate toggling between breaking old
              habits and returning to them demonstrates that even semiautomatic
              behaviors are under cortical control and that this control occurs
              online, second by second. These temporal characteristics define a
              framework for uncovering cellular transitions between fixed and
              flexible behaviors, and corresponding disturbances in
              pathologies.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  109,
  number   =  46,
  pages    = "18932--18937",
  month    =  nov,
  year     =  2012,
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "23112197",
  doi      = "10.1073/pnas.1216264109",
  pmc      = "PMC3503190"
}

@ARTICLE{Kraus2013-yt,
  title    = "Hippocampal ``time cells'': time versus path integration",
  author   = "Kraus, Benjamin J and Robinson, 2nd, Robert J and White, John A
              and Eichenbaum, Howard and Hasselmo, Michael E",
  abstract = "Recent studies have reported the existence of hippocampal ``time
              cells,'' neurons that fire at particular moments during periods
              when behavior and location are relatively constant. However, an
              alternative explanation of apparent time coding is that
              hippocampal neurons ``path integrate'' to encode the distance an
              animal has traveled. Here, we examined hippocampal neuronal
              firing patterns as rats ran in place on a treadmill, thus
              ``clamping'' behavior and location, while we varied the treadmill
              speed to distinguish time elapsed from distance traveled.
              Hippocampal neurons were strongly influenced by time and
              distance, and less so by minor variations in location.
              Furthermore, the activity of different neurons reflected
              integration over time and distance to varying extents, with most
              neurons strongly influenced by both factors and some
              significantly influenced by only time or distance. Thus,
              hippocampal neuronal networks captured both the organization of
              time and distance in a situation where these dimensions dominated
              an ongoing experience.",
  journal  = "Neuron",
  volume   =  78,
  number   =  6,
  pages    = "1090--1101",
  month    =  jun,
  year     =  2013,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "23707613",
  doi      = "10.1016/j.neuron.2013.04.015",
  pmc      = "PMC3913731"
}

@ARTICLE{Friston2010-yo,
  title    = "The free-energy principle: a unified brain theory?",
  author   = "Friston, Karl",
  abstract = "A free-energy principle has been proposed recently that accounts
              for action, perception and learning. This Review looks at some
              key brain theories in the biological (for example, neural
              Darwinism) and physical (for example, information theory and
              optimal control theory) sciences from the free-energy
              perspective. Crucially, one key theme runs through each of these
              theories - optimization. Furthermore, if we look closely at what
              is optimized, the same quantity keeps emerging, namely value
              (expected reward, expected utility) or its complement, surprise
              (prediction error, expected cost). This is the quantity that is
              optimized under the free-energy principle, which suggests that
              several global brain theories might be unified within a
              free-energy framework.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  11,
  number   =  2,
  pages    = "127--138",
  month    =  feb,
  year     =  2010,
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "20068583",
  doi      = "10.1038/nrn2787"
}

@ARTICLE{Niv2009-gn,
  title     = "Reinforcement learning in the brain",
  author    = "Niv, Yael",
  abstract  = "A wealth of research focuses on the decision-making processes
               that animals and humans employ when selecting actions in the
               face of reward and punishment. Initially such work stemmed from
               psychological investigations of conditioned behavior, and
               explanations of these in terms of computational models.
               Increasingly, analysis at the computational level has drawn on
               ideas from reinforcement learning, which provide a normative
               framework within which decision-making can be analyzed. More
               recently, the fruits of these extensive lines of research have
               made contact with investigations into the neural basis of
               decision making. Converging evidence now links reinforcement
               learning to specific neural substrates, assigning them precise
               computational roles. Specifically, electrophysiological
               recordings in behaving animals and functional imaging of human
               decision-making have revealed in the brain the existence of a
               key reinforcement learning signal, the temporal difference
               reward prediction error. Here, we first introduce the formal
               reinforcement learning framework. We then review the multiple
               lines of evidence linking reinforcement learning to the function
               of dopaminergic neurons in the mammalian midbrain and to more
               recent data from human imaging experiments. We further extend
               the discussion to aspects of learning not associated with phasic
               dopamine signals, such as learning of goal-directed responding
               that may not be dopamine-dependent, and learning about the vigor
               (or rate) with which actions should be performed that has been
               linked to tonic aspects of dopaminergic signaling. We end with a
               brief discussion of some of the limitations of the reinforcement
               learning framework, highlighting questions for future research.",
  journal   = "J. Math. Psychol.",
  publisher = "Elsevier",
  volume    =  53,
  number    =  3,
  pages     = "139--154",
  month     =  jun,
  year      =  2009,
  issn      = "0022-2496",
  doi       = "10.1016/j.jmp.2008.12.005"
}

@ARTICLE{Pinero_Jordi2019-zs,
  title     = "Statistical physics of liquid brains",
  author    = "{Pi{\~n}ero Jordi} and {Sol{\'e} Ricard}",
  journal   = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  publisher = "Royal Society",
  volume    =  374,
  number    =  1774,
  pages     = "20180376",
  month     =  jun,
  year      =  2019,
  issn      = "0962-8436",
  doi       = "10.1098/rstb.2018.0376"
}

@ARTICLE{Dalley2004-ta,
  title    = "Prefrontal executive and cognitive functions in rodents: neural
              and neurochemical substrates",
  author   = "Dalley, Jeffrey W and Cardinal, Rudolf N and Robbins, Trevor W",
  abstract = "The prefrontal cortex has been implicated in a variety of
              cognitive and executive processes, including working memory,
              decision-making, inhibitory response control, attentional
              set-shifting and the temporal integration of voluntary behaviour.
              This article reviews current progress in our understanding of the
              rodent prefrontal cortex, especially evidence for functional
              divergence of the anatomically distinct sub-regions of the rat
              prefrontal cortex. Recent findings suggest clear distinctions
              between the dorsal (precentral and anterior cingulate) and
              ventral (prelimbic, infralimbic and medial orbital) sub-divisions
              of the medial prefrontal cortex, and between the orbitofrontal
              cortex (ventral orbital, ventrolateral orbital, dorsal and
              ventral agranular cortices) and the adjacent medial wall of the
              prefrontal cortex. The dorso-medial prefrontal cortex is
              implicated in memory for motor responses, including response
              selection, and the temporal processing of information. Ventral
              regions of the medial prefrontal cortex are implicated in
              interrelated 'supervisory' attentional functions, including
              attention to stimulus features and task contingencies (or
              action-outcome rules), attentional set-shifting, and behavioural
              flexibility. The orbitofrontal cortex is implicated in
              lower-order discriminations, including reversal of
              stimulus-reward associations (reversal learning), and choice
              involving delayed reinforcement. It is anticipated that a greater
              understanding of the prefrontal cortex will come from using tasks
              that load specific cognitive and executive processes, in parallel
              with discovering new ways of manipulating the different
              sub-regions and neuromodulatory systems of the prefrontal cortex.",
  journal  = "Neurosci. Biobehav. Rev.",
  volume   =  28,
  number   =  7,
  pages    = "771--784",
  month    =  nov,
  year     =  2004,
  language = "en",
  issn     = "0149-7634",
  pmid     = "15555683",
  doi      = "10.1016/j.neubiorev.2004.09.006"
}

@ARTICLE{Sole1995-op,
  title     = "Information at the edge of chaos in fluid neural networks",
  author    = "Sol{\'e}, Ricard V and Miramontes, Octavio",
  abstract  = "Fluid neural networks, defined as neural nets of mobile elements
               with random activation, are studied by means of several
               approaches. They are proposed as a theoretical framework for a
               wide class of systems as insect societies, collectives of robots
               or the immune system. The critical properties of this model are
               also analysed, showing the existence of a critical boundary in
               parameter space where maximum information transfer occurs. In
               this sense, this boundary is in fact an example of the ``edge of
               chaos'' in systems like those described in our approach. Recent
               experiments with ant colonies seem to confirm our result.",
  journal   = "Physica D",
  publisher = "Elsevier",
  volume    =  80,
  number    =  1,
  pages     = "171--180",
  month     =  jan,
  year      =  1995,
  issn      = "0167-2789",
  doi       = "10.1016/0167-2789(95)90075-6"
}

@ARTICLE{Detrain2006-vd,
  title     = "Self-organized structures in a superorganism: do ants ``behave''
               like molecules?",
  author    = "Detrain, Claire and Deneubourg, Jean-Louis",
  abstract  = "While the striking structures (e.g. nest architecture, trail
               networks) of insect societies may seem familiar to many of us,
               the understanding of pattern formation still constitutes a
               challenging problem. Over the last two decades,
               self-organization has dramatically changed our view on how
               collective decision-making and structures may emerge out of a
               population of ant workers having each their own individuality as
               well as a limited access to information. A variety of collective
               behaviour spontaneously outcome from multiple interactions
               between nestmates, even when there is no directing influence
               imposed by an external template, a pacemaker or a leader. By
               focussing this review on foraging structures, we show that ant
               societies display some properties which are usually considered
               in physico-chemical systems, as typical signatures of
               self-organization. We detail the key role played by feed-back
               loops, fluctuations, number of interacting units and sensitivity
               to environmental factors in the emergence of a structured
               collective behaviour. Nonetheless, going beyond simple analogies
               with non-living self-organized patterns, we stress on the
               specificities of social structures made of complex living units
               of which the biological features have been selected throughout
               the evolution depending on their adaptive value. In particular,
               we consider the ability of each ant individual to process
               information about environmental and social parameters, to
               accordingly tune its interactions with nestmates and ultimately
               to determine the final pattern emerging at the collective level.
               We emphasize on the parsimony and simplicity of behavioural
               rules at the individual level which allow an efficient
               processing of information, energy and matter within the whole
               colony.",
  journal   = "Phys. Life Rev.",
  publisher = "Elsevier",
  volume    =  3,
  number    =  3,
  pages     = "162--187",
  month     =  sep,
  year      =  2006,
  keywords  = "Self-organization; Decision-making; Pattern formation; Social
               insects; Foraging; Trail",
  issn      = "1571-0645",
  doi       = "10.1016/j.plrev.2006.07.001"
}

@ARTICLE{Marshall2009-pa,
  title     = "On optimal decision-making in brains and social insect colonies",
  author    = "Marshall, James A R and Bogacz, Rafal and Dornhaus, Anna and
               Planqu{\'e}, Robert and Kovacs, Tim and Franks, Nigel R",
  abstract  = "The problem of how to compromise between speed and accuracy in
               decision-making faces organisms at many levels of biological
               complexity. Striking parallels are evident between
               decision-making in primate brains and collective decision-making
               in social insect colonies: in both systems, separate populations
               accumulate evidence for alternative choices; when one population
               reaches a threshold, a decision is made for the corresponding
               alternative, and this threshold may be varied to compromise
               between the speed and the accuracy of decision-making. In
               primate decision-making, simple models of these processes have
               been shown, under certain parametrizations, to implement the
               statistically optimal procedure that minimizes decision time for
               any given error rate. In this paper, we adapt these same
               analysis techniques and apply them to new models of collective
               decision-making in social insect colonies. We show that social
               insect colonies may also be able to achieve statistically
               optimal collective decision-making in a very similar way to
               primate brains, via direct competition between
               evidence-accumulating populations. This optimality result makes
               testable predictions for how collective decision-making in
               social insects should be organized. Our approach also represents
               the first attempt to identify a common theoretical framework for
               the study of decision-making in diverse biological systems.",
  journal   = "J. R. Soc. Interface",
  publisher = "royalsocietypublishing.org",
  volume    =  6,
  number    =  40,
  pages     = "1065--1074",
  month     =  nov,
  year      =  2009,
  language  = "en",
  issn      = "1742-5689, 1742-5662",
  pmid      = "19324679",
  doi       = "10.1098/rsif.2008.0511",
  pmc       = "PMC2827444"
}

@TECHREPORT{Millonas1993-ss,
  title     = "Swarms, Phase Transitions, and Collective Intelligence (Paper
               1); and A Nonequilibrium Statistical Field Theory of Swarms and
               Other Spatially Extended Complex Systems (Paper 2)",
  author    = "Millonas, Mark M",
  abstract  = "(Paper 1) A spacially extended model of the collective behavior
               of a large number of locally acting organisms is proposed in
               which organisms move probabilistically between local cells in
               space, but with weights dependent on local morphogenetic
               substances, or morphogens. The morphogens are in turn effected
               by the passage of an organism. The evolution of the morphogens,
               and the corresponding flow of the organisms constitutes the
               collective behavior of the group. Such models have various types
               of phase transitions and self-organizing properties controlled
               both by the level of the noise, and other parameters. The model
               is then applied to the specific case of ants moving on a
               lattice. The local behavior of the ants is inspired by the
               actual behavior observed in the laboratory, and analytic results
               for the collective behavior are compared to the corresponding
               laboratory results. It is hoped that the present model might
               serve as a paradigmatic example of a complex cooperative system
               in nature. In particular swarm models can be used to explore the
               relation of nonequilibrium phase transitions to at least three
               important issues encountered in artificial life. Firstly, that
               of emergence as complex adaptive behavior. Secondly, as an
               exporation of continuous phase transitions in biological
               systems. Lastly, to derive behavioral criteria for the evolution
               of collective behavior in social organisms. (Paper 2) A class of
               models with applications to swarm behavior as well as many other
               types of spatially extended complex biological and physical
               systems is studied. Internal fluctuations can play an active
               role in the organization of the phase structure of such systems.
               Consequently, it is not possible to fully understand the
               behavior of these systems without explicitly incorporating the
               fluctuations. In particular, for the class of models studied
               here the effect of internal fluctuations due to finite size is a
               renormalized \{\textbackslashit decrease\} in the temperature
               near the point of spontaneous symmetry breaking. We briefly
               outline how these models can be applied to the behavior of an
               ant swarm.",
  publisher = "Santa Fe Institute",
  number    = "93-06-039",
  month     =  jun,
  year      =  1993
}

@ARTICLE{Altshuler2005-ci,
  title     = "Symmetry breaking in escaping ants",
  author    = "Altshuler, E and Ramos, O and N{\'u}{\~n}ez, Y and
               Fern{\'a}ndez, J and Batista-Leyva, A J and Noda, C",
  abstract  = "The phenomenon of herding is a very general feature of the
               collective behavior of many species in panic conditions,
               including humans. It has been predicted theoretically that
               panic-induced herding in individuals confined to a room can
               produce a nonsymmetrical use of two identical exit doors. Here
               we demonstrate the existence of that phenomenon in experiments,
               using ants as a model of pedestrians. We show that ants confined
               to a cell with two symmetrically located exits use both exits in
               approximately equal proportions to abandon it in normal
               conditions but prefer one of the exits if panic is created by
               adding a repellent fluid. In addition, we are able to reproduce
               the observed escape dynamics in detail using a modification of a
               previous theoretical model that includes herding associated with
               a panic parameter as a central ingredient. Our experimental
               results, combined with theoretical models, suggest that some
               features of the collective behavior of humans and ants can be
               quite similar when escaping under panic.",
  journal   = "Am. Nat.",
  publisher = "journals.uchicago.edu",
  volume    =  166,
  number    =  6,
  pages     = "643--649",
  month     =  dec,
  year      =  2005,
  language  = "en",
  issn      = "0003-0147, 1537-5323",
  pmid      = "16475081",
  doi       = "10.1086/498139"
}

@ARTICLE{Rangel2010-ch,
  title     = "Neural computations associated with goal-directed choice",
  author    = "Rangel, Antonio and Hare, Todd",
  abstract  = "In goal-directed decision-making, animals choose between actions
               that are associated with different reward outcomes (e.g., foods)
               and with different costs (e.g., effort). Rapid advances have
               been made over the past few years in our understanding of the
               computations associated with goal-directed choices, and of how
               those computations are implemented in the brain. We review some
               important findings, with an emphasis on computational models,
               human fMRI, and monkey neurophysiology studies.",
  journal   = "Curr. Opin. Neurobiol.",
  publisher = "rnl.caltech.edu",
  volume    =  20,
  number    =  2,
  pages     = "262--270",
  month     =  apr,
  year      =  2010,
  language  = "en",
  issn      = "0959-4388, 1873-6882",
  pmid      = "20338744",
  doi       = "10.1016/j.conb.2010.03.001"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Becker1964-sy,
  title     = "Measuring utility by a single-response sequential method",
  author    = "Becker, Gordon M and DeGroot, Morris H and Marschak, Jacob",
  abstract  = "A person deciding on a career, a wife, or a place to live bases
               his choice on two factors:(1) How much do I like each of the
               available alternatives? and (2) What are the chances for a
               successful outcome of each alternative? These two factors
               comprise the utility of each outcome for the person making the
               choice. This notion of utility is fundamental to most current
               theories of decision behavior. According to the expected utility
               hypothesis, if we could know the utility function of a person,
               we could predict his choice from among any set of …",
  journal   = "Behav. Sci.",
  publisher = "Wiley Online Library",
  volume    =  9,
  number    =  3,
  pages     = "226--232",
  year      =  1964,
  issn      = "0005-7940"
}

@ARTICLE{Ghahramani2015-gx,
  title     = "Probabilistic machine learning and artificial intelligence",
  author    = "Ghahramani, Zoubin",
  abstract  = "How can a machine learn from experience? Probabilistic modelling
               provides a framework for understanding what learning is, and has
               therefore emerged as one of the principal theoretical and
               practical approaches for designing machines that learn from data
               acquired through experience. The probabilistic framework, which
               describes how to represent and manipulate uncertainty about
               models and predictions, has a central role in scientific data
               analysis, machine learning, robotics, cognitive science and
               artificial intelligence. This Review provides an introduction to
               this framework, and discusses some of the state-of-the-art
               advances in the field, namely, probabilistic programming,
               Bayesian optimization, data compression and automatic model
               discovery.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  521,
  number    =  7553,
  pages     = "452--459",
  month     =  may,
  year      =  2015,
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "26017444",
  doi       = "10.1038/nature14541"
}

@ARTICLE{Buschman2014-yb,
  title     = "Goal-direction and top-down control",
  author    = "Buschman, Timothy J and Miller, Earl K",
  abstract  = "We review the neural mechanisms that support top-down control of
               behaviour and suggest that goal-directed behaviour uses two
               systems that work in concert. A basal ganglia-centred system
               quickly learns simple, fixed goal-directed behaviours while a
               prefrontal cortex-centred system gradually learns more complex
               (abstract or long-term) goal-directed behaviours. Interactions
               between these two systems allow top-down control mechanisms to
               learn how to direct behaviour towards a goal but also how to
               guide behaviour when faced with a novel situation.",
  journal   = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  publisher = "royalsocietypublishing.org",
  volume    =  369,
  number    =  1655,
  month     =  nov,
  year      =  2014,
  keywords  = "basal ganglia; cognition; frontal lobe; goal direction; learning",
  language  = "en",
  issn      = "0962-8436, 1471-2970",
  pmid      = "25267814",
  doi       = "10.1098/rstb.2013.0471",
  pmc       = "PMC4186225"
}

@ARTICLE{Harvey2009-ql,
  title     = "Intracellular dynamics of hippocampal place cells during virtual
               navigation",
  author    = "Harvey, Christopher D and Collman, Forrest and Dombeck, Daniel A
               and Tank, David W",
  abstract  = "Hippocampal place cells encode spatial information in rate and
               temporal codes. To examine the mechanisms underlying hippocampal
               coding, here we measured the intracellular dynamics of place
               cells by combining in vivo whole-cell recordings with a
               virtual-reality system. Head-restrained mice, running on a
               spherical treadmill, interacted with a computer-generated visual
               environment to perform spatial behaviours. Robust place-cell
               activity was present during movement along a virtual linear
               track. From whole-cell recordings, we identified three
               subthreshold signatures of place fields: an asymmetric ramp-like
               depolarization of the baseline membrane potential, an increase
               in the amplitude of intracellular theta oscillations, and a
               phase precession of the intracellular theta oscillation relative
               to the extracellularly recorded theta rhythm. These
               intracellular dynamics underlie the primary features of
               place-cell rate and temporal codes. The virtual-reality system
               developed here will enable new experimental approaches to study
               the neural circuits underlying navigation.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  461,
  number    =  7266,
  pages     = "941--946",
  month     =  oct,
  year      =  2009,
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "19829374",
  doi       = "10.1038/nature08499",
  pmc       = "PMC2771429"
}

@ARTICLE{Patrick_undated-xh,
  title  = "Computational model of habit learning and reversal",
  author = "Patrick, Sean and Bullock, Daniel",
  doi    = "10.1101/619445"
}

@ARTICLE{Fiore2015-om,
  title    = "Evolutionarily conserved mechanisms for the selection and
              maintenance of behavioural activity",
  author   = "Fiore, Vincenzo G and Dolan, Raymond J and Strausfeld, Nicholas J
              and Hirth, Frank",
  abstract = "Survival and reproduction entail the selection of adaptive
              behavioural repertoires. This selection manifests as
              phylogenetically acquired activities that depend on evolved
              nervous system circuitries. Lorenz and Tinbergen already
              postulated that heritable behaviours and their reliable
              performance are specified by genetically determined programs.
              Here we compare the functional anatomy of the insect central
              complex and vertebrate basal ganglia to illustrate their role in
              mediating selection and maintenance of adaptive behaviours.
              Comparative analyses reveal that central complex and basal
              ganglia circuitries share comparable lineage relationships within
              clusters of functionally integrated neurons. These clusters are
              specified by genetic mechanisms that link birth time and order to
              their neuronal identities and functions. Their subsequent
              connections and associated functions are characterized by similar
              mechanisms that implement dimensionality reduction and transition
              through attractor states, whereby spatially organized
              parallel-projecting loops integrate and convey sensorimotor
              representations that select and maintain behavioural activity. In
              both taxa, these neural systems are modulated by dopamine
              signalling that also mediates memory-like processes. The
              multiplicity of similarities between central complex and basal
              ganglia suggests evolutionarily conserved computational
              mechanisms for action selection. We speculate that these may have
              originated from ancestral ground pattern circuitries present in
              the brain of the last common ancestor of insects and vertebrates.",
  journal  = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  volume   =  370,
  number   =  1684,
  month    =  dec,
  year     =  2015,
  keywords = "action selection; attractor state; basal ganglia; brain
              evolution; central complex; sensorimotor representation",
  language = "en",
  issn     = "0962-8436, 1471-2970",
  pmid     = "26554043",
  doi      = "10.1098/rstb.2015.0053",
  pmc      = "PMC4650127"
}

@ARTICLE{Yin2006-jc,
  title     = "The role of the basal ganglia in habit formation",
  author    = "Yin, Henry H and Knowlton, Barbara J",
  abstract  = "Many organisms, especially humans, are characterized by their
               capacity for intentional, goal-directed actions. However,
               similar behaviours often proceed automatically, as habitual
               responses to antecedent stimuli. How are goal-directed actions
               transformed into habitual responses? Recent work combining
               modern behavioural assays and neurobiological analysis of the
               basal ganglia has begun to yield insights into the neural basis
               of habit formation.",
  journal   = "Nat. Rev. Neurosci.",
  publisher = "nature.com",
  volume    =  7,
  number    =  6,
  pages     = "464--476",
  month     =  jun,
  year      =  2006,
  language  = "en",
  issn      = "1471-003X",
  pmid      = "16715055",
  doi       = "10.1038/nrn1919"
}

@ARTICLE{Van_der_Meer2010-ka,
  title    = "Triple dissociation of information processing in dorsal striatum,
              ventral striatum, and hippocampus on a learned spatial decision
              task",
  author   = "van der Meer, Matthijs A A and Johnson, Adam and
              Schmitzer-Torbert, Neil C and Redish, A David",
  abstract = "Decision-making studies across different domains suggest that
              decisions can arise from multiple, parallel systems in the brain:
              a flexible system utilizing action-outcome expectancies and a
              more rigid system based on situation-action associations. The
              hippocampus, ventral striatum, and dorsal striatum make unique
              contributions to each system, but how information processing in
              each of these structures supports these systems is unknown.
              Recent work has shown covert representations of future paths in
              hippocampus and of future rewards in ventral striatum. We
              developed analyses in order to use a comparative methodology and
              apply the same analyses to all three structures. Covert
              representations of future paths and reward were both absent from
              the dorsal striatum. In contrast, dorsal striatum slowly
              developed situation representations that selectively represented
              action-rich parts of the task. This triple dissociation suggests
              that the different roles these structures play are due to
              differences in information-processing mechanisms.",
  journal  = "Neuron",
  volume   =  67,
  number   =  1,
  pages    = "25--32",
  month    =  jul,
  year     =  2010,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "20624589",
  doi      = "10.1016/j.neuron.2010.06.023",
  pmc      = "PMC4020415"
}

@ARTICLE{Rao2010-cq,
  title    = "Decision making under uncertainty: a neural model based on
              partially observable markov decision processes",
  author   = "Rao, Rajesh P N",
  abstract = "A fundamental problem faced by animals is learning to select
              actions based on noisy sensory information and incomplete
              knowledge of the world. It has been suggested that the brain
              engages in Bayesian inference during perception but how such
              probabilistic representations are used to select actions has
              remained unclear. Here we propose a neural model of action
              selection and decision making based on the theory of partially
              observable Markov decision processes (POMDPs). Actions are
              selected based not on a single ``optimal'' estimate of state but
              on the posterior distribution over states (the ``belief'' state).
              We show how such a model provides a unified framework for
              explaining experimental results in decision making that involve
              both information gathering and overt actions. The model utilizes
              temporal difference (TD) learning for maximizing expected reward.
              The resulting neural architecture posits an active role for the
              neocortex in belief computation while ascribing a role to the
              basal ganglia in belief representation, value computation, and
              action selection. When applied to the random dots motion
              discrimination task, model neurons representing belief exhibit
              responses similar to those of LIP neurons in primate neocortex.
              The appropriate threshold for switching from information
              gathering to overt actions emerges naturally during reward
              maximization. Additionally, the time course of reward prediction
              error in the model shares similarities with dopaminergic
              responses in the basal ganglia during the random dots task. For
              tasks with a deadline, the model learns a decision making
              strategy that changes with elapsed time, predicting a collapsing
              decision threshold consistent with some experimental studies. The
              model provides a new framework for understanding neural decision
              making and suggests an important role for interactions between
              the neocortex and the basal ganglia in learning the mapping
              between probabilistic sensory representations and actions that
              maximize rewards.",
  journal  = "Front. Comput. Neurosci.",
  volume   =  4,
  pages    = "146",
  month    =  nov,
  year     =  2010,
  keywords = "Bayesian inference; basal ganglia; decision theory; dopamine;
              parietal cortex; probabilistic models; reinforcement learning;
              temporal difference learning",
  language = "en",
  issn     = "1662-5188",
  pmid     = "21152255",
  doi      = "10.3389/fncom.2010.00146",
  pmc      = "PMC2998859"
}

@ARTICLE{Coutureau2003-sj,
  title     = "Inactivation of the infralimbic prefrontal cortex reinstates
               goal-directed responding in overtrained rats",
  author    = "Coutureau, Etienne and Killcross, Simon",
  abstract  = "Over the course of extended training, instrumental responding in
               rats shows a transition from goal-dependent performance to
               goal-independent performance, as assessed by sensitivity to
               reward-devaluation induced by taste aversions or specific
               satiety. It has been suggested that this reflects the gradual
               dominance of reflexive, habit-based responding over voluntary,
               goal-directed actions. Previous research suggests that lesions
               of the medial prefrontal cortex disrupt this interaction between
               goal-directed and habitual responding. More specifically,
               whereas lesions of the prelimbic prefrontal cortex appear to
               disrupt normal goal-directed responding, lesions of the
               infralimbic prefrontal cortex cause animals to remain
               goal-directed even after substantial overtraining. The current
               experiment explored further the nature of this interaction
               between actions and habits. Rats were given extended training of
               an instrumental lever press response before bilateral
               intracerebral cannulae giving access to the infralimbic cortex
               were implanted. Following further reminder training all animals
               were given a test of goal sensitivity by specific-satiety
               devaluation of the instrumental outcome, or a matched reward,
               prior to extinction tests. Before these tests, half of the
               animals received bilateral infusions of muscimol into the
               infralimbic cortex, and the remainder, control vehicle
               infusions. As expected after extended instrumental training,
               control-infused animals showed habitual performance that was not
               selectively influenced by devaluation of the instrumental
               outcome. In contrast, animals receiving temporary inactivation
               of the infralimbic cortex by muscimol showed selective
               sensitivity to devaluation of the instrumental outcome,
               indicating a reinstatement of goal-directed responding in these
               animals. This suggests that the development of habitual
               responding reflects the active inhibition of goal-directed
               responses that are mediated by action-outcome associations.",
  journal   = "Behav. Brain Res.",
  publisher = "Elsevier",
  volume    =  146,
  number    = "1-2",
  pages     = "167--174",
  month     =  nov,
  year      =  2003,
  language  = "en",
  issn      = "0166-4328",
  pmid      = "14643469"
}

@ARTICLE{McDannald2011-df,
  title     = "Ventral striatum and orbitofrontal cortex are both required for
               model-based, but not model-free, reinforcement learning",
  author    = "McDannald, Michael A and Lucantonio, Federica and Burke, Kathryn
               A and Niv, Yael and Schoenbaum, Geoffrey",
  abstract  = "In many cases, learning is thought to be driven by differences
               between the value of rewards we expect and rewards we actually
               receive. Yet learning can also occur when the identity of the
               reward we receive is not as expected, even if its value remains
               unchanged. Learning from changes in reward identity implies
               access to an internal model of the environment, from which
               information about the identity of the expected reward can be
               derived. As a result, such learning is not easily accounted for
               by model-free reinforcement learning theories such as temporal
               difference reinforcement learning (TDRL), which predicate
               learning on changes in reward value, but not identity. Here, we
               used unblocking procedures to assess learning driven by value-
               versus identity-based prediction errors. Rats were trained to
               associate distinct visual cues with different food quantities
               and identities. These cues were subsequently presented in
               compound with novel auditory cues and the reward quantity or
               identity was selectively changed. Unblocking was assessed by
               presenting the auditory cues alone in a probe test. Consistent
               with neural implementations of TDRL models, we found that the
               ventral striatum was necessary for learning in response to
               changes in reward value. However, this area, along with
               orbitofrontal cortex, was also required for learning driven by
               changes in reward identity. This observation requires that
               existing models of TDRL in the ventral striatum be modified to
               include information about the specific features of expected
               outcomes derived from model-based representations, and that the
               role of orbitofrontal cortex in these models be clearly
               delineated.",
  journal   = "J. Neurosci.",
  publisher = "Soc Neuroscience",
  volume    =  31,
  number    =  7,
  pages     = "2700--2705",
  month     =  feb,
  year      =  2011,
  language  = "en",
  issn      = "0270-6474, 1529-2401",
  pmid      = "21325538",
  doi       = "10.1523/JNEUROSCI.5499-10.2011",
  pmc       = "PMC3079289"
}

@ARTICLE{Gremel2013-yb,
  title     = "Orbitofrontal and striatal circuits dynamically encode the shift
               between goal-directed and habitual actions",
  author    = "Gremel, Christina M and Costa, Rui M",
  abstract  = "Shifting between goal-directed and habitual actions allows for
               efficient and flexible decision making. Here we demonstrate a
               novel, within-subject instrumental lever-pressing paradigm, in
               which mice shift between goal-directed and habitual actions. We
               identify a role for orbitofrontal cortex (OFC) in actions
               following outcome revaluation, and confirm that dorsal medial
               (DMS) and lateral striatum (DLS) mediate different action
               strategies. Simultaneous in vivo recordings of OFC, DMS and DLS
               neuronal ensembles during shifting reveal that the same neurons
               display different activities depending on whether presses are
               goal-directed or habitual, with DMS and OFC becoming more and
               DLS less engaged during goal-directed actions. Importantly, the
               magnitude of neural activity changes in OFC following changes in
               outcome value positively correlates with the level of
               goal-directed behavior. Chemogenetic inhibition of OFC disrupts
               goal-directed actions, whereas optogenetic activation of OFC
               specifically increases goal-directed pressing. These results
               also reveal a role for OFC in action revaluation, which has
               implications for understanding compulsive behavior.",
  journal   = "Nat. Commun.",
  publisher = "nature.com",
  volume    =  4,
  pages     = "2264",
  year      =  2013,
  language  = "en",
  issn      = "2041-1723",
  pmid      = "23921250",
  doi       = "10.1038/ncomms3264",
  pmc       = "PMC4026062"
}

@UNPUBLISHED{Huda2018-bn,
  title    = "Bidirectional control of goal-oriented action selection by
              distinct prefrontal cortex circuits",
  author   = "Huda, Rafiq and Sipe, Grayson O and Adam, Elie and
              Breton-Provencher, Vincent and Pho, Gerald N and Gunter, Liadan M
              and Wickersham, Ian R and Sur, Mriganka",
  abstract = "Summary The immense behavioral repertoire of animals necessitates
              mechanisms that select and suppress specific actions depending on
              current goals. The prefrontal cortex (PFC) has been suggested to
              orchestrate these processes by biasing activity in its target
              structures, but how its vastly converging inputs and diverging
              outputs are coordinated to control goal-oriented actions remains
              unclear. Here we use a bilateral task in which mice select
              between symmetric but opposing actions to show that distinct
              outputs from a subdivision of the PFC, the anterior cingulate
              cortex (ACC), promote correct and suppress incorrect actions.
              Surprisingly, ACC outputs to the superior colliculus principally
              inhibit incorrect actions. Optogenetic analyses and a
              projection-based activity model make the unexpected prediction
              that feedback from the ACC to the visual cortex promotes correct
              actions, which we confirm. Our results show that anatomically
              non-overlapping but functionally complementary PFC outputs
              bidirectionally control actions, and suggest a candidate
              organizing principle for PFC circuits.",
  journal  = "bioRxiv",
  pages    = "307009",
  month    =  jul,
  year     =  2018,
  language = "en",
  doi      = "10.1101/307009"
}

@ARTICLE{Botvinick2019-ac,
  title    = "Reinforcement Learning, Fast and Slow",
  author   = "Botvinick, Matthew and Ritter, Sam and Wang, Jane X and
              Kurth-Nelson, Zeb and Blundell, Charles and Hassabis, Demis",
  abstract = "Deep reinforcement learning (RL) methods have driven impressive
              advances in artificial intelligence in recent years, exceeding
              human performance in domains ranging from Atari to Go to no-limit
              poker. This progress has drawn the attention of cognitive
              scientists interested in understanding human learning. However,
              the concern has been raised that deep RL may be too
              sample-inefficient - that is, it may simply be too slow - to
              provide a plausible model of how humans learn. In the present
              review, we counter this critique by describing recently developed
              techniques that allow deep RL to operate more nimbly, solving
              problems much more quickly than previous methods. Although these
              techniques were developed in an AI context, we propose that they
              may have rich implications for psychology and neuroscience. A key
              insight, arising from these AI methods, concerns the fundamental
              connection between fast RL and slower, more incremental forms of
              learning.",
  journal  = "Trends Cogn. Sci.",
  month    =  apr,
  year     =  2019,
  language = "en",
  issn     = "1364-6613, 1879-307X",
  pmid     = "31003893",
  doi      = "10.1016/j.tics.2019.02.006"
}

@ARTICLE{Miller2017-em,
  title    = "Dorsal hippocampus contributes to model-based planning",
  author   = "Miller, Kevin J and Botvinick, Matthew M and Brody, Carlos D",
  abstract = "Planning can be defined as action selection that leverages an
              internal model of the outcomes likely to follow each possible
              action. Its neural mechanisms remain poorly understood. Here we
              adapt recent advances from human research for rats, presenting
              for the first time an animal task that produces many trials of
              planned behavior per session, making multitrial rodent
              experimental tools available to study planning. We use part of
              this toolkit to address a perennially controversial issue in
              planning: the role of the dorsal hippocampus. Although
              prospective hippocampal representations have been proposed to
              support planning, intact planning in animals with damaged
              hippocampi has been repeatedly observed. Combining formal
              algorithmic behavioral analysis with muscimol inactivation, we
              provide causal evidence directly linking dorsal hippocampus with
              planning behavior. Our results and methods open the door to new
              and more detailed investigations of the neural mechanisms of
              planning in the hippocampus and throughout the brain.",
  journal  = "Nat. Neurosci.",
  volume   =  20,
  number   =  9,
  pages    = "1269--1276",
  month    =  sep,
  year     =  2017,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "28758995",
  doi      = "10.1038/nn.4613",
  pmc      = "PMC5575950"
}

@ARTICLE{Karlsson2009-wx,
  title    = "Awake replay of remote experiences in the hippocampus",
  author   = "Karlsson, Mattias P and Frank, Loren M",
  abstract = "Hippocampal replay is thought to be essential for the
              consolidation of event memories in hippocampal-neocortical
              networks. Replay is present during both sleep and waking
              behavior, but although sleep replay involves the reactivation of
              stored representations in the absence of specific sensory inputs,
              awake replay is thought to depend on sensory input from the
              current environment. Here, we show that stored representations
              are reactivated during both waking and sleep replay. We found
              frequent awake replay of sequences of rat hippocampal place cells
              from a previous experience. This spatially remote replay was as
              common as local replay of the current environment and was more
              robust when the rat had recently been in motion than during
              extended periods of quiescence. Our results indicate that the
              hippocampus consistently replays past experiences during brief
              pauses in waking behavior, suggesting a role for waking replay in
              memory consolidation and retrieval.",
  journal  = "Nat. Neurosci.",
  volume   =  12,
  number   =  7,
  pages    = "913--918",
  month    =  jul,
  year     =  2009,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "19525943",
  doi      = "10.1038/nn.2344",
  pmc      = "PMC2750914"
}

@ARTICLE{Trimmer_Pete_C2008-ub,
  title     = "Mammalian choices: combining fast-but-inaccurate and
               slow-but-accurate decision-making systems",
  author    = "{Trimmer Pete C} and {Houston Alasdair I} and {Marshall James
               A.R} and {Bogacz Rafal} and {Paul Elizabeth S} and {Mendl Mike
               T} and {McNamara John M}",
  journal   = "Proceedings of the Royal Society B: Biological Sciences",
  publisher = "Royal Society",
  volume    =  275,
  number    =  1649,
  pages     = "2353--2361",
  month     =  oct,
  year      =  2008,
  doi       = "10.1098/rspb.2008.0417"
}

@ARTICLE{Beekman2001-xe,
  title    = "Phase transition between disordered and ordered foraging in
              Pharaoh's ants",
  author   = "Beekman, M and Sumpter, D J and Ratnieks, F L",
  abstract = "The complex collective behavior seen in many insect societies
              strongly suggests that a minimum number of workers are required
              for these societies to function effectively. Here we investigated
              the transition between disordered and ordered foraging in the
              Pharaoh's ant. We show that small colonies forage in a
              disorganized manner, with a transition to organized
              pheromone-based foraging in larger colonies. We also show that
              when food sources are difficult to locate through independent
              searching, this transition is first-order and exhibits
              hysteresis, comparable to a first-order phase transition found in
              many physical systems. To our knowledge, this is the first
              experimental evidence of a behavioral phase transition between a
              maladaptive (disorganized) and an adaptive (organized) state.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  98,
  number   =  17,
  pages    = "9703--9706",
  month    =  aug,
  year     =  2001,
  language = "en",
  issn     = "0027-8424",
  pmid     = "11493681",
  doi      = "10.1073/pnas.161285298",
  pmc      = "PMC55516"
}

@ARTICLE{Balaguer2016-ho,
  title    = "Neural Mechanisms of Hierarchical Planning in a Virtual Subway
              Network",
  author   = "Balaguer, Jan and Spiers, Hugo and Hassabis, Demis and
              Summerfield, Christopher",
  abstract = "Planning allows actions to be structured in pursuit of a future
              goal. However, in natural environments, planning over multiple
              possible future states incurs prohibitive computational costs. To
              represent plans efficiently, states can be clustered
              hierarchically into ``contexts''. For example, representing a
              journey through a subway network as a succession of individual
              states (stations) is more costly than encoding a sequence of
              contexts (lines) and context switches (line changes). Here, using
              functional brain imaging, we asked humans to perform a planning
              task in a virtual subway network. Behavioral analyses revealed
              that humans executed a hierarchically organized plan. Brain
              activity in the dorsomedial prefrontal cortex and premotor cortex
              scaled with the cost of hierarchical plan representation and
              unique neural signals in these regions signaled contexts and
              context switches. These results suggest that humans represent
              hierarchical plans using a network of caudal prefrontal
              structures. VIDEO ABSTRACT.",
  journal  = "Neuron",
  volume   =  90,
  number   =  4,
  pages    = "893--903",
  month    =  may,
  year     =  2016,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "27196978",
  doi      = "10.1016/j.neuron.2016.03.037",
  pmc      = "PMC4882377"
}

@INPROCEEDINGS{Lobo1997-qb,
  title     = "Decision making in a hybrid genetic algorithm",
  booktitle = "Proceedings of 1997 {IEEE} International Conference on
               Evolutionary Computation ({ICEC} '97)",
  author    = "Lobo, F G and Goldberg, D E",
  abstract  = "There are several issues that need to be taken into
               consideration when designing a hybrid problem solver. The paper
               focuses on one of them-decision making. More specifically, we
               address the following questions: given two different methods,
               how to get the most out of both of them? When should we use one
               and when should we use the other in order to get maximum
               efficiency? We present a model for hybridizing genetic
               algorithms (GAs) based on a concept that decision theorists call
               probability matching and we use it to combine an elitist
               selecto-recombinative GA with a simple hill climber (HC). Tests
               on an easy problem with a small population size match our
               intuition that both GA and HC are needed to solve the problem
               efficiently.",
  pages     = "121--125",
  month     =  apr,
  year      =  1997,
  keywords  = "decision theory;genetic algorithms;probability;decision
               making;hybrid genetic algorithm;hybrid problem solver;maximum
               efficiency;decision theorists;probability matching;elitist
               selecto-recombinative GA;simple hill climber;population
               size;Decision making;Genetic algorithms;Algorithm design and
               analysis;Testing;Expert systems;Turbines;Jet engines;Diversity
               reception;Maintenance engineering;Mathematical analysis",
  doi       = "10.1109/ICEC.1997.592281"
}

@ARTICLE{Gronenberg2008-rj,
  title   = "Structure and function of ant (Hymenoptera: Formicidae) brains:
             strength in numbers",
  author  = "Gronenberg, Wulfila",
  journal = "Myrmecol. News",
  volume  =  11,
  pages   = "25--36",
  year    =  2008,
  issn    = "1994-4136"
}

@ARTICLE{Seth_Anil_K2007-vj,
  title     = "The ecology of action selection: insights from artificial life",
  author    = "{Seth Anil K}",
  journal   = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  publisher = "Royal Society",
  volume    =  362,
  number    =  1485,
  pages     = "1545--1558",
  month     =  sep,
  year      =  2007,
  issn      = "0962-8436",
  doi       = "10.1098/rstb.2007.2052"
}

@ARTICLE{Azim2014-xn,
  title     = "Skilled reaching relies on a V2a propriospinal internal copy
               circuit",
  author    = "Azim, Eiman and Jiang, Juan and Alstermark, Bror and Jessell,
               Thomas M",
  abstract  = "The precision of skilled forelimb movement has long been
               presumed to rely on rapid feedback corrections triggered by
               internally directed copies of outgoing motor commands, but the
               functional relevance of inferred internal copy circuits has
               remained unclear. One class of spinal interneurons implicated in
               the control of mammalian forelimb movement, cervical
               propriospinal neurons (PNs), has the potential to convey an
               internal copy of premotor signals through dual innervation of
               forelimb-innervating motor neurons and precerebellar neurons of
               the lateral reticular nucleus. Here we examine whether the PN
               internal copy pathway functions in the control of goal-directed
               reaching. In mice, PNs include a genetically accessible
               subpopulation of cervical V2a interneurons, and their targeted
               ablation perturbs reaching while leaving intact other elements
               of forelimb movement. Moreover, optogenetic activation of the PN
               internal copy branch recruits a rapid cerebellar feedback loop
               that modulates forelimb motor neuron activity and severely
               disrupts reaching kinematics. Our findings implicate V2a PNs as
               the focus of an internal copy pathway assigned to the rapid
               updating of motor output during reaching behaviour.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  508,
  number    =  7496,
  pages     = "357--363",
  month     =  apr,
  year      =  2014,
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "24487617",
  doi       = "10.1038/nature13021",
  pmc       = "PMC4230338"
}

@ARTICLE{Gao2015-ik,
  title    = "On simplicity and complexity in the brave new world of
              large-scale neuroscience",
  author   = "Gao, Peiran and Ganguli, Surya",
  abstract = "Technological advances have dramatically expanded our ability to
              probe multi-neuronal dynamics and connectivity in the brain.
              However, our ability to extract a simple conceptual understanding
              from complex data is increasingly hampered by the lack of
              theoretically principled data analytic procedures, as well as
              theoretical frameworks for how circuit connectivity and dynamics
              can conspire to generate emergent behavioral and cognitive
              functions. We review and outline potential avenues for progress,
              including new theories of high dimensional data analysis, the
              need to analyze complex artificial networks, and methods for
              analyzing entire spaces of circuit models, rather than one model
              at a time. Such interplay between experiments, data analysis and
              theory will be indispensable in catalyzing conceptual advances in
              the age of large-scale neuroscience.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  32,
  pages    = "148--155",
  month    =  jun,
  year     =  2015,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "25932978",
  doi      = "10.1016/j.conb.2015.04.003"
}

@ARTICLE{Daw2011-jx,
  title     = "Model-based influences on humans' choices and striatal
               prediction errors",
  author    = "Daw, Nathaniel D and Gershman, Samuel J and Seymour, Ben and
               Dayan, Peter and Dolan, Raymond J",
  abstract  = "The mesostriatal dopamine system is prominently implicated in
               model-free reinforcement learning, with fMRI BOLD signals in
               ventral striatum notably covarying with model-free prediction
               errors. However, latent learning and devaluation studies show
               that behavior also shows hallmarks of model-based planning, and
               the interaction between model-based and model-free values,
               prediction errors, and preferences is underexplored. We designed
               a multistep decision task in which model-based and model-free
               influences on human choice behavior could be distinguished. By
               showing that choices reflected both influences we could then
               test the purity of the ventral striatal BOLD signal as a
               model-free report. Contrary to expectations, the signal
               reflected both model-free and model-based predictions in
               proportions matching those that best explained choice behavior.
               These results challenge the notion of a separate model-free
               learner and suggest a more integrated computational architecture
               for high-level human decision-making.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  69,
  number    =  6,
  pages     = "1204--1215",
  month     =  mar,
  year      =  2011,
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "21435563",
  doi       = "10.1016/j.neuron.2011.02.027",
  pmc       = "PMC3077926"
}

@ARTICLE{Czaczkes2015-tx,
  title    = "Trail pheromones: an integrative view of their role in social
              insect colony organization",
  author   = "Czaczkes, Tomer J and Gr{\"u}ter, Christoph and Ratnieks, Francis
              L W",
  abstract = "Trail pheromones do more than simply guide social insect workers
              from point A to point B. Recent research has revealed additional
              ways in which they help to regulate colony foraging, often via
              positive and negative feedback processes that influence the
              exploitation of the different resources that a colony has
              knowledge of. Trail pheromones are often complementary or
              synergistic with other information sources, such as individual
              memory. Pheromone trails can be composed of two or more
              pheromones with different functions, and information may be
              embedded in the trail network geometry. These findings indicate
              remarkable sophistication in how trail pheromones are used to
              regulate colony-level behavior, and how trail pheromones are used
              and deployed at the individual level.",
  journal  = "Annu. Rev. Entomol.",
  volume   =  60,
  pages    = "581--599",
  month    =  jan,
  year     =  2015,
  keywords = "ants; complex adaptive systems; complexity; organization;
              recruitment; review",
  language = "en",
  issn     = "0066-4170, 1545-4487",
  pmid     = "25386724",
  doi      = "10.1146/annurev-ento-010814-020627"
}

@ARTICLE{noauthor_undated-nr,
  title = "Goal Inference as Inverse Planning"
}

@ARTICLE{Blum2005-ut,
  title    = "Ant colony optimization: Introduction and recent trends",
  author   = "Blum, Christian",
  abstract = "Ant colony optimization is a technique for optimization that was
              introduced in the early 1990's. The inspiring source of ant
              colony optimization is the foraging behavior of real ant
              colonies. This behavior is exploited in artificial ant colonies
              for the search of approximate solutions to discrete optimization
              problems, to continuous optimization problems, and to important
              problems in telecommunications, such as routing and load
              balancing. First, we deal with the biological inspiration of ant
              colony optimization algorithms. We show how this biological
              inspiration can be transfered into an algorithm for discrete
              optimization. Then, we outline ant colony optimization in more
              general terms in the context of discrete optimization, and
              present some of the nowadays best-performing ant colony
              optimization variants. After summarizing some important
              theoretical results, we demonstrate how ant colony optimization
              can be applied to continuous optimization problems. Finally, we
              provide examples of an interesting recent research direction: The
              hybridization with more classical techniques from artificial
              intelligence and operations research.",
  journal  = "Phys. Life Rev.",
  volume   =  2,
  number   =  4,
  pages    = "353--373",
  month    =  dec,
  year     =  2005,
  keywords = "Ant colony optimization; Discrete optimization; Hybridization",
  issn     = "1571-0645",
  doi      = "10.1016/j.plrev.2005.10.001"
}

@ARTICLE{Pezzulo2019-dg,
  title    = "Planning at decision time and in the background during spatial
              navigation",
  author   = "Pezzulo, Giovanni and Donnarumma, Francesco and Maisto, Domenico
              and Stoianov, Ivilin",
  abstract = "Planning is the model-based approach to solving control problems.
              The hallmark of planning is the endogenous generation of
              dynamical representations of future states, like goal locations,
              or state sequences, like trajectories to the goal location, using
              an internal model of the task. We review recent evidence of
              model-based planning processes and the representation of future
              goal states in the brain of rodents and humans engaged in spatial
              navigation tasks. We highlight two distinct but complementary
              usages of planning as identified in artificial intelligence: `at
              decision time', to support goal-directed choices and sequential
              memory encoding, and `in the background', to learn behavioral
              policies and to optimize internal models. We discuss how two
              kinds of internally generated sequences in the hippocampus --
              theta and SWR sequences -- might participate in the neuronal
              implementation of these two planning modes, thus supporting a
              flexible model-based system for adaptive cognition and action.",
  journal  = "Current Opinion in Behavioral Sciences",
  volume   =  29,
  pages    = "69--76",
  month    =  oct,
  year     =  2019,
  issn     = "2352-1546",
  doi      = "10.1016/j.cobeha.2019.04.009"
}

@ARTICLE{Sych2019-ds,
  title    = "High-density multi-fiber photometry for studying large-scale
              brain circuit dynamics",
  author   = "Sych, Yaroslav and Chernysheva, Maria and Sumanovski, Lazar T and
              Helmchen, Fritjof",
  abstract = "Animal behavior originates from neuronal activity distributed
              across brain-wide networks. However, techniques available to
              assess large-scale neural dynamics in behaving animals remain
              limited. Here we present compact, chronically implantable,
              high-density arrays of optical fibers that enable multi-fiber
              photometry and optogenetic perturbations across many regions in
              the mammalian brain. In mice engaged in a texture discrimination
              task, we achieved simultaneous photometric calcium recordings
              from networks of 12-48 brain regions, including striatal,
              thalamic, hippocampal and cortical areas. Furthermore, we
              optically perturbed subsets of regions in VGAT-ChR2 mice by
              targeting specific fiber channels with a spatial light modulator.
              Perturbation of ventral thalamic nuclei caused distributed
              network modulation and behavioral deficits. Finally, we
              demonstrate multi-fiber photometry in freely moving animals,
              including simultaneous recordings from two mice during social
              interaction. High-density multi-fiber arrays are versatile tools
              for the investigation of large-scale brain dynamics during
              behavior.",
  journal  = "Nat. Methods",
  month    =  may,
  year     =  2019,
  language = "en",
  issn     = "1548-7091, 1548-7105",
  pmid     = "31086339",
  doi      = "10.1038/s41592-019-0400-4"
}

@ARTICLE{Forstmeier2011-tz,
  title     = "Cryptic multiple hypotheses testing in linear models:
               overestimated effect sizes and the winner's curse",
  author    = "Forstmeier, Wolfgang and Schielzeth, Holger",
  abstract  = "Fitting generalised linear models (GLMs) with more than one
               predictor has become the standard method of analysis in
               evolutionary and behavioural research. Often, GLMs are used for
               exploratory data analysis, where one starts with a complex full
               model including interaction terms and then simplifies by
               removing non-significant terms. While this approach can be
               useful, it is problematic if significant effects are interpreted
               as if they arose from a single a priori hypothesis test. This is
               because model selection involves cryptic multiple hypothesis
               testing, a fact that has only rarely been acknowledged or
               quantified. We show that the probability of finding at least one
               'significant' effect is high, even if all null hypotheses are
               true (e.g. 40\% when starting with four predictors and their
               two-way interactions). This probability is close to theoretical
               expectations when the sample size (N) is large relative to the
               number of predictors including interactions (k). In contrast,
               type I error rates strongly exceed even those expectations when
               model simplification is applied to models that are over-fitted
               before simplification (low N/k ratio). The increase in
               false-positive results arises primarily from an overestimation
               of effect sizes among significant predictors, leading to
               upward-biased effect sizes that often cannot be reproduced in
               follow-up studies ('the winner's curse'). Despite having their
               own problems, full model tests and P value adjustments can be
               used as a guide to how frequently type I errors arise by
               sampling variation alone. We favour the presentation of full
               models, since they best reflect the range of predictors
               investigated and ensure a balanced representation also of
               non-significant results.",
  journal   = "Behav. Ecol. Sociobiol.",
  publisher = "Springer",
  volume    =  65,
  number    =  1,
  pages     = "47--55",
  month     =  jan,
  year      =  2011,
  language  = "en",
  issn      = "0340-5443",
  pmid      = "21297852",
  doi       = "10.1007/s00265-010-1038-5",
  pmc       = "PMC3015194"
}

@ARTICLE{Smith2004-ti,
  title    = "Psychology and neurobiology of simple decisions",
  author   = "Smith, Philip L and Ratcliff, Roger",
  abstract = "Patterns of neural firing linked to eye movement decisions show
              that behavioral decisions are predicted by the differential
              firing rates of cells coding selected and nonselected stimulus
              alternatives. These results can be interpreted using models
              developed in mathematical psychology to model behavioral
              decisions. Current models assume that decisions are made by
              accumulating noisy stimulus information until sufficient
              information for a response is obtained. Here, the models, and the
              techniques used to test them against response-time distribution
              and accuracy data, are described. Such models provide a
              quantitative link between the time-course of behavioral decisions
              and the growth of stimulus information in neural firing data.",
  journal  = "Trends Neurosci.",
  volume   =  27,
  number   =  3,
  pages    = "161--168",
  month    =  mar,
  year     =  2004,
  language = "en",
  issn     = "0166-2236",
  pmid     = "15036882",
  doi      = "10.1016/j.tins.2004.01.006"
}

@UNPUBLISHED{Obaid2019-jn,
  title    = "Massively Parallel Microwire Arrays Integrated with {CMOS} chips
              for Neural Recording",
  author   = "Obaid, Abdulmalik and Hanna, Mina-Elraheb and Wu, Yu-Wei and
              Kollo, Mihaly and Racz, Romeo and Angle, Matthew R and
              M{\"u}ller, Jan and Brackbill, Nora and Wray, William and Franke,
              Felix and Chichilinsky, E J and Hierlemann, Andreas and Ding, Jun
              B and Schaefer, Andreas T and Melosh, Nicholas A",
  abstract = "Abstract Multiple-channel count neural recordings of brain
              activity are a powerful technique that is increasingly uncovering
              new aspects of neural communication, computation, and prosthetic
              interfaces. However, while silicon CMOS devices continue to scale
              rapidly in number and power in planar geometries, this scaling
              has not been followed for large-scale mapping along three
              dimensions. Here, we present a new strategy to interface
              CMOS-based devices with a three-dimensional microwire array,
              providing the link between rapidly-developing electronics, and
              high density neural interfaces. The system consists of a bundle
              of insulated and spaced microwires perpendicularly mated to a
              commercial large-scale CMOS microelectrode array, such as a
              camera chip. The modular nature of the design enables a variety
              of microwire types and sizes to be integrated with different
              types of silicon-based arrays, allowing channel counts to be
              scaled from a few dozen to thousands of electrodes using the same
              fundamental platform. This system has excellent recording
              performance, demonstrated via single unit and local-field
              potential recordings in isolated retina, and in the motor cortex
              and striatum of awake moving mice. This concept links the rapid
              progress and power of commercial multiplexing, digitisation and
              data acquisition hardware together with a three-dimensional
              neural interface.",
  journal  = "bioRxiv",
  pages    = "573295",
  month    =  mar,
  year     =  2019,
  language = "en",
  doi      = "10.1101/573295"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Tarsitano1997-jo,
  title    = "Araneophagic jumping spiders discriminate between detour routes
              that do and do not lead to prey",
  author   = "Tarsitano, Michael S and Jackson, Robert R",
  abstract = "In a laboratory study, 12 different experimental set-ups were
              used to examine the ability ofPortia fimbriataa web-invading
              araneophagic jumping spider from Queensland, Australia, to choose
              between two detour paths, only one of which led to a lure (a
              dead, dried spider). Regardless of set-up, the spider could see
              the lure when on the starting platform of the apparatus, but not
              after leaving the starting platform. The spider consistently
              chose the `correct route' (the route that led to the lure) more
              often than the `wrong route' (the route that did not lead to the
              lure). In these tests, the spider was able to make detours that
              required walking about 180° away from the lure and walking past
              where the incorrect route began. There was also a pronounced
              relationship between time of day when tests were carried out and
              the spider's tendency to choose a route. Furthermore, those
              spiders that chose the wrong route abandoned the detour more
              frequently than those that chose the correct route, despite both
              groups being unable to see the lure when the decision was made to
              abandon the detour.",
  journal  = "Anim. Behav.",
  volume   =  53,
  number   =  2,
  pages    = "257--266",
  month    =  feb,
  year     =  1997,
  issn     = "0003-3472",
  doi      = "10.1006/anbe.1996.0372"
}

@ARTICLE{Garrett_undated-lg,
  title  = "Biased belief updating and suboptimal choice in foraging decisions",
  author = "Garrett, Neil and Daw, Nathaniel D",
  doi    = "10.1101/713941"
}

@ARTICLE{Bolker2009-az,
  title    = "Generalized linear mixed models: a practical guide for ecology
              and evolution",
  author   = "Bolker, Benjamin M and Brooks, Mollie E and Clark, Connie J and
              Geange, Shane W and Poulsen, John R and Stevens, M Henry H and
              White, Jada-Simone S",
  abstract = "How should ecologists and evolutionary biologists analyze
              nonnormal data that involve random effects? Nonnormal data such
              as counts or proportions often defy classical statistical
              procedures. Generalized linear mixed models (GLMMs) provide a
              more flexible approach for analyzing nonnormal data when random
              effects are present. The explosion of research on GLMMs in the
              last decade has generated considerable uncertainty for
              practitioners in ecology and evolution. Despite the availability
              of accurate techniques for estimating GLMM parameters in simple
              cases, complex GLMMs are challenging to fit and statistical
              inference such as hypothesis testing remains difficult. We review
              the use (and misuse) of GLMMs in ecology and evolution, discuss
              estimation and inference and summarize 'best-practice' data
              analysis procedures for scientists facing this challenge.",
  journal  = "Trends Ecol. Evol.",
  volume   =  24,
  number   =  3,
  pages    = "127--135",
  month    =  mar,
  year     =  2009,
  language = "en",
  issn     = "0169-5347",
  pmid     = "19185386",
  doi      = "10.1016/j.tree.2008.10.008"
}

@ARTICLE{Miller_undated-ho,
  title  = "Re-aligning models of habitual and goal-directed decision-making",
  author = "Miller, Kevin and Ludvig, Elliot A and Pezzulo, Giovanni and
            Shenhav, Amitai"
}

@ARTICLE{Doll2012-qb,
  title    = "The ubiquity of model-based reinforcement learning",
  author   = "Doll, Bradley B and Simon, Dylan A and Daw, Nathaniel D",
  abstract = "The reward prediction error (RPE) theory of dopamine (DA)
              function has enjoyed great success in the neuroscience of
              learning and decision-making. This theory is derived from
              model-free reinforcement learning (RL), in which choices are made
              simply on the basis of previously realized rewards. Recently,
              attention has turned to correlates of more flexible, albeit
              computationally complex, model-based methods in the brain. These
              methods are distinguished from model-free learning by their
              evaluation of candidate actions using expected future outcomes
              according to a world model. Puzzlingly, signatures from these
              computations seem to be pervasive in the very same regions
              previously thought to support model-free learning. Here, we
              review recent behavioral and neural evidence about these two
              systems, in attempt to reconcile their enigmatic cohabitation in
              the brain.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  22,
  number   =  6,
  pages    = "1075--1081",
  month    =  dec,
  year     =  2012,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "22959354",
  doi      = "10.1016/j.conb.2012.08.003",
  pmc      = "PMC3513648"
}

@UNPUBLISHED{Miller2018-ag,
  title    = "Habits without Values",
  author   = "Miller, Kevin and Shenhav, Amitai and Ludvig, Elliot",
  abstract = "Habits form a crucial component of behavior. In recent years, key
              computational models have conceptualized habits as arising from
              model-free reinforcement learning (RL) mechanisms, which
              typically select between available actions based on the future
              value expected to result from each. Traditionally, however,
              habits have been understood as behaviors that can be triggered
              directly by a stimulus, without requiring the animal to evaluate
              expected outcomes. Here, we develop a computational model
              instantiating this traditional view, in which habits develop
              through the direct strengthening of recently taken actions rather
              than through the encoding of outcomes. We demonstrate that this
              model accounts for key behavioral manifestations of habits,
              including insensitivity to outcome devaluation and contingency
              degradation, as well as the effects of reinforcement schedule on
              the rate of habit formation. The model also explains the
              prevalent observation of perseveration in repeated-choice tasks
              as an additional behavioral manifestation of the habit system. We
              suggest that mapping habitual behaviors onto value-free
              mechanisms provides a parsimonious account of existing behavioral
              and neural data. This mapping may provide a new foundation for
              building robust and comprehensive models of the interaction of
              habits with other, more goal-directed types of behaviors and help
              to better guide research into the neural mechanisms underlying
              control of instrumental behavior more generally.",
  journal  = "bioRxiv",
  pages    = "067603",
  month    =  mar,
  year     =  2018,
  language = "en",
  doi      = "10.1101/067603"
}

@ARTICLE{Friston2017-ib,
  title    = "Active Inference: A Process Theory",
  author   = "Friston, Karl and FitzGerald, Thomas and Rigoli, Francesco and
              Schwartenbeck, Philipp and Pezzulo, Giovanni",
  abstract = "This article describes a process theory based on active inference
              and belief propagation. Starting from the premise that all
              neuronal processing (and action selection) can be explained by
              maximizing Bayesian model evidence-or minimizing variational free
              energy-we ask whether neuronal responses can be described as a
              gradient descent on variational free energy. Using a standard
              (Markov decision process) generative model, we derive the
              neuronal dynamics implicit in this description and reproduce a
              remarkable range of well-characterized neuronal phenomena. These
              include repetition suppression, mismatch negativity, violation
              responses, place-cell activity, phase precession, theta
              sequences, theta-gamma coupling, evidence accumulation,
              race-to-bound dynamics, and transfer of dopamine responses.
              Furthermore, the (approximately Bayes' optimal) behavior
              prescribed by these dynamics has a degree of face validity,
              providing a formal explanation for reward seeking, context
              learning, and epistemic foraging. Technically, the fact that a
              gradient descent appears to be a valid description of neuronal
              activity means that variational free energy is a Lyapunov
              function for neuronal dynamics, which therefore conform to
              Hamilton's principle of least action.",
  journal  = "Neural Comput.",
  volume   =  29,
  number   =  1,
  pages    = "1--49",
  month    =  jan,
  year     =  2017,
  language = "en",
  issn     = "0899-7667, 1530-888X",
  pmid     = "27870614",
  doi      = "10.1162/NECO\_a\_00912"
}

@ARTICLE{Daw2014-uh,
  title    = "The algorithmic anatomy of model-based evaluation",
  author   = "Daw, Nathaniel D and Dayan, Peter",
  abstract = "Despite many debates in the first half of the twentieth century,
              it is now largely a truism that humans and other animals build
              models of their environments and use them for prediction and
              control. However, model-based (MB) reasoning presents severe
              computational challenges. Alternative, computationally simpler,
              model-free (MF) schemes have been suggested in the reinforcement
              learning literature, and have afforded influential accounts of
              behavioural and neural data. Here, we study the realization of MB
              calculations, and the ways that this might be woven together with
              MF values and evaluation methods. There are as yet mostly only
              hints in the literature as to the resulting tapestry, so we offer
              more preview than review.",
  journal  = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  volume   =  369,
  number   =  1655,
  month    =  nov,
  year     =  2014,
  keywords = "Monte Carlo tree search; model-based reasoning; model-free
              reasoning; orbitofrontal cortex; reinforcement learning; striatum",
  language = "en",
  issn     = "0962-8436, 1471-2970",
  pmid     = "25267820",
  doi      = "10.1098/rstb.2013.0478",
  pmc      = "PMC4186231"
}

@ARTICLE{Russek2017-vt,
  title    = "Predictive representations can link model-based reinforcement
              learning to model-free mechanisms",
  author   = "Russek, Evan M and Momennejad, Ida and Botvinick, Matthew M and
              Gershman, Samuel J and Daw, Nathaniel D",
  abstract = "Humans and animals are capable of evaluating actions by
              considering their long-run future rewards through a process
              described using model-based reinforcement learning (RL)
              algorithms. The mechanisms by which neural circuits perform the
              computations prescribed by model-based RL remain largely unknown;
              however, multiple lines of evidence suggest that neural circuits
              supporting model-based behavior are structurally homologous to
              and overlapping with those thought to carry out model-free
              temporal difference (TD) learning. Here, we lay out a family of
              approaches by which model-based computation may be built upon a
              core of TD learning. The foundation of this framework is the
              successor representation, a predictive state representation that,
              when combined with TD learning of value predictions, can produce
              a subset of the behaviors associated with model-based learning,
              while requiring less decision-time computation than dynamic
              programming. Using simulations, we delineate the precise
              behavioral capabilities enabled by evaluating actions using this
              approach, and compare them to those demonstrated by biological
              organisms. We then introduce two new algorithms that build upon
              the successor representation while progressively mitigating its
              limitations. Because this framework can account for the full
              range of observed putatively model-based behaviors while still
              utilizing a core TD framework, we suggest that it represents a
              neurally plausible family of mechanisms for model-based
              evaluation.",
  journal  = "PLoS Comput. Biol.",
  volume   =  13,
  number   =  9,
  pages    = "e1005768",
  month    =  sep,
  year     =  2017,
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "28945743",
  doi      = "10.1371/journal.pcbi.1005768",
  pmc      = "PMC5628940"
}

@ARTICLE{Maisto_Domenico2015-mt,
  title     = "Divide et impera: subgoaling reduces the complexity of
               probabilistic inference and problem solving",
  author    = "{Maisto Domenico} and {Donnarumma Francesco} and {Pezzulo
               Giovanni}",
  journal   = "J. R. Soc. Interface",
  publisher = "Royal Society",
  volume    =  12,
  number    =  104,
  pages     = "20141335",
  month     =  mar,
  year      =  2015,
  issn      = "1742-5689",
  doi       = "10.1098/rsif.2014.1335"
}

@MISC{Anil_K_Seth_Tony_J_Prescott_Joanna_J_Bryson_undated-eg,
  title    = "Modelling Natural Action Selection",
  author   = "{Anil K. Seth, Tony J. Prescott, Joanna J. Bryson}",
  keywords = "books"
}

@ARTICLE{Deneubourg1989-ff,
  title     = "Collective patterns and decision-making",
  author    = "Deneubourg, J L and Goss, S",
  abstract  = "Autocatalytic interactions between the members of an animal
               group or society, and particularly chemically or visually
               mediated allelomimesis, can be an important factor in the
               organisation of their collective activity. Furthermore, the
               interactions between the individuals and the environment allow
               different collective patterns and decisions to appear under
               different conditions, with the same individual behaviour. While
               most clearly demonstrable in social insects, these principles
               are fundamental to schools of fishes, flocks of birds, groups of
               mammals, and many other social aggregates. The analysis of
               collective behaviour in these terms implies detailed observation
               of both individual and collective behaviour, combined with
               mathematical modelling to link the two.",
  journal   = "Ethol. Ecol. Evol.",
  publisher = "Taylor \& Francis",
  volume    =  1,
  number    =  4,
  pages     = "295--311",
  month     =  dec,
  year      =  1989,
  issn      = "0394-9370",
  doi       = "10.1080/08927014.1989.9525500"
}

@ARTICLE{Ramsch2012-so,
  title    = "A mathematical model of foraging in a dynamic environment by
              trail-laying Argentine ants",
  author   = "Ramsch, Kai and Reid, Chris R and Beekman, Madeleine and
              Middendorf, Martin",
  abstract = "Ants live in dynamically changing environments, where food
              sources become depleted and alternative sources appear. Yet most
              mathematical models of ant foraging assume that the ants'
              foraging environment is static. Here we describe a mathematical
              model of ant foraging in a dynamic environment. Our model
              attempts to explain recent empirical data on dynamic foraging in
              the Argentine ant Linepithema humile (Mayr). The ants are able to
              find the shortest path in a Towers of Hanoi maze, a complex
              network containing 32,768 alternative paths, even when the maze
              is altered dynamically. We modify existing models developed to
              explain ant foraging in static environments, to elucidate what
              possible mechanisms allow the ants to quickly adapt to changes in
              their foraging environment. Our results suggest that navigation
              of individual ants based on a combination of one pheromone
              deposited during foraging and directional information enables the
              ants to adapt their foraging trails and recreates the
              experimental results.",
  journal  = "J. Theor. Biol.",
  volume   =  306,
  pages    = "32--45",
  month    =  aug,
  year     =  2012,
  language = "en",
  issn     = "0022-5193, 1095-8541",
  pmid     = "22575583",
  doi      = "10.1016/j.jtbi.2012.04.003"
}

@ARTICLE{Vittori2006-qd,
  title    = "Path efficiency of ant foraging trails in an artificial network",
  author   = "Vittori, Karla and Talbot, Gr{\'e}goire and Gautrais, Jacques and
              Fourcassi{\'e}, Vincent and Ara{\'u}jo, Aluizio F R and
              Theraulaz, Guy",
  abstract = "In this paper we present an individual-based model describing the
              foraging behavior of ants moving in an artificial network of
              tunnels in which several interconnected paths can be used to
              reach a single food source. Ants lay a trail pheromone while
              moving in the network and this pheromone acts as a system of mass
              recruitment that attracts other ants in the network. The rules
              implemented in the model are based on measures of the decisions
              taken by ants at tunnel bifurcations during real experiments. The
              collective choice of the ants is estimated by measuring their
              probability to take a given path in the network. Overall, we
              found a good agreement between the results of the simulations and
              those of the experiments, showing that simple behavioral rules
              can lead ants to find the shortest paths in the network. The
              match between the experiments and the model, however, was better
              for nestbound than for outbound ants. A sensitivity study of the
              model suggests that the bias observed in the choice of the ants
              at asymmetrical bifurcations is a key behavior to reproduce the
              collective choice observed in the experiments.",
  journal  = "J. Theor. Biol.",
  volume   =  239,
  number   =  4,
  pages    = "507--515",
  month    =  apr,
  year     =  2006,
  language = "en",
  issn     = "0022-5193",
  pmid     = "16199059",
  doi      = "10.1016/j.jtbi.2005.08.017"
}

@INPROCEEDINGS{Gordon2004-gu,
  title     = "Evolving sparse direction maps for maze pathfinding",
  booktitle = "Proceedings of the 2004 Congress on Evolutionary Computation
               ({IEEE} Cat. {No.04TH8753})",
  author    = "Gordon, V S and Matley, Z",
  abstract  = "A genetic algorithm is used to solve a class of maze pathfinding
               problems. In particular, we find a complete set of paths
               directing an agent from any position in the maze towards a
               single goal. To this end, we define a sparse direction map,
               wherein the maze is divided into sectors, each of which contains
               a direction indicator. Maps are evolved using a simple genetic
               algorithm. The fitness function samples the efficacy of the map
               from random starting points, this estimating the likelihood that
               agents find the goal. The framework was effective in evolving
               successful maps for three different mazes of varying size and
               complexity, resulting in interesting and lifelike agent behavior
               suitable for games, but not always the shortest paths.",
  volume    =  1,
  pages     = "835--838 Vol.1",
  month     =  jun,
  year      =  2004,
  keywords  = "genetic algorithms;path planning;game theory;graph theory;sparse
               direction maps;maze pathfinding;genetic algorithm;fitness
               function;shortest paths;direction indicator;agent
               behavior;Genetic algorithms;Filling;Counting circuits;Computer
               science;Delay",
  doi       = "10.1109/CEC.2004.1330947"
}

@ARTICLE{Bogacz_Rafal2007-kq,
  title     = "Extending a biologically inspired model of choice:
               multi-alternatives, nonlinearity and value-based
               multidimensional choice",
  author    = "{Bogacz Rafal} and {Usher Marius} and {Zhang Jiaxiang} and
               {McClelland James L}",
  journal   = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  publisher = "Royal Society",
  volume    =  362,
  number    =  1485,
  pages     = "1655--1670",
  month     =  sep,
  year      =  2007,
  issn      = "0962-8436",
  doi       = "10.1098/rstb.2007.2059"
}

@ARTICLE{Kording2007-va,
  title    = "Decision theory: what ``should'' the nervous system do?",
  author   = "K{\"o}rding, Konrad",
  abstract = "The purpose of our nervous system is to allow us to successfully
              interact with our environment. This normative idea is formalized
              by decision theory that defines which choices would be most
              beneficial. We live in an uncertain world, and each decision may
              have many possible outcomes; choosing the best decision is thus
              complicated. Bayesian decision theory formalizes these problems
              in the presence of uncertainty and often provides compact models
              that predict observed behavior. With its elegant formalization of
              the problems faced by the nervous system, it promises to become a
              major inspiration for studies in neuroscience.",
  journal  = "Science",
  volume   =  318,
  number   =  5850,
  pages    = "606--610",
  month    =  oct,
  year     =  2007,
  language = "en",
  issn     = "0036-8075, 1095-9203",
  pmid     = "17962554",
  doi      = "10.1126/science.1142998"
}

@ARTICLE{Trimmer2011-pv,
  title     = "Decision-making under uncertainty: biases and Bayesians",
  author    = "Trimmer, Pete C and Houston, Alasdair I and Marshall, James A R
               and Mendl, Mike T and Paul, Elizabeth S and McNamara, John M",
  abstract  = "Animals (including humans) often face circumstances in which the
               best choice of action is not certain. Environmental cues may be
               ambiguous, and choices may be risky. This paper reviews the
               theoretical side of decision-making under uncertainty,
               particularly with regard to unknown risk (ambiguity). We use
               simple models to show that, irrespective of pay-offs, whether it
               is optimal to bias probability estimates depends upon how those
               estimates have been generated. In particular, if estimates have
               been calculated in a Bayesian framework with a sensible prior,
               it is best to use unbiased estimates. We review the extent of
               evidence for and against viewing animals (including humans) as
               Bayesian decision-makers. We pay particular attention to the
               Ellsberg Paradox, a classic result from experimental economics,
               in which human subjects appear to deviate from optimal
               decision-making by demonstrating an apparent aversion to
               ambiguity in a choice between two options with equal expected
               rewards. The paradox initially seems to be an example where
               decision-making estimates are biased relative to the Bayesian
               optimum. We discuss the extent to which the Bayesian paradigm
               might be applied to the evolution of decision-makers and how the
               Ellsberg Paradox may, with a deeper understanding, be resolved.",
  journal   = "Anim. Cogn.",
  publisher = "Springer",
  volume    =  14,
  number    =  4,
  pages     = "465--476",
  month     =  jul,
  year      =  2011,
  language  = "en",
  issn      = "1435-9448, 1435-9456",
  pmid      = "21360119",
  doi       = "10.1007/s10071-011-0387-4"
}

@ARTICLE{Trimmer_Pete_C2008-ht,
  title     = "Mammalian choices: combining fast-but-inaccurate and
               slow-but-accurate decision-making systems",
  author    = "{Trimmer Pete C} and {Houston Alasdair I} and {Marshall James
               A.R} and {Bogacz Rafal} and {Paul Elizabeth S} and {Mendl Mike
               T} and {McNamara John M}",
  journal   = "Proceedings of the Royal Society B: Biological Sciences",
  publisher = "Royal Society",
  volume    =  275,
  number    =  1649,
  pages     = "2353--2361",
  month     =  oct,
  year      =  2008,
  doi       = "10.1098/rspb.2008.0417"
}

@ARTICLE{Franks2006-ul,
  title     = "Not everything that counts can be counted: ants use multiple
               metrics for a single nest trait",
  author    = "Franks, Nigel R and Dornhaus, Anna and Metherell, Bonnie G and
               Nelson, Toby R and Lanfear, Sophie A J and Symes, William S",
  abstract  = "There are claims in the literature that certain insects can
               count. We question the generality of these claims and suggest
               that summation rather than counting (sensu stricto) is a more
               likely explanation. We show that Temnothorax albipennis ant
               colonies can discriminate between potential nest sites with
               different numbers of entrances. However, our experiments suggest
               that the ants use ambient light levels within the nest cavity to
               assess the abundance of nest entrances rather than counting per
               se. Intriguingly, Weber's Law cannot explain the ants'
               inaccuracy. The ants also use a second metric, independent of
               light, to assess and discriminate against wide entrances. Thus,
               these ants use at least two metrics to evaluate one nest trait:
               the configuration of the portals to their potential homes.",
  journal   = "Proc. Biol. Sci.",
  publisher = "royalsocietypublishing.org",
  volume    =  273,
  number    =  1583,
  pages     = "165--169",
  month     =  jan,
  year      =  2006,
  language  = "en",
  issn      = "0962-8452",
  pmid      = "16555783",
  doi       = "10.1098/rspb.2005.3312",
  pmc       = "PMC1560019"
}

@ARTICLE{J_Valone2006-fh,
  title    = "Are animals capable of Bayesian updating? An empirical review",
  author   = "J. Valone, Thomas",
  abstract = "Numerous behavioral models assume individuals combine knowledge
              in the form of a prior distribution with current sample
              information using Bayesian updating to estimate the quality of
              environmental parameters. I examine this assumption by reviewing
              11 empirical studies. Six studies compared observed behavior to
              predictions of Bayesian and non-Bayesian models, while five
              studies manipulated prior distributions directly and observed how
              such manipulations altered behavior. Eight species of birds,
              three mammals, one fish and one insect exhibited behavior
              consistent with Bayesian updating models; one studied bird
              species failed to show evidence of Bayesian updating. Most
              studies examined how individuals estimated food patch quality but
              two investigated mating decisions. These studies suggest a
              variety of animals in different ecological contexts behave in
              manners consistent with predictions of Bayesian updating models.
              Future work on decision-making should focus on understanding how
              animals learn prior distributions and on decision-making in
              additional ecological contexts.",
  journal  = "Oikos",
  volume   =  112,
  number   =  2,
  pages    = "252--259",
  month    =  feb,
  year     =  2006,
  issn     = "0030-1299, 1600-0706",
  doi      = "10.1111/j.0030-1299.2006.13465.x"
}

@ARTICLE{Daunizeau2010-kj,
  title    = "Observing the observer (I): meta-bayesian models of learning and
              decision-making",
  author   = "Daunizeau, Jean and den Ouden, Hanneke E M and Pessiglione,
              Matthias and Kiebel, Stefan J and Stephan, Klaas E and Friston,
              Karl J",
  abstract = "In this paper, we present a generic approach that can be used to
              infer how subjects make optimal decisions under uncertainty. This
              approach induces a distinction between a subject's perceptual
              model, which underlies the representation of a hidden ``state of
              affairs'' and a response model, which predicts the ensuing
              behavioural (or neurophysiological) responses to those inputs. We
              start with the premise that subjects continuously update a
              probabilistic representation of the causes of their sensory
              inputs to optimise their behaviour. In addition, subjects have
              preferences or goals that guide decisions about actions given the
              above uncertain representation of these hidden causes or state of
              affairs. From a Bayesian decision theoretic perspective,
              uncertain representations are so-called ``posterior'' beliefs,
              which are influenced by subjective ``prior'' beliefs. Preferences
              and goals are encoded through a ``loss'' (or ``utility'')
              function, which measures the cost incurred by making any
              admissible decision for any given (hidden) state of affair. By
              assuming that subjects make optimal decisions on the basis of
              updated (posterior) beliefs and utility (loss) functions, one can
              evaluate the likelihood of observed behaviour. Critically, this
              enables one to ``observe the observer'', i.e. identify (context-
              or subject-dependent) prior beliefs and utility-functions using
              psychophysical or neurophysiological measures. In this paper, we
              describe the main theoretical components of this meta-Bayesian
              approach (i.e. a Bayesian treatment of Bayesian decision
              theoretic predictions). In a companion paper ('Observing the
              observer (II): deciding when to decide'), we describe a concrete
              implementation of it and demonstrate its utility by applying it
              to simulated and real reaction time data from an associative
              learning task.",
  journal  = "PLoS One",
  volume   =  5,
  number   =  12,
  pages    = "e15554",
  month    =  dec,
  year     =  2010,
  language = "en",
  issn     = "1932-6203",
  pmid     = "21179480",
  doi      = "10.1371/journal.pone.0015554",
  pmc      = "PMC3001878"
}

@ARTICLE{McFarland1977-gm,
  title    = "Decision making in animals",
  author   = "McFarland, D J",
  abstract = "Animals must make decisions about when to feed, when to court,
              when to sleep, and so on, in such a way as to maximise as far as
              possible their chances of survival and reproductive success. It
              is possible to formulate in mathematical terms the optimal
              strategy for an animal to pursue. The theoretical optimum
              behaviour can be compared with the actual behaviour of the
              animal, and perhaps shed some light on the evolution of
              behaviour.",
  journal  = "Nature",
  volume   =  269,
  number   =  5623,
  pages    = "15--21",
  month    =  sep,
  year     =  1977,
  issn     = "0028-0836, 1476-4687",
  doi      = "10.1038/269015a0"
}

@INPROCEEDINGS{Rothkopf2011-xk,
  title     = "Preference Elicitation and Inverse Reinforcement Learning",
  booktitle = "Machine Learning and Knowledge Discovery in Databases",
  author    = "Rothkopf, Constantin A and Dimitrakakis, Christos",
  abstract  = "We state the problem of inverse reinforcement learning in terms
               of preference elicitation, resulting in a principled (Bayesian)
               statistical formulation. This generalises previous work on
               Bayesian inverse reinforcement learning and allows us to obtain
               a posterior distribution on the agent's preferences, policy and
               optionally, the obtained reward sequence, from observations. We
               examine the relation of the resulting approach to other
               statistical methods for inverse reinforcement learning via
               analysis and experimental results. We show that preferences can
               be determined accurately, even if the observed agent's policy is
               sub-optimal with respect to its own preferences. In that case,
               significantly improved policies with respect to the agent's
               preferences are obtained, compared to both other methods and to
               the performance of the demonstrated policy.",
  publisher = "Springer Berlin Heidelberg",
  pages     = "34--48",
  year      =  2011,
  doi       = "10.1007/978-3-642-23808-6\_3"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{McNamara1980-xn,
  title     = "The application of statistical decision theory to animal
               behaviour",
  author    = "McNamara, J and Houston, A",
  abstract  = "Statistical decision theory is discussed as a general framework
               for analysing how animals should learn. Attention is focused on
               optimal foraging behaviour in stochastic environments. We
               emphasise the distinction between the mathematical procedure
               that can be used to find optimal solutions and the mechanism an
               animal might use to implement such solutions. The mechanisms
               might be specific to a restricted class of problems and produce
               suboptimal behaviour when faced with problems outside this
               class. We illustrate this point by an …",
  journal   = "J. Theor. Biol.",
  publisher = "Elsevier",
  volume    =  85,
  number    =  4,
  pages     = "673--690",
  month     =  aug,
  year      =  1980,
  language  = "en",
  issn      = "0022-5193",
  pmid      = "7442286"
}

@ARTICLE{Clarke2015-kk,
  title    = "Human and machine learning in non-Markovian decision making",
  author   = "Clarke, Aaron Michael and Friedrich, Johannes and Tartaglia,
              Elisa M and Marchesotti, Silvia and Senn, Walter and Herzog,
              Michael H",
  abstract = "Humans can learn under a wide variety of feedback conditions.
              Reinforcement learning (RL), where a series of rewarded decisions
              must be made, is a particularly important type of learning.
              Computational and behavioral studies of RL have focused mainly on
              Markovian decision processes, where the next state depends on
              only the current state and action. Little is known about
              non-Markovian decision making, where the next state depends on
              more than the current state and action. Learning is
              non-Markovian, for example, when there is no unique mapping
              between actions and feedback. We have produced a model based on
              spiking neurons that can handle these non-Markovian conditions by
              performing policy gradient descent [1]. Here, we examine the
              model's performance and compare it with human learning and a
              Bayes optimal reference, which provides an upper-bound on
              performance. We find that in all cases, our population of spiking
              neurons model well-describes human performance.",
  journal  = "PLoS One",
  volume   =  10,
  number   =  4,
  pages    = "e0123105",
  month    =  apr,
  year     =  2015,
  language = "en",
  issn     = "1932-6203",
  pmid     = "25898139",
  doi      = "10.1371/journal.pone.0123105",
  pmc      = "PMC4405578"
}

@ARTICLE{Bogacz2007-hx,
  title    = "Optimal decision-making theories: linking neurobiology with
              behaviour",
  author   = "Bogacz, Rafal",
  abstract = "This article reviews recently proposed theories postulating that,
              during simple choices, the brain performs statistically optimal
              decision making. These theories are ecologically motivated by
              evolutionary pressures to optimize the speed and accuracy of
              decisions and to maximize the rate of receiving rewards for
              correct choices. This article suggests that the models of
              decision making that are proposed on different levels of
              abstraction can be linked by virtue of the same optimal
              computation. Also reviewed here are recent observations that many
              aspects of the circuit that involves the cortex and basal ganglia
              are the same as those that are required to perform statistically
              optimal choice. This review illustrates how optimal-decision
              theories elucidate current data and provide experimental
              predictions that concern both neurobiology and behaviour.",
  journal  = "Trends Cogn. Sci.",
  volume   =  11,
  number   =  3,
  pages    = "118--125",
  month    =  mar,
  year     =  2007,
  language = "en",
  issn     = "1364-6613",
  pmid     = "17276130",
  doi      = "10.1016/j.tics.2006.12.006"
}

@ARTICLE{McNamara2006-sr,
  title    = "Bayes' theorem and its applications in animal behaviour",
  author   = "McNamara, John M and Green, Richard F and Olsson, Ola",
  abstract = "Bayesian decision theory can be used to model animal behaviour.
              In this paper we give an overview of the theoretical concepts in
              such models. We also review the biological contexts in which
              Bayesian models have been applied, and outline some directions
              where future studies would be useful. Bayesian decision theory,
              when applied to animal behaviour, is based on the assumption that
              the individual has some sort of ?prior opinion? of the possible
              states of the world. This may, for example, be a previously
              experienced distribution of qualities of food patches, or
              qualities of potential mates. The animal is then assumed to be
              able use sampling information to arrive at a ?posterior opinion?,
              concerning e.g. the quality of a given food patch, or the average
              qualities of mates in a year. A correctly formulated Bayesian
              model predicts how animals may combine previous experience with
              sampling information to make optimal decisions. We argue that the
              assumption that animals may have ?prior opinions? is reasonable.
              Their priors may come from one or both of two sources: either
              from their own individual experience, gained while sampling the
              environment, or from an adaptation to the environment experienced
              by previous generations. This means that we should often expect
              to see ?Bayesian-like? decision-making in nature.",
  journal  = "Oikos",
  volume   =  112,
  number   =  2,
  pages    = "243--251",
  month    =  feb,
  year     =  2006,
  issn     = "0030-1299, 1600-0706",
  doi      = "10.1111/j.0030-1299.2006.14228.x"
}

@ARTICLE{Kording2006-ty,
  title    = "Bayesian decision theory in sensorimotor control",
  author   = "K{\"o}rding, Konrad P and Wolpert, Daniel M",
  abstract = "Action selection is a fundamental decision process for us, and
              depends on the state of both our body and the environment.
              Because signals in our sensory and motor systems are corrupted by
              variability or noise, the nervous system needs to estimate these
              states. To select an optimal action these state estimates need to
              be combined with knowledge of the potential costs or rewards of
              different action outcomes. We review recent studies that have
              investigated the mechanisms used by the nervous system to solve
              such estimation and decision problems, which show that human
              behaviour is close to that predicted by Bayesian Decision Theory.
              This theory defines optimal behaviour in a world characterized by
              uncertainty, and provides a coherent way of describing
              sensorimotor processes.",
  journal  = "Trends Cogn. Sci.",
  volume   =  10,
  number   =  7,
  pages    = "319--326",
  month    =  jul,
  year     =  2006,
  language = "en",
  issn     = "1364-6613",
  pmid     = "16807063",
  doi      = "10.1016/j.tics.2006.05.003"
}

@ARTICLE{Kording2004-ui,
  title    = "A neuroeconomics approach to inferring utility functions in
              sensorimotor control",
  author   = "K{\"o}rding, Konrad P and Fukunaga, Izumi and Howard, Ian S and
              Ingram, James N and Wolpert, Daniel M",
  abstract = "Making choices is a fundamental aspect of human life. For over a
              century experimental economists have characterized the decisions
              people make based on the concept of a utility function. This
              function increases with increasing desirability of the outcome,
              and people are assumed to make decisions so as to maximize
              utility. When utility depends on several variables, indifference
              curves arise that represent outcomes with identical utility that
              are therefore equally desirable. Whereas in economics utility is
              studied in terms of goods and services, the sensorimotor system
              may also have utility functions defining the desirability of
              various outcomes. Here, we investigate the indifference curves
              when subjects experience forces of varying magnitude and
              duration. Using a two-alternative forced-choice paradigm, in
              which subjects chose between different magnitude-duration
              profiles, we inferred the indifference curves and the utility
              function. Such a utility function defines, for example, whether
              subjects prefer to lift a 4-kg weight for 30 s or a 1-kg weight
              for a minute. The measured utility function depends nonlinearly
              on the force magnitude and duration and was remarkably conserved
              across subjects. This suggests that the utility function, a
              central concept in economics, may be applicable to the study of
              sensorimotor control.",
  journal  = "PLoS Biol.",
  volume   =  2,
  number   =  10,
  pages    = "e330",
  month    =  oct,
  year     =  2004,
  language = "en",
  issn     = "1544-9173, 1545-7885",
  pmid     = "15383835",
  doi      = "10.1371/journal.pbio.0020330",
  pmc      = "PMC517826"
}

@ARTICLE{Ortega_Pedro_A2013-ub,
  title     = "Thermodynamics as a theory of decision-making with
               information-processing costs",
  author    = "{Ortega Pedro A.} and {Braun Daniel A.}",
  journal   = "Proceedings of the Royal Society A: Mathematical, Physical and
               Engineering Sciences",
  publisher = "Royal Society",
  volume    =  469,
  number    =  2153,
  pages     = "20120683",
  month     =  may,
  year      =  2013,
  doi       = "10.1098/rspa.2012.0683"
}

@ARTICLE{Kording2004-ii,
  title    = "The loss function of sensorimotor learning",
  author   = "K{\"o}rding, Konrad Paul and Wolpert, Daniel M",
  abstract = "Motor learning can be defined as changing performance so as to
              optimize some function of the task, such as accuracy. The measure
              of accuracy that is optimized is called a loss function and
              specifies how the CNS rates the relative success or cost of a
              particular movement outcome. Models of pointing in sensorimotor
              control and learning usually assume a quadratic loss function in
              which the mean squared error is minimized. Here we develop a
              technique for measuring the loss associated with errors. Subjects
              were required to perform a task while we experimentally
              controlled the skewness of the distribution of errors they
              experienced. Based on the change in the subjects' average
              performance, we infer the loss function. We show that people use
              a loss function in which the cost increases approximately
              quadratically with error for small errors and significantly less
              than quadratically for large errors. The system is thus robust to
              outliers. This suggests that models of sensorimotor control and
              learning that have assumed minimizing squared error are a good
              approximation but tend to penalize large errors excessively.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  101,
  number   =  26,
  pages    = "9839--9842",
  month    =  jun,
  year     =  2004,
  language = "en",
  issn     = "0027-8424",
  pmid     = "15210973",
  doi      = "10.1073/pnas.0308394101",
  pmc      = "PMC470761"
}

@ARTICLE{Vilares2011-lp,
  title    = "Bayesian models: the structure of the world, uncertainty,
              behavior, and the brain",
  author   = "Vilares, Iris and Kording, Konrad",
  abstract = "Experiments on humans and other animals have shown that
              uncertainty due to unreliable or incomplete information affects
              behavior. Recent studies have formalized uncertainty and asked
              which behaviors would minimize its effect. This formalization
              results in a wide range of Bayesian models that derive from
              assumptions about the world, and it often seems unclear how these
              models relate to one another. In this review, we use the concept
              of graphical models to analyze differences and commonalities
              across Bayesian approaches to the modeling of behavioral and
              neural data. We review behavioral and neural data associated with
              each type of Bayesian model and explain how these models can be
              related. We finish with an overview of different theories that
              propose possible ways in which the brain can represent
              uncertainty.",
  journal  = "Ann. N. Y. Acad. Sci.",
  volume   =  1224,
  pages    = "22--39",
  month    =  apr,
  year     =  2011,
  language = "en",
  issn     = "0077-8923, 1749-6632",
  pmid     = "21486294",
  doi      = "10.1111/j.1749-6632.2011.05965.x",
  pmc      = "PMC3079291"
}

@ARTICLE{Trommershauser2003-gp,
  title     = "Statistical decision theory and the selection of rapid,
               goal-directed movements",
  author    = "Trommersh{\"a}user, Julia and Maloney, Laurence T and Landy,
               Michael S",
  abstract  = "We present two experiments that test the range of applicability
               of a movement planning model (MEGaMove) based on statistical
               decision theory. Subjects attempted to earn money by rapidly
               touching a green target region on a computer screen while
               avoiding nearby red penalty regions. In two experiments we
               varied the magnitudes of penalties, the degree of overlap of
               target and penalty regions, and the number of penalty regions.
               Overall, subjects acted so as to maximize gain in a wide variety
               of stimulus configurations, in good agreement with predictions
               of the model.",
  journal   = "J. Opt. Soc. Am. A Opt. Image Sci. Vis.",
  publisher = "osapublishing.org",
  volume    =  20,
  number    =  7,
  pages     = "1419--1433",
  month     =  jul,
  year      =  2003,
  language  = "en",
  issn      = "1084-7529",
  pmid      = "12868646"
}

@ARTICLE{Constantinople2019-hd,
  title    = "An Analysis of Decision under Risk in Rats",
  author   = "Constantinople, Christine M and Piet, Alex T and Brody, Carlos D",
  abstract = "In 1979, Daniel Kahneman and Amos Tversky published a
              ground-breaking paper titled ``Prospect Theory: An Analysis of
              Decision under Risk,'' which presented a behavioral economic
              theory that accounted for the ways in which humans deviate from
              economists' normative workhorse model, Expected Utility Theory
              [1, 2]. For example, people exhibit probability distortion (they
              overweight low probabilities), loss aversion (losses loom larger
              than gains), and reference dependence (outcomes are evaluated as
              gains or losses relative to an internal reference point). We
              found that rats exhibited many of these same biases, using a task
              in which rats chose between guaranteed and probabilistic rewards.
              However, prospect theory assumes stable preferences in the
              absence of learning, an assumption at odds with alternative
              frameworks such as animal learning theory and reinforcement
              learning [3-7]. Rats also exhibited trial history effects,
              consistent with ongoing learning. A reinforcement learning model
              in which state-action values were updated by the subjective value
              of outcomes according to prospect theory reproduced rats'
              nonlinear utility and probability weighting functions and also
              captured trial-by-trial learning dynamics.",
  journal  = "Curr. Biol.",
  volume   =  29,
  number   =  12,
  pages    = "2066--2074.e5",
  month    =  jun,
  year     =  2019,
  keywords = "computational model; decision-making; prospect theory; rat
              behavior; reinforcement learning; reward; subjective value",
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "31155352",
  doi      = "10.1016/j.cub.2019.05.013"
}

@MISC{noauthor_undated-pm,
  title    = "Refactoring {UI} v1.0.1.pdf",
  keywords = "books"
}

@ARTICLE{Gold2007-tn,
  title     = "The neural basis of decision making",
  author    = "Gold, Joshua I and Shadlen, Michael N",
  abstract  = "The study of decision making spans such varied fields as
               neuroscience, psychology, economics, statistics, political
               science, and computer science. Despite this diversity of
               applications, most decisions share common elements including
               deliberation and commitment. Here we evaluate recent progress in
               understanding how these basic elements of decision formation are
               implemented in the brain. We focus on simple decisions that can
               be studied in the laboratory but emphasize general principles
               likely to extend to other settings.",
  journal   = "Annu. Rev. Neurosci.",
  publisher = "annualreviews.org",
  volume    =  30,
  pages     = "535--574",
  year      =  2007,
  language  = "en",
  issn      = "0147-006X",
  pmid      = "17600525",
  doi       = "10.1146/annurev.neuro.29.051605.113038"
}

@ARTICLE{Sanfey2006-em,
  title    = "Neuroeconomics: cross-currents in research on decision-making",
  author   = "Sanfey, Alan G and Loewenstein, George and McClure, Samuel M and
              Cohen, Jonathan D",
  abstract = "Despite substantial advances, the question of how we make
              decisions and judgments continues to pose important challenges
              for scientific research. Historically, different disciplines have
              approached this problem using different techniques and
              assumptions, with few unifying efforts made. However, the field
              of neuroeconomics has recently emerged as an inter-disciplinary
              effort to bridge this gap. Research in neuroscience and
              psychology has begun to investigate neural bases of decision
              predictability and value, central parameters in the economic
              theory of expected utility. Economics, in turn, is being
              increasingly influenced by a multiple-systems approach to
              decision-making, a perspective strongly rooted in psychology and
              neuroscience. The integration of these disparate theoretical
              approaches and methodologies offers exciting potential for the
              construction of more accurate models of decision-making.",
  journal  = "Trends Cogn. Sci.",
  volume   =  10,
  number   =  3,
  pages    = "108--116",
  month    =  mar,
  year     =  2006,
  language = "en",
  issn     = "1364-6613",
  pmid     = "16469524",
  doi      = "10.1016/j.tics.2006.01.009"
}

@UNPUBLISHED{BRAIN_Initiative_Cell_Census_Network_BICCN2020-cp,
  title    = "A multimodal cell census and atlas of the mammalian primary motor
              cortex",
  author   = "{BRAIN Initiative Cell Census Network (BICCN)} and Adkins, Ricky
              S and Aldridge, Andrew I and Allen, Shona and Ament, Seth A and
              An, Xu and Armand, Ethan and Ascoli, Giorgio A and Bakken, Trygve
              E and Bandrowski, Anita and Banerjee, Samik and Barkas, Nikolaos
              and Bartlett, Anna and Bateup, Helen S and Margarita Behrens, M
              and Berens, Philipp and Berg, Jim and Bernabucci, Matteo and
              Bernaerts, Yves and Bertagnolli, Darren and Biancalani, Tommaso
              and Boggeman, Lara and Sina Booeshaghi, A and Bowman, Ian and
              Bravo, H{\'e}ctor Corrada and Cadwell, Cathryn Ren{\'e} and
              Callaway, Edward M and Carlin, Benjamin and O'Connor, Carolyn and
              Carter, Robert and Casper, Tamara and Castanon, Rosa G and
              Castro, Jesus Ramon and Chance, Rebecca K and Chatterjee, Apaala
              and Chen, Huaming and Chun, Jerold and Colantuoni, Carlo and
              Crabtree, Jonathan and Creasy, Heather and Crichton, Kirsten and
              Crow, Megan and D'Orazi, Florence D and Daigle, Tanya L and
              Dalley, Rachel and Dee, Nick and Degatano, Kylee and Dichter,
              Benjamin and Diep, Dinh and Ding, Liya and Ding, Song-Lin and
              Dominguez, Bertha and Dong, Hong-Wei and Dong, Weixiu and
              Dougherty, Elizabeth L and Dudoit, Sandrine and Ecker, Joseph R
              and Eichhorn, Stephen W and Fang, Rongxin and Felix, Victor and
              Feng, Guoping and Feng, Zhao and Fischer, Stephan and
              Fitzpatrick, Conor and Fong, Olivia and Foster, Nicholas N and
              Galbavy, William and Gee, James C and Ghosh, Satrajit S and
              Giglio, Michelle and Gillespie, Thomas H and Gillis, Jesse and
              Goldman, Melissa and Goldy, Jeff and Gong, Hui and Gou, Lin and
              Grauer, Michael and Halchenko, Yaroslav O and Harris, Julie A and
              Hartmanis, Leonard and Hatfield, Joshua T and Hawrylycz, Mike and
              Helba, Brian and Herb, Brian R and Hertzano, Ronna and Hintiryan,
              Houri and Hirokawa, Karla E and Hockemeyer, Dirk and Hodge,
              Rebecca D and Hood, Greg and Horwitz, Gregory D and Hou, Xiaomeng
              and Hu, Lijuan and Hu, Qiwen and Josh Huang, Z and Huo, Bingxing
              and Ito-Cole, Tony and Jacobs, Matthew and Jia, Xueyan and Jiang,
              Shengdian and Jiang, Tao and Jiang, Xiaolong and Jin, Xin and
              Jorstad, Nikolas L and Kalmbach, Brian E and Kancherla, Jayaram
              and Dirk Keene, C and Kelly, Kathleen and Khajouei, Farzaneh and
              Kharchenko, Peter V and Kim, Gukhan and Ko, Andrew L and Kobak,
              Dmitry and Konwar, Kishori and Kramer, Daniel J and Krienen,
              Fenna M and Kroll, Matthew and Kuang, Xiuli and Kuo, Hsien-Chi
              and Lake, Blue B and Larsen, Rachael and Lathia, Kanan and
              Laturnus, Sophie and Lee, Angus Y and Lee, Cheng-Ta and Lee,
              Kuo-Fen and Lein, Ed S and Lesnar, Phil and Li, Anan and Li,
              Xiangning and Li, Xu and Li, Yang Eric and Li, Yaoyao and Li,
              Yuanyuan and Lim, Byungkook and Linnarsson, Sten and Liu,
              Christine S and Liu, Hanqing and Liu, Lijuan and Lucero, Jacinta
              D and Luo, Chongyuan and Luo, Qingming and Macosko, Evan Z and
              Mahurkar, Anup and Martone, Maryann E and Matho, Katherine S and
              McCarroll, Steven A and McCracken, Carrie and McMillen, Delissa
              and Miranda, Elanine and Mitra, Partha P and Miyazaki, Paula
              Assakura and Mizrachi, Judith and Mok, Stephanie and Mukamel,
              Eran A and Mulherkar, Shalaka and Nadaf, Naeem M and Naeemi,
              Maitham and Narasimhan, Arun and Nery, Joseph R and Ng, Lydia and
              Ngai, John and Nguyen, Thuc Nghi and Nickel, Lance and Nicovich,
              Philip R and Niu, Sheng-Yong and Ntranos, Vasilis and Nunn,
              Michael and Olley, Dustin and Orvis, Joshua and Osteen, Julia K
              and Osten, Pavel and Owen, Scott F and Pachter, Lior and
              Palaniswamy, Ramesh and Palmer, Carter R and Pang, Yan and Peng,
              Hanchuan and Pham, Thanh and Pinto-Duarte, Antonio and
              Plongthongkum, Nongluk and Poirion, Olivier and Preissl,
              Sebastian and Purdom, Elizabeth and Qu, Lei and Rashid, Mohammad
              and Reed, Nora M and Regev, Aviv and Ren, Bing and Ren, Miao and
              Rimorin, Christine and Risso, Davide and Rivkin, Angeline C and
              Mu{\~n}oz-Casta{\~n}eda, Rodrigo and Romanow, William J and
              Ropelewski, Alexander J and de B{\'e}zieux, Hector Roux and Ruan,
              Zongcai and Sandberg, Rickard and Savoia, Steven and Scala,
              Federico and Schor, Michael and Shen, Elise and Siletti, Kimberly
              and Smith, Jared B and Smith, Kimberly and Somasundaram, Saroja
              and Song, Yuanyuan and Sorensen, Staci A and Stafford, David A
              and Street, Kelly and Sulc, Josef and Sunkin, Susan and Svensson,
              Valentine and Tan, Pengcheng and Tan, Zheng Huan and Tasic,
              Bosiljka and Thompson, Carol and Tian, Wei and Tickle, Timothy L
              and Tieu, Michael and Ting, Jonathan T and Tolias, Andreas Savas
              and Torkelson, Amy and Tung, Herman and Vaishnav, Eeshit Dhaval
              and Van den Berge, Koen and van Velthoven, Cindy T J and
              Vanderburg, Charles R and Veldman, Matthew B and Vu, Minh and
              Wakeman, Wayne and Wang, Peng and Wang, Quanxin and Wang, Xinxin
              and Wang, Yimin and Wang, Yun and Welch, Joshua D and White, Owen
              and Williams, Elora and Xie, Fangming and Xie, Peng and Xiong,
              Feng and William Yang, X and Yanny, Anna Marie and Yao, Zizhen
              and Yin, Lulu and Yu, Yang and Yuan, Jing and Zeng, Hongkui and
              Zhang, Kun and Zhang, Meng and Zhang, Zhuzhu and Zhao, Sujun and
              Zhao, Xuan and Zhou, Jingtian and Zhuang, Xiaowei and Zingg,
              Brian",
  abstract = "We report the generation of a multimodal cell census and atlas of
              the mammalian primary motor cortex (MOp or M1) as the initial
              product of the BRAIN Initiative Cell Census Network (BICCN). This
              was achieved by coordinated large-scale analyses of single-cell
              transcriptomes, chromatin accessibility, DNA methylomes,
              spatially resolved single-cell transcriptomes, morphological and
              electrophysiological properties, and cellular resolution
              input-output mapping, integrated through cross-modal
              computational analysis. Together, our results advance the
              collective knowledge and understanding of brain cell type
              organization: First, our study reveals a unified molecular
              genetic landscape of cortical cell types that congruently
              integrates their transcriptome, open chromatin and DNA
              methylation maps. Second, cross-species analysis achieves a
              unified taxonomy of transcriptomic types and their hierarchical
              organization that are conserved from mouse to marmoset and human.
              Third, cross-modal analysis provides compelling evidence for the
              epigenomic, transcriptomic, and gene regulatory basis of neuronal
              phenotypes such as their physiological and anatomical properties,
              demonstrating the biological validity and genomic underpinning of
              neuron types and subtypes. Fourth, in situ single-cell
              transcriptomics provides a spatially-resolved cell type atlas of
              the motor cortex. Fifth, integrated transcriptomic, epigenomic
              and anatomical analyses reveal the correspondence between neural
              circuits and transcriptomic cell types. We further present an
              extensive genetic toolset for targeting and fate mapping
              glutamatergic projection neuron types toward linking their
              developmental trajectory to their circuit function. Together, our
              results establish a unified and mechanistic framework of neuronal
              cell type organization that integrates multi-layered molecular
              genetic and spatial information with multi-faceted phenotypic
              properties. \#\#\# Competing Interest Statement The competing
              interests are detailed in the Competing Interests section in the
              manuscript file.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2020.10.19.343129",
  month    =  oct,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.10.19.343129"
}

@ARTICLE{Todorov2009-gp,
  title    = "Efficient computation of optimal actions",
  author   = "Todorov, Emanuel",
  abstract = "Optimal choice of actions is a fundamental problem relevant to
              fields as diverse as neuroscience, psychology, economics,
              computer science, and control engineering. Despite this broad
              relevance the abstract setting is similar: we have an agent
              choosing actions over time, an uncertain dynamical system whose
              state is affected by those actions, and a performance criterion
              that the agent seeks to optimize. Solving problems of this kind
              remains hard, in part, because of overly generic formulations.
              Here, we propose a more structured formulation that greatly
              simplifies the construction of optimal control laws in both
              discrete and continuous domains. An exhaustive search over
              actions is avoided and the problem becomes linear. This yields
              algorithms that outperform Dynamic Programming and Reinforcement
              Learning, and thereby solve traditional problems more
              efficiently. Our framework also enables computations that were
              not possible before: composing optimal control laws by mixing
              primitives, applying deterministic methods to stochastic systems,
              quantifying the benefits of error tolerance, and inferring goals
              from behavioral data via convex optimization. Development of a
              general class of easily solvable problems tends to accelerate
              progress--as linear systems theory has done, for example. Our
              framework may have similar impact in fields where optimal choice
              of actions is relevant.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  106,
  number   =  28,
  pages    = "11478--11483",
  month    =  jul,
  year     =  2009,
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "19574462",
  doi      = "10.1073/pnas.0710743106",
  pmc      = "PMC2705278"
}

@ARTICLE{Etienne2004-dr,
  title    = "Path integration in mammals",
  author   = "Etienne, Ariane S and Jeffery, Kathryn J",
  abstract = "It is often assumed that navigation implies the use, by animals,
              of landmarks indicating the location of the goal. However, many
              animals (including humans) are able to return to the starting
              point of a journey, or to other goal sites, by relying on
              self-motion cues only. This process is known as path integration,
              and it allows an agent to calculate a route without making use of
              landmarks. We review the current literature on path integration
              and its interaction with external, location-based cues. Special
              importance is given to the correlation between observable
              behavior and the activity pattern of particular neural cell
              populations that implement the internal representation of space.
              In mammals, the latter may well be the first high-level cognitive
              representation to be understood at the neural level.",
  journal  = "Hippocampus",
  volume   =  14,
  number   =  2,
  pages    = "180--192",
  year     =  2004,
  language = "en",
  issn     = "1050-9631",
  pmid     = "15098724",
  doi      = "10.1002/hipo.10173"
}

@ARTICLE{Quian_Quiroga2009-gj,
  title     = "Extracting information from neuronal populations: information
               theory and decoding approaches",
  author    = "Quian Quiroga, Rodrigo and Panzeri, Stefano",
  abstract  = "To a large extent, progress in neuroscience has been driven by
               the study of single-cell responses averaged over several
               repetitions of stimuli or behaviours. However,the brain
               typically makes decisions based on single events by evaluating
               the activity of large neuronal populations. Therefore, to
               further understand how the brain processes information, it is
               important to shift from a single-neuron, multiple-trial
               framework to multiple-neuron, single-trial methodologies. Two
               related approaches--decoding and information theory--can be used
               to extract single-trial information from the activity of
               neuronal populations. Such population analysis can give us more
               information about how neurons encode stimulus features than
               traditional single-cell studies.",
  journal   = "Nat. Rev. Neurosci.",
  publisher = "nature.com",
  volume    =  10,
  number    =  3,
  pages     = "173--185",
  month     =  mar,
  year      =  2009,
  language  = "en",
  issn      = "1471-003X, 1471-0048",
  pmid      = "19229240",
  doi       = "10.1038/nrn2578"
}

@ARTICLE{Globus1992-on,
  title     = "Toward a noncomputational cognitive neuroscience",
  author    = "Globus, G G",
  abstract  = "The near universally accepted theory that the brain processes
               information persists in current neural network theory where
               there is ``subsymbolic'' computation (Smolensky, 1988) on
               distributed representations. This theory of brain information
               processing may suffice for simplifying models simulated in
               silicon but not for living neural nets where there is ongoing
               chemical tuning of the input/output transfer function at the
               nodes, connection weights, network parameters, and connectivity.
               Here the brain continually changes itself as it intersects with
               information from the outside. An alternative theory to
               information processing is developed in which the brain permits
               and supports ``participation'' of self and other as constraints
               on the dynamically evolving, self-organizing whole. The
               noncomputational process of ``differing and deferring'' in
               nonlinear dynamic neural systems is contrasted with Black's
               (1991) account of molecular information processing. State
               hyperspace for the noncomputational process of nonlinear
               dynamical systems, unlike classical systems, has a fractal
               dimension. The noncomputational model is supported by suggestive
               evidence for fractal properties of the brain.",
  journal   = "J. Cogn. Neurosci.",
  publisher = "MIT Press",
  volume    =  4,
  number    =  4,
  pages     = "299--300",
  year      =  1992,
  language  = "en",
  issn      = "0898-929X",
  pmid      = "23968124",
  doi       = "10.1162/jocn.1992.4.4.299"
}

@ARTICLE{Japyassu2017-rx,
  title    = "Extended spider cognition",
  author   = "Japyass{\'u}, Hilton F and Laland, Kevin N",
  abstract = "There is a tension between the conception of cognition as a
              central nervous system (CNS) process and a view of cognition as
              extending towards the body or the contiguous environment. The
              centralised conception requires large or complex nervous systems
              to cope with complex environments. Conversely, the extended
              conception involves the outsourcing of information processing to
              the body or environment, thus making fewer demands on the
              processing power of the CNS. The evolution of extended cognition
              should be particularly favoured among small, generalist predators
              such as spiders, and here, we review the literature to evaluate
              the fit of empirical data with these contrasting models of
              cognition. Spiders do not seem to be cognitively limited,
              displaying a large diversity of learning processes, from
              habituation to contextual learning, including a sense of
              numerosity. To tease apart the central from the extended
              cognition, we apply the mutual manipulability criterion, testing
              the existence of reciprocal causal links between the putative
              elements of the system. We conclude that the web threads and
              configurations are integral parts of the cognitive systems. The
              extension of cognition to the web helps to explain some puzzling
              features of spider behaviour and seems to promote evolvability
              within the group, enhancing innovation through cognitive
              connectivity to variable habitat features. Graded changes in
              relative brain size could also be explained by outsourcing
              information processing to environmental features. More generally,
              niche-constructed structures emerge as prime candidates for
              extending animal cognition, generating the selective pressures
              that help to shape the evolving cognitive system.",
  journal  = "Anim. Cogn.",
  volume   =  20,
  number   =  3,
  pages    = "375--395",
  month    =  may,
  year     =  2017,
  keywords = "Evolvability; Extended cognition; Modular cognition; Niche
              construction; Web building",
  language = "en",
  issn     = "1435-9448, 1435-9456",
  pmid     = "28176133",
  doi      = "10.1007/s10071-017-1069-7",
  pmc      = "PMC5394149"
}

@ARTICLE{Edwards1954-hk,
  title    = "The theory of decision making",
  author   = "Edwards, W",
  journal  = "Psychol. Bull.",
  volume   =  51,
  number   =  4,
  pages    = "380--417",
  month    =  jul,
  year     =  1954,
  keywords = "THINKING",
  language = "en",
  issn     = "0033-2909",
  pmid     = "13177802",
  doi      = "10.1037/h0053870"
}

@UNPUBLISHED{Vertechi2019-bo,
  title    = "Inference based decisions in a hidden state foraging task:
              differential contributions of prefrontal cortical areas",
  author   = "Vertechi, Pietro and Lottem, Eran and Sarra, Dario and Godinho,
              Beatriz and Treves, Isaac and Quendera, Tiago and Lohuis,
              Matthijs Nicolai Oude and Mainen, Zachary F",
  abstract = "Essential features of the world are often hidden and must be
              inferred by constructing internal models based on indirect
              evidence. Here, to study the mechanisms of inference we
              established a foraging task that is naturalistic and easily
              learned, yet can distinguish inference from simpler strategies
              such as the direct integration of sensory data. We show that both
              mice and humans learn a strategy consistent with optimal
              inference of a hidden state. However, humans acquire this
              strategy more than an order of magnitude faster than mice. Using
              optogenetics in mice we show that orbitofrontal and anterior
              cingulate cortex inactivation impact task performance, but only
              orbitofrontal inactivation reverts mice from an inference-based
              to a stimulus-bound decision strategy. These results establish a
              cross-species paradigm for studying the problem of
              inference-based decision-making and begin to dissect the network
              of brain regions crucial for its performance.",
  journal  = "bioRxiv",
  pages    = "679142",
  month    =  jun,
  year     =  2019,
  language = "en",
  doi      = "10.1101/679142"
}

@UNPUBLISHED{De_Groot2019-zn,
  title    = "{NINscope}: a versatile miniscope for multi-region circuit
              investigations",
  author   = "de Groot, Andres and van den Boom, Bastijn J G and van Genderen,
              Romano M and Coppens, Joris and van Veldhuijzen, John and Bos,
              Joop and Hoedemaker, Hugo and Negrello, Mario and Wiluhn, Ingo
              and De Zeeuw, Chris I and Hoogland, Tycho M",
  abstract = "Miniaturized fluorescence microscopes (miniscopes) have been
              instrumental to monitor neural activity during unrestrained
              behavior and their open-source versions have helped to distribute
              them at an affordable cost. Generally, the footprint and weight
              of open-source miniscopes is sacrificed for added functionality.
              Here, we present NINscope: a light-weight, small footprint
              open-source miniscope that incorporates a high-sensitivity image
              sensor, an inertial measurement unit (IMU), and an LED driver for
              an external optogenetic probe. We highlight the advantages of
              NINscope by performing the first simultaneous cellular resolution
              (dual scope) recordings from cerebellum and cerebral cortex in
              unrestrained mice, revealing that the activity of both regions
              generally precede the onset of behavioral acceleration. At the
              same time, we demonstrate the optogenetic stimulation
              capabilities of NINscope and show that cerebral cortical activity
              can be driven strongly by cerebellar stimulation. Finally, we
              combine optogenetic stimulation of cortex with imaging in the
              dorsal striatum and replicate previous studies that show action
              space is encoded by neurons in this subcortical region. In
              combination with cross-platform control software NINscope is a
              versatile addition to the expanding toolbox of open-source
              miniscopes and will aid multi-region circuit investigations
              during unrestrained behavior.",
  journal  = "bioRxiv",
  pages    = "685909",
  month    =  jun,
  year     =  2019,
  language = "en",
  doi      = "10.1101/685909"
}

@UNPUBLISHED{Johnson2019-wt,
  title    = "Probabilistic Models of Larval Zebrafish Behavior: Structure on
              Many Scales",
  author   = "Johnson, Robert Evan and Linderman, Scott and Panier, Thomas and
              Wee, Caroline Lei and Song, Erin and Herrera, Kristian Joseph and
              Miller, Andrew and Engert, Florian",
  abstract = "Nervous systems have evolved to combine environmental information
              with internal state to select and generate adaptive behavioral
              sequences. To better understand these computations and their
              implementation in neural circuits, natural behavior must be
              carefully measured and quantified. Here, we collect high spatial
              resolution video of single zebrafish larvae swimming in a
              naturalistic environment and develop models of their action
              selection across exploration and hunting. Zebrafish larvae swim
              in punctuated bouts separated by longer periods of rest called
              interbout intervals. We take advantage of this structure by
              categorizing bouts into discrete types and representing their
              behavior as labeled sequences of bout-types emitted over time. We
              then construct probabilistic models - specifically, marked
              renewal processes - to evaluate how bout-types and interbout
              intervals are selected by the fish as a function of its internal
              hunger state, behavioral history, and the locations and
              properties of nearby prey. Finally, we evaluate the models by
              their predictive likelihood and their ability to generate
              realistic trajectories of virtual fish swimming through simulated
              environments. Our simulations capture multiple timescales of
              structure in larval zebrafish behavior and expose many ways in
              which hunger state influences their action selection to promote
              food seeking during hunger and safety during satiety.",
  journal  = "bioRxiv",
  pages    = "672246",
  month    =  jun,
  year     =  2019,
  language = "en",
  doi      = "10.1101/672246"
}

@ARTICLE{Groman2019-xc,
  title    = "Orbitofrontal Circuits Control Multiple {Reinforcement-Learning}
              Processes",
  author   = "Groman, Stephanie M and Keistler, Colby and Keip, Alex J and
              Hammarlund, Emma and DiLeone, Ralph J and Pittenger, Christopher
              and Lee, Daeyeol and Taylor, Jane R",
  abstract = "Adaptive decision making in dynamic environments requires
              multiple reinforcement-learning steps that may be implemented by
              dissociable neural circuits. Here, we used a novel directionally
              specific viral ablation approach to investigate the function of
              several anatomically defined orbitofrontal cortex (OFC) circuits
              during adaptive, flexible decision making in rats trained on a
              probabilistic reversal learning task. Ablation of OFC neurons
              projecting to the nucleus accumbens selectively disrupted
              performance following a reversal, by disrupting the use of
              negative outcomes to guide subsequent choices. Ablation of
              amygdala neurons projecting to the OFC also impaired reversal
              performance, but due to disruptions in the use of positive
              outcomes to guide subsequent choices. Ablation of OFC neurons
              projecting to the amygdala, by contrast, enhanced reversal
              performance by destabilizing action values. Our data are
              inconsistent with a unitary function of the OFC in decision
              making. Rather, distinct OFC-amygdala-striatal circuits mediate
              distinct components of the action-value updating and maintenance
              necessary for decision making.",
  journal  = "Neuron",
  month    =  jun,
  year     =  2019,
  keywords = "amygdala; decision making; nucleus accumbens; orbitofrontal
              cortex; reinforcement learning",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "31253468",
  doi      = "10.1016/j.neuron.2019.05.042"
}

@ARTICLE{Hinman2019-nx,
  title    = "Neuronal representation of environmental boundaries in egocentric
              coordinates",
  author   = "Hinman, James R and Chapman, G William and Hasselmo, Michael E",
  abstract = "Movement through space is a fundamental behavior for all animals.
              Cognitive maps of environments are encoded in the hippocampal
              formation in an allocentric reference frame, but motor movements
              that comprise physical navigation are represented within an
              egocentric reference frame. Allocentric navigational plans must
              be converted to an egocentric reference frame prior to
              implementation as overt behavior. Here we describe an egocentric
              spatial representation of environmental boundaries in the
              dorsomedial striatum.",
  journal  = "Nat. Commun.",
  volume   =  10,
  number   =  1,
  pages    = "2772",
  month    =  jun,
  year     =  2019,
  language = "en",
  issn     = "2041-1723",
  pmid     = "31235693",
  doi      = "10.1038/s41467-019-10722-y",
  pmc      = "PMC6591168"
}

@ARTICLE{Gallego2017-bn,
  title    = "Neural Manifolds for the Control of Movement",
  author   = "Gallego, Juan A and Perich, Matthew G and Miller, Lee E and
              Solla, Sara A",
  abstract = "The analysis of neural dynamics in several brain cortices has
              consistently uncovered low-dimensional manifolds that capture a
              significant fraction of neural variability. These neural
              manifolds are spanned by specific patterns of correlated neural
              activity, the ``neural modes.'' We discuss a model for neural
              control of movement in which the time-dependent activation of
              these neural modes is the generator of motor behavior. This
              manifold-based view of motor cortex may lead to a better
              understanding of how the brain controls movement.",
  journal  = "Neuron",
  volume   =  94,
  number   =  5,
  pages    = "978--984",
  month    =  jun,
  year     =  2017,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "28595054",
  doi      = "10.1016/j.neuron.2017.05.025",
  pmc      = "PMC6122849"
}

@UNPUBLISHED{Calhoun2019-qk,
  title    = "Unsupervised identification of the internal states that shape
              natural behavior",
  author   = "Calhoun, Adam J and Pillow, Jonathan and Murthy, Mala",
  abstract = "Internal states can shape stimulus responses and decision-making,
              but we lack methods to identify internal states and how they
              evolve over time. To address this gap, we have developed an
              unsupervised method to identify internal states from behavioral
              data, and have applied it to the study of a dynamic social
              interaction. During courtship, Drosophila melanogaster males
              pattern their songs using feedback cues from their partner. Our
              model uncovers three latent states underlying this behavior, and
              is able to predict the moment-to-moment variation in natural song
              patterning decisions. These distinct behavioral states correspond
              to different sensorimotor strategies, each of which is
              characterized by different mappings from feedback cues to song
              modes. Using the model, we show that a pair of neurons previously
              thought to be command neurons for song production are sufficient
              to drive switching between states. Our results reveal how animals
              compose behavior from previously unidentified internal states, a
              necessary step for quantitative descriptions of animal behavior
              that link environmental cues, internal needs, neuronal activity,
              and motor outputs.",
  journal  = "bioRxiv",
  pages    = "691196",
  month    =  jul,
  year     =  2019,
  language = "en",
  doi      = "10.1101/691196"
}

@ARTICLE{Milkowski2018-bi,
  title     = "Morphological Computation: Nothing but Physical Computation",
  author    = "Mi{\l}kowski, Marcin",
  abstract  = "The purpose of this paper is to argue against the claim that
               morphological computation is substantially different from other
               kinds of physical computation. I show that some (but not all)
               purported cases of morphological computation do not count as
               specifically computational, and that those that do are solely
               physical computational systems. These latter cases are not,
               however, specific enough: all computational systems, not only
               morphological ones, may (and sometimes should) be studied in
               various ways, including their energy efficiency, cost,
               reliability, and durability. Second, I critically analyze the
               notion of ``offloading'' computation to the morphology of an
               agent or robot, by showing that, literally, computation is
               sometimes not offloaded but simply avoided. Third, I point out
               that while the morphology of any agent is indicative of the
               environment that it is adapted to, or informative about that
               environment, it does not follow that every agent has access to
               its morphology as the model of its environment.",
  journal   = "Entropy",
  publisher = "Multidisciplinary Digital Publishing Institute",
  volume    =  20,
  number    =  12,
  pages     = "942",
  month     =  dec,
  year      =  2018,
  language  = "en",
  doi       = "10.3390/e20120942"
}

@ARTICLE{Pezzulo2017-xp,
  title     = "{Model-Based} Approaches to Active Perception and Control",
  author    = "Pezzulo, Giovanni and Donnarumma, Francesco and Iodice,
               Pierpaolo and Maisto, Domenico and Stoianov, Ivilin",
  abstract  = "There is an on-going debate in cognitive (neuro) science and
               philosophy between classical cognitive theory and embodied,
               embedded, extended, and enactive (``4-Es'') views of
               cognition---a family of theories that emphasize the role of the
               body in cognition and the importance of brain-body-environment
               interaction over and above internal representation. This debate
               touches foundational issues, such as whether the brain
               internally represents the external environment, and ``infers''
               or ``computes'' something. Here we focus on two (4-Es-based)
               criticisms to traditional cognitive theories---to the notions of
               passive perception and of serial information processing---and
               discuss alternative ways to address them, by appealing to
               frameworks that use, or do not use, notions of internal
               modelling and inference. Our analysis illustrates that: an
               explicitly inferential framework can capture some key aspects of
               embodied and enactive theories of cognition; some claims of
               computational and dynamical theories can be reconciled rather
               than seen as alternative explanations of cognitive phenomena;
               and some aspects of cognitive processing (e.g., detached
               cognitive operations, such as planning and imagination) that are
               sometimes puzzling to explain from enactive and
               non-representational perspectives can, instead, be captured
               nicely from the perspective that internal generative models and
               predictive processing mediate adaptive control loops.",
  journal   = "Entropy",
  publisher = "Multidisciplinary Digital Publishing Institute",
  volume    =  19,
  number    =  6,
  pages     = "266",
  month     =  jun,
  year      =  2017,
  language  = "en",
  doi       = "10.3390/e19060266"
}

@ARTICLE{Muller2017-ag,
  title    = "What Is Morphological Computation? On How the Body Contributes to
              Cognition and Control",
  author   = "M{\"u}ller, Vincent C and Hoffmann, Matej",
  abstract = "The contribution of the body to cognition and control in natural
              and artificial agents is increasingly described as ``offloading
              computation from the brain to the body,'' where the body is said
              to perform ``morphological computation.'' Our investigation of
              four characteristic cases of morphological computation in animals
              and robots shows that the ``offloading'' perspective is
              misleading. Actually, the contribution of body morphology to
              cognition and control is rarely computational, in any useful
              sense of the word. We thus distinguish (1) morphology that
              facilitates control, (2) morphology that facilitates perception,
              and the rare cases of (3) morphological computation proper, such
              as reservoir computing, where the body is actually used for
              computation. This result contributes to the understanding of the
              relation between embodiment and computation: The question for
              robot design and cognitive science is not whether computation is
              offloaded to the body, but to what extent the body facilitates
              cognition and control-how it contributes to the overall
              orchestration of intelligent behavior.",
  journal  = "Artif. Life",
  volume   =  23,
  number   =  1,
  pages    = "1--24",
  month    =  jan,
  year     =  2017,
  keywords = "Body; cognition; computation; control; embodiment; soft robotics",
  language = "en",
  issn     = "1064-5462",
  pmid     = "28140632",
  doi      = "10.1162/ARTL\_a\_00219"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Toussaint2009-ac,
  title     = "Probabilistic inference as a model of planned behavior",
  author    = "Toussaint, Marc",
  abstract  = "The problem of planning and goal-directed behavior has been
               addressed in computer science for many years, typically based on
               classical concepts like Bellman's optimality principle, dynamic
               programming, or Reinforcement Learning methods--but is this the
               only way to address the problem? Recently there is growing
               interest in using probabilistic inference methods for decision
               making and planning. Promising about such approaches is that
               they naturally extend to distributed state representations and
               efficiently cope with …",
  journal   = "KI",
  publisher = "researchgate.net",
  volume    =  23,
  number    =  3,
  pages     = "23--29",
  year      =  2009
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Murphy2002-fs,
  title     = "Dynamic bayesian networks: representation, inference and
               learning",
  author    = "Murphy, Kevin Patrick and Russell, Stuart",
  abstract  = "Sequential data arises in many areas of science and engineering.
               The data may either be a time series, generated by a dynamical
               system, or a sequence generated by a 1-dimensional spatial
               process, eg, biosequences. One may be interested either in
               online analysis, where the data arrives in real-time, or in
               offline analysis, where all the data has already been collected.
               In online analysis, one common task is to predict future
               observations, given all the observations up to the present time,
               which we will denote by y1: t=(y1,..., yt).(In this thesis …",
  publisher = "University of California, Berkeley Dissertation",
  year      =  2002
}

@ARTICLE{Grush2004-db,
  title     = "The emulation theory of representation: motor control, imagery,
               and perception",
  author    = "Grush, Rick",
  abstract  = "The emulation theory of representation is developed and explored
               as a framework that can revealingly synthesize a wide variety of
               representational functions of the brain. The framework is based
               on constructs from control theory (forward models) and signal
               processing (Kalman filters). The idea is that in addition to
               simply engaging with the body and environment, the brain
               constructs neural circuits that act as models of the body and
               environment. During overt sensorimotor engagement, these models
               are driven by efference copies in parallel with the body and
               environment, in order to provide expectations of the sensory
               feedback, and to enhance and process sensory information. These
               models can also be run off-line in order to produce imagery,
               estimate outcomes of different actions, and evaluate and develop
               motor plans. The framework is initially developed within the
               context of motor control, where it has been shown that inner
               models running in parallel with the body can reduce the effects
               of feedback delay problems. The same mechanisms can account for
               motor imagery as the off-line driving of the emulator via
               efference copies. The framework is extended to account for
               visual imagery as the off-line driving of an emulator of the
               motor-visual loop. I also show how such systems can provide for
               amodal spatial imagery. Perception, including visual perception,
               results from such models being used to form expectations of, and
               to interpret, sensory input. I close by briefly outlining other
               cognitive functions that might also be synthesized within this
               framework, including reasoning, theory of mind phenomena, and
               language.",
  journal   = "Behav. Brain Sci.",
  publisher = "cambridge.org",
  volume    =  27,
  number    =  3,
  pages     = "377--96; discussion 396--442",
  month     =  jun,
  year      =  2004,
  language  = "en",
  issn      = "0140-525X",
  pmid      = "15736871"
}

@ARTICLE{Boutilier2011-ui,
  title     = "{Decision-Theoretic} Planning: Structural Assumptions and
               Computational Leverage",
  author    = "Boutilier, C and Dean, T and Hanks, S",
  abstract  = "Planning under uncertainty is a central problem in the study of",
  journal   = "arXiv e-prints",
  publisher = "adsabs.harvard.edu",
  month     =  may,
  year      =  2011,
  keywords  = "Computer Science - Artificial Intelligence",
  arxivid   = "1105.5460"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Attias2003-wk,
  title     = "Planning by probabilistic inference",
  booktitle = "{AISTATS}",
  author    = "Attias, Hagai",
  abstract  = "This paper presents and demonstrates a new approach to the
               problem of planning under uncertainty. Actions are treated as
               hidden variables, with their own prior distributions, in a
               probabilistic generative model involving actions and states.
               Planning is done by computing …",
  publisher = "pdfs.semanticscholar.org",
  year      =  2003
}

@ARTICLE{Schaefer2001-fc,
  title    = "Descending influences on escape behavior and motor pattern in the
              cockroach",
  author   = "Schaefer, P L and Ritzmann, R E",
  abstract = "The escape behavior of the cockroach is a ballistic behavior with
              well characterized kinematics. The circuitry known to control the
              behavior lies in the thoracic ganglia, abdominal ganglia, and
              abdominal nerve cord. Some evidence suggests inputs may occur
              from the brain or suboesophageal ganglion. We tested this notion
              by decapitating cockroaches, removing all descending inputs, and
              evoking escape responses. The decapitated cockroaches exhibited
              directionally appropriate escape turns. However, there was a
              front-to-back gradient of change: the front legs moved little if
              at all, the middle legs moved in the proper direction but with
              reduced excursion, and the rear legs moved normally. The same
              pattern was seen when only inputs from the brain were removed,
              the suboesophageal ganglion remaining intact and connected to the
              thoracic ganglia. Electromyogram (EMG) analysis showed that the
              loss of or reduction in excursion was accompanied by a loss of or
              reduction in fast motor neuron activity. The loss of fast motor
              neuron activity was also observed in a reduced preparation in
              which descending neural signals were reversibly blocked via an
              isotonic sucrose solution superfusing the neck connectives,
              indicating that the changes seen were not due to trauma. Our data
              demonstrate that while the thoracic circuitry is sufficient to
              produce directional escape, lesion or blockage of the connective
              affects the excitability of components of the escape circuitry.
              Because of the rapidity of the escape response, such effects are
              likely due to the elimination of tonic descending inputs.",
  journal  = "J. Neurobiol.",
  volume   =  49,
  number   =  1,
  pages    = "9--28",
  month    =  oct,
  year     =  2001,
  language = "en",
  issn     = "0022-3034",
  pmid     = "11536194"
}

@ARTICLE{Domenici2011-ex,
  title    = "Animal escapology I: theoretical issues and emerging trends in
              escape trajectories",
  author   = "Domenici, Paolo and Blagburn, Jonathan M and Bacon, Jonathan P",
  abstract = "Escape responses are used by many animal species as their main
              defence against predator attacks. Escape success is determined by
              a number of variables; important are the directionality (the
              percentage of responses directed away from the threat) and the
              escape trajectories (ETs) measured relative to the threat.
              Although logic would suggest that animals should always turn away
              from a predator, work on various species shows that these away
              responses occur only approximately 50-90\% of the time. A small
              proportion of towards responses may introduce some
              unpredictability and may be an adaptive feature of the escape
              system. Similar issues apply to ETs. Theoretically, an optimal ET
              can be modelled on the geometry of predator-prey encounters.
              However, unpredictability (and hence high variability) in
              trajectories may be necessary for preventing predators from
              learning a simple escape pattern. This review discusses the
              emerging trends in escape trajectories, as well as the modulating
              key factors, such as the surroundings and body design. The main
              ET patterns identified are: (1) high ET variability within a
              limited angular sector (mainly 90-180 deg away from the threat;
              this variability is in some cases based on multiple peaks of
              ETs), (2) ETs that allow sensory tracking of the threat and (3)
              ETs towards a shelter. These characteristic features are observed
              across various taxa and, therefore, their expression may be
              mainly related to taxon-independent animal design features and to
              the environmental context in which prey live - for example
              whether the immediate surroundings of the prey provide potential
              refuges.",
  journal  = "J. Exp. Biol.",
  volume   =  214,
  number   = "Pt 15",
  pages    = "2463--2473",
  month    =  aug,
  year     =  2011,
  language = "en",
  issn     = "0022-0949, 1477-9145",
  pmid     = "21753039",
  doi      = "10.1242/jeb.029652",
  pmc      = "PMC4495464"
}

@ARTICLE{Ache2019-jc,
  title    = "Neural Basis for Looming Size and Velocity Encoding in the
              Drosophila Giant Fiber Escape Pathway",
  author   = "Ache, Jan M and Polsky, Jason and Alghailani, Shada and Parekh,
              Ruchi and Breads, Patrick and Peek, Martin Y and Bock, Davi D and
              von Reyn, Catherine R and Card, Gwyneth M",
  abstract = "Identified neuron classes in vertebrate cortical [1-4] and
              subcortical [5-8] areas and invertebrate peripheral [9-11] and
              central [12-14] brain neuropils encode specific visual features
              of a panorama. How downstream neurons integrate these features to
              control vital behaviors, like escape, is unclear [15]. In
              Drosophila, the timing of a single spike in the giant fiber (GF)
              descending neuron [16-18] determines whether a fly uses a short
              or long takeoff when escaping a looming predator [13]. We
              previously proposed that GF spike timing results from summation
              of two visual features whose detection is highly conserved across
              animals [19]: an object's subtended angular size and its angular
              velocity [5-8, 11, 20, 21]. We attributed velocity encoding to
              input from lobula columnar type 4 (LC4) visual projection
              neurons, but the size-encoding source remained unknown. Here, we
              show that lobula plate/lobula columnar, type 2 (LPLC2) visual
              projection neurons anatomically specialized to detect looming
              [22] provide the entire GF size component. We find LPLC2 neurons
              to be necessary for GF-mediated escape and show that LPLC2 and
              LC4 synapse directly onto the GF via reconstruction in a fly
              brain electron microscopy (EM) volume [23]. LPLC2 silencing
              eliminates the size component of the GF looming response in
              patch-clamp recordings, leaving only the velocity component. A
              model summing a linear function of angular velocity (provided by
              LC4) and a Gaussian function of angular size (provided by LPLC2)
              replicates GF looming response dynamics and predicts the peak
              response time. We thus present an identified circuit in which
              information from looming feature-detecting neurons is combined by
              a common post-synaptic target to determine behavioral output.",
  journal  = "Curr. Biol.",
  volume   =  29,
  number   =  6,
  pages    = "1073--1081.e4",
  month    =  mar,
  year     =  2019,
  keywords = "Drosophila; descending neuron; electrophysiology; escape; in vivo
              patch clamp; neural circuit reconstruction; sensorimotor
              integration; visual feature detection; visual looming; visual
              projection neuron",
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "30827912",
  doi      = "10.1016/j.cub.2019.01.079"
}

@ARTICLE{Peek2016-wi,
  title    = "Comparative approaches to escape",
  author   = "Peek, Martin Y and Card, Gwyneth M",
  abstract = "Neural circuits mediating visually evoked escape behaviors are
              promising systems in which to dissect the neural basis of
              behavior. Behavioral responses to predator-like looming stimuli,
              and their underlying neural computations, are remarkably similar
              across species. Recently, genetic tools have been applied in this
              classical paradigm, revealing novel non-cortical pathways that
              connect loom processing to defensive behaviors in mammals and
              demonstrating that loom encoding models from locusts also fit
              vertebrate neural responses. In both invertebrates and
              vertebrates, relative spike-timing in descending pathways is a
              mechanism for escape behavior choice. Current findings suggest
              that experimentally tractable systems, such as Drosophila, may be
              applicable models for sensorimotor processing and persistent
              states in higher organisms.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  41,
  pages    = "167--173",
  month    =  dec,
  year     =  2016,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "27710794",
  doi      = "10.1016/j.conb.2016.09.012"
}

@ARTICLE{noauthor_undated-vy,
  title = "mataric.pdf"
}

@ARTICLE{Borst1999-st,
  title    = "Information theory and neural coding",
  author   = "Borst, A and Theunissen, F E",
  abstract = "Information theory quantifies how much information a neural
              response carries about the stimulus. This can be compared to the
              information transferred in particular models of the
              stimulus-response function and to maximum possible information
              transfer. Such comparisons are crucial because they validate
              assumptions present in any neurophysiological analysis. Here we
              review information-theory basics before demonstrating its use in
              neural coding. We show how to use information theory to validate
              simple stimulus-response models of neural coding of dynamic
              stimuli. Because these models require specification of spike
              timing precision, they can reveal which time scales contain
              information in neural coding. This approach shows that dynamic
              stimuli can be encoded efficiently by single neurons and that
              each spike contributes to information transmission. We argue,
              however, that the data obtained so far do not suggest a temporal
              code, in which the placement of spikes relative to each other
              yields additional information.",
  journal  = "Nat. Neurosci.",
  volume   =  2,
  number   =  11,
  pages    = "947--957",
  month    =  nov,
  year     =  1999,
  language = "en",
  issn     = "1097-6256",
  pmid     = "10526332",
  doi      = "10.1038/14731"
}

@INCOLLECTION{Nadel2006-ld,
  title     = "Information Theory",
  booktitle = "Encyclopedia of Cognitive Science",
  editor    = "Nadel, Lynn",
  abstract  = "Abstract Information theory is a mathematical theory defining
               the limits and possibilities of communication. It provides a
               quantitative measure of the information content of a message,
               which is independent of the meaning of the message, in terms of
               the reduction of uncertainty resulting from receiving the
               message.",
  publisher = "John Wiley \& Sons, Ltd",
  volume    =  61,
  pages     = "183",
  month     =  jan,
  year      =  2006,
  address   = "Chichester",
  isbn      = "9780470016190, 9780470016190",
  doi       = "10.1002/0470018860.s00643"
}

@ARTICLE{Dimitrov2011-fm,
  title    = "Information theory in neuroscience",
  author   = "Dimitrov, Alexander G and Lazar, Aurel A and Victor, Jonathan D",
  journal  = "J. Comput. Neurosci.",
  volume   =  30,
  number   =  1,
  pages    = "1--5",
  month    =  feb,
  year     =  2011,
  language = "en",
  issn     = "0929-5313, 1573-6873",
  pmid     = "21279429",
  doi      = "10.1007/s10827-011-0314-3",
  pmc      = "PMC3736735"
}

@ARTICLE{Kawato2007-vk,
  title     = "Efficient reinforcement learning: computational theories,
               neuroscience and robotics",
  author    = "Kawato, Mitsuo and Samejima, Kazuyuki",
  abstract  = "Reinforcement learning algorithms have provided some of the most
               influential computational theories for behavioral learning that
               depends on reward and penalty. After briefly reviewing
               supporting experimental data, this paper tackles three difficult
               theoretical issues that remain to be explored. First, plain
               reinforcement learning is much too slow to be considered a
               plausible brain model. Second, although the temporal-difference
               error has an important role both in theory and in experiments,
               how to compute it remains an enigma. Third, function of all
               brain areas, including the cerebral cortex, cerebellum,
               brainstem and basal ganglia, seems to necessitate a new
               computational framework. Computational studies that emphasize
               meta-parameters, hierarchy, modularity and supervised learning
               to resolve these issues are reviewed here, together with the
               related experimental data.",
  journal   = "Curr. Opin. Neurobiol.",
  publisher = "Elsevier",
  volume    =  17,
  number    =  2,
  pages     = "205--212",
  month     =  apr,
  year      =  2007,
  language  = "en",
  issn      = "0959-4388",
  pmid      = "17374483",
  doi       = "10.1016/j.conb.2007.03.004"
}

@ARTICLE{Alexander1990-rz,
  title     = "Functional architecture of basal ganglia circuits: neural
               substrates of parallel processing",
  author    = "Alexander, G E and Crutcher, M D",
  abstract  = "Concepts of basal ganglia organization have changed markedly
               over the past decade, due to significant advances in our
               understanding of the anatomy, physiology and pharmacology of
               these structures. Independent evidence from each of these fields
               has reinforced a growing perception that the functional
               architecture of the basal ganglia is essentially parallel in
               nature, regardless of the perspective from which these
               structures are viewed. This represents a significant departure
               from earlier concepts of basal ganglia organization, which
               generally emphasized the serial aspects of their connectivity.
               Current evidence suggests that the basal ganglia are organized
               into several structurally and functionally distinct 'circuits'
               that link cortex, basal ganglia and thalamus, with each circuit
               focused on a different portion of the frontal lobe. In this
               review, Garrett Alexander and Michael Crutcher, using the basal
               ganglia 'motor' circuit as the principal example, discuss recent
               evidence indicating that a parallel functional architecture may
               also be characteristic of the organization within each
               individual circuit.",
  journal   = "Trends Neurosci.",
  publisher = "Elsevier",
  volume    =  13,
  number    =  7,
  pages     = "266--271",
  month     =  jul,
  year      =  1990,
  language  = "en",
  issn      = "0166-2236",
  pmid      = "1695401"
}

@ARTICLE{Maaswinkel1999-yb,
  title    = "Homing with locale, taxon, and dead reckoning strategies by
              foraging rats: sensory hierarchy in spatial navigation",
  author   = "Maaswinkel, H and Whishaw, I Q",
  abstract = "Studies on foraging rats suggest that they can use visual,
              olfactory, and self-movement cues for spatial guidance, but their
              relative reliance on these different cues is not well understood.
              In the present study, rats left a hidden refuge to search for a
              large food pellet located somewhere on a circular table, and the
              accuracy with which they returned to the refuge with the food
              pellet was measured. Cue use was manipulated by administering
              probe trials from novel locations, blindfolding, moving the home
              cage relative to the table, rotating the table and using
              combinations of these manipulations. When visual cues were
              available and a consistent starting location used, a visual
              strategy dominated performance. When blindfolded, the rats used
              olfactory cues from the surface of the table and from the
              starting hole. When olfactory stimuli were made uninformative, by
              changing the starting hole and rotating the table, the rats still
              homed accurately, suggesting they used self-movement cues. In a
              number of cue combinations, in which cues gave conflicting
              information, performance degraded. The results suggest that rats
              display a hierarchical preference in using visual, olfactory and
              self-movement cues while at the same time being able to reaffirm
              or switch between various cue combinations. The results are
              discussed in relation to ideas concerning the neural basis of
              spatial navigation.",
  journal  = "Behav. Brain Res.",
  volume   =  99,
  number   =  2,
  pages    = "143--152",
  month    =  mar,
  year     =  1999,
  language = "en",
  issn     = "0166-4328",
  pmid     = "10512581",
  doi      = "10.1016/S0166-4328(98)00100-4"
}

@ARTICLE{Marques2018-kf,
  title    = "Structure of the Zebrafish Locomotor Repertoire Revealed with
              Unsupervised Behavioral Clustering",
  author   = "Marques, Jo{\~a}o C and Lackner, Simone and F{\'e}lix, Rita and
              Orger, Michael B",
  abstract = "An important concept in ethology is that complex behaviors can be
              constructed from a set of basic motor patterns. Identifying the
              set of patterns available to an animal is key to making
              quantitative descriptions of behavior that reflect the underlying
              motor system organization. We addressed these questions in
              zebrafish larvae, which swim in bouts that are naturally
              segmented in time. We developed a robust and general purpose
              clustering method (clusterdv) to ensure accurate identification
              of movement clusters and applied it to a dataset consisting of
              millions of swim bouts, captured at high temporal resolution from
              a comprehensive set of behavioral contexts. We identified a set
              of thirteen basic swimming patterns that are used flexibly in
              various combinations across different behavioral contexts and
              show that this classification can be used to dissect the
              sensorimotor transformations underlying larval social behavior
              and hunting. Furthermore, using the same approach at different
              levels in the behavioral hierarchy, we show that the set of swim
              bouts are themselves constructed from a basic set of tail
              movements and that bouts are executed in sequences specific to
              different behaviors.",
  journal  = "Curr. Biol.",
  volume   =  28,
  number   =  2,
  pages    = "181--195.e5",
  month    =  jan,
  year     =  2018,
  keywords = "behavior; behavioral motifs; cluster analysis; clusterdv;
              locomotion; motor control; sequences; unsupervised machine
              learning; visual behavior; zebrafish",
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "29307558",
  doi      = "10.1016/j.cub.2017.12.002"
}

@ARTICLE{Pereira2019-ym,
  title    = "Fast animal pose estimation using deep neural networks",
  author   = "Pereira, Talmo D and Aldarondo, Diego E and Willmore, Lindsay and
              Kislin, Mikhail and Wang, Samuel S-H and Murthy, Mala and
              Shaevitz, Joshua W",
  abstract = "The need for automated and efficient systems for tracking full
              animal pose has increased with the complexity of behavioral data
              and analyses. Here we introduce LEAP (LEAP estimates animal
              pose), a deep-learning-based method for predicting the positions
              of animal body parts. This framework consists of a graphical
              interface for labeling of body parts and training the network.
              LEAP offers fast prediction on new data, and training with as few
              as 100 frames results in 95\% of peak performance. We validated
              LEAP using videos of freely behaving fruit flies and tracked 32
              distinct points to describe the pose of the head, body, wings and
              legs, with an error rate of <3\% of body length. We recapitulated
              reported findings on insect gait dynamics and demonstrated LEAP's
              applicability for unsupervised behavioral classification.
              Finally, we extended the method to more challenging imaging
              situations and videos of freely moving mice.",
  journal  = "Nat. Methods",
  volume   =  16,
  number   =  1,
  pages    = "117--125",
  month    =  jan,
  year     =  2019,
  language = "en",
  issn     = "1548-7091, 1548-7105",
  pmid     = "30573820",
  doi      = "10.1038/s41592-018-0234-5"
}

@INPROCEEDINGS{Koza1991-pg,
  title     = "Evolution and co-evolution of computer programs to control
               independently-acting agents",
  booktitle = "Proceedings of the First International Conference on Simulation
               of Adaptive Behavior: From Animals to Animats. {MIT} Press,
               Cambridge, {MA}",
  author    = "Koza, John R",
  abstract  = "This paper describes the recently developed`` genetic
               programming'' paradigm which genetically breeds populations of
               computer programs to solve problems. In genetic programming, the
               individuals in the population are hierarchical computer programs
               of various sizes and shapes. This paper also extends the genetic
               programming paradigm to a`` co-evolution'' algorithm which
               operates simultaneously on two populations of independently-
               acting hierarchical computer programs of various sizes and
               shapes.",
  publisher = "sci.brooklyn.cuny.edu",
  pages     = "366--375",
  year      =  1991
}

@ARTICLE{noauthor_undated-eq,
  title = "Decision Field Theory"
}

@UNPUBLISHED{Mohl2019-dl,
  title    = "Sensitivity and specificity of a Bayesian single trial analysis
              for time varying neural signals",
  author   = "Mohl, Jeff T and Caruso, Valeria C and Tokdar, Surya T and Groh,
              J M",
  abstract = "We recently reported the existence of fluctuations in neural
              signals that may permit neurons to code multiple simultaneous
              stimuli sequentially across time[1][1]. This required deploying a
              novel statistical approach to permit investigation of neural
              activity at the scale of individual trials. Here we present tests
              using synthetic data to assess the sensitivity and specificity of
              this analysis. Data sets were fabricated to match each of several
              potential response patterns derived from single-stimulus response
              distributions. In particular, we simulated dual stimulus trial
              spike counts that reflected fluctuating mixtures of the single
              stimulus spike counts, stable intermediate averages, single
              stimulus winner-take-all, or response distributions that were
              outside the range defined by the single stimulus responses (such
              as summation or suppression). We then assessed how well the
              analysis recovered the correct response pattern as a function of
              the number of simulated trials and the difference between the
              simulated responses to each ``stimulus'' alone. We found
              excellent recovery of the mixture, intermediate, and outside
              categories (>97\% correct), and good recovery of the
              single/winner-take-all category (>90\% correct) when the number
              of trials was >20 and the single-stimulus response rates were
              50Hz and 20Hz respectively. Both larger numbers of trials and
              greater separation between the single stimulus firing rates
              improved categorization accuracy. The results provide a valid
              benchmark, and guidelines for data collection, for use of this
              method to investigate coding of multiple items at the
              individual-trial time scale. [1]: \#ref-1",
  journal  = "bioRxiv",
  pages    = "690958",
  month    =  jul,
  year     =  2019,
  language = "en",
  doi      = "10.1101/690958"
}

@ARTICLE{Bari2019-iw,
  title    = "Stable Representations of Decision Variables for Flexible
              Behavior",
  author   = "Bari, Bilal A and Grossman, Cooper D and Lubin, Emily E and
              Rajagopalan, Adithya E and Cressy, Jianna I and Cohen, Jeremiah Y",
  abstract = "Decisions occur in dynamic environments. In the framework of
              reinforcement learning, the probability of performing an action
              is influenced by decision variables. Discrepancies between
              predicted and obtained rewards (reward prediction errors) update
              these variables, but they are otherwise stable between decisions.
              Although reward prediction errors have been mapped to midbrain
              dopamine neurons, it is unclear how the brain represents decision
              variables themselves. We trained mice on a dynamic foraging task
              in which they chose between alternatives that delivered reward
              with changing probabilities. Neurons in the medial prefrontal
              cortex, including projections to the dorsomedial striatum,
              maintained persistent firing rate changes over long timescales.
              These changes stably represented relative action values (to bias
              choices) and total action values (to bias response times) with
              slow decay. In contrast, decision variables were weakly
              represented in the anterolateral motor cortex, a region necessary
              for generating choices. Thus, we define a stable neural mechanism
              to drive flexible behavior.",
  journal  = "Neuron",
  month    =  jun,
  year     =  2019,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "31280924",
  doi      = "10.1016/j.neuron.2019.06.001"
}

@MISC{Hyvonen2019-se,
  title        = "Bayesian Inference 2019",
  author       = "Hyv{\"o}nen, Ville and Tolonen, Topias",
  abstract     = "Lecture notes for Bayesian Inference course lectured at
                  University of Helsinki Spring 2019",
  month        =  mar,
  year         =  2019,
  howpublished = "\url{https://vioshyvo.github.io/Bayesian_inference/index.html}",
  note         = "Accessed: 2019-7-15",
  keywords     = "books"
}

@ARTICLE{Draft2018-dk,
  title    = "Carpenter ants use diverse antennae sampling strategies to track
              odor trails",
  author   = "Draft, Ryan W and McGill, Matthew R and Kapoor, Vikrant and
              Murthy, Venkatesh N",
  abstract = "Directed and meaningful animal behavior depends on the ability to
              sense key features in the environment. Among the different
              environmental signals, olfactory cues are critically important
              for foraging, navigation and social communication in many
              species, including ants. Ants use their two antennae to explore
              the olfactory world, but how they do so remains largely unknown.
              In this study, we used high-resolution videography to
              characterize the antennae dynamics of carpenter ants (Camponotus
              pennsylvanicus). Antennae are highly active during both odor
              tracking and exploratory behavior. When tracking, ants used
              several distinct behavioral strategies with stereotyped antennae
              sampling patterns (which we call 'sinusoidal', 'probing' and
              'trail following'). In all behaviors, left and right antennae
              movements were anti-correlated, and tracking ants exhibited
              biases in the use of left versus right antenna to sample the odor
              trail. These results suggest non-redundant roles for the two
              antennae. In one of the behavioral modules (trail following),
              ants used both antennae to detect trail edges and direct
              subsequent turns, suggesting a specialized form of tropotaxis.
              Lastly, removal of an antenna resulted not only in less accurate
              tracking but also in changes in the sampling pattern of the
              remaining antenna. Our quantitative characterization of odor
              trail tracking lays a foundation to build better models of
              olfactory sensory processing and sensorimotor behavior in
              terrestrial insects.",
  journal  = "J. Exp. Biol.",
  volume   =  221,
  number   = "Pt 22",
  month    =  nov,
  year     =  2018,
  keywords = "Behavior; Camponotus; Navigation; Olfaction; Pheromone; Trail
              tracking",
  language = "en",
  issn     = "0022-0949, 1477-9145",
  pmid     = "30266788",
  doi      = "10.1242/jeb.185124"
}

@ARTICLE{Sohn2019-kc,
  title    = "Bayesian Computation through Cortical Latent Dynamics",
  author   = "Sohn, Hansem and Narain, Devika and Meirhaeghe, Nicolas and
              Jazayeri, Mehrdad",
  abstract = "Statistical regularities in the environment create prior beliefs
              that we rely on to optimize our behavior when sensory information
              is uncertain. Bayesian theory formalizes how prior beliefs can be
              leveraged and has had a major impact on models of perception,
              sensorimotor function, and cognition. However, it is not known
              how recurrent interactions among neurons mediate Bayesian
              integration. By using a time-interval reproduction task in
              monkeys, we found that prior statistics warp neural
              representations in the frontal cortex, allowing the mapping of
              sensory inputs to motor outputs to incorporate prior statistics
              in accordance with Bayesian inference. Analysis of recurrent
              neural network models performing the task revealed that this
              warping was enabled by a low-dimensional curved manifold and
              allowed us to further probe the potential causal underpinnings of
              this computational strategy. These results uncover a simple and
              general principle whereby prior beliefs exert their influence on
              behavior by sculpting cortical latent dynamics.",
  journal  = "Neuron",
  month    =  jul,
  year     =  2019,
  keywords = "Bayesian inference; Bayesian integration; frontal cortex; neural
              manifold; neural trajectories; recurrent neural networks",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "31320220",
  doi      = "10.1016/j.neuron.2019.06.012"
}

@UNPUBLISHED{Trueblood2019-vi,
  title    = "Urgency, Leakage, and the Relative Nature of Information
              Processing in Decision-making",
  author   = "Trueblood, Jennifer S and Heathcote, Andrew and Evans, Nathan J
              and Holmes, William R",
  abstract = "Over the last decade, there has been a robust debate in decision
              neuroscience and psychology about what mechanism governs the time
              course of decision making. Historically, the most prominent
              hypothesis is that neural architectures accumulate information
              over time until some threshold is met, the so-called Evidence
              Accumulation hypothesis. However, most applications of this
              theory rely on simplifying assumptions, belying a number of
              potential complexities. Is changing stimulus information
              perceived and processed in an independent manner or is there a
              relative component? Does urgency play a role? What about evidence
              leakage? Although the latter questions have been the subject of
              recent investigations, most studies to date have been piecemeal
              in nature, addressing one aspect of the decision process or
              another. Here we develop a modeling framework, an extension of
              the Urgency Gating Model, in conjunction with a changing
              information experimental paradigm to simultaneously probe these
              aspects of the decision process. Using state-of-the-art Bayesian
              methods to perform parameter-based inference, we find that 1)
              information processing is relative with early information
              influencing the perception of late information, 2) time varying
              urgency and evidence accumulation are of roughly equal importance
              in the decision process, and 3) leakage is present with a time
              scale of ~200-250ms. To our knowledge, this is the first
              comprehensive study to utilize a changing information paradigm to
              jointly and quantitatively estimate the temporal dynamics of
              human decision-making.",
  journal  = "bioRxiv",
  pages    = "706291",
  month    =  jul,
  year     =  2019,
  language = "en",
  doi      = "10.1101/706291"
}

@ARTICLE{Iwanir2019-dw,
  title    = "Irrational behavior in C. elegans arises from asymmetric
              modulatory effects within single sensory neurons",
  author   = "Iwanir, Shachar and Ruach, Rotem and Itskovits, Eyal and Pritz,
              Christian O and Bokman, Eduard and Zaslaver, Alon",
  abstract = "C. elegans worms exhibit a natural chemotaxis towards food cues.
              This provides a potential platform to study the interactions
              between stimulus valence and innate behavioral preferences. Here
              we perform a comprehensive set of choice assays to measure worms'
              relative preference towards various attractants. Surprisingly, we
              find that when facing a combination of choices, worms'
              preferences do not always follow value-based hierarchy. In fact,
              the innate chemotaxis behavior in worms robustly violates key
              rationality paradigms of transitivity, independence of irrelevant
              alternatives and regularity. These violations arise due to
              asymmetric modulatory effects between the presented options.
              Functional analysis of the entire chemosensory system at a
              single-neuron resolution, coupled with analyses of mutants,
              defective in individual neurons, reveals that these asymmetric
              effects originate in specific sensory neurons.",
  journal  = "Nat. Commun.",
  volume   =  10,
  number   =  1,
  pages    = "3202",
  month    =  jul,
  year     =  2019,
  language = "en",
  issn     = "2041-1723",
  pmid     = "31324786",
  doi      = "10.1038/s41467-019-11163-3",
  pmc      = "PMC6642097"
}

@ARTICLE{Gershman_undated-ml,
  title  = "The generative adversarial brain",
  author = "Gershman, Samuel J"
}

@UNPUBLISHED{Gupta2019-hk,
  title    = "A context-free grammar for Caenorhabditis elegans behavior",
  author   = "Gupta, Saurabh and Gomez-Marin, Alex",
  abstract = "Hierarchy is a candidate organizing principle of ethology, where
              actions grouped into higher order chunks combine in specific ways
              to generate adaptive behavior. However, demonstrations of
              hierarchical organization in behavior have been scarce. Moreover,
              it remains unclear how such underlying organization allows for
              behavioral flexibility. Here we uncover the hierarchical and
              flexible nature of Caenorhabditis elegans behavior. By describing
              worm locomotion as a sequence of discrete postural templates, we
              identified chunks containing mutually substitutable postures
              along the dynamics. We then elucidated the rules governing their
              interactions. We found that stereotypical roaming can be
              described by a specific sequence of postural chunks, which
              exhibit flexibility at the lowest postural level. The same chunks
              get combined differently to produce dwelling, capturing
              non-stereotypical actions across timescales. We show that worm
              foraging is organized hierarchically ---a feature not explainable
              via Markovian dynamics---, and derive a context-free grammar
              governing its behavior ---which is different than a regular
              grammar, or a hidden Markov chain. In sum, in making the analogy
              with human language concrete (but not literal) our work
              demonstrates, in line with the foundational insights of classical
              ethologists, that spontaneous behavior is orderly flexible. Once
              more, investigating the humble nematode suggests that everything
              human has its roots in lower animal behavior. ![Figure][1]
              Graphical abstract [1]: pending:yes",
  journal  = "bioRxiv",
  pages    = "708891",
  month    =  jul,
  year     =  2019,
  language = "en",
  doi      = "10.1101/708891"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{McNamara2014-xz,
  title     = "Natural selection can favour `irrational'behaviour",
  author    = "McNamara, John M and Trimmer, Pete C and Houston, A I",
  abstract  = "Understanding decisions is the fundamental aim of the
               behavioural sciences. The theory of rational choice is based on
               axiomatic principles such as transitivity and independence of
               irrelevant alternatives (IIA). Empirical studies have
               demonstrated that the behaviour of humans and other animals
               often seems irrational; there can be a lack of transitivity in
               choice and seemingly irrelevant alternatives can alter
               decisions. These violations of transitivity and IIA undermine
               rational choice theory. However, we show that an individual that
               is …",
  journal   = "Biol. Lett.",
  publisher = "The Royal Society",
  volume    =  10,
  number    =  1,
  pages     = "20130935",
  year      =  2014,
  issn      = "1744-9561"
}

@ARTICLE{Pouget2003-qe,
  title    = "Inference and computation with population codes",
  author   = "Pouget, Alexandre and Dayan, Peter and Zemel, Richard S",
  abstract = "In the vertebrate nervous system, sensory stimuli are typically
              encoded through the concerted activity of large populations of
              neurons. Classically, these patterns of activity have been
              treated as encoding the value of the stimulus (e.g., the
              orientation of a contour), and computation has been formalized in
              terms of function approximation. More recently, there have been
              several suggestions that neural computation is akin to a Bayesian
              inference process, with population activity patterns representing
              uncertainty about stimuli in the form of probability
              distributions (e.g., the probability density function over the
              orientation of a contour). This paper reviews both approaches,
              with a particular emphasis on the latter, which we see as a very
              promising framework for future modeling and experimental work.",
  journal  = "Annu. Rev. Neurosci.",
  volume   =  26,
  pages    = "381--410",
  month    =  apr,
  year     =  2003,
  language = "en",
  issn     = "0147-006X",
  pmid     = "12704222",
  doi      = "10.1146/annurev.neuro.26.041002.131112"
}

@ARTICLE{Whitlock2014-oa,
  title    = "Navigating actions through the rodent parietal cortex",
  author   = "Whitlock, Jonathan R",
  abstract = "The posterior parietal cortex (PPC) participates in a manifold of
              cognitive functions, including visual attention, working memory,
              spatial processing, and movement planning. Given the vast
              interconnectivity of PPC with sensory and motor areas, it is not
              surprising that neuronal recordings show that PPC often encodes
              mixtures of spatial information as well as the movements required
              to reach a goal. Recent work sought to discern the relative
              strength of spatial vs. motor signaling in PPC by recording
              single unit activity in PPC of freely behaving rats during
              selective changes in either the spatial layout of the local
              environment or in the pattern of locomotor behaviors executed
              during navigational tasks. The results revealed unequivocally a
              predominant sensitivity of PPC neurons to locomotor action
              structure, with subsets of cells even encoding upcoming movements
              more than 1 s in advance. In light of these and other recent
              findings in the field, I propose that one of the key
              contributions of PPC to navigation is the synthesis of
              goal-directed behavioral sequences, and that the rodent PPC may
              serve as an apt system to investigate cellular mechanisms for
              spatial motor planning as traditionally studied in humans and
              monkeys.",
  journal  = "Front. Hum. Neurosci.",
  volume   =  8,
  pages    = "293",
  month    =  may,
  year     =  2014,
  keywords = "cognitive motor function; parietal cortex; parieto-frontal
              network; rodent model; spatial navigation",
  language = "en",
  issn     = "1662-5161",
  pmid     = "24860475",
  doi      = "10.3389/fnhum.2014.00293",
  pmc      = "PMC4026689"
}

@ARTICLE{Harvey2012-th,
  title    = "Choice-specific sequences in parietal cortex during a
              virtual-navigation decision task",
  author   = "Harvey, Christopher D and Coen, Philip and Tank, David W",
  abstract = "The posterior parietal cortex (PPC) has an important role in many
              cognitive behaviours; however, the neural circuit dynamics
              underlying PPC function are not well understood. Here we
              optically imaged the spatial and temporal activity patterns of
              neuronal populations in mice performing a PPC-dependent task that
              combined a perceptual decision and memory-guided navigation in a
              virtual environment. Individual neurons had transient activation
              staggered relative to one another in time, forming a sequence of
              neuronal activation spanning the entire length of a task trial.
              Distinct sequences of neurons were triggered on trials with
              opposite behavioural choices and defined divergent,
              choice-specific trajectories through a state space of neuronal
              population activity. Cells participating in the different
              sequences and at distinct time points in the task were
              anatomically intermixed over microcircuit length scales (<100
              micrometres). During working memory decision tasks, the PPC may
              therefore perform computations through sequence-based circuit
              dynamics, rather than long-lived stable states, implemented using
              anatomically intermingled microcircuits.",
  journal  = "Nature",
  volume   =  484,
  number   =  7392,
  pages    = "62--68",
  month    =  mar,
  year     =  2012,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "22419153",
  doi      = "10.1038/nature10918",
  pmc      = "PMC3321074"
}

@ARTICLE{Krumin2018-vd,
  title     = "Decision and navigation in mouse parietal cortex",
  author    = "Krumin, Michael and Lee, Julie J and Harris, Kenneth D and
               Carandini, Matteo",
  abstract  = "Posterior parietal cortex (PPC) has been implicated in
               navigation, in the control of movement, and in visually-guided
               decisions. To relate these views, we measured activity in PPC
               while mice performed a virtual navigation task driven by visual
               decisions. PPC neurons were selective for specific combinations
               of the animal's spatial position and heading angle. This
               selectivity closely predicted both the activity of individual
               PPC neurons, and the arrangement of their collective firing
               patterns in choice-selective sequences. These sequences
               reflected PPC encoding of the animal's navigation trajectory.
               Using decision as a predictor instead of heading yielded worse
               fits, and using it in addition to heading only slightly improved
               the fits. Alternative models based on visual or motor variables
               were inferior. We conclude that when mice use vision to choose
               their trajectories, a large fraction of parietal cortex activity
               can be predicted from simple attributes such as spatial position
               and heading.",
  journal   = "Elife",
  publisher = "cdn.elifesciences.org",
  volume    =  7,
  month     =  nov,
  year      =  2018,
  keywords  = "cortex; decision; mouse; navigation; neuroscience; visual
               processing",
  language  = "en",
  issn      = "2050-084X",
  pmid      = "30468146",
  doi       = "10.7554/eLife.42583",
  pmc       = "PMC6300355"
}

@ARTICLE{Mitchell2018-wv,
  title    = "Retrosplenial cortex and its role in spatial cognition",
  author   = "Mitchell, Anna S and Czajkowski, Rafal and Zhang, Ningyu and
              Jeffery, Kate and Nelson, Andrew J D",
  abstract = "Retrosplenial cortex is a region within the posterior neocortical
              system, heavily interconnected with an array of brain networks,
              both cortical and subcortical, that is, engaged by a myriad of
              cognitive tasks. Although there is no consensus as to its precise
              function, evidence from both human and animal studies clearly
              points to a role in spatial cognition. However, the spatial
              processing impairments that follow retrosplenial cortex damage
              are not straightforward to characterise, leading to difficulties
              in defining the exact nature of its role. In this article, we
              review this literature and classify the types of ideas that have
              been put forward into three broad, somewhat overlapping classes:
              (1) learning of landmark location, stability and permanence; (2)
              integration between spatial reference frames; and (3)
              consolidation and retrieval of spatial knowledge (schemas). We
              evaluate these models and suggest ways to test them, before
              briefly discussing whether the spatial function may be a subset
              of a more general function in episodic memory.",
  journal  = "Brain Neurosci Adv",
  volume   =  2,
  pages    = "2398212818757098",
  month    =  mar,
  year     =  2018,
  keywords = "Learning; cingulate cortex; default mode network;
              electrophysiology; hippocampal formation; immediate-early genes;
              memory; neuroimaging; primate; thalamus",
  language = "en",
  issn     = "2398-2128",
  pmid     = "30221204",
  doi      = "10.1177/2398212818757098",
  pmc      = "PMC6095108"
}

@ARTICLE{Curto2016-sc,
  title    = "What can topology tell us about the neural code?",
  author   = "Curto, Carina",
  abstract = "Neuroscience is undergoing a period of rapid experimental
              progress and expansion. New mathematical tools, previously
              unknown in the neuroscience community, are now being used to
              tackle fundamental questions and analyze emerging data sets.
              Consistent with this trend, the last decade has seen an uptick in
              the use of topological ideas and methods in neuroscience. In this
              paper I will survey recent applications of topology in
              neuroscience, and explain why topology is an especially natural
              tool for understanding neural codes.",
  journal  = "Bull. Am. Math. Soc.",
  volume   =  54,
  number   =  1,
  pages    = "63--78",
  month    =  sep,
  year     =  2016,
  issn     = "0273-0979, 1088-9485",
  doi      = "10.1090/bull/1554"
}

@ARTICLE{Baas2017-zd,
  title    = "On the concept of space in neuroscience",
  author   = "Baas, Nils A",
  abstract = "In this paper we study recording of neurons creating spatial
              information in the brain. To sets of spike trains we associate a
              topological space which captures the structure of the space in
              which the movement takes place. This space has an even richer
              structure depending on other than spatial stimuli. We describe a
              method to separate the various stimuli and conclude when they
              describe the structure of the space. We discuss what we should
              mean by neural space and its structure, and come up with some
              speculations for the future.",
  journal  = "Current Opinion in Systems Biology",
  volume   =  1,
  pages    = "32--37",
  month    =  feb,
  year     =  2017,
  keywords = "Neurons; spike trains; place cells; grid cells; persistent
              homology; dynamic Ising model; neural space; hyperstructure",
  issn     = "2452-3100",
  doi      = "10.1016/j.coisb.2016.12.002"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Tolman1938-aa,
  title     = "The determiners of behavior at a choice point",
  author    = "Tolman, Edward Chace",
  abstract  = "An analysis of the complex of causal determinants on which a
               rat's behavior of turning right or left depends shows them to be
               divided into`` environmental variables,'' such as maintenance
               schedule, appropriate goal-object, types of stimuli provided and
               responses …",
  journal   = "Psychol. Rev.",
  publisher = "American Psychological Association",
  volume    =  45,
  number    =  1,
  pages     = "1",
  year      =  1938,
  issn      = "0033-295X"
}

@ARTICLE{Peleg2016-kk,
  title    = "Optimal switching between geocentric and egocentric strategies in
              navigation",
  author   = "Peleg, O and Mahadevan, L",
  abstract = "Animals use a combination of egocentric navigation driven by the
              internal integration of environmental cues, interspersed with
              geocentric course correction and reorientation. These processes
              are accompanied by uncertainty in sensory acquisition of
              information, planning and execution. Inspired by observations of
              dung beetle navigational strategies that show switching between
              geocentric and egocentric strategies, we consider the question of
              optimal reorientation rates for the navigation of an agent moving
              along a preferred direction in the presence of multiple sources
              of noise. We address this using a model that takes the form of a
              correlated random walk at short time scales that is punctuated by
              reorientation events leading to a biased random walks at long
              time scales. This allows us to identify optimal alternation
              schemes and characterize their robustness in the context of noisy
              sensory acquisition as well as performance errors linked with
              variations in environmental conditions and agent-environment
              interactions.",
  journal  = "R Soc Open Sci",
  volume   =  3,
  number   =  7,
  pages    = "160128",
  month    =  jul,
  year     =  2016,
  keywords = "cognition; navigation; optimal switching; random walks",
  language = "en",
  issn     = "2054-5703",
  pmid     = "27493769",
  doi      = "10.1098/rsos.160128",
  pmc      = "PMC4968461"
}

@ARTICLE{Humphries1970-rt,
  title    = "Protean defence by prey animals",
  author   = "Humphries, D A and Driver, P M",
  abstract = "Attention is drawn to the widespread occurrence ofprotean
              phenomena, in which the appearance and behaviour of prey animals
              are rendered variable and irregular, as a weapon in the
              biological arms race between predators and their prey. Protean
              behaviour is defined as that behaviour which is sufficiently
              unsystematic to prevent a reactor predicting in detail the
              position or actions of the actor.Single prey animals frequently
              flee from a predator in an irregular manner, zigzagging,
              spinning, looping, or bouncing. Thissingle erratic display occurs
              widely in the Animal Kingdom, and may also be utilised in
              everyday movements of potential prey as insurance against
              possible attack. Examples are given.In a group of prey animals
              the protean aspect of escape is enhanced by the effect of
              numbers. In scatter reactions the effect is of multiple choice
              and of the simultaneous operation of several single erratics. In
              mobbing displays there are also successive changes in the actors'
              behavioural role. In protean deterrence the shuffling of
              individuals within a tightly packed group prevents a predator
              from singling one out for attack.In many species the confusing
              effect of changes in movement and behavioural role is enhanced by
              rapid changes in appearance, particularly colour.It is suggested
              that those prey individuals which employ escape patterns
              unfamiliar to the predator will tend to be at a selective
              advantage. During phylogeny this is likely to lead to
              intra-specific and inter-specific increase in the number and
              diversity of escape behaviours. Apostatic polymorphism is seen as
              a special case of protean variation within populations.There is
              evidence that protean displays operate by arousing neurological
              conflict, thereby delaying the predator's reactions and reducing
              the effectiveness of predatory mechanisms. Also they insure
              against learned countermeasures by incorporating irregularities
              as a basic principle. It is stressed that the irregular
              variability of protean displays is not accidental but has been
              selected for in phylogeny. A number of poorly understood
              behavioural aspects of the ecology of predator-prey relationships
              are thus united in a single theory.",
  journal  = "Oecologia",
  volume   =  5,
  number   =  4,
  pages    = "285--302",
  month    =  dec,
  year     =  1970,
  language = "en",
  issn     = "0029-8549, 1432-1939",
  pmid     = "28309783",
  doi      = "10.1007/BF00815496"
}

@ARTICLE{Domenici2011-op,
  title    = "Animal escapology {II}: escape trajectory case studies",
  author   = "Domenici, Paolo and Blagburn, Jonathan M and Bacon, Jonathan P",
  abstract = "Escape trajectories (ETs; measured as the angle relative to the
              direction of the threat) have been studied in many taxa using a
              variety of methodologies and definitions. Here, we provide a
              review of methodological issues followed by a survey of ET
              studies across animal taxa, including insects, crustaceans,
              molluscs, lizards, fish, amphibians, birds and mammals.
              Variability in ETs is examined in terms of ecological
              significance and morpho-physiological constraints. The survey
              shows that certain escape strategies (single ETs and highly
              variable ETs within a limited angular sector) are found in most
              taxa reviewed here, suggesting that at least some of these ET
              distributions are the result of convergent evolution. High
              variability in ETs is found to be associated with multiple
              preferred trajectories in species from all taxa, and is suggested
              to provide unpredictability in the escape response. Random ETs
              are relatively rare and may be related to constraints in the
              manoeuvrability of the prey. Similarly, reports of the effect of
              refuges in the immediate environment are relatively uncommon, and
              mainly confined to lizards and mammals. This may be related to
              the fact that work on ETs carried out in laboratory settings has
              rarely provided shelters. Although there are a relatively large
              number of examples in the literature that suggest trends in the
              distribution of ETs, our understanding of animal escape
              strategies would benefit from a standardization of the analytical
              approach in the study of ETs, using circular statistics and
              related tests, in addition to the generation of large data sets.",
  journal  = "J. Exp. Biol.",
  volume   =  214,
  number   = "Pt 15",
  pages    = "2474--2494",
  month    =  aug,
  year     =  2011,
  language = "en",
  issn     = "0022-0949, 1477-9145",
  pmid     = "21753040",
  doi      = "10.1242/jeb.053801",
  pmc      = "PMC3135389"
}

@UNPUBLISHED{Cregg2019-ah,
  title    = "Brainstem Neurons that Command {Left/Right} Locomotor Asymmetries",
  author   = "Cregg, Jared M and Leiras, Roberto and Montalant, Alexia and
              Wickersham, Ian R and Kiehn, Ole",
  abstract = "Descending command neurons instruct spinal networks to execute
              basic locomotor functions, such as which gait and what speed. The
              command functions for gait and speed are symmetric, implying that
              a separate unknown system directs asymmetric movements---the
              ability to move left or right. Here we report the discovery that
              Chx10-lineage reticulospinal neurons act to control the direction
              of locomotor movements in mammals. Chx10 neurons exhibit
              ipsilateral projection, and can decrease spinal limb-based
              locomotor activity ipsilaterally. This circuit mechanism acts as
              the basis for left or right locomotor movements in freely moving
              animals: selective unilateral activation of Chx10 neurons causes
              ipsilateral movements whereas inhibition causes contralateral
              movements. Spontaneous forward locomotion is thus transformed
              into an ipsilateral movement by braking locomotion on the
              ipsilateral side. We identify sensorimotor brain regions that
              project onto Chx10 reticulospinal neurons, and demonstrate that
              their unilateral activation can impart left/right directional
              commands. Together these data identify the descending motor
              system which commands left/right locomotor asymmetries in
              mammals.",
  journal  = "bioRxiv",
  pages    = "754812",
  month    =  sep,
  year     =  2019,
  keywords = "Locomotion",
  language = "en",
  doi      = "10.1101/754812"
}

@ARTICLE{Carey2019-gk,
  title    = "Reward revaluation biases hippocampal replay content away from
              the preferred outcome",
  author   = "Carey, Alyssa A and Tanaka, Youki and van der Meer, Matthijs A A",
  abstract = "The rodent hippocampus spontaneously generates bursts of neural
              activity (replay) that can depict spatial trajectories to reward
              locations, suggesting a role in model-based behavioral control. A
              largely separate literature emphasizes reward revaluation as the
              litmus test for such control, yet the content of hippocampal
              replay under revaluation conditions is unknown. We examined the
              content of awake replay events following motivational shifts
              between hunger and thirst. On a T-maze offering free choice
              between food and water outcomes, rats shifted their behavior
              toward the restricted outcome, but replay content was shifted
              away from the restricted outcome. This effect preceded experience
              on the task each day and did not reverse with experience. These
              results demonstrate that replay content is not limited to
              reflecting recent experience or trajectories toward the preferred
              goal and suggest a role for motivational states in determining
              replay content.",
  journal  = "Nat. Neurosci.",
  month    =  aug,
  year     =  2019,
  issn     = "1097-6256, 1546-1726",
  doi      = "10.1038/s41593-019-0464-6"
}

@UNPUBLISHED{Fakhar2019-ew,
  title    = "Neuronal Causes and Behavioural Effects: a Review on Logical,
              Methodological, and Technical Issues With Respect to Causal
              Explanations of Behaviour in Neuroscience",
  author   = "Fakhar, Kayson and Gonschorek, Dominic and Schmors, Lisa and
              Bielczyk, Natalia Z",
  abstract = "Elucidating causal, neurobiological underpinnings of behaviour is
              an ultimate goal of every neuroscientific study. However, due to
              the complexity of the brain as well as the complexity of the
              human environment, finding a~causal architecture that underlies
              behaviour remains a~formidable challenge. In this manuscript, we
              review the logical and conceptual issues with respect to causal
              research in neuroscience. First, we review the state of the art
              interventional and computational approaches to infer causal
              brain-behaviour relationships. We provide an~overview of
              potential issues, flaws, and confounds in these studies. We
              conclude that studies on the causal structure underlying
              behaviour should be performed by accumulating evidence coming
              from several lines of experimental and modelling studies. Lastly,
              we also propose computational models including artificial
              neuronal networks and simulated animats as a~potential
              breakthrough to causal brain-behaviour investigations.",
  month    =  aug,
  year     =  2019,
  keywords = "brain-behaviour relations; brain interventions; causal inference;
              causality; cause and effect; computational models; Necessity and
              Sufficiency",
  doi      = "10.31234/osf.io/zk2dy"
}

@INCOLLECTION{Gomez-Marin2017-xa,
  title     = "Causal Circuit Explanations of Behavior: Are Necessity and
               Sufficiency Necessary and Sufficient?",
  booktitle = "Decoding Neural Circuit Structure and Function: Cellular
               Dissection Using Genetic Model Organisms",
  author    = "Gomez-Marin, Alex",
  editor    = "{\c C}elik, Arzu and Wernet, Mathias F",
  abstract  = "In the current advent of technological innovation allowing for
               precise neural manipulations and copious data collection, it is
               hardly questioned that the explanation of behavioral processes
               is to be chiefly found in neural circuits. Such belief, rooted
               in the exhausted dualism of cause and effect, is enacted by a
               methodology that promotes ``necessity and sufficiency'' claims
               as the goal-standard in neuroscience, thus instructing young
               students on what shall reckon as explanation. Here I wish to
               deconstruct and explicate the difference between what is done,
               what is said, and what is meant by such causal circuit
               explanations of behavior. Well-known to most philosophers, yet
               ignored or at least hardly ever made explicit by
               neuroscientists, the original grand claim of ``understanding the
               brain'' is imperceptibly substituted by the methodologically
               sophisticated task of empirically establishing counterfactual
               dependencies. But for the twenty-first century neuroscientist,
               after so much pride, this is really an excess of humility. I
               argue that to upgrade intervention to explanation is prone to
               logical fallacies, interpretational leaps and carries a weak
               explanatory force, thus settling and maintaining low standards
               for intelligibility in neuroscience. To claim that behavior is
               explained by a ``necessary and sufficient'' neural circuit is,
               at best, misleading. In that, my critique (rather than
               criticism) is indeed mainly negative. Positively, I briefly
               suggest some available alternatives for conceptual progress,
               such as adopting circular causality (rather than lineal
               causality in the flavor of top-down reductionism), searching for
               principles of behavior (rather than taking an arbitrary
               definition of behavior and rushing to dissect its ``underlying''
               neural mechanisms), and embracing process philosophy (rather
               than substance-mechanistic ontologies). Overall, if the goal of
               neuroscience is to understand the relation between brain and
               behavior then, in addition to excruciating neural studies (one
               pillar), we will need a strong theory of behavior (the other
               pillar) and a solid foundation to establish their relation (the
               bridge).",
  publisher = "Springer International Publishing",
  pages     = "283--306",
  year      =  2017,
  address   = "Cham",
  isbn      = "9783319573632",
  doi       = "10.1007/978-3-319-57363-2\_11"
}

@ARTICLE{Cande2018-le,
  title    = "Optogenetic dissection of descending behavioral control in
              Drosophila",
  author   = "Cande, Jessica and Namiki, Shigehiro and Qiu, Jirui and Korff,
              Wyatt and Card, Gwyneth M and Shaevitz, Joshua W and Stern, David
              L and Berman, Gordon J",
  abstract = "In most animals, the brain makes behavioral decisions that are
              transmitted by descending neurons to the nerve cord circuitry
              that produces behaviors. In insects, only a few descending
              neurons have been associated with specific behaviors. To explore
              how descending neurons control an insect's movements, we
              developed a novel method to systematically assay the behavioral
              effects of activating individual neurons on freely behaving
              terrestrial D. melanogaster. We calculated a two-dimensional
              representation of the entire behavior space explored by these
              flies, and we associated descending neurons with specific
              behaviors by identifying regions of this space that were visited
              with increased frequency during optogenetic activation. Applying
              this approach across a large collection of descending neurons, we
              found that (1) activation of most of the descending neurons drove
              stereotyped behaviors, (2) in many cases multiple descending
              neurons activated similar behaviors, and (3) optogenetically
              activated behaviors were often dependent on the behavioral state
              prior to activation.",
  journal  = "Elife",
  volume   =  7,
  month    =  jun,
  year     =  2018,
  keywords = "D. melanogaster; behavior; descending interneurons; neuroscience;
              optogenetics",
  language = "en",
  issn     = "2050-084X",
  pmid     = "29943729",
  doi      = "10.7554/eLife.34275",
  pmc      = "PMC6031430"
}

@ARTICLE{Bogacz2006-lr,
  title     = "The physics of optimal decision making: a formal analysis of
               models of performance in two-alternative forced-choice tasks",
  author    = "Bogacz, Rafal and Brown, Eric and Moehlis, Jeff and Holmes,
               Philip and Cohen, Jonathan D",
  abstract  = "In this article, the authors consider optimal decision making in
               two-alternative forced-choice (TAFC) tasks. They begin by
               analyzing 6 models of TAFC decision making and show that all but
               one can be reduced to the drift diffusion model, implementing
               the statistically optimal algorithm (most accurate for a given
               speed or fastest for a given accuracy). They prove further that
               there is always an optimal trade-off between speed and accuracy
               that maximizes various reward functions, including reward rate
               (percentage of correct responses per unit time), as well as
               several other objective functions, including ones weighted for
               accuracy. They use these findings to address empirical data and
               make novel predictions about performance under optimality.",
  journal   = "Psychol. Rev.",
  publisher = "psycnet.apa.org",
  volume    =  113,
  number    =  4,
  pages     = "700--765",
  month     =  oct,
  year      =  2006,
  language  = "en",
  issn      = "0033-295X",
  pmid      = "17014301",
  doi       = "10.1037/0033-295X.113.4.700"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Pezzulo2014-up,
  title     = "The principles of goal-directed decision-making: from neural
               mechanisms to computation and robotics",
  author    = "Pezzulo, Giovanni and Verschure, Paul F M J and Balkenius,
               Christian and Pennartz, Cyriel M A",
  abstract  = "… Verschure et al … Footnotes. One contribution of 18 to a Theme
               Issue 'The principles of goal-directed decision - making : from
               neural mechanisms to computation and robotics'. \copyright{}
               2014 The Author(s) Published by the Royal Society. All rights
               reserved. References …",
  journal   = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  publisher = "royalsocietypublishing.org",
  volume    =  369,
  number    =  1655,
  month     =  nov,
  year      =  2014,
  keywords  = "computational model; decision-making; goal-directed; neural
               mechanism; prediction; robotics",
  language  = "en",
  issn      = "0962-8436, 1471-2970",
  pmid      = "25267813",
  doi       = "10.1098/rstb.2013.0470",
  pmc       = "PMC4186224"
}

@ARTICLE{Stephens2008-um,
  title    = "Decision ecology: foraging and the ecology of animal decision
              making",
  author   = "Stephens, David W",
  abstract = "In this article, I review the approach taken by behavioral
              ecologists to the study of animal foraging behavior and explore
              connections with general analyses of decision making. I use the
              example of patch exploitation decisions in this article in order
              to develop several key points about the properties of naturally
              occurring foraging decisions. First, I argue that experimental
              preparations based on binary, mutually exclusive choice are not
              good models of foraging decisions. Instead, foraging choices have
              a sequential foreground-background structure, in which one option
              is in the background of all other options. Second, behavioral
              ecologists view foraging as a hierarchy of decisions that range
              from habitat selection to food choice. Finally, data suggest that
              foraging animals are sensitive to several important trade-offs.
              These trade-offs include the effects of competitors and group
              mates, as well as the problem of predator avoidance.",
  journal  = "Cogn. Affect. Behav. Neurosci.",
  volume   =  8,
  number   =  4,
  pages    = "475--484",
  month    =  dec,
  year     =  2008,
  language = "en",
  issn     = "1530-7026",
  pmid     = "19033242",
  doi      = "10.3758/CABN.8.4.475"
}

@ARTICLE{Vicente2019-kq,
  title         = "The many faces of deep learning",
  author        = "Vicente, Raul",
  abstract      = "Deep learning has sparked a network of mutual interactions
                   between different disciplines and AI. Naturally, each
                   discipline focuses and interprets the workings of deep
                   learning in different ways. This diversity of perspectives
                   on deep learning, from neuroscience to statistical physics,
                   is a rich source of inspiration that fuels novel
                   developments in the theory and applications of machine
                   learning. In this perspective, we collect and synthesize
                   different intuitions scattered across several communities as
                   for how deep learning works. In particular, we will briefly
                   discuss the different perspectives that disciplines across
                   mathematics, physics, computation, and neuroscience take on
                   how deep learning does its tricks. Our discussion on each
                   perspective is necessarily shallow due to the multiple views
                   that had to be covered. The deepness in this case should
                   come from putting all these faces of deep learning together
                   in the reader's mind, so that one can look at the same
                   problem from different angles.",
  month         =  aug,
  year          =  2019,
  archivePrefix = "arXiv",
  eprint        = "1908.10206",
  primaryClass  = "cs.LG",
  arxivid       = "1908.10206"
}

@BOOK{Hebb2005-wq,
  title     = "The Organization of Behavior: A Neuropsychological Theory",
  author    = "Hebb, D O",
  abstract  = "Since its publication in 1949, D.O. Hebb's, The Organization of
               Behavior has been one of the most influential books in the
               fields of psychology and neuroscience. However, the original
               edition has been unavailable since 1966, ensuring that Hebb's
               comment that a classic normally means ``cited but not read'' is
               true in his case. This new edition rectifies a long-standing
               problem for behavioral neuroscientists--the inability to obtain
               one of the most cited publications in the field. The
               Organization of Behavior played a significant part in
               stimulating the investigation of the neural foundations of
               behavior and continues to be inspiring because it provides a
               general framework for relating behavior to synaptic organization
               through the dynamics of neural networks. D.O. Hebb was also the
               first to examine the mechanisms by which environment and
               experience can influence brain structure and function, and his
               ideas formed the basis for work on enriched environments as
               stimulants for behavioral development. References to Hebb, the
               Hebbian cell assembly, the Hebb synapse, and the Hebb rule
               increase each year. These forceful ideas of 1949 are now applied
               in engineering, robotics, and computer science, as well as
               neurophysiology, neuroscience, and psychology--a tribute to
               Hebb's foresight in developing a foundational neuropsychological
               theory of the organization of behavior.",
  publisher = "Psychology Press",
  month     =  apr,
  year      =  2005,
  language  = "en",
  isbn      = "9781135631918"
}

@ARTICLE{Neftci2019-pw,
  title    = "Reinforcement learning in artificial and biological systems",
  author   = "Neftci, Emre O and Averbeck, Bruno B",
  abstract = "There is and has been a fruitful flow of concepts and ideas
              between studies of learning in biological and artificial systems.
              Much early work that led to the development of reinforcement
              learning (RL) algorithms for artificial systems was inspired by
              learning rules first developed in biology by Bush and Mosteller,
              and Rescorla and Wagner. More recently, temporal-difference RL,
              developed for learning in artificial agents, has provided a
              foundational framework for interpreting the activity of dopamine
              neurons. In this Review, we describe state-of-the-art work on RL
              in biological and artificial agents. We focus on points of
              contact between these disciplines and identify areas where future
              research can benefit from information flow between these fields.
              Most work in biological systems has focused on simple learning
              problems, often embedded in dynamic environments where
              flexibility and ongoing learning are important, similar to
              real-world learning problems faced by biological systems. In
              contrast, most work in artificial agents has focused on learning
              a single complex problem in a static environment. Moving forward,
              work in each field will benefit from a flow of ideas that
              represent the strengths within each discipline.",
  journal  = "Nature Machine Intelligence",
  volume   =  1,
  number   =  3,
  pages    = "133--143",
  month    =  mar,
  year     =  2019,
  issn     = "2522-5839",
  doi      = "10.1038/s42256-019-0025-4"
}

@ARTICLE{Dunn2016-xl,
  title     = "Brain-wide mapping of neural activity controlling zebrafish
               exploratory locomotion",
  author    = "Dunn, Timothy W and Mu, Yu and Narayan, Sujatha and Randlett,
               Owen and Naumann, Eva A and Yang, Chao-Tsung and Schier,
               Alexander F and Freeman, Jeremy and Engert, Florian and Ahrens,
               Misha B",
  abstract  = "In the absence of salient sensory cues to guide behavior,
               animals must still execute sequences of motor actions in order
               to forage and explore. How such successive motor actions are
               coordinated to form global locomotion trajectories is unknown.
               We mapped the structure of larval zebrafish swim trajectories in
               homogeneous environments and found that trajectories were
               characterized by alternating sequences of repeated turns to the
               left and to the right. Using whole-brain light-sheet imaging, we
               identified activity relating to the behavior in specific neural
               populations that we termed the anterior rhombencephalic turning
               region (ARTR). ARTR perturbations biased swim direction and
               reduced the dependence of turn direction on turn history,
               indicating that the ARTR is part of a network generating the
               temporal correlations in turn direction. We also find suggestive
               evidence for ARTR mutual inhibition and ARTR projections to
               premotor neurons. Finally, simulations suggest the observed turn
               sequences may underlie efficient exploration of local
               environments.",
  journal   = "Elife",
  publisher = "cdn.elifesciences.org",
  volume    =  5,
  pages     = "e12741",
  month     =  mar,
  year      =  2016,
  keywords  = "exploration strategies; higher-order motor control; larval
               zebrafish; neural basis of behavior; neuroscience; spontaneous
               brain activity; whole-brain functional imaging; zebrafish",
  language  = "en",
  issn      = "2050-084X",
  pmid      = "27003593",
  doi       = "10.7554/eLife.12741",
  pmc       = "PMC4841782"
}

@ARTICLE{Fanselow2018-bx,
  title    = "The Role of Learning in Threat Imminence and Defensive Behaviors",
  author   = "Fanselow, Michael S",
  abstract = "Life threatening situations as urgent as defending against a
              predator precludes the use of slow trial and error strategies.
              Natural selection has led to the evolution of a behavioral system
              that has 3 critical elements. 1) When it is activated it limits
              the behaviors available to the organism to a set of prewired
              responses that have proven over phylogeny to be effective at
              defense. 2) A rapid learning system, called Pavlovian fear
              conditioning, that has the ability to immediately identify
              threats and promote prewired defensive behaviors. 3) That
              learning system has the ability to integrate several
              informational dimensions to determine threat imminence and this
              allows the organism to match the most effective defensive
              behavior to the current situation. The adaptive significance of
              conscious experiential states is also considered.",
  journal  = "Curr Opin Behav Sci",
  volume   =  24,
  pages    = "44--49",
  month    =  dec,
  year     =  2018,
  keywords = "Anxiety; Defensive Behavior; Fear; Fear Conditioning; Innate
              Fear; Panic; Predatory Imminence; Threat Imminence; amygdala;
              avoidance; consciousness; freezing; selective association",
  language = "en",
  issn     = "2352-1546",
  pmid     = "30276224",
  doi      = "10.1016/j.cobeha.2018.03.003",
  pmc      = "PMC6162067"
}

@ARTICLE{Capelli2017-hq,
  title    = "Locomotor speed control circuits in the caudal brainstem",
  author   = "Capelli, Paolo and Pivetta, Chiara and Soledad Esposito, Maria
              and Arber, Silvia",
  abstract = "Locomotion is a universal behaviour that provides animals with
              the ability to move between places. Classical experiments have
              used electrical microstimulation to identify brain regions that
              promote locomotion, but the identity of neurons that act as key
              intermediaries between higher motor planning centres and
              executive circuits in the spinal cord has remained controversial.
              Here we show that the mouse caudal brainstem encompasses
              functionally heterogeneous neuronal subpopulations that have
              differential effects on locomotion. These subpopulations are
              distinguishable by location, neurotransmitter identity and
              connectivity. Notably, glutamatergic neurons within the lateral
              paragigantocellular nucleus (LPGi), a small subregion in the
              caudal brainstem, are essential to support high-speed locomotion,
              and can positively tune locomotor speed through inputs from
              glutamatergic neurons of the upstream midbrain locomotor region.
              By contrast, glycinergic inhibitory neurons can induce different
              forms of behavioural arrest mapping onto distinct caudal
              brainstem regions. Anatomically, descending pathways of
              glutamatergic and glycinergic LPGi subpopulations communicate
              with distinct effector circuits in the spinal cord. Our results
              reveal that behaviourally opposing locomotor functions in the
              caudal brainstem were historically masked by the unexposed
              diversity of intermingled neuronal subpopulations. We demonstrate
              how specific brainstem neuron populations represent essential
              substrates to implement key parameters in the execution of motor
              programs.",
  journal  = "Nature",
  volume   =  551,
  number   =  7680,
  pages    = "373--377",
  month    =  nov,
  year     =  2017,
  keywords = "Locomotion",
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "29059682",
  doi      = "10.1038/nature24064"
}

@BOOK{Kirk2012-ji,
  title     = "Optimal Control Theory: An Introduction",
  author    = "Kirk, Donald E",
  abstract  = "Optimal control theory is the science of maximizing the returns
               from and minimizing the costs of the operation of physical,
               social, and economic processes. Geared toward upper-level
               undergraduates, this text introduces three aspects of optimal
               control theory: dynamic programming, Pontryagin's minimum
               principle, and numerical techniques for trajectory
               optimization.Chapters 1 and 2 focus on describing systems and
               evaluating their performances. Chapter 3 deals with dynamic
               programming. The calculus of variations and Pontryagin's minimum
               principle are the subjects of chapters 4 and 5, and chapter 6
               examines iterative numerical techniques for finding optimal
               controls and trajectories. Numerous problems, intended to
               introduce additional topics as well as to illustrate basic
               concepts, appear throughout the text.",
  publisher = "Courier Corporation",
  month     =  apr,
  year      =  2012,
  language  = "en",
  isbn      = "9780486135076"
}

@BOOK{Von_Neumann2007-ip,
  title     = "Theory of Games and Economic Behavior (Commemorative Edition)",
  author    = "von Neumann, John and Morgenstern, Oskar and Kuhn, Harold
               William",
  abstract  = "This is the classic work upon which modern-day game theory is
               based. What began more than sixty years ago as a modest proposal
               that a mathematician and an economist write a short paper
               together blossomed, in 1944, when Princeton University Press
               published Theory of Games and Economic Behavior. In it, John von
               Neumann and Oskar Morgenstern conceived a groundbreaking
               mathematical theory of economic and social organization, based
               on a theory of games of strategy. Not only would this
               revolutionize economics, but the entirely new field of
               scientific inquiry it yielded--game theory--has since been
               widely used to analyze a host of real-world phenomena from arms
               races to optimal policy choices of presidential candidates, from
               vaccination policy to major league baseball salary negotiations.
               And it is today established throughout both the social sciences
               and a wide range of other sciences. This sixtieth anniversary
               edition includes not only the original text but also an
               introduction by Harold Kuhn, an afterword by Ariel Rubinstein,
               and reviews and articles on the book that appeared at the time
               of its original publication in the New York Times, tthe American
               Economic Review, and a variety of other publications. Together,
               these writings provide readers a matchless opportunity to more
               fully appreciate a work whose influence will yet resound for
               generations to come.",
  publisher = "Princeton University Press",
  month     =  mar,
  year      =  2007,
  language  = "en",
  isbn      = "9780691130613"
}

@ARTICLE{Zador2019-wh,
  title     = "A critique of pure learning and what artificial neural networks
               can learn from animal brains",
  author    = "Zador, Anthony M",
  abstract  = "Artificial neural networks (ANNs) have undergone a revolution,
               catalyzed by better supervised learning algorithms. However, in
               stark contrast to young animals (including humans), training
               such networks requires enormous numbers of labeled examples,
               leading to the belief that animals must rely instead mainly on
               unsupervised learning. Here we argue that most animal behavior
               is not the result of clever learning algorithms-supervised or
               unsupervised-but is encoded in the genome. Specifically, animals
               are born with highly structured brain connectivity, which
               enables them to learn very rapidly. Because the wiring diagram
               is far too complex to be specified explicitly in the genome, it
               must be compressed through a ``genomic bottleneck''. The genomic
               bottleneck suggests a path toward ANNs capable of rapid
               learning.",
  journal   = "Nat. Commun.",
  publisher = "nature.com",
  volume    =  10,
  number    =  1,
  pages     = "3770",
  month     =  aug,
  year      =  2019,
  language  = "en",
  issn      = "2041-1723",
  pmid      = "31434893",
  doi       = "10.1038/s41467-019-11786-6",
  pmc       = "PMC6704116"
}

@BOOK{noauthor_1995-id,
  title     = "The Myth of the Framework",
  publisher = "Routledge",
  month     =  dec,
  year      =  1995,
  isbn      = "9780203535806, 9781135974732",
  doi       = "10.4324/9780203535806"
}

@ARTICLE{Turney1996-uv,
  title     = "Evolution, Learning, and Instinct: 100 Years of the Baldwin
               Effect",
  author    = "Turney, Peter and Whitley, Darrell and Anderson, Russell W",
  journal   = "Evol. Comput.",
  publisher = "MIT Press",
  volume    =  4,
  number    =  3,
  pages     = "iv--viii",
  month     =  sep,
  year      =  1996,
  issn      = "1063-6560",
  doi       = "10.1162/evco.1996.4.3.iv"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@BOOK{Belew2018-rz,
  title     = "Adaptive individuals in evolving populations: models and
               algorithms",
  author    = "Belew, Richard K",
  abstract  = "A Model of Individual Adaptive Behavior in a Fluctuating
               Environment Individual behavioral strategies that use
               conditional probabilities for future environments and
               information about past environments are studied. The
               environments are random and Markovian. The individual uses the
               available information to prepare for the next environmental
               state in order to increase its fitness. The fitness depends on
               the discrepancy between the realized environment and that for
               which the individual is prepared. Additive and multiplicative …",
  publisher = "Routledge",
  year      =  2018
}

@ARTICLE{Richards1974-wh,
  title     = "The Innate and the Learned: The Evolution of Konrad Lorenz's
               Theory of Instinct",
  author    = "Richards, Robert J",
  journal   = "Philos. Soc. Sci.",
  publisher = "SAGE Publications Inc",
  volume    =  4,
  number    = "2-3",
  pages     = "111--133",
  month     =  jun,
  year      =  1974,
  issn      = "0048-3931",
  doi       = "10.1177/004839317400400201"
}

@ARTICLE{Swartz2006-xa,
  title     = "Inverse Decision Theory",
  author    = "Swartz, Richard J and Cox, Dennis D and Cantor, Scott B and
               Davies, Kalatu and Follen, Michele",
  abstract  = "Identifying an optimal decision rule using Bayesian decision
               theory requires priors, likelihoods, and losses. In many medical
               settings, we can develop priors and likelihoods, but specifying
               losses can be difficult, especially when considering both
               patient outcomes and economic costs. If there is a widely
               accepted treatment strategy, then we can consider the inverse
               problem and find a region in the space of losses where the
               procedure is optimal. We call this approach inverse decision
               theory (IDT). We apply IDT to the standard of care for diagnosis
               and treatment of precancerous lesions of the cervix, and
               consider an alternative procedure that has been proposed. We use
               a Bayesian approach to estimate the probabilities associated
               with the diagnostic tests and make inferences about the region
               in loss space where these medical procedures are optimal. In
               particular, we find evidence supporting the current standard of
               care.",
  journal   = "J. Am. Stat. Assoc.",
  publisher = "Taylor \& Francis",
  volume    =  101,
  number    =  473,
  pages     = "1--8",
  month     =  mar,
  year      =  2006,
  issn      = "0162-1459",
  doi       = "10.1198/016214505000000998"
}

@BOOK{Kagel2016-ih,
  title     = "The Handbook of Experimental Economics",
  author    = "Kagel, John H and Roth, Alvin E",
  abstract  = "When The Handbook of Experimental Economics first came out in
               1995, the notion of economists conducting lab experiments to
               generate data was relatively new. Since then, the field has
               exploded. This second volume of the Handbook covers some of the
               most exciting new growth areas in experimental economics,
               presents the latest results and experimental methods, and
               identifies promising new directions for future
               research.Featuring contributions by leading practitioners, the
               Handbook describes experiments in macroeconomics, charitable
               giving, neuroeconomics, other-regarding preferences, market
               design, political economy, subject population effects, gender
               effects, auctions, and learning and the economics of small
               decisions. Contributors focus on key developments and report on
               experiments, highlighting the dialogue between experimenters and
               theorists. While most of the experiments consist of laboratory
               studies, the book also includes several chapters that report
               extensively on field experiments related to the subject area
               studied.Covers exciting new growth areas in experimental
               economicsFeatures contributions by leading expertsDescribes
               experiments in macroeconomics, charitable giving,
               neuroeconomics, market design, political economy, gender
               effects, auctions, and moreHighlights the dialogue by
               experimenters with theorists and each otherIncludes several
               chapters covering field experiments related to the subject area
               studied",
  publisher = "Princeton University Press",
  month     =  oct,
  year      =  2016,
  language  = "en",
  isbn      = "9780691139999"
}

@BOOK{Burkhardt2005-ej,
  title     = "Patterns of Behavior: Konrad Lorenz, Niko Tinbergen, and the
               Founding of Ethology",
  author    = "Burkhardt, Richard W",
  abstract  = "It is hard to imagine, by their very name, the life sciences not
               involving the study of living things, but until the twentieth
               century much of what was known in the field was based primarily
               on specimens that had long before taken their last breaths. Only
               in the last century has ethology---the study of animal
               behavior---emerged as a major field of the life sciences. In
               Patterns of Behavior, Richard W. Burkhardt Jr. traces the
               scientific theories, practices, subjects, and settings integral
               to the construction of a discipline pivotal to our understanding
               of the diversity of life. Central to this tale are Konrad Lorenz
               and Niko Tinbergen, 1973 Nobel laureates whose research helped
               legitimize the field of ethology and bring international
               attention to the culture of behavioral research. Demonstrating
               how matters of practice, politics, and place all shaped
               ``ethology's ecologies,'' Burkhardt's book offers a sensitive
               reading of the complex interplay of the field's celebrated
               pioneers and a richly textured reconstruction of ethology's
               transformation from a quiet backwater of natural history to the
               forefront of the biological sciences. Winner of the 2006 Pfizer
               Awad from the History of Science Society",
  publisher = "University of Chicago Press",
  month     =  mar,
  year      =  2005,
  language  = "en",
  isbn      = "9780226080901"
}

@UNPUBLISHED{Bolton2019-kt,
  title    = "Elements of a stochastic {3D} prediction engine in larval
              zebrafish prey capture",
  author   = "Bolton, Andrew D and Haesemeyer, Martin and Jordi, Josua and
              Schaechtle, Ulrich and Saad, Feras and Mansinghka, Vikash K and
              Tenenbaum, Joshua B and Engert, Florian",
  abstract = "Many predatory animals rely on accurate sensory perception,
              predictive models, and precise pursuits to catch moving prey.
              Larval zebrafish intercept paramecia during their hunting
              behavior, but the precise trajectories of their prey have never
              been recorded in relation to fish movements in three dimensions.
              As a means of uncovering what a simple organism understands about
              its physical world, we have constructed a 3D-imaging setup to
              simultaneously record the behavior of larval zebrafish, as well
              as their moving prey, during hunting. We show that zebrafish
              robustly transform their 3D displacement and rotation according
              to the position of their prey while modulating both of these
              variables depending on prey velocity. This is true for both
              azimuth and altitude, but particulars of the hunting algorithm in
              the two planes are slightly different to accommodate an
              asymmetric strike zone. We show that the combination of position
              and velocity perception provides the fish with a preferred future
              positional estimate, indicating an ability to project
              trajectories forward in time. Using computational models, we show
              that this projection ability is critical for prey capture
              efficiency and success. Further, we demonstrate that fish use a
              graded stochasticity algorithm where the variance around the mean
              result of each swim scales with distance from the target.
              Notably, this strategy provides the animal with a considerable
              improvement over equivalent noise-free strategies. In sum, our
              quantitative and probabilistic modeling shows that zebrafish are
              equipped with a stochastic recursive algorithm that embodies an
              implicit predictive model of the world. This algorithm, built by
              a simple set of behavioral rules, allows the fish to optimize
              their hunting strategy in a naturalistic three-dimensional
              environment.",
  journal  = "bioRxiv",
  pages    = "755777",
  month    =  sep,
  year     =  2019,
  language = "en",
  doi      = "10.1101/755777"
}

@ARTICLE{Juechems2019-kv,
  title    = "Where Does Value Come From?",
  author   = "Juechems, Keno and Summerfield, Christopher",
  abstract = "The computational framework of reinforcement learning (RL) has
              allowed us to both understand biological brains and build
              successful artificial agents. However, in this opinion, we
              highlight open challenges for RL as a model of animal behaviour
              in natural environments. We ask how the external reward function
              is designed for biological systems, and how we can account for
              the context sensitivity of valuation. We summarise both old and
              new theories proposing that animals track current and desired
              internal states and seek to minimise the distance to a goal
              across multiple value dimensions. We suggest that this framework
              readily accounts for canonical phenomena observed in the fields
              of psychology, behavioural ecology, and economics, and recent
              findings from brain-imaging studies of value-guided
              decision-making.",
  journal  = "Trends Cogn. Sci.",
  month    =  sep,
  year     =  2019,
  keywords = "goal-directed decision-making; homeostasis; medial prefrontal
              cortex; reinforcement learning; reward; value",
  language = "en",
  issn     = "1364-6613, 1879-307X",
  pmid     = "31494042",
  doi      = "10.1016/j.tics.2019.07.012"
}

@ARTICLE{Santer2005-km,
  title    = "Motor activity and trajectory control during escape jumping in
              the locust Locusta migratoria",
  author   = "Santer, Roger D and Yamawaki, Yoshifumi and Rind, F Claire and
              Simmons, Peter J",
  abstract = "We investigated the escape jumps that locusts produce in response
              to approaching objects. Hindleg muscular activity during an
              escape jump is similar to that during a defensive kick. Locusts
              can direct their escape jumps up to 50 degrees either side of the
              direction of their long axis at the time of hindleg flexion,
              allowing them to consistently jump away from the side towards
              which an object is approaching. Variation in jump trajectory is
              achieved by rolling and yawing movements of the body that are
              controlled by the fore- and mesothoracic legs. During hindleg
              flexion, a locust flexes the foreleg ipsilateral to its eventual
              jump trajectory and then extends the contralateral foreleg. These
              foreleg movements continue throughout co-contraction of the
              hindleg tibial muscles, pivoting the locust's long axis towards
              its eventual jump trajectory. However, there are no bilateral
              differences in the motor programs of the left and right hindlegs
              that correlate with jump trajectory. Foreleg movements enable a
              locust to control its jump trajectory independent of the hindleg
              motor program, allowing a decision on jump trajectory to be made
              after the hindlegs have been cocked in preparation for a jump.",
  journal  = "J. Comp. Physiol. A Neuroethol. Sens. Neural Behav. Physiol.",
  volume   =  191,
  number   =  10,
  pages    = "965--975",
  month    =  oct,
  year     =  2005,
  language = "en",
  issn     = "0340-7594",
  pmid     = "16044332",
  doi      = "10.1007/s00359-005-0023-3"
}

@ARTICLE{Card2008-kq,
  title    = "Visually mediated motor planning in the escape response of
              Drosophila",
  author   = "Card, Gwyneth and Dickinson, Michael H",
  abstract = "A key feature of reactive behaviors is the ability to spatially
              localize a salient stimulus and act accordingly. Such
              sensory-motor transformations must be particularly fast and well
              tuned in escape behaviors, in which both the speed and accuracy
              of the evasive response determine whether an animal successfully
              avoids predation [1]. We studied the escape behavior of the fruit
              fly, Drosophila, and found that flies can use visual information
              to plan a jump directly away from a looming threat. This is
              surprising, given the architecture of the pathway thought to
              mediate escape [2, 3]. Using high-speed videography, we found
              that approximately 200 ms before takeoff, flies begin a series of
              postural adjustments that determine the direction of their
              escape. These movements position their center of mass so that leg
              extension will push them away from the expanding visual stimulus.
              These preflight movements are not the result of a simple
              feed-forward motor program because their magnitude and direction
              depend on the flies' initial postural state. Furthermore, flies
              plan a takeoff direction even in instances when they choose not
              to jump. This sophisticated motor program is evidence for a form
              of rapid, visually mediated motor planning in a genetically
              accessible model organism.",
  journal  = "Curr. Biol.",
  volume   =  18,
  number   =  17,
  pages    = "1300--1307",
  month    =  sep,
  year     =  2008,
  language = "en",
  issn     = "0960-9822",
  pmid     = "18760606",
  doi      = "10.1016/j.cub.2008.07.094"
}

@INCOLLECTION{Balakrishnan2014-zj,
  title     = "Escape Trajectory",
  booktitle = "Wiley {StatsRef}: Statistics Reference Online",
  editor    = "Balakrishnan, N and Colton, Theodore and Everitt, Brian and
               Piegorsch, Walter and Ruggeri, Fabrizio and Teugels, Jozef L",
  abstract  = "Abstract Escape responses consist of sudden accelerations as
               reactions to threatening stimuli and are present in most animals
               as a means of avoiding predation. Escape responses are currently
               receiving increased attention as valuable models for animal
               behavior, ecology, and neurobiology. The path along which an
               animal moves during an escape response (its escape trajectory)
               has attracted the interest of ecologists and behaviorists in
               relation to its functional role in predator?prey interactions.
               Escape trajectories (ETs) as considered in this article refer to
               the initial prey response to a predator's attack. Such a
               trajectory should be measured at the end of the main rotational
               motion present during the escape response, which usually
               corresponds to a specific kinematic stage of the animal's
               locomotion. Beyond this stage, prey may continue escaping along
               a zigzag path, especially if predators follow up their attack
               with a chase.",
  publisher = "John Wiley \& Sons, Ltd",
  volume    =  200,
  pages     = "1",
  month     =  apr,
  year      =  2014,
  address   = "Chichester, UK",
  isbn      = "9781118445112",
  doi       = "10.1002/9781118445112.stat07694"
}

@ARTICLE{Card2012-fz,
  title    = "Escape behaviors in insects",
  author   = "Card, Gwyneth M",
  abstract = "Escape behaviors are, by necessity, fast and robust, making them
              excellent systems with which to study the neural basis of
              behavior. This is especially true in insects, which have
              comparatively tractable nervous systems and members who are
              amenable to manipulation with genetic tools. Recent technical
              developments in high-speed video reveal that, despite their short
              duration, insect escape behaviors are more complex than
              previously appreciated. For example, before initiating an escape
              jump, a fly performs sophisticated posture and stimulus-dependent
              preparatory leg movements that enable it to jump away from a
              looming threat. This newfound flexibility raises the question of
              how the nervous system generates a behavior that is both rapid
              and flexible. Recordings from the cricket nervous system suggest
              that synchrony between the activity of specific interneuron pairs
              may provide a rapid cue for the cricket to detect the direction
              of an approaching predator and thus which direction it should
              run. Technical advances make possible wireless recording from
              neurons while locusts escape from a looming threat, enabling, for
              the first time, a direct correlation between the activity of
              multiple neurons and the time-course of an insect escape
              behavior.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  22,
  number   =  2,
  pages    = "180--186",
  month    =  apr,
  year     =  2012,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "22226514",
  doi      = "10.1016/j.conb.2011.12.009"
}

@ARTICLE{Moore2017-ge,
  title    = "Unpredictability of escape trajectory explains predator evasion
              ability and microhabitat preference of desert rodents",
  author   = "Moore, Talia Y and Cooper, Kimberly L and Biewener, Andrew A and
              Vasudevan, Ramanarayan",
  abstract = "Mechanistically linking movement behaviors and ecology is key to
              understanding the adaptive evolution of locomotion. Predator
              evasion, a behavior that enhances fitness, may depend upon short
              bursts or complex patterns of locomotion. However, such movements
              are poorly characterized by existing biomechanical metrics. We
              present methods based on the entropy measure of randomness from
              Information Theory to quantitatively characterize the
              unpredictability of non-steady-state locomotion. We then apply
              the method by examining sympatric rodent species whose escape
              trajectories differ in dimensionality. Unlike the speed-regulated
              gait use of cursorial animals to enhance locomotor economy,
              bipedal jerboa (family Dipodidae) gait transitions likely enhance
              maneuverability. In field-based observations, jerboa trajectories
              are significantly less predictable than those of quadrupedal
              rodents, likely increasing predator evasion ability. Consistent
              with this hypothesis, jerboas exhibit lower anxiety in open
              fields than quadrupedal rodents, a behavior that varies inversely
              with predator evasion ability. Our unpredictability metric
              expands the scope of quantitative biomechanical studies to
              include non-steady-state locomotion in a variety of evolutionary
              and ecologically significant contexts.Biomechanical understanding
              of animal gait and maneuverability has primarily been limited to
              species with more predictable, steady-state movement patterns.
              Here, the authors develop a method to quantify movement
              predictability, and apply the method to study escape-related
              movement in several species of desert rodents.",
  journal  = "Nat. Commun.",
  volume   =  8,
  number   =  1,
  pages    = "440",
  month    =  sep,
  year     =  2017,
  language = "en",
  issn     = "2041-1723",
  pmid     = "28874728",
  doi      = "10.1038/s41467-017-00373-2",
  pmc      = "PMC5585173"
}

@ARTICLE{Domenici2008-so,
  title    = "Cockroaches keep predators guessing by using preferred escape
              trajectories",
  author   = "Domenici, Paolo and Booth, David and Blagburn, Jonathan M and
              Bacon, Jonathan P",
  abstract = "Antipredator behavior is vital for most animals and calls for
              accurate timing and swift motion. Whereas fast reaction times [1]
              and predictable, context-dependent escape-initiation distances
              [2] are common features of most escape systems, previous work has
              highlighted the need for unpredictability in escape directions,
              in order to prevent predators from learning a repeated, fixed
              pattern [3-5]. Ultimate unpredictability would result from random
              escape trajectories. Although this strategy would deny any
              predictive power to the predator, it would also result in some
              escape trajectories toward the threat. Previous work has shown
              that escape trajectories are in fact generally directed away from
              the threat, although with a high variability [5-8]. However, the
              rules governing this variability are largely unknown. Here, we
              demonstrate that individual cockroaches (Periplaneta americana, a
              much-studied model prey species [9-14]) keep each escape
              unpredictable by running along one of a set of preferred
              trajectories at fixed angles from the direction of the
              threatening stimulus. These results provide a new paradigm for
              understanding the behavioral strategies for escape responses,
              underscoring the need to revisit the neural mechanisms
              controlling escape directions in the cockroach and similar animal
              models, and the evolutionary forces driving unpredictable, or
              ``protean''[3], antipredator behavior.",
  journal  = "Curr. Biol.",
  volume   =  18,
  number   =  22,
  pages    = "1792--1796",
  month    =  nov,
  year     =  2008,
  language = "en",
  issn     = "0960-9822",
  pmid     = "19013065",
  doi      = "10.1016/j.cub.2008.09.062",
  pmc      = "PMC2678410"
}

@ARTICLE{Feierstein2006-hs,
  title    = "Representation of spatial goals in rat orbitofrontal cortex",
  author   = "Feierstein, Claudia E and Quirk, Michael C and Uchida, Naoshige
              and Sosulski, Dara L and Mainen, Zachary F",
  abstract = "The orbitofrontal cortex (OFC) is thought to participate in
              making and evaluating goal-directed decisions. In rodents,
              spatial navigation is a major mode of goal-directed behavior, and
              anatomical and lesion studies implicate the OFC in spatial
              processing, but there is little direct evidence for coding of
              spatial or motor variables. Here, we recorded from ventrolateral
              and lateral OFC in an odor-cued two-alternative choice task
              requiring orientation and approach to spatial goal ports. In this
              context, over half of OFC neurons encoded choice direction or
              goal port location. A subset of neurons was jointly selective for
              the trial outcome and port location, information useful for the
              selection or evaluation of spatial goals. These observations show
              that the rodent OFC not only encodes information relating to
              general motivational significance, as shown previously, but also
              encodes spatiomotor variables needed to define specific
              behavioral goals and the locomotor actions required to attain
              them.",
  journal  = "Neuron",
  volume   =  51,
  number   =  4,
  pages    = "495--507",
  month    =  aug,
  year     =  2006,
  language = "en",
  issn     = "0896-6273",
  pmid     = "16908414",
  doi      = "10.1016/j.neuron.2006.06.032"
}

@ARTICLE{Vedder2017-qz,
  title    = "Retrosplenial Cortical Neurons Encode Navigational Cues,
              Trajectories and Reward Locations During Goal Directed Navigation",
  author   = "Vedder, Lindsey C and Miller, Adam M P and Harrison, Marc B and
              Smith, David M",
  abstract = "The retrosplenial cortex (RSC) plays an important role in memory
              and spatial navigation. It shares functional similarities with
              the hippocampus, including the presence of place fields and
              lesion-induced impairments in spatial navigation, and the RSC is
              an important source of visual-spatial input to the hippocampus.
              Recently, the RSC has been the target of intense scrutiny among
              investigators of human memory and navigation. fMRI and lesion
              data suggest an RSC role in the ability to use landmarks to
              navigate to goal locations. However, no direct neurophysiological
              evidence of encoding navigational cues has been reported so the
              specific RSC contribution to spatial cognition has been
              uncertain. To examine this, we trained rats on a T-maze task in
              which the reward location was explicitly cued by a flashing light
              and we recorded RSC neurons as the rats learned. We found that
              RSC neurons rapidly encoded the light cue. Additionally, RSC
              neurons encoded the reward and its location, and they showed
              distinct firing patterns along the left and right trajectories to
              the goal. These responses may provide key information for
              goal-directed navigation, and the loss of these signals may
              underlie navigational impairments in subjects with RSC damage.",
  journal  = "Cereb. Cortex",
  volume   =  27,
  number   =  7,
  pages    = "3713--3723",
  month    =  jul,
  year     =  2017,
  keywords = "cingulate cortex; landmark; learning and memory; visual cue",
  language = "en",
  issn     = "1047-3211, 1460-2199",
  pmid     = "27473323",
  doi      = "10.1093/cercor/bhw192",
  pmc      = "PMC6059095"
}

@ARTICLE{Ito2015-ld,
  title    = "A prefrontal-thalamo-hippocampal circuit for goal-directed
              spatial navigation",
  author   = "Ito, Hiroshi T and Zhang, Sheng-Jia and Witter, Menno P and
              Moser, Edvard I and Moser, May-Britt",
  abstract = "Spatial navigation requires information about the relationship
              between current and future positions. The activity of hippocampal
              neurons appears to reflect such a relationship, representing not
              only instantaneous position but also the path towards a goal
              location. However, how the hippocampus obtains information about
              goal direction is poorly understood. Here we report a
              prefrontal-thalamic neural circuit that is required for
              hippocampal representation of routes or trajectories through the
              environment. Trajectory-dependent firing was observed in medial
              prefrontal cortex, the nucleus reuniens of the thalamus, and the
              CA1 region of the hippocampus in rats. Lesioning or optogenetic
              silencing of the nucleus reuniens substantially reduced
              trajectory-dependent CA1 firing. Trajectory-dependent activity
              was almost absent in CA3, which does not receive nucleus reuniens
              input. The data suggest that projections from medial prefrontal
              cortex, via the nucleus reuniens, are crucial for representation
              of the future path during goal-directed behaviour and point to
              the thalamus as a key node in networks for long-range
              communication between cortical regions involved in navigation.",
  journal  = "Nature",
  volume   =  522,
  number   =  7554,
  pages    = "50--55",
  month    =  jun,
  year     =  2015,
  keywords = "navigation",
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "26017312",
  doi      = "10.1038/nature14396"
}

@ARTICLE{Alyan1994-ev,
  title    = "Short-range homing in the house mouse, Mus musculus: stages in
              the learning of directions",
  author   = "Alyan, Sofyan and Jander, Rudolf",
  abstract = "Abstract. Female house mice readily learn to retrieve their pups
              50 cm from the centre of an open arena and take them to their
              nest outside the arena's periphery. Experimental manipulation to
              reveal the spatial-orientation constituents of this behaviour
              disclosed thus submechanisms. Guided orientation, the direct
              response to objects. Path integration, the continuous monitoring
              of spatial displacements combined with computation of the
              locomotor vector to the starting point of the path. Landmark
              navigation, the movement by means of distal visual cues toward a
              goal not directly perceived. Learning to home passes through
              three stages. First, the exploring mouse is directly guided to
              objects of interest. Second, the homing mouse adds path
              integration; that is, it keeps a running, integrated spatial
              record derived from locomotion. Finally (circumstances
              permitting) the homing mouse links path integration with spatial
              references to distal visual landmarks. Sparse comparative
              evidence from other species of rodents suggests that such a
              system of short-range topographical orientation is universal
              among rodents.",
  journal  = "Anim. Behav.",
  volume   =  48,
  number   =  2,
  pages    = "285--298",
  month    =  aug,
  year     =  1994,
  issn     = "0003-3472",
  doi      = "10.1006/anbe.1994.1242"
}

@ARTICLE{Poucet2004-wh,
  title    = "Spatial navigation and hippocampal place cell firing: the problem
              of goal encoding",
  author   = "Poucet, B and Lenck-Santini, P P and Hok, V and Save, E and
              Banquet, J P and Gaussier, P and Muller, R U",
  abstract = "Place cells are hippocampal neurons whose discharge is strongly
              related to a rat's location in the environment. The existence of
              such cells, combined with the reliable impairments seen in
              spatial tasks after hippocampal damage, has led to the proposal
              that place cells form part of an integrated neural system
              dedicated to spatial navigation. This hypothesis is supported by
              the strong relationships between place cell activity and spatial
              problem solving, which indicate that the place cell
              representation must be both functional and in register with the
              surroundings for the animal to perform correctly in spatial
              tasks. The place cell system nevertheless requires other
              essential elements to be competent, such as a component that
              specifies the overall goal of the animal and computes the path
              required to take the rat from its current location to the goal.
              Here, we propose a model of the neural network responsible for
              spatial navigation that includes goal coding and path selection.
              In this model, the hippocampal formation allows for place
              recognition, and stores the set of places that can be accessed
              from each position in the environment. The prefrontal cortex is
              responsible for encoding goal location and for route planning.
              The nucleus accumbens translates paths in neural space into
              appropriate locomotor activity that moves the animal towards the
              goal in real space. The complete model assumes that the
              hippocampal output to nucleus accumbens and prefrontal cortex
              provides information for generating solutions to spatial
              problems. In support of this model, we finally present
              preliminary evidence that the goal representation necessary for
              path planning might be encoded in the prelimbic/infralimbic
              region of the medial prefrontal cortex.",
  journal  = "Rev. Neurosci.",
  volume   =  15,
  number   =  2,
  pages    = "89--107",
  year     =  2004,
  language = "en",
  issn     = "0334-1763",
  pmid     = "15202682",
  doi      = "10.1515/REVNEURO.2004.15.2.89"
}

@ARTICLE{Arnott1999-vi,
  title    = "Escape trajectories of the brown shrimp crangon crangon, and a
              theoretical consideration of initial escape angles from predators",
  author   = "Arnott, S A and Neil, D M and Ansell, A D",
  abstract = "Tail-flip escape trajectories of the brown shrimp Crangon crangon
              have been investigated in response to a natural predator, the cod
              Gadus morhua, and an artificial stimulus. Shrimps escaped by
              rolling to their left or right during the initial tail-flip of a
              response, and thereafter swam on their side. As a result of the
              laterally directed first tail-flip, initial escape angles always
              lay between 75 degrees and 156 degrees with respect to the
              (pre-escape) longitudinal axis (anterior=0 degrees) of the
              shrimp. Symmetrical attacks from either head-on or tail-on
              produced escapes to the shrimp's left or right in equal
              proportions, although a contralateral bias did occur if the
              shrimp experienced a looming object from one side before a
              symmetrical attack was applied. Lateral attacks produced a
              significantly greater proportion of contralateral responses than
              ipsilateral ones. Empirical and theoretical analyses indicate
              that the initial escape direction is influenced by an interaction
              between the range of first tail-flip escape angles that the
              shrimp is capable of performing and the risk of being intercepted
              by a predator during the initial stage of an escape. Thus, the
              unpredictability ('protean behaviour') of the response may be
              affected by the conditions of the interaction. Subsequent
              tail-flips of an escape usually directed the response away from
              the stimulus, but sometimes escapes were instead steered to the
              side of the stimulus and then behind it. The probability of each
              type of escape occurring changed with attack direction. The
              elements of protean behaviour that have been identified in both
              the initial and subsequent stages of the escape may prevent
              predators from learning a fixed pattern of response, but a
              trade-off occurs when escape trajectories infringe upon zones of
              high capture risk.",
  journal  = "J. Exp. Biol.",
  volume   = "202 (Pt 2)",
  pages    = "193--209",
  month    =  jan,
  year     =  1999,
  language = "en",
  issn     = "0022-0949, 1477-9145",
  pmid     = "9851908"
}

@ARTICLE{Comer2009-mh,
  title    = "Behavioral biology: inside the mind of proteus?",
  author   = "Comer, Christopher",
  abstract = "A new study of the escape behavior of the cockroach has found
              that its spatial variability is based on some underlying
              regularity. This constrained variability may maximise the
              effectiveness of the escape strategy.",
  journal  = "Curr. Biol.",
  volume   =  19,
  number   =  1,
  pages    = "R27--8",
  month    =  jan,
  year     =  2009,
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "19138587",
  doi      = "10.1016/j.cub.2008.11.010"
}

@INCOLLECTION{Knudsen2017-ji,
  title     = "1.21 - The Optic Tectum: A Structure Evolved for Stimulus
               Selection",
  booktitle = "Evolution of Nervous Systems (Second Edition)",
  author    = "Knudsen, E I and Schwarz, J S",
  editor    = "Kaas, Jon H",
  abstract  = "The core function of the optic tectum (OT) in all vertebrates is
               to collect information about the location and immediate
               relevance of stimuli in the environment and, based on this
               information, to compute the ``highest priority'' stimulus at
               each moment in time. The OT transmits the location of this
               stimulus to the forebrain to help direct spatial attention and,
               when appropriate, to the brain stem and spinal cord to guide
               immediate orienting or defensive behaviors. This chapter
               describes how a stimulus selection network in the midbrain
               generates the OT signal that identifies the location of the
               ``highest priority'' stimulus.",
  publisher = "Academic Press",
  pages     = "387--408",
  month     =  jan,
  year      =  2017,
  address   = "Oxford",
  keywords  = "Amphibians; Attention; Birds; Fish; Gamma oscillations; Gaze
               control; Isthmic nuclei; Mammals; Orienting response; Primates;
               Reptiles; Retinotectal; Selective attention; Superior
               colliculus; Visual pathways",
  isbn      = "9780128040966",
  doi       = "10.1016/B978-0-12-804042-3.00016-6"
}

@ARTICLE{Kim2017-mo,
  title    = "Integration of Descending Command Systems for the Generation of
              {Context-Specific} Locomotor Behaviors",
  author   = "Kim, Linda H and Sharma, Sandeep and Sharples, Simon A and Mayr,
              Kyle A and Kwok, Charlie H T and Whelan, Patrick J",
  abstract = "Over the past decade there has been a renaissance in our
              understanding of spinal cord circuits; new technologies are
              beginning to provide key insights into descending circuits which
              project onto spinal cord central pattern generators. By
              integrating work from both the locomotor and animal behavioral
              fields, we can now examine context-specific control of
              locomotion, with an emphasis on descending modulation arising
              from various regions of the brainstem. Here we examine approach
              and avoidance behaviors and the circuits that lead to the
              production and arrest of locomotion.",
  journal  = "Front. Neurosci.",
  volume   =  11,
  pages    = "581",
  month    =  oct,
  year     =  2017,
  keywords = "approach; aversion; descending; goal-directed; locomotor
              behavior; supraspinal",
  language = "en",
  issn     = "1662-4548, 1662-453X",
  pmid     = "29093660",
  doi      = "10.3389/fnins.2017.00581",
  pmc      = "PMC5651258"
}

@ARTICLE{Tovote2016-fr,
  title    = "Midbrain circuits for defensive behaviour",
  author   = "Tovote, Philip and Esposito, Maria Soledad and Botta, Paolo and
              Chaudun, Fabrice and Fadok, Jonathan P and Markovic, Milica and
              Wolff, Steffen B E and Ramakrishnan, Charu and Fenno, Lief and
              Deisseroth, Karl and Herry, Cyril and Arber, Silvia and
              L{\"u}thi, Andreas",
  abstract = "Survival in threatening situations depends on the selection and
              rapid execution of an appropriate active or passive defensive
              response, yet the underlying brain circuitry is not understood.
              Here we use circuit-based optogenetic, in vivo and in vitro
              electrophysiological, and neuroanatomical tracing methods to
              define midbrain periaqueductal grey circuits for specific
              defensive behaviours. We identify an inhibitory pathway from the
              central nucleus of the amygdala to the ventrolateral
              periaqueductal grey that produces freezing by disinhibition of
              ventrolateral periaqueductal grey excitatory outputs to pre-motor
              targets in the magnocellular nucleus of the medulla. In addition,
              we provide evidence for anatomical and functional interaction of
              this freezing pathway with long-range and local circuits
              mediating flight. Our data define the neuronal circuitry
              underlying the execution of freezing, an evolutionarily conserved
              defensive behaviour, which is expressed by many species including
              fish, rodents and primates. In humans, dysregulation of this
              'survival circuit' has been implicated in anxiety-related
              disorders.",
  journal  = "Nature",
  volume   =  534,
  number   =  7606,
  pages    = "206--212",
  month    =  jun,
  year     =  2016,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "27279213",
  doi      = "10.1038/nature17996"
}

@INCOLLECTION{May2006-kw,
  title     = "The mammalian superior colliculus: laminar structure and
               connections",
  booktitle = "Progress in Brain Research",
  author    = "May, Paul J",
  editor    = "B{\"u}ttner-Ennever, J A",
  abstract  = "The superior colliculus is a laminated midbrain structure that
               acts as one of the centers organizing gaze movements. This
               review will concentrate on sensory and motor inputs to the
               superior colliculus, on its internal circuitry, and on its
               connections with other brainstem gaze centers, as well as its
               extensive outputs to those structures with which it is
               reciprocally connected. This will be done in the context of its
               laminar arrangement. Specifically, the superficial layers
               receive direct retinal input, and are primarily visual sensory
               in nature. They project upon the visual thalamus and pretectum
               to influence visual perception. These visual layers also project
               upon the deeper layers, which are both multimodal, and premotor
               in nature. Thus, the deep layers receive input from both
               somatosensory and auditory sources, as well as from the basal
               ganglia and cerebellum. Sensory, association, and motor areas of
               cerebral cortex provide another major source of collicular
               input, particularly in more encephalized species. For example,
               visual sensory cortex terminates superficially, while the eye
               fields target the deeper layers. The deeper layers are
               themselves the source of a major projection by way of the
               predorsal bundle which contributes collicular target information
               to the brainstem structures containing gaze-related burst
               neurons, and the spinal cord and medullary reticular formation
               regions that produce head turning.",
  publisher = "Elsevier",
  volume    =  151,
  pages     = "321--378",
  month     =  jan,
  year      =  2006,
  doi       = "10.1016/S0079-6123(05)51011-2"
}

@ARTICLE{Reinhold2019-pr,
  title     = "Behavioral and neural correlates of hide-and-seek in rats",
  author    = "Reinhold, Annika Stefanie and Sanguinetti-Scheck, Juan Ignacio
               and Hartmann, Konstantin and Brecht, Michael",
  abstract  = "There is controversy regarding how widespread animal play
               behavior is and what its evolutionary function might be.
               Reinhold et al. demonstrated that rats can play hide-and-seek
               with a human. In the ``seek'' condition, rats learned to look
               for the hidden humans and kept seeking until they found them. In
               the ``hide'' condition, they learned to hide in one of several
               locations and waited there until being found. In both cases, the
               rats were rewarded by social interaction with the human. Rats
               vocalized when seeking and finding and were silent when hiding.
               Recordings in the medial prefrontal cortex detected neurons that
               were sensitive to the game structure. Science , this issue p.
               [1180][1] Evolutionary, cognitive, and neural underpinnings of
               mammalian play are not yet fully elucidated. We played
               hide-and-seek, an elaborate role-play game, with rats. We did
               not offer food rewards but engaged in playful interactions after
               finding or being found. Rats quickly learned the game and
               learned to alternate between hiding versus seeking roles. They
               guided seeking by vision and memories of past hiding locations
               and emitted game event--specific vocalizations. When hiding,
               rats vocalized infrequently and they preferred opaque over
               transparent hiding enclosures, a preference not observed during
               seeking. Neuronal recordings revealed intense prefrontal cortex
               activity that varied with game events and trial types (``hide''
               versus ``seek'') and might instruct role play. The elaborate
               cognitive capacities for hide-and-seek in rats suggest that this
               game might be evolutionarily old. [1]:
               /lookup/doi/10.1126/science.aax4705",
  journal   = "Science",
  publisher = "American Association for the Advancement of Science",
  volume    =  365,
  number    =  6458,
  pages     = "1180--1183",
  month     =  sep,
  year      =  2019,
  language  = "en",
  issn      = "0036-8075, 1095-9203",
  doi       = "10.1126/science.aax4705"
}

@ARTICLE{Kiehn2016-nj,
  title    = "Decoding the organization of spinal circuits that control
              locomotion",
  author   = "Kiehn, Ole",
  abstract = "Unravelling the functional operation of neuronal networks and
              linking cellular activity to specific behavioural outcomes are
              among the biggest challenges in neuroscience. In this broad field
              of research, substantial progress has been made in studies of the
              spinal networks that control locomotion. Through united efforts
              using electrophysiological and molecular genetic network
              approaches and behavioural studies in phylogenetically diverse
              experimental models, the organization of locomotor networks has
              begun to be decoded. The emergent themes from this research are
              that the locomotor networks have a modular organization with
              distinct transmitter and molecular codes and that their
              organization is reconfigured with changes to the speed of
              locomotion or changes in gait.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  17,
  number   =  4,
  pages    = "224--238",
  month    =  apr,
  year     =  2016,
  keywords = "Locomotion",
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "26935168",
  doi      = "10.1038/nrn.2016.9",
  pmc      = "PMC4844028"
}

@ARTICLE{Josset2018-oj,
  title    = "Distinct Contributions of Mesencephalic Locomotor Region Nuclei
              to Locomotor Control in the Freely Behaving Mouse",
  author   = "Josset, Nicolas and Roussel, Marie and Lemieux, Maxime and
              Lafrance-Zoubga, David and Rastqar, Ali and Bretzner, Frederic",
  abstract = "The mesencephalic locomotor region (MLR) has been initially
              identified as a supraspinal center capable of initiating and
              modulating locomotion. Whereas its functional contribution to
              locomotion has been widely documented throughout the phylogeny
              from the lamprey to humans, there is still debate about its exact
              organization. Combining kinematic and electrophysiological
              recordings in mouse genetics, our study reveals that
              glutamatergic neurons of the cuneiform nucleus initiate
              locomotion and induce running gaits, whereas glutamatergic and
              cholinergic neurons of the pedunculopontine nucleus modulate
              locomotor pattern and rhythm, contributing to slow-walking gaits.
              By initiating, modulating, and accelerating locomotion, our study
              identifies and characterizes distinct neuronal populations of
              this functional region important to locomotor command.",
  journal  = "Curr. Biol.",
  volume   =  28,
  number   =  6,
  pages    = "884--901.e3",
  month    =  mar,
  year     =  2018,
  keywords = "cuneiform nucleus; electrophysiology; glutamatergic and
              cholinergic neurons; kinematic analysis; locomotor command;
              locomotor pattern rhythm and gait; mesencephalic locomotor
              region; optogenetic tools; pedunculopontine nucleus;Locomotion",
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "29526593",
  doi      = "10.1016/j.cub.2018.02.007"
}

@ARTICLE{Roseberry2016-xm,
  title    = "{Cell-Type-Specific} Control of Brainstem Locomotor Circuits by
              Basal Ganglia",
  author   = "Roseberry, Thomas K and Lee, A Moses and Lalive, Arnaud L and
              Wilbrecht, Linda and Bonci, Antonello and Kreitzer, Anatol C",
  abstract = "The basal ganglia (BG) are critical for adaptive motor control,
              but the circuit principles underlying their pathway-specific
              modulation of target regions are not well understood. Here, we
              dissect the mechanisms underlying BG direct and indirect
              pathway-mediated control of the mesencephalic locomotor region
              (MLR), a brainstem target of BG that is critical for locomotion.
              We optogenetically dissect the locomotor function of the three
              neurochemically distinct cell types within the MLR:
              glutamatergic, GABAergic, and cholinergic neurons. We find that
              the glutamatergic subpopulation encodes locomotor state and
              speed, is necessary and sufficient for locomotion, and is
              selectively innervated by BG. We further show activation and
              suppression, respectively, of MLR glutamatergic neurons by direct
              and indirect pathways, which is required for bidirectional
              control of locomotion by BG circuits. These findings provide a
              fundamental understanding of how BG can initiate or suppress a
              motor program through cell-type-specific regulation of neurons
              linked to specific actions.",
  journal  = "Cell",
  volume   =  164,
  number   =  3,
  pages    = "526--537",
  month    =  jan,
  year     =  2016,
  language = "en",
  issn     = "0092-8674, 1097-4172",
  pmid     = "26824660",
  doi      = "10.1016/j.cell.2015.12.037",
  pmc      = "PMC4733247"
}

@ARTICLE{Sharma2019-bp,
  title    = "Towards a connectome of descending commands controlling
              locomotion",
  author   = "Sharma, Sandeep and Kim, Linda H and Whelan, Patrick J",
  abstract = "Understanding the neural basis for locomotion is of critical
              importance since it subserves many behaviours necessary for
              survival. The spinal cord contains all the elements required to
              produce the basic locomotor pattern. These elements which compose
              the central pattern generator for locomotion are activated and
              sculpted by descending inputs from the brainstem, subcortical and
              cortical structures. In this review, we examine the aspects of
              descending control of spinal cord circuits, focusing on the
              spinal cord, brainstem, and the diencephalon--hypothalamus. In
              this short review, we discuss recent data and consider
              opportunities for incorporating connectomics and optogenetic
              advances to continue the progress in deciphering the descending
              locomotor connectome.",
  journal  = "Current Opinion in Physiology",
  volume   =  8,
  pages    = "70--75",
  month    =  apr,
  year     =  2019,
  keywords = "Locomotion",
  issn     = "2468-8673",
  doi      = "10.1016/j.cophys.2018.12.005"
}

@ARTICLE{Li2018-xo,
  title    = "Hypothalamic Circuits for Predation and Evasion",
  author   = "Li, Yi and Zeng, Jiawei and Zhang, Juen and Yue, Chenyu and
              Zhong, Weixin and Liu, Zhixiang and Feng, Qiru and Luo, Minmin",
  abstract = "The interactions between predator and prey represent some of the
              most dramatic events in nature and constitute a matter of life
              and death for both sides. The hypothalamus has been implicated in
              driving predation and evasion; however, the exact hypothalamic
              neural circuits underlying these behaviors remain poorly defined.
              Here, we demonstrate that inhibitory and excitatory projections
              from the mouse lateral hypothalamus (LH) to the periaqueductal
              gray (PAG) in the midbrain drive, respectively, predation and
              evasion. LH GABA neurons were activated during predation.
              Optogenetically stimulating PAG-projecting LH GABA neurons drove
              strong predatory attack, and inhibiting these cells reversibly
              blocked predation. In contrast, LH glutamate neurons were
              activated during evasion. Stimulating PAG-projecting LH glutamate
              neurons drove evasion and inhibiting them impeded predictive
              evasion. Therefore, the seemingly opposite behaviors of predation
              and evasion are tightly regulated by two dissociable modular
              command systems within a single neural projection from the LH to
              the PAG. VIDEO ABSTRACT.",
  journal  = "Neuron",
  volume   =  97,
  number   =  4,
  pages    = "911--924.e5",
  month    =  feb,
  year     =  2018,
  keywords = "GABA; chemogenetics; escape behavior; fiber photometry;
              glutamate; hunting behavior; lateral hypothalamus; optogenetics;
              periaqueductal gray",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "29398361",
  doi      = "10.1016/j.neuron.2018.01.005"
}

@ARTICLE{Thompson2013-zi,
  title    = "Activity in mouse pedunculopontine tegmental nucleus reflects
              action and outcome in a decision-making task",
  author   = "Thompson, John A and Felsen, Gidon",
  abstract = "Recent studies across several mammalian species have revealed a
              distributed network of cortical and subcortical brain regions
              responsible for sensorimotor decision making. Many of these
              regions have been shown to be interconnected with the
              pedunculopontine tegmental nucleus (PPTg), a brain stem structure
              characterized by neuronal heterogeneity and thought to be
              involved in several cognitive and behavioral functions. However,
              whether this structure plays a general functional role in
              sensorimotor decision making is unclear. We hypothesized that, in
              the context of a sensorimotor task, activity in the PPTg would
              reflect task-related variables in a similar manner as do the
              cortical and subcortical regions with which it is anatomically
              associated. To examine this hypothesis, we recorded PPTg activity
              in mice performing an odor-cued spatial choice task requiring a
              stereotyped leftward or rightward orienting movement to obtain a
              reward. We studied single-neuron activity during epochs of the
              task related to movement preparation, execution, and outcome
              (i.e., whether or not the movement was rewarded). We found that a
              substantial proportion of neurons in the PPTg exhibited
              direction-selective activity during one or more of these epochs.
              In addition, an overlapping population of neurons reflected
              movement direction and reward outcome. These results suggest that
              the PPTg should be considered within the network of brain areas
              responsible for sensorimotor decision making and lay the
              foundation for future experiments to examine how the PPTg
              interacts with other regions to control sensory-guided motor
              output.",
  journal  = "J. Neurophysiol.",
  volume   =  110,
  number   =  12,
  pages    = "2817--2829",
  month    =  dec,
  year     =  2013,
  keywords = "basal ganglia; decision making; pedunculopontine tegmental
              nucleus; sensorimotor",
  language = "en",
  issn     = "0022-3077, 1522-1598",
  pmid     = "24089397",
  doi      = "10.1152/jn.00464.2013",
  pmc      = "PMC3882813"
}

@ARTICLE{Noga2003-nn,
  title     = "Mechanism for activation of locomotor centers in the spinal cord
               by stimulation of the mesencephalic locomotor region",
  author    = "Noga, Brian R and Kriellaars, Dean J and Brownstone, Robert M
               and Jordan, Larry M",
  abstract  = "The synaptic pathways of mesencephalic locomotor region
               (MLR)-evoked excitatory and inhibitory postsynaptic potentials
               (EPSPs and IPSPs) recorded from lumbar motoneurons of
               unanesthetized decerebrate cats during fictive locomotion were
               analyzed prior to, during, and after cold block of the medial
               reticular formation (MedRF) or the low thoracic ventral
               funiculus (VF). As others have shown, electrical stimulation of
               the MLR typically evoked short-latency excitatory or mixed
               excitatory/inhibitory PSPs in flexor and extensor motoneurons.
               The bulbospinal conduction velocities averaged approximately 88
               m/s (range: 62-145 m/s) and segmental latencies for EPSPs ranged
               from 1.2 to 10.9 ms. The histogram of segmental latencies showed
               three peaks, suggesting di-, tri-, and polysynaptic linkages.
               Segmental latencies for IPSPs suggested trisynaptic or
               polysynaptic transmission. Most EPSPs (69/77) were significantly
               larger during the depolarized phase of the intracellular
               locomotor drive potential (LDP), and most IPSPs (35/46) were
               larger during the corresponding hyperpolarized phase. Bilateral
               cooling of the MedRF reversibly abolished locomotion of both
               hindlimbs as measured from the electroneurogram (ENG) activity
               of muscle nerves and simultaneously abolished or diminished the
               motoneuron PSPs and LDPs. Unilateral cooling of the VF blocked
               locomotion ipsilaterally and diminished it contralaterally with
               concomitant loss or decrease the motoneuron PSPs and LDPs.
               Relative to the side of motoneuron recording, cooling of the
               ipsilateral VF sometimes uncovered longer-latency EPSPs, whereas
               cooling of the contralateral VF abolished longer-latency EPSPs.
               It is concluded that MLR stimulation activates a pathway that
               relays in the MedRF and descends bilaterally in the VF to
               contact spinal interneurons that project to motoneurons. Local
               segmental pathways that activate or inhibit motoneurons during
               MLR-evoked fictive locomotion appear to be both ipsilateral and
               contralateral.",
  journal   = "J. Neurophysiol.",
  publisher = "physiology.org",
  volume    =  90,
  number    =  3,
  pages     = "1464--1478",
  month     =  sep,
  year      =  2003,
  language  = "en",
  issn      = "0022-3077",
  pmid      = "12634275",
  doi       = "10.1152/jn.00034.2003"
}

@ARTICLE{Ferreira-Pinto2018-kr,
  title     = "Connecting Circuits for Supraspinal Control of Locomotion",
  author    = "Ferreira-Pinto, Manuel J and Ruder, Ludwig and Capelli, Paolo
               and Arber, Silvia",
  abstract  = "Locomotion is regulated by distributed circuits and achieved by
               the concerted activation of body musculature. While the basic
               properties of executive circuits in the spinal cord are fairly
               well understood, the precise mechanisms by which the brain
               impacts locomotion are much less clear. This Review discusses
               recent work unraveling the cellular identity, connectivity, and
               function of supraspinal circuits. We focus on their involvement
               in the regulation of the different phases of locomotion and
               their interaction with spinal circuits. Dedicated neuronal
               populations in the brainstem carry locomotor instructions,
               including initiation, speed, and termination. To align
               locomotion with behavioral needs, brainstem output structures
               are recruited by midbrain and forebrain circuits that compute
               and infer volitional, innate, and context-dependent locomotor
               properties. We conclude that the emerging logic of supraspinal
               circuit organization helps to understand how locomotor programs
               from exploration to hunting and escape are regulated by the
               brain.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  100,
  number    =  2,
  pages     = "361--374",
  month     =  oct,
  year      =  2018,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "30359602",
  doi       = "10.1016/j.neuron.2018.09.015"
}

@UNPUBLISHED{Mengiste2021-pq,
  title    = "Relevance of network topology for the dynamics of biological
              neuronal networks",
  author   = "Mengiste, Simachew and Aertsen, Ad and Kumar, Arvind",
  abstract = "Complex random networks provide a powerful mathematical framework
              to study high-dimensional physical and biological systems.
              Several features of network structure (e.g. degree correlation,
              average path length, clustering coefficient) are correlated with
              descriptors of network dynamics and function. However, it is not
              clear which features of network structure relate to the dynamics
              of biological neuronal networks (BNNs), characterized by
              non-linear nodes with high in- and out degrees, but being weakly
              connected and communicating in an event-driven manner, i.e. only
              when neurons spike. To better understand the structure-dynamics
              relationship in BNNs, we analysed the structure and dynamics of
              >9,000 BNNs with different sizes and topologies. In addition, we
              also studied the effect of network degeneration on neuronal
              network structure and dynamics. Surprisingly, we found that the
              topological class (random, small-world, scale-free) was not an
              indicator of the BNNs activity state as quantified by the firing
              rate, network synchrony and spiking regularity. In fact, we show
              that different network topologies could result in similar
              activity dynamics. Furthermore, in most cases, the network
              activity changes did not depend on the rules according to which
              neurons or synapses were pruned from the networks. The analysis
              of dynamics and structure of the networks we studied revealed
              that the effective synaptic weight (ESW ) was the most crucial
              feature in predicting the statistics of spiking activity in BNNs.
              ESW also explained why different synapse and neuron pruning
              strategies resulted in almost identical effects on the network
              dynamics. Thus, our findings provide new insights into the
              structure-dynamics relationships in BNNs. Moreover, we argue that
              network topology and rules by which BNNs degenerate are
              irrelevant for BNN activity dynamics. Beyond neuroscience, our
              results suggest that in large networks with non-linear nodes, the
              effective interaction strength among the nodes, instead of the
              topological network class, may be a better predictor of the
              network dynamics and information flow. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.02.19.431963",
  month    =  feb,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.02.19.431963"
}

@ARTICLE{Ma2019-uk,
  title     = "Bayesian Decision Models: A Primer",
  author    = "Ma, Wei Ji",
  abstract  = "To understand decision-making behavior in simple, controlled
               environments, Bayesian models are often useful. First, optimal
               behavior is always Bayesian. Second, even when behavior deviates
               from optimality, the Bayesian approach offers candidate models
               to account for suboptimalities. Third, a realist interpretation
               of Bayesian models opens the door to studying the neural
               representation of uncertainty. In this tutorial, we review the
               principles of Bayesian models of decision making and then focus
               on five case studies with exercises. We conclude with
               reflections and future directions.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  104,
  number    =  1,
  pages     = "164--175",
  month     =  oct,
  year      =  2019,
  language  = "en",
  issn      = "0896-6273",
  doi       = "10.1016/j.neuron.2019.09.037"
}

@ARTICLE{Balleine2019-si,
  title     = "The Meaning of Behavior: Discriminating Reflex and Volition in
               the Brain",
  author    = "Balleine, Bernard W",
  abstract  = "The ability to establish behaviorally what psychological
               capacity an animal is deploying---to discern accurately what an
               animal is doing---is key to functional analyses of the brain.
               Our current understanding of these capacities suggests, however,
               that this task is complex; there is evidence that multiple
               capacities are engaged simultaneously and contribute
               independently to the control of behavior. As such, establishing
               the contribution of a cell, circuit, or neural system to any one
               function requires careful dissection of that role from its
               influence on other functions and, therefore, the careful
               selection and design of behavioral tasks fit for that purpose.
               Here I describe recent research that has sought to utilize
               behavioral tools to investigate the neural bases of instrumental
               conditioning, particularly the circuits and systems supporting
               the capacity for goal-directed action, as opposed to conditioned
               reflexes and habits, and how these sources of action control
               interact to generate adaptive behavior.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  104,
  number    =  1,
  pages     = "47--62",
  month     =  oct,
  year      =  2019,
  keywords  = "goal-directed action; habitual action; incentive learning;
               reward; reinforcement; experienced value; predicted value;
               corticostriatal circuits; behavioral analysis",
  language  = "en",
  issn      = "0896-6273",
  doi       = "10.1016/j.neuron.2019.09.024"
}

@ARTICLE{Gomez-Marin2019-nv,
  title     = "The Life of Behavior",
  author    = "Gomez-Marin, Alex and Ghazanfar, Asif A",
  abstract  = "Neuroscience needs behavior. However, it is daunting to render
               the behavior of organisms intelligible without suppressing most,
               if not all, references to life. When animals are treated as
               passive stimulus-response, disembodied and identical machines,
               the life of behavior perishes. Here, we distill three biological
               principles (materiality, agency, and historicity), spell out
               their consequences for the study of animal behavior, and
               illustrate them with various examples from the literature. We
               propose to put behavior back into context, with the brain in a
               species-typical body and with the animal's body situated in the
               world; stamp Newtonian time with nested ontogenetic and
               phylogenetic processes that give rise to individuals with their
               own histories; and supplement linear cause-and-effect chains and
               information processing with circular loops of purpose and
               meaning. We believe that conceiving behavior in these ways is
               imperative for neuroscience.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  104,
  number    =  1,
  pages     = "25--36",
  month     =  oct,
  year      =  2019,
  language  = "en",
  issn      = "0896-6273",
  doi       = "10.1016/j.neuron.2019.09.017"
}

@ARTICLE{Wang2015-yh,
  title    = "Collateral pathways from the ventromedial hypothalamus mediate
              defensive behaviors",
  author   = "Wang, Li and Chen, Irene Z and Lin, Dayu",
  abstract = "The ventromedial hypothalamus (VMH) was thought to be essential
              for coping with threat, although its circuit mechanism remains
              unclear. To investigate this, we optogenetically activated
              steroidogenic factor 1 (SF1)-expressing neurons in the
              dorsomedial and central parts of the VMH (VMHdm/c), and observed
              a range of context-dependent somatomotor and autonomic responses
              resembling animals' natural defensive behaviors. By activating
              independent pathways emanating from the VMHdm/c, we demonstrated
              that VMHdm/c projection to the dorsolateral periaqueductal gray
              (dlPAG) induces inflexible immobility, while the VMHdm/c to
              anterior hypothalamic nucleus (AHN) pathway promotes avoidance.
              Consistent with the behavior changes induced by VMH to AHN
              pathway activation, direct activation of the AHN elicited
              avoidance and escape jumping, but not immobility. Retrograde
              tracing studies revealed that nearly 50\% of PAG-projecting
              VMHdm/c neurons send collateral projection to the AHN and vice
              versa. Thus, VMHdm/c neurons employ a one-to-many wiring
              configuration to orchestrate multiple aspects of defensive
              behaviors.",
  journal  = "Neuron",
  volume   =  85,
  number   =  6,
  pages    = "1344--1358",
  month    =  mar,
  year     =  2015,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "25754823",
  doi      = "10.1016/j.neuron.2014.12.025",
  pmc      = "PMC4368499"
}

@ARTICLE{Sul2011-yj,
  title    = "Role of rodent secondary motor cortex in value-based action
              selection",
  author   = "Sul, Jung Hoon and Jo, Suhyun and Lee, Daeyeol and Jung, Min Whan",
  abstract = "Despite widespread neural activity related to reward values,
              signals related to upcoming choice have not been clearly
              identified in the rodent brain. Here we examined neuronal
              activity in the lateral (AGl) and medial (AGm) agranular cortex,
              corresponding to the primary and secondary motor cortex,
              respectively, in rats performing a dynamic foraging task. Choice
              signals, before behavioral manifestation of the rat's choice,
              arose in the AGm earlier than in any other areas of the rat brain
              previously studied under free-choice conditions. The AGm also
              conveyed neural signals for decision value and chosen value. By
              contrast, upcoming choice signals arose later, and value signals
              were weaker, in the AGl. We also found that AGm lesions made the
              rats' choices less dependent on dynamically updated values. These
              results suggest that rodent secondary motor cortex might be
              uniquely involved in both representing and reading out value
              signals for flexible action selection.",
  journal  = "Nat. Neurosci.",
  volume   =  14,
  number   =  9,
  pages    = "1202--1208",
  month    =  aug,
  year     =  2011,
  keywords = "Locomotion;navigation",
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "21841777",
  doi      = "10.1038/nn.2881",
  pmc      = "PMC3164897"
}

@ARTICLE{Datta2019-ph,
  title     = "Computational Neuroethology: A Call to Action",
  author    = "Datta, Sandeep Robert and Anderson, David J and Branson, Kristin
               and Perona, Pietro and Leifer, Andrew",
  abstract  = "The brain is worthy of study because it is in charge of
               behavior. A flurry of recent technical advances in measuring and
               quantifying naturalistic behaviors provide an important
               opportunity for advancing brain science. However, the problem of
               understanding unrestrained behavior in the context of neural
               recordings and manipulations remains unsolved, and developing
               approaches to addressing this challenge is critical. Here we
               discuss considerations in computational neuroethology---the
               science of quantifying naturalistic behaviors for understanding
               the brain---and propose strategies to evaluate progress. We
               point to open questions that require resolution and call upon
               the broader systems neuroscience community to further develop
               and leverage measures of naturalistic, unrestrained behavior,
               which will enable us to more effectively probe the richness and
               complexity of the brain.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  104,
  number    =  1,
  pages     = "11--24",
  month     =  oct,
  year      =  2019,
  language  = "en",
  issn      = "0896-6273",
  doi       = "10.1016/j.neuron.2019.09.038"
}

@MISC{Tolman1967-ym,
  title  = "Purposive Behavior in Animal",
  author = "{Tolman}",
  year   =  1967
}

@ARTICLE{Esposito2014-ls,
  title    = "Brainstem nucleus {MdV} mediates skilled forelimb motor tasks",
  author   = "Esposito, Maria Soledad and Capelli, Paolo and Arber, Silvia",
  abstract = "Translating the behavioural output of the nervous system into
              movement involves interaction between brain and spinal cord. The
              brainstem provides an essential bridge between the two
              structures, but circuit-level organization and function of this
              intermediary system remain poorly understood. Here we use
              intersectional virus tracing and genetic strategies in mice to
              reveal a selective synaptic connectivity matrix between brainstem
              substructures and functionally distinct spinal motor neurons that
              regulate limb movement. The brainstem nucleus medullary reticular
              formation ventral part (MdV) stands out as specifically targeting
              subpopulations of forelimb-innervating motor neurons. Its
              glutamatergic premotor neurons receive synaptic input from key
              upper motor centres and are recruited during motor tasks.
              Selective neuronal ablation or silencing experiments reveal that
              MdV is critically important specifically for skilled motor
              behaviour, including accelerating rotarod and single-food-pellet
              reaching tasks. Our results indicate that distinct premotor
              brainstem nuclei access spinal subcircuits to mediate
              task-specific aspects of motor programs.",
  journal  = "Nature",
  volume   =  508,
  number   =  7496,
  pages    = "351--356",
  month    =  apr,
  year     =  2014,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "24487621",
  doi      = "10.1038/nature13023"
}

@ARTICLE{Chou2018-sq,
  title    = "Inhibitory gain modulation of defense behaviors by zona incerta",
  author   = "Chou, Xiao-Lin and Wang, Xiyue and Zhang, Zheng-Gang and Shen, Li
              and Zingg, Brian and Huang, Junxiang and Zhong, Wen and Mesik,
              Lukas and Zhang, Li I and Tao, Huizhong Whit",
  abstract = "Zona incerta (ZI) is a functionally mysterious subthalamic
              nucleus containing mostly inhibitory neurons. Here, we discover
              that GABAergic neurons in the rostral sector of ZI (ZIr) directly
              innervate excitatory but not inhibitory neurons in the
              dorsolateral and ventrolateral compartments of periaqueductal
              gray (PAG), which can drive flight and freezing behaviors
              respectively. Optogenetic activation of ZIr neurons or their
              projections to PAG reduces both sound-induced innate flight
              response and conditioned freezing response, while optogenetic
              suppression of these neurons enhances these defensive behaviors,
              likely through a mechanism of gain modulation. ZIr activity
              progressively increases during extinction of conditioned freezing
              response, and suppressing ZIr activity impairs the expression of
              fear extinction. Furthermore, ZIr is innervated by the medial
              prefrontal cortex (mPFC), and silencing mPFC prevents the
              increase of ZIr activity during extinction and the expression of
              fear extinction. Together, our results suggest that ZIr is
              engaged in modulating defense behaviors.",
  journal  = "Nat. Commun.",
  volume   =  9,
  number   =  1,
  pages    = "1151",
  month    =  mar,
  year     =  2018,
  language = "en",
  issn     = "2041-1723",
  pmid     = "29559622",
  doi      = "10.1038/s41467-018-03581-6",
  pmc      = "PMC5861117"
}

@ARTICLE{Mitrofanis2005-lq,
  title    = "Some certainty for the ``zone of uncertainty''? Exploring the
              function of the zona incerta",
  author   = "Mitrofanis, J",
  abstract = "The zona incerta (ZI), first described over a century ago by
              Auguste Forel as a ``region of which nothing certain can be
              said,'' forms a collection of cells that derives from the
              diencephalon. To this day, we are still not certain of the
              precise function of this ``zone of uncertainty'' although many
              have been proposed, from controlling visceral activity to
              shifting attention and from influencing arousal to maintaining
              posture and locomotion. In this review, I shall outline the
              recent advances in the understanding of the structure,
              connectivity and functions of the ZI. I will then focus on a
              possible and often neglected global role for the ZI, one that
              links its diverse functions together. In particular, I aim to
              highlight the idea that the ZI forms a primal center of the
              diencephalon for generating direct responses (visceral, arousal,
              attention and/or posture-locomotion) to a given sensory (somatic
              and/or visceral) stimulus. With this global role in mind, I will
              then address recent results indicating that abnormal ZI activity
              manifests in clinical symptoms of Parkinson disease.",
  journal  = "Neuroscience",
  volume   =  130,
  number   =  1,
  pages    = "1--15",
  year     =  2005,
  language = "en",
  issn     = "0306-4522",
  pmid     = "15561420",
  doi      = "10.1016/j.neuroscience.2004.08.017"
}

@ARTICLE{Svoboda2018-rr,
  title    = "Neural mechanisms of movement planning: motor cortex and beyond",
  author   = "Svoboda, Karel and Li, Nuo",
  abstract = "Neurons in motor cortex and connected brain regions fire in
              anticipation of specific movements, long before movement occurs.
              This neural activity reflects internal processes by which the
              brain plans and executes volitional movements. The study of motor
              planning offers an opportunity to understand how the structure
              and dynamics of neural circuits support persistent internal
              states and how these states influence behavior. Recent advances
              in large-scale neural recordings are beginning to decipher the
              relationship of the dynamics of populations of neurons during
              motor planning and movements. New behavioral tasks in rodents,
              together with quantified perturbations, link dynamics in specific
              nodes of neural circuits to behavior. These studies reveal a
              neural network distributed across multiple brain regions that
              collectively supports motor planning. We review recent advances
              and highlight areas where further work is needed to achieve a
              deeper understanding of the mechanisms underlying motor planning
              and related cognitive processes.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  49,
  pages    = "33--41",
  month    =  apr,
  year     =  2018,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "29172091",
  doi      = "10.1016/j.conb.2017.10.023"
}

@ARTICLE{Wong2015-pi,
  title    = "Motor Planning",
  author   = "Wong, Aaron L and Haith, Adrian M and Krakauer, John W",
  abstract = "Motor planning colloquially refers to any process related to the
              preparation of a movement that occurs during the reaction time
              prior to movement onset. However, this broad definition
              encompasses processes that are not strictly motor-related, such
              as decision-making about the identity of task-relevant stimuli in
              the environment. Furthermore, the assumption that all
              motor-planning processes require processing time, and can
              therefore be studied behaviorally by measuring changes in the
              reaction time, needs to be reexamined. In this review, we take a
              critical look at the processes leading from perception to action
              and suggest a definition of motor planning that encompasses only
              those processes necessary for a movement to be executed-that is,
              processes that are strictly movement related. These processes
              resolve the ambiguity inherent in an abstract goal by defining a
              specific movement to achieve it. We propose that the majority of
              processes that meet this definition can be completed nearly
              instantaneously, which means that motor planning itself in fact
              consumes only a small fraction of the reaction time.",
  journal  = "Neuroscientist",
  volume   =  21,
  number   =  4,
  pages    = "385--398",
  month    =  aug,
  year     =  2015,
  keywords = "attention; decision making; dynamical systems model; motor
              control; motor goal; optimal control theory; reaction time",
  language = "en",
  issn     = "1073-8584, 1089-4098",
  pmid     = "24981338",
  doi      = "10.1177/1073858414541484"
}

@ARTICLE{Wolpert2012-ch,
  title    = "Motor control is decision-making",
  author   = "Wolpert, Daniel M and Landy, Michael S",
  abstract = "Motor behavior may be viewed as a problem of maximizing the
              utility of movement outcome in the face of sensory, motor and
              task uncertainty. Viewed in this way, and allowing for the
              availability of prior knowledge in the form of a probability
              distribution over possible states of the world, the choice of a
              movement plan and strategy for motor control becomes an
              application of statistical decision theory. This point of view
              has proven successful in recent years in accounting for movement
              under risk, inferring the loss function used in motor tasks, and
              explaining motor behavior in a wide variety of circumstances.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  22,
  number   =  6,
  pages    = "996--1003",
  month    =  dec,
  year     =  2012,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "22647641",
  doi      = "10.1016/j.conb.2012.05.003",
  pmc      = "PMC3434279"
}

@UNPUBLISHED{Huang2018-ny,
  title    = "High-throughput mapping of mesoscale connectomes in individual
              mice",
  author   = "Huang, Longwen and Kebschull, Justus M and Furth, Daniel and
              Musall, Simon and Kaufman, Matthew T and Churchland, Anne K and
              Zador, Anthony M",
  abstract = "Abstract Brain function is determined by connectivity among brain
              areas, and disruption of this connectivity leads to
              neuropsychiatric disorders. Understanding connectivity is
              essential to modern neuroscience, but mesoscale connectivity
              atlases are currently slow and expensive to generate, exist for
              few model systems, and require pooling across many brains. Here
              we present a method, muMAPseq (multisource Multiplexed Analysis
              of Projections by sequencing), which leverages barcoding and
              high-throughput sequencing to generate atlases from single
              animals rapidly and at low cost. We apply muMAPseq to tracing the
              neocortical connectome of individual mice, and demonstrate high
              reproducibility, and accuracy. Applying muMAPseq to the mutant
              BTBR mouse strain, which lacks a corpus callosum, we recapitulate
              its known connectopathies, and also uncover novel deficits.
              muMAPseq allows individual laboratories to generate atlases
              tailored to individuals, disease models, and new model species,
              and will facilitate quantitative comparative connectomics,
              permitting examination of how age, sex, environment, genetics and
              species affect neuronal wiring.",
  journal  = "bioRxiv",
  pages    = "422477",
  month    =  sep,
  year     =  2018,
  language = "en",
  doi      = "10.1101/422477"
}

@ARTICLE{Furth2018-lg,
  title    = "An interactive framework for whole-brain maps at cellular
              resolution",
  author   = "F{\"u}rth, Daniel and Vaissi{\`e}re, Thomas and Tzortzi, Ourania
              and Xuan, Yang and M{\"a}rtin, Antje and Lazaridis, Iakovos and
              Spigolon, Giada and Fisone, Gilberto and Tomer, Raju and
              Deisseroth, Karl and Carl{\'e}n, Marie and Miller, Courtney A and
              Rumbaugh, Gavin and Meletis, Konstantinos",
  abstract = "To deconstruct the architecture and function of brain circuits,
              it is necessary to generate maps of neuronal connectivity and
              activity on a whole-brain scale. New methods now enable
              large-scale mapping of the mouse brain at cellular and
              subcellular resolution. We developed a framework to automatically
              annotate, analyze, visualize and easily share whole-brain data at
              cellular resolution, based on a scale-invariant, interactive
              mouse brain atlas. This framework enables connectivity and
              mapping projects in individual laboratories and across imaging
              platforms, as well as multiplexed quantitative information on the
              molecular identity of single neurons. As a proof of concept, we
              generated a comparative connectivity map of five major neuron
              types in the corticostriatal circuit, as well as an
              activity-based map to identify hubs mediating the behavioral
              effects of cocaine. Thus, this computational framework provides
              the necessary tools to generate brain maps that integrate data
              from connectivity, neuron identity and function.",
  journal  = "Nat. Neurosci.",
  volume   =  21,
  number   =  1,
  pages    = "139--149",
  month    =  jan,
  year     =  2018,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "29203898",
  doi      = "10.1038/s41593-017-0027-7",
  pmc      = "PMC5994773"
}

@ARTICLE{Kaufman2014-cw,
  title    = "Cortical activity in the null space: permitting preparation
              without movement",
  author   = "Kaufman, Matthew T and Churchland, Mark M and Ryu, Stephen I and
              Shenoy, Krishna V",
  abstract = "Neural circuits must perform computations and then selectively
              output the results to other circuits. Yet synapses do not change
              radically at millisecond timescales. A key question then is: how
              is communication between neural circuits controlled? In motor
              control, brain areas directly involved in driving movement are
              active well before movement begins. Muscle activity is some
              readout of neural activity, yet it remains largely unchanged
              during preparation. Here we find that during preparation, while
              the monkey holds still, changes in motor cortical activity cancel
              out at the level of these population readouts. Motor cortex can
              thereby prepare the movement without prematurely causing it.
              Further, we found evidence that this mechanism also operates in
              dorsal premotor cortex, largely accounting for how preparatory
              activity is attenuated in primary motor cortex. Selective use of
              'output-null' vs. 'output-potent' patterns of activity may thus
              help control communication to the muscles and between these brain
              areas.",
  journal  = "Nat. Neurosci.",
  volume   =  17,
  number   =  3,
  pages    = "440--448",
  month    =  mar,
  year     =  2014,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "24487233",
  doi      = "10.1038/nn.3643",
  pmc      = "PMC3955357"
}

@ARTICLE{Zingg2017-bx,
  title    = "{AAV-Mediated} Anterograde Transsynaptic Tagging: Mapping
              Corticocollicular {Input-Defined} Neural Pathways for Defense
              Behaviors",
  author   = "Zingg, Brian and Chou, Xiao-Lin and Zhang, Zheng-Gang and Mesik,
              Lukas and Liang, Feixue and Tao, Huizhong Whit and Zhang, Li I",
  abstract = "To decipher neural circuits underlying brain functions, viral
              tracers are widely applied to map input and output connectivity
              of neuronal populations. Despite the successful application of
              retrograde transsynaptic viruses for identifying presynaptic
              neurons of transduced neurons, analogous anterograde
              transsynaptic tools for tagging postsynaptically targeted neurons
              remain under development. Here, we discovered that
              adeno-associated viruses (AAV1 and AAV9) exhibit anterograde
              transsynaptic spread properties. AAV1-Cre from transduced
              presynaptic neurons effectively and specifically drives
              Cre-dependent transgene expression in selected postsynaptic
              neuronal targets, thus allowing axonal tracing and functional
              manipulations of the latter input-defined neuronal population.
              Its application in superior colliculus (SC) reveals that SC
              neuron subpopulations receiving corticocollicular projections
              from auditory and visual cortex specifically drive flight and
              freezing, two different types of defense behavior, respectively.
              Together with an intersectional approach, AAV-mediated
              anterograde transsynaptic tagging can categorize neurons by their
              inputs and molecular identity, and allow forward screening of
              distinct functional neural pathways embedded in complex brain
              circuits.",
  journal  = "Neuron",
  volume   =  93,
  number   =  1,
  pages    = "33--47",
  month    =  jan,
  year     =  2017,
  keywords = "AAV serotypes; Cre and Flp system; corticofugal projection;
              defensive behavior; flight and freezing; intersectional strategy;
              mapping neural circuits; superior colliculus;
              transsynaptic/transneuronal tracer",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "27989459",
  doi      = "10.1016/j.neuron.2016.11.045",
  pmc      = "PMC5538794"
}

@ARTICLE{Miller2012-rt,
  title    = "Mathematical equivalence of two common forms of firing rate
              models of neural networks",
  author   = "Miller, Kenneth D and Fumarola, Francesco",
  abstract = "We demonstrate the mathematical equivalence of two commonly used
              forms of firing rate model equations for neural networks. In
              addition, we show that what is commonly interpreted as the firing
              rate in one form of model may be better interpreted as a
              low-pass-filtered firing rate, and we point out a
              conductance-based firing rate model.",
  journal  = "Neural Comput.",
  volume   =  24,
  number   =  1,
  pages    = "25--31",
  month    =  jan,
  year     =  2012,
  keywords = "RNN",
  language = "en",
  issn     = "0899-7667, 1530-888X",
  pmid     = "22023194",
  doi      = "10.1162/NECO\_a\_00221",
  pmc      = "PMC3237837"
}

@BOOK{Cooper2015-qw,
  title     = "Escaping From Predators: An Integrative View of Escape Decisions",
  author    = "Cooper, Jr, William and Cooper, Jr, William E and Blumstein,
               Daniel T",
  abstract  = "When a predator attacks, prey are faced with a series of 'if',
               'when' and 'how' escape decisions - these critical questions are
               the foci of this book. Cooper and Blumstein bring together a
               balance of theory and empirical research to summarise over fifty
               years of scattered research and benchmark current thinking in
               the rapidly expanding literature on the behavioural ecology of
               escaping. The book consolidates current and new behaviour models
               with taxonomically divided empirical chapters that demonstrate
               the application of escape theory to different groups. The
               chapters integrate behaviour with physiology, genetics and
               evolution to lead the reader through the complex decisions faced
               by prey during a predator attack, examining how these decisions
               interact with life history and individual variation. The chapter
               on best practice field methodology and the ideas for future
               research presented throughout, ensure this volume is practical
               as well as informative.",
  publisher = "Cambridge University Press",
  month     =  may,
  year      =  2015,
  keywords  = "books",
  language  = "en",
  isbn      = "9781107060548"
}

@ARTICLE{Chiel1997-dl,
  title    = "The brain has a body: adaptive behavior emerges from interactions
              of nervous system, body and environment",
  author   = "Chiel, H J and Beer, R D",
  abstract = "Studies of mechanisms of adaptive behavior generally focus on
              neurons and circuits. But adaptive behavior also depends on
              interactions among the nervous system, body and environment:
              sensory preprocessing and motor post-processing filter inputs to
              and outputs from the nervous system; co-evolution and
              co-development of nervous system and periphery create matching
              and complementarity between them; body structure creates
              constraints and opportunities for neural control; and continuous
              feedback between nervous system, body and environment are
              essential for normal behavior. This broader view of adaptive
              behavior has been a major underpinning of ecological psychology
              and has influenced behavior-based robotics. Computational
              neuroethology, which jointly models neural control and periphery
              of animals, is a promising methodology for understanding adaptive
              behavior.",
  journal  = "Trends Neurosci.",
  volume   =  20,
  number   =  12,
  pages    = "553--557",
  month    =  dec,
  year     =  1997,
  language = "en",
  issn     = "0166-2236",
  pmid     = "9416664",
  doi      = "10.1016/s0166-2236(97)01149-1"
}

@ARTICLE{Calhoun2017-ur,
  title    = "Quantifying behavior to solve sensorimotor transformations:
              advances from worms and flies",
  author   = "Calhoun, Adam J and Murthy, Mala",
  abstract = "The development of new computational tools has recently opened up
              the study of natural behaviors at a precision that was previously
              unachievable. These tools permit a highly quantitative analysis
              of behavioral dynamics at timescales that are well matched to the
              timescales of neural activity. Here we examine how combining
              these methods with established techniques for estimating an
              animal's sensory experience presents exciting new opportunities
              for dissecting the sensorimotor transformations performed by the
              nervous system. We focus this review primarily on examples from
              Caenorhabditis elegans and Drosophila melanogaster-for these
              model systems, computational approaches to characterize behavior,
              in combination with unparalleled genetic tools for neural
              activation, silencing, and recording, have already proven
              instrumental for illuminating underlying neural mechanisms.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  46,
  pages    = "90--98",
  month    =  oct,
  year     =  2017,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "28850885",
  doi      = "10.1016/j.conb.2017.08.006",
  pmc      = "PMC5765764"
}

@ARTICLE{Honegger2018-xu,
  title    = "Stochasticity, individuality and behavior",
  author   = "Honegger, Kyle and de Bivort, Benjamin",
  abstract = "No two individuals are exactly alike. More than a simple
              platitude, this observation reflects the fundamentally stochastic
              nature of biological systems. The term 'stochastic' describes
              features that cannot be predicted a priori from readily
              measurable variables. In the dichotomous framework in which
              biological variation arises from genetic or environmental
              effects, stochastic effects are classified as environmental
              because they are not passed on to offspring - any non-heritable
              cause is, by definition, environmental. But non-heritable effects
              can be subdivided into those which can be predicted from
              measurable variables, and those that cannot. These latter effects
              are stochastic.",
  journal  = "Curr. Biol.",
  volume   =  28,
  number   =  1,
  pages    = "R8--R12",
  month    =  jan,
  year     =  2018,
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "29316423",
  doi      = "10.1016/j.cub.2017.11.058"
}

@ARTICLE{Headley2019-if,
  title     = "Embracing Complexity in Defensive Networks",
  author    = "Headley, Drew B and Kanta, Vasiliki and Kyriazi, Pinelopi and
               Par{\'e}, Denis",
  abstract  = "The neural basis of defensive behaviors continues to attract
               much interest, not only because they are important for survival
               but also because their dysregulation may be at the origin of
               anxiety disorders. Recently, a dominant approach in the field
               has been the optogenetic manipulation of specific circuits or
               cell types within these circuits to dissect their role in
               different defensive behaviors. While the usefulness of
               optogenetics is unquestionable, we argue that this method, as
               currently applied, fosters an atomistic conceptualization of
               defensive behaviors, which hinders progress in understanding the
               integrated responses of nervous systems to threats. Instead, we
               advocate for a holistic approach to the problem, including
               observational study of natural behaviors and their neuronal
               correlates at multiple sites, coupled to the use of
               optogenetics, not to globally turn on or off neurons of
               interest, but to manipulate specific activity patterns
               hypothesized to regulate defensive behaviors.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  103,
  number    =  2,
  pages     = "189--201",
  month     =  jul,
  year      =  2019,
  keywords  = "amygdala; defensive behaviors; extinction; fear; infralimbic;
               medial prefrontal cortex; prelimbic",
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "31319049",
  doi       = "10.1016/j.neuron.2019.05.024",
  pmc       = "PMC6641575"
}

@UNPUBLISHED{Van_Wijngaarden2019-md,
  title    = "Representation of Distance and Direction of Nearby Boundaries in
              Retrosplenial Cortex",
  author   = "van Wijngaarden, Joeri B G and Babl, Susanne S and Ito, Hiroshi T",
  abstract = "Borders and edges are salient and behaviourally relevant features
              for navigating the environment. The brain forms dedicated neural
              representations of environmental boundaries, which are assumed to
              serve as a reference for spatial coding. Here we expand this
              border coding network to include the retrosplenial cortex (RSC)
              in which we identified neurons that increase their firing near
              all boundaries of an arena. RSC border cells specifically encode
              walls, but not objects, and maintain their tuning in the absence
              of direct sensory detection. Unlike border cells in the medial
              entorhinal cortex (MEC), RSC border cells are sensitive to the
              animal9s direction to nearby walls located contralateral to the
              recorded hemisphere. Pharmacogenetic inactivation of MEC led to a
              disruption of RSC border coding, but not vice versa, indicating
              network directionality. Together these data shed light on how
              information about distance and direction of boundaries is
              generated in the brain for guiding navigation behaviour.",
  journal  = "bioRxiv",
  pages    = "807453",
  month    =  oct,
  year     =  2019,
  language = "en",
  doi      = "10.1101/807453"
}

@UNPUBLISHED{Kastner2019-xb,
  title    = "Dynamic preferences account for inter-animal variability during
              the continual learning of a cognitive task",
  author   = "Kastner, David B and Miller, Eric A and Yang, Zhounan and Roumis,
              Demetris K and Liu, Daniel F and Frank, Loren M and Dayan, Peter",
  abstract = "In novel situations, behavior necessarily reduces to latent
              biases. How these biases interact with new experiences to enable
              subsequent behavior remains poorly understood. We exposed rats to
              a family of spatial alternation contingencies and developed a
              series of reinforcement learning agents to describe the behavior.
              The performance of these agents shows that accurately describing
              the learning of individual animals requires accounting for their
              individual dynamic preferences as well as general, shared,
              cognitive processes. Agents that include only memory of past
              choice do not account for the behavior. Adding an explicit
              representation of biases allows agents to perform the task as
              rapidly as the rats, to accurately predict critical facets of
              their behavior on which it was not fitted, and to capture
              individual differences quantitatively. Our results illustrate the
              value of making explicit models of learning and highlight the
              importance of considering the initial state of each animal in
              understanding behavior.",
  journal  = "bioRxiv",
  pages    = "808006",
  month    =  oct,
  year     =  2019,
  language = "en",
  doi      = "10.1101/808006"
}

@ARTICLE{Alexander2015-vc,
  title    = "Retrosplenial cortex maps the conjunction of internal and
              external spaces",
  author   = "Alexander, Andrew S and Nitz, Douglas A",
  abstract = "Intelligent behavior demands not only multiple forms of spatial
              representation, but also coordination among the brain regions
              mediating those representations. Retrosplenial cortex is densely
              interconnected with the majority of cortical and subcortical
              brain structures that register an animal's position in multiple
              internal and external spatial frames of reference. This unique
              anatomy suggests that it functions to integrate distinct forms of
              spatial information and provides an interface for transformations
              between them. Evidence for this was found in rats traversing two
              different routes placed at different environmental locations.
              Retrosplenial ensembles robustly encoded conjunctions of progress
              through the current route, position in the larger environment and
              the left versus right turning behavior of the animal. Thus, the
              retrosplenial cortex has the requisite dynamics to serve as an
              intermediary between brain regions generating different forms of
              spatial mapping, a result that is consistent with navigational
              and episodic memory impairments following damage to this region
              in humans.",
  journal  = "Nat. Neurosci.",
  volume   =  18,
  number   =  8,
  pages    = "1143--1151",
  month    =  aug,
  year     =  2015,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "26147532",
  doi      = "10.1038/nn.4058"
}

@ARTICLE{Chen2019-pb,
  title    = "{High-Throughput} Mapping of {Long-Range} Neuronal Projection
              Using In Situ Sequencing",
  author   = "Chen, Xiaoyin and Sun, Yu-Chi and Zhan, Huiqing and Kebschull,
              Justus M and Fischer, Stephan and Matho, Katherine and Huang, Z
              Josh and Gillis, Jesse and Zador, Anthony M",
  abstract = "Summary Understanding neural circuits requires deciphering
              interactions among myriad cell types defined by spatial
              organization, connectivity, gene expression, and other
              properties. Resolving these cell types requires both
              single-neuron resolution and high throughput, a challenging
              combination with conventional methods. Here, we introduce
              barcoded anatomy resolved by sequencing (BARseq), a multiplexed
              method based on RNA barcoding for mapping projections of
              thousands of spatially resolved neurons in a single brain and
              relating those projections to other properties such as gene or
              Cre expression. Mapping the projections to 11 areas of 3,579
              neurons in mouse auditory cortex using BARseq confirmed the
              laminar organization of the three top classes (intratelencephalic
              [IT], pyramidal tract-like [PT-like], and corticothalamic [CT])
              of projection neurons. In depth analysis uncovered a projection
              type restricted almost exclusively to transcriptionally defined
              subtypes of IT neurons. By bridging anatomical and transcriptomic
              approaches at cellular resolution with high throughput, BARseq
              can potentially uncover the organizing principles underlying the
              structure and formation of neural circuits.",
  journal  = "Cell",
  volume   =  179,
  number   =  3,
  pages    = "772--786.e19",
  month    =  oct,
  year     =  2019,
  keywords = "high throughput; projection mapping; cellular barcoding;
              sequencing; auditory cortex",
  issn     = "0092-8674",
  doi      = "10.1016/j.cell.2019.09.023"
}

@ARTICLE{noauthor_undated-jd,
  title = "{ICRA\_2010\_OpenCV\_Tutorial.pdf}"
}

@ARTICLE{Ellard2009-vi,
  title    = "Spatial cognition in the gerbil: computing optimal escape routes
              from visual threats",
  author   = "Ellard, Colin G and Eller, Meghan C",
  abstract = "Previous studies in our laboratory have shown that when presented
              with a sudden stimulus simulating an oncoming predator, Mongolian
              gerbils can compute the optimal trajectory to a safe refuge,
              taking into account the position of the threat, the location of a
              clearly visible refuge, and several other contextual variables as
              well. In the present studies, the main goal was to explore the
              abilities of gerbils to use mental representations of spaces that
              were visually occluded by opaque barriers to compute efficient
              escape trajectories. In all studies, gerbils were placed into a
              round open field containing a single refuge. On each trial, an
              overhead visual stimulus was caused to 'fly' overhead, eliciting
              robust escape movements from the gerbils. By manipulating the
              shape and position of a series of opaque barriers that were
              interposed between the gerbils and the refuge, we were able to
              show that gerbils can compute the shortest route to an invisible
              target, even when the available routes to the target are made
              complex by using elaborate barrier shapes. These findings suggest
              that gerbils can maintain representations of their locations with
              respect to salient environmental landmarks and refuges, even when
              such locations are not continuously visible.",
  journal  = "Anim. Cogn.",
  volume   =  12,
  number   =  2,
  pages    = "333--345",
  month    =  mar,
  year     =  2009,
  language = "en",
  issn     = "1435-9448, 1435-9456",
  pmid     = "18956215",
  doi      = "10.1007/s10071-008-0193-9"
}

@ARTICLE{Beck2012-xf,
  title     = "Not noisy, just wrong: the role of suboptimal inference in
               behavioral variability",
  author    = "Beck, Jeffrey M and Ma, Wei Ji and Pitkow, Xaq and Latham, Peter
               E and Pouget, Alexandre",
  abstract  = "Behavior varies from trial to trial even when the stimulus is
               maintained as constant as possible. In many models, this
               variability is attributed to noise in the brain. Here, we
               propose that there is another major source of variability:
               suboptimal inference. Importantly, we argue that in most tasks
               of interest, and particularly complex ones, suboptimal inference
               is likely to be the dominant component of behavioral
               variability. This perspective explains a variety of intriguing
               observations, including why variability appears to be larger on
               the sensory than on the motor side, and why our sensors are
               sometimes surprisingly unreliable.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  74,
  number    =  1,
  pages     = "30--39",
  month     =  apr,
  year      =  2012,
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "22500627",
  doi       = "10.1016/j.neuron.2012.03.016",
  pmc       = "PMC4486264"
}

@ARTICLE{Faisal2008-as,
  title     = "Noise in the nervous system",
  author    = "Faisal, A Aldo and Selen, Luc P J and Wolpert, Daniel M",
  abstract  = "Noise--random disturbances of signals--poses a fundamental
               problem for information processing and affects all aspects of
               nervous-system function. However, the nature, amount and impact
               of noise in the nervous system have only recently been addressed
               in a quantitative manner. Experimental and computational methods
               have shown that multiple noise sources contribute to cellular
               and behavioural trial-to-trial variability. We review the
               sources of noise in the nervous system, from the molecular to
               the behavioural level, and show how noise contributes to
               trial-to-trial variability. We highlight how noise affects
               neuronal networks and the principles the nervous system applies
               to counter detrimental effects of noise, and briefly discuss
               noise's potential benefits.",
  journal   = "Nat. Rev. Neurosci.",
  publisher = "nature.com",
  volume    =  9,
  number    =  4,
  pages     = "292--303",
  month     =  apr,
  year      =  2008,
  language  = "en",
  issn      = "1471-003X, 1471-0048",
  pmid      = "18319728",
  doi       = "10.1038/nrn2258",
  pmc       = "PMC2631351"
}

@ARTICLE{Rubin2019-tw,
  title    = "Revealing neural correlates of behavior without behavioral
              measurements",
  author   = "Rubin, Alon and Sheintuch, Liron and Brande-Eilat, Noa and
              Pinchasof, Or and Rechavi, Yoav and Geva, Nitzan and Ziv, Yaniv",
  abstract = "Measuring neuronal tuning curves has been instrumental for many
              discoveries in neuroscience but requires a priori assumptions
              regarding the identity of the encoded variables. We applied
              unsupervised learning to large-scale neuronal recordings in
              behaving mice from circuits involved in spatial cognition and
              uncovered a highly-organized internal structure of ensemble
              activity patterns. This emergent structure allowed defining for
              each neuron an 'internal tuning-curve' that characterizes its
              activity relative to the network activity, rather than relative
              to any predefined external variable, revealing place-tuning and
              head-direction tuning without relying on measurements of place or
              head-direction. Similar investigation in prefrontal cortex
              revealed schematic representations of distances and actions, and
              exposed a previously unknown variable, the 'trajectory-phase'.
              The internal structure was conserved across mice, allowing using
              one animal's data to decode another animal's behavior. Thus, the
              internal structure of neuronal activity itself enables
              reconstructing internal representations and discovering new
              behavioral variables hidden within a neural code.",
  journal  = "Nat. Commun.",
  volume   =  10,
  number   =  1,
  pages    = "4745",
  month    =  oct,
  year     =  2019,
  language = "en",
  issn     = "2041-1723",
  pmid     = "31628322",
  doi      = "10.1038/s41467-019-12724-2"
}

@ARTICLE{Tingley2018-yq,
  title    = "Transformation of a Spatial Map across the {Hippocampal-Lateral}
              Septal Circuit",
  author   = "Tingley, David and Buzs{\'a}ki, Gy{\"o}rgy",
  abstract = "The hippocampus constructs a map of the environment. How this
              ``cognitive map'' is utilized by other brain regions to guide
              behavior remains unexplored. To examine how neuronal firing
              patterns in the hippocampus are transmitted and transformed, we
              recorded neurons in its principal subcortical target, the lateral
              septum (LS). We observed that LS neurons carry reliable spatial
              information in the phase of action potentials, relative to
              hippocampal theta oscillations, while the firing rates of LS
              neurons remained uninformative. Furthermore, this spatial phase
              code had an anatomical microstructure within the LS and was bound
              to the hippocampal spatial code by synchronous gamma frequency
              cell assemblies. Using a data-driven model, we show that
              rate-independent spatial tuning arises through the dynamic
              weighting of CA1 and CA3 cell assemblies. Our findings
              demonstrate that transformation of the hippocampal spatial map
              depends on higher-order theta-dependent neuronal sequences. VIDEO
              ABSTRACT.",
  journal  = "Neuron",
  volume   =  98,
  number   =  6,
  pages    = "1229--1242.e5",
  month    =  jun,
  year     =  2018,
  keywords = "cell assemblies; dynamic weighting; hippocampus; information
              transfer; lateral septum; phase coding; rate coding; theta
              sequences; transformation;Spatial Navigation",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "29779942",
  doi      = "10.1016/j.neuron.2018.04.028"
}

@ARTICLE{Friedmann_undated-xv,
  title  = "Mapping Mesoscale Axonal Projections in the Mouse Brain Using A
            {3D} Convolutional Network",
  author = "Friedmann, Drew and Pun, Albert and Adams, Eliza L and Lui, Jan H
            and Kebschull, Justus M and Grutzner, Sophie M and Castagnola,
            Caitlin and Tessier-Lavigne, Marc and Luo, Liqun",
  doi    = "10.1101/812644"
}

@UNPUBLISHED{McClain2019-rs,
  title    = "Position-theta-phase model of hippocampal place cell activity
              applied to quantification of running speed modulation of firing
              rate",
  author   = "McClain, Kathryn and Tingley, David and Heeger, David and
              Buzs{\'a}ki, Gy{\"o}rgy",
  abstract = "Abstract Spiking activity of place cells in the hippocampus
              encodes the animal's position as it moves through an environment.
              Within a cell's place field, both the firing rate and the phase
              of spiking in the local theta oscillation contain spatial
              information. We propose a position-theta-phase (PTP) model that
              captures the simultaneous expression of the firing-rate code and
              theta-phase code in place cell spiking. This model parametrically
              characterizes place fields to compare across cells, time and
              condition, generates realistic place cell simulation data, and
              conceptualizes a framework for principled hypothesis testing to
              identify additional features of place cell activity. We use the
              PTP model to assess the effect of running speed in place cell
              data recorded from rats running on linear tracks. For the
              majority of place fields we do not find evidence for speed
              modulation of the firing rate. For a small subset of place
              fields, we find firing rates significantly increase or decrease
              with speed. We use the PTP model to compare candidate mechanisms
              of speed modulation in significantly modulated fields, and
              determine that speed acts as a gain control on the magnitude of
              firing rate. Our model provides a tool that connects rigorous
              analysis with a computational framework for understanding place
              cell activity.Significance The hippocampus is heavily studied in
              the context of spatial navigation, and the format of spatial
              information in hippocampus is multifaceted and complex.
              Furthermore, the hippocampus is also thought to contain
              information about other important aspects of behavior such as
              running speed, though there is not agreement on the nature and
              magnitude of their effect. To understand how all of these
              variables are simultaneously represented and used to guide
              behavior, a theoretical framework is needed that can be directly
              applied to the data we record. We present a model that captures
              well-established spatial-encoding features of hippocampal
              activity and provides the opportunity to identify and incorporate
              novel features for our collective understanding.",
  journal  = "bioRxiv",
  pages    = "714105",
  month    =  jul,
  year     =  2019,
  language = "en",
  doi      = "10.1101/714105"
}

@ARTICLE{Chen2014-rg,
  title    = "Neural representation of spatial topology in the rodent
              hippocampus",
  author   = "Chen, Zhe and Gomperts, Stephen N and Yamamoto, Jun and Wilson,
              Matthew A",
  abstract = "Pyramidal cells in the rodent hippocampus often exhibit clear
              spatial tuning in navigation. Although it has been long suggested
              that pyramidal cell activity may underlie a topological code
              rather than a topographic code, it remains unclear whether an
              abstract spatial topology can be encoded in the ensemble spiking
              activity of hippocampal place cells. Using a statistical approach
              developed previously, we investigate this question and related
              issues in greater detail. We recorded ensembles of hippocampal
              neurons as rodents freely foraged in one- and two-dimensional
              spatial environments and used a ``decode-to-uncover'' strategy to
              examine the temporally structured patterns embedded in the
              ensemble spiking activity in the absence of observed spatial
              correlates during periods of rodent navigation or awake
              immobility. Specifically, the spatial environment was represented
              by a finite discrete state space. Trajectories across spatial
              locations (``states'') were associated with consistent
              hippocampal ensemble spiking patterns, which were characterized
              by a state transition matrix. From this state transition matrix,
              we inferred a topology graph that defined the connectivity in the
              state space. In both one- and two-dimensional environments, the
              extracted behavior patterns from the rodent hippocampal
              population codes were compared against randomly shuffled spike
              data. In contrast to a topographic code, our results support the
              efficiency of topological coding in the presence of sparse sample
              size and fuzzy space mapping. This computational approach allows
              us to quantify the variability of ensemble spiking activity,
              examine hippocampal population codes during off-line states, and
              quantify the topological complexity of the environment.",
  journal  = "Neural Comput.",
  volume   =  26,
  number   =  1,
  pages    = "1--39",
  month    =  jan,
  year     =  2014,
  language = "en",
  issn     = "0899-7667, 1530-888X",
  pmid     = "24102128",
  doi      = "10.1162/NECO\_a\_00538",
  pmc      = "PMC3967246"
}

@ARTICLE{Spreemann2015-as,
  title         = "Using persistent homology to reveal hidden information in
                   neural data",
  author        = "Spreemann, Gard and Dunn, Benjamin and Botnan, Magnus Bakke
                   and Baas, Nils A",
  abstract      = "We propose a method, based on persistent homology, to
                   uncover topological properties of a priori unknown
                   covariates of neuron activity. Our input data consist of
                   spike train measurements of a set of neurons of interest, a
                   candidate list of the known stimuli that govern neuron
                   activity, and the corresponding state of the animal
                   throughout the experiment performed. Using a generalized
                   linear model for neuron activity and simple assumptions on
                   the effects of the external stimuli, we infer away any
                   contribution to the observed spike trains by the candidate
                   stimuli. Persistent homology then reveals useful information
                   about any further, unknown, covariates.",
  month         =  oct,
  year          =  2015,
  archivePrefix = "arXiv",
  eprint        = "1510.06629",
  primaryClass  = "q-bio.NC",
  arxivid       = "1510.06629"
}

@ARTICLE{Chaudhuri2019-yh,
  title     = "The intrinsic attractor manifold and population dynamics of a
               canonical cognitive circuit across waking and sleep",
  author    = "Chaudhuri, Rishidev and Ger{\c c}ek, Berk and Pandey, Biraj and
               Peyrache, Adrien and Fiete, Ila",
  abstract  = "Neural circuits construct distributed representations of key
               variables-external stimuli or internal constructs of quantities
               relevant for survival, such as an estimate of one's location in
               the world-as vectors of population activity. Although population
               activity vectors may have thousands of entries (dimensions), we
               consider that they trace out a low-dimensional manifold whose
               dimension and topology match the represented variable. This
               manifold perspective enables blind discovery and decoding of the
               represented variable using only neural population activity
               (without knowledge of the input, output, behavior or
               topography). We characterize and directly visualize manifold
               structure in the mammalian head direction circuit, revealing
               that the states form a topologically nontrivial one-dimensional
               ring. The ring exhibits isometry and is invariant across waking
               and rapid eye movement sleep. This result directly demonstrates
               that there are continuous attractor dynamics and enables
               powerful inference about mechanism. Finally, external rather
               than internal noise limits memory fidelity, and the manifold
               approach reveals new dynamical trajectories during sleep.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  22,
  number    =  9,
  pages     = "1512--1520",
  month     =  sep,
  year      =  2019,
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "31406365",
  doi       = "10.1038/s41593-019-0460-x"
}

@ARTICLE{Guo2015-ev,
  title    = "Multi-channel fiber photometry for population neuronal activity
              recording",
  author   = "Guo, Qingchun and Zhou, Jingfeng and Feng, Qiru and Lin, Rui and
              Gong, Hui and Luo, Qingming and Zeng, Shaoqun and Luo, Minmin and
              Fu, Ling",
  abstract = "Fiber photometry has become increasingly popular among
              neuroscientists as a convenient tool for the recording of
              genetically defined neuronal population in behaving animals.
              Here, we report the development of the multi-channel fiber
              photometry system to simultaneously monitor neural activities in
              several brain areas of an animal or in different animals. In this
              system, a galvano-mirror modulates and cyclically couples the
              excitation light to individual multimode optical fiber bundles. A
              single photodetector collects excited light and the configuration
              of fiber bundle assembly and the scanner determines the total
              channel number. We demonstrated that the system exhibited
              negligible crosstalk between channels and optical signals could
              be sampled simultaneously with a sample rate of at least 100 Hz
              for each channel, which is sufficient for recording calcium
              signals. Using this system, we successfully recorded GCaMP6
              fluorescent signals from the bilateral barrel cortices of a
              head-restrained mouse in a dual-channel mode, and the
              orbitofrontal cortices of multiple freely moving mice in a
              triple-channel mode. The multi-channel fiber photometry system
              would be a valuable tool for simultaneous recordings of
              population activities in different brain areas of a given animal
              and different interacting individuals.",
  journal  = "Biomed. Opt. Express",
  volume   =  6,
  number   =  10,
  pages    = "3919--3931",
  month    =  oct,
  year     =  2015,
  keywords = "(170.0170) Medical optics and biotechnology; (170.2150)
              Endoscopic imaging; (170.2655) Functional monitoring and imaging;
              (180.2520) Fluorescence microscopy",
  language = "en",
  issn     = "2156-7085",
  pmid     = "26504642",
  doi      = "10.1364/BOE.6.003919",
  pmc      = "PMC4605051"
}

@ARTICLE{Kim2016-zg,
  title    = "Simultaneous fast measurement of circuit dynamics at multiple
              sites across the mammalian brain",
  author   = "Kim, Christina K and Yang, Samuel J and Pichamoorthy, Nandini and
              Young, Noah P and Kauvar, Isaac and Jennings, Joshua H and
              Lerner, Talia N and Berndt, Andre and Lee, Soo Yeun and
              Ramakrishnan, Charu and Davidson, Thomas J and Inoue, Masatoshi
              and Bito, Haruhiko and Deisseroth, Karl",
  abstract = "Real-time activity measurements from multiple specific cell
              populations and projections are likely to be important for
              understanding the brain as a dynamical system. Here we developed
              frame-projected independent-fiber photometry (FIP), which we used
              to record fluorescence activity signals from many brain regions
              simultaneously in freely behaving mice. We explored the
              versatility of the FIP microscope by quantifying real-time
              activity relationships among many brain regions during social
              behavior, simultaneously recording activity along multiple axonal
              pathways during sensory experience, performing simultaneous
              two-color activity recording, and applying optical perturbation
              tuned to elicit dynamics that match naturally occurring patterns
              observed during behavior.",
  journal  = "Nat. Methods",
  volume   =  13,
  number   =  4,
  pages    = "325--328",
  month    =  apr,
  year     =  2016,
  language = "en",
  issn     = "1548-7091, 1548-7105",
  pmid     = "26878381",
  doi      = "10.1038/nmeth.3770",
  pmc      = "PMC5717315"
}

@ARTICLE{Varela2014-yv,
  title    = "Anatomical substrates for direct interactions between
              hippocampus, medial prefrontal cortex, and the thalamic nucleus
              reuniens",
  author   = "Varela, C and Kumar, S and Yang, J Y and Wilson, M A",
  abstract = "The reuniens nucleus in the midline thalamus projects to the
              medial prefrontal cortex (mPFC) and the hippocampus, and has been
              suggested to modulate interactions between these regions, such as
              spindle-ripple correlations during sleep and theta band coherence
              during exploratory behavior. Feedback from the hippocampus to the
              nucleus reuniens has received less attention but has the
              potential to influence thalamocortical networks as a function of
              hippocampal activation. We used the retrograde tracer cholera
              toxin B conjugated to two fluorophores to study thalamic
              projections to the dorsal and ventral hippocampus and to the
              prelimbic and infralimbic subregions of mPFC. We also examined
              the feedback connections from the hippocampus to reuniens. The
              goal was to evaluate the anatomical basis for direct coordination
              between reuniens, mPFC, and hippocampus by looking for
              double-labeled cells in reuniens and hippocampus. In confirmation
              of previous reports, the nucleus reuniens was the origin of most
              thalamic afferents to the dorsal hippocampus, whereas both
              reuniens and the lateral dorsal nucleus projected to ventral
              hippocampus. Feedback from hippocampus to reuniens originated
              primarily in the dorsal and ventral subiculum. Thalamic cells
              with collaterals to mPFC and hippocampus were found in reuniens,
              across its anteroposterior axis, and represented, on average,
              about 8 \% of the labeled cells in reuniens. Hippocampal cells
              with collaterals to mPFC and reuniens were less common (~1 \% of
              the labeled subicular cells), and located in the molecular layer
              of the subiculum. The results indicate that a subset of reuniens
              cells can directly coordinate activity in mPFC and hippocampus.
              Cells with collaterals in the hippocampus-reuniens-mPFC network
              may be important for the systems consolidation of memory traces
              and for theta synchronization during exploratory behavior.",
  journal  = "Brain Struct. Funct.",
  volume   =  219,
  number   =  3,
  pages    = "911--929",
  month    =  may,
  year     =  2014,
  language = "en",
  issn     = "1863-2653, 1863-2661",
  pmid     = "23571778",
  doi      = "10.1007/s00429-013-0543-5",
  pmc      = "PMC4179252"
}

@ARTICLE{McKenna2004-kw,
  title    = "Afferent projections to nucleus reuniens of the thalamus",
  author   = "McKenna, James Timothy and Vertes, Robert P",
  abstract = "The nucleus reuniens (RE) is the largest of the midline nuclei of
              the thalamus and the major source of thalamic afferents to the
              hippocampus and parahippocampal structures. Nucleus reuniens has
              recently been shown to exert powerful excitatory actions on CA1
              of the hippocampus. Few reports on any species have examined
              afferent projections to nucleus reuniens. By using the retrograde
              anatomical tracer Fluorogold, we examined patterns of afferent
              projections to RE in the rat. We showed that RE receives a
              diverse and widely distributed set of afferents projections. The
              main sources of input to nucleus reuniens were from the
              orbitomedial, insular, ectorhinal, perirhinal, and retrosplenial
              cortices; CA1/subiculum of hippocampus; claustrum, tania tecta,
              lateral septum, substantia innominata, and medial and lateral
              preoptic nuclei of the basal forebrain; medial nucleus of
              amygdala; paraventricular and lateral geniculate nuclei of the
              thalamus; zona incerta; anterior, ventromedial, lateral,
              posterior, supramammillary, and dorsal premammillary nuclei of
              the hypothalamus; and ventral tegmental area, periaqueductal
              gray, medial and posterior pretectal nuclei, superior colliculus,
              precommissural/commissural nuclei, nucleus of the posterior
              commissure, parabrachial nucleus, laterodorsal and
              pedunculopontine tegmental nuclei, nucleus incertus, and dorsal
              and median raphe nuclei of the brainstem. The present findings of
              widespread projections to RE, mainly from
              limbic/limbic-associated structures, suggest that nucleus
              reuniens represents a critical relay in the transfer of limbic
              information (emotional/cognitive) from RE to its major targets,
              namely, to the hippocampus and orbitomedial prefrontal cortex. RE
              appears to be a major link in the two-way exchange of information
              between the hippocampus and the medial prefrontal cortex.",
  journal  = "J. Comp. Neurol.",
  volume   =  480,
  number   =  2,
  pages    = "115--142",
  month    =  dec,
  year     =  2004,
  language = "en",
  issn     = "0021-9967",
  pmid     = "15514932",
  doi      = "10.1002/cne.20342"
}

@ARTICLE{Ito2018-xs,
  title    = "Prefrontal-hippocampal interactions for spatial navigation",
  author   = "Ito, Hiroshi T",
  abstract = "Animals have the ability to navigate to a desired location by
              making use of information about environmental landmarks and their
              own movements. While decades of neuroscience research have
              identified neurons in the hippocampus and parahippocampal
              structures that represent an animal's position in space, it is
              still largely unclear how an animal can choose the next movement
              direction to reach a desired goal. As the goal destination is
              typically located somewhere outside of the range of sensory
              perception, the animal is required to rely on the internal metric
              of space to estimate the direction and distance of the
              destination to plan a next action. Therefore, the hippocampal
              spatial map should interact with action-planning systems in other
              cortical regions. In accordance with this idea, several recent
              studies have indicated the importance of functional interactions
              between the hippocampus and the prefrontal cortex for
              goal-directed navigation. In this paper, I will review these
              studies and discuss how an animal can estimate its future
              positions correspond to a next movement. Investigation of the
              navigation problem may further provide general insights into
              internal models of the brain for action planning.",
  journal  = "Neurosci. Res.",
  volume   =  129,
  pages    = "2--7",
  month    =  apr,
  year     =  2018,
  keywords = "Hippocampus; Prefrontal cortex; Spatial navigation",
  language = "en",
  issn     = "0168-0102, 1872-8111",
  pmid     = "28476463",
  doi      = "10.1016/j.neures.2017.04.016"
}

@ARTICLE{Cholvin2013-ad,
  title    = "The ventral midline thalamus contributes to strategy shifting in
              a memory task requiring both prefrontal cortical and hippocampal
              functions",
  author   = "Cholvin, Thibault and Loureiro, Micha{\"e}l and Cassel, Raphaelle
              and Cosquer, Brigitte and Geiger, Karine and De Sa Nogueira,
              David and Raingard, H{\'e}l{\`e}ne and Robelin, Laura and Kelche,
              Christian and Pereira de Vasconcelos, Anne and Cassel,
              Jean-Christophe",
  abstract = "Electrophysiological and neuroanatomical evidence for reciprocal
              connections with the medial prefrontal cortex (mPFC) and the
              hippocampus make the reuniens and rhomboid (ReRh) thalamic nuclei
              a putatively major functional link for regulations of
              cortico-hippocampal interactions. In a first experiment using a
              new water escape device for rodents, the double-H maze, we
              demonstrated in rats that a bilateral muscimol (MSCI)
              inactivation (0.70 vs 0.26 and 0 nmol) of the mPFC or dorsal
              hippocampus (dHip) induces major deficits in a strategy
              shifting/spatial memory retrieval task. By way of comparison,
              only dHip inactivation impaired recall in a classical spatial
              memory task in the Morris water maze. In the second experiment,
              we showed that ReRh inactivation using 0.70 nmol of MSCI, which
              reduced performance without obliterating memory retrieval in the
              water maze, produces an as large strategy shifting/memory
              retrieval deficit as mPFC or dHip inactivation in the double-H
              maze. Thus, behavioral adaptations to task contingency
              modifications requiring a shift toward the use of a memory for
              place might operate in a distributed circuit encompassing the
              mPFC (as the potential set-shifting structure), the hippocampus
              (as the spatial memory substrate), and the ventral midline
              thalamus, and therein the ReRh (as the coordinator of this
              processing). The results of the current experiments provide a
              significant extension of our understanding of the involvement of
              ventral midline thalamic nuclei in cognitive processes: they
              point to a role of the ReRh in strategy shifting in a memory task
              requiring cortical and hippocampal functions and further
              elucidate the functional system underlying behavioral
              flexibility.",
  journal  = "J. Neurosci.",
  volume   =  33,
  number   =  20,
  pages    = "8772--8783",
  month    =  may,
  year     =  2013,
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "23678120",
  doi      = "10.1523/JNEUROSCI.0771-13.2013",
  pmc      = "PMC6618831"
}

@ARTICLE{Dabaghian2014-yp,
  title    = "Reconceiving the hippocampal map as a topological template",
  author   = "Dabaghian, Yuri and Brandt, Vicky L and Frank, Loren M",
  abstract = "The role of the hippocampus in spatial cognition is
              incontrovertible yet controversial. Place cells, initially
              thought to be location-specifiers, turn out to respond
              promiscuously to a wide range of stimuli. Here we test the idea,
              which we have recently demonstrated in a computational model,
              that the hippocampal place cells may ultimately be interested in
              a space's topological qualities (its connectivity) more than its
              geometry (distances and angles); such higher-order functioning
              would be more consistent with other known hippocampal functions.
              We recorded place cell activity in rats exploring morphing linear
              tracks that allowed us to dissociate the geometry of the track
              from its topology. The resulting place fields preserved the
              relative sequence of places visited along the track but did not
              vary with the metrical features of the track or the direction of
              the rat's movement. These results suggest a reinterpretation of
              previous studies and new directions for future experiments.",
  journal  = "Elife",
  volume   =  3,
  pages    = "e03476",
  month    =  aug,
  year     =  2014,
  keywords = "geometry; hippocampus; place cells; spatial learning; topology",
  language = "en",
  issn     = "2050-084X",
  pmid     = "25141375",
  doi      = "10.7554/eLife.03476",
  pmc      = "PMC4161971"
}

@ARTICLE{Ghrist2007-kx,
  title    = "Barcodes: The persistent topology of data",
  author   = "Ghrist, Robert",
  abstract = "This article surveys recent work of Carlsson and collaborators on
              applications of computational algebraic topology to problems of
              feature detection and shape recognition in high-dimensional data.
              The primary mathematical tool considered is a homology theory for
              point-cloud data sets--persistent homology--and a novel
              representation of this algebraic characterization--barcodes. We
              sketch an application of these techniques to the classification
              of natural images.",
  journal  = "Bull. Am. Math. Soc.",
  volume   =  45,
  number   =  01,
  pages    = "61--76",
  month    =  oct,
  year     =  2007,
  issn     = "0273-0979",
  doi      = "10.1090/S0273-0979-07-01191-3"
}

@ARTICLE{Cox2016-ty,
  title         = "Clique Topology Reveals Intrinsic Geometric Structure in
                   Neural Correlations: An Overview",
  author        = "Cox, David",
  abstract      = "This publication serves as an overview of clique topology --
                   a novel matrix analysis technique used to extract structural
                   features from neural activity data that contains hidden
                   nonlinearities. We highlight work done by Gusti et al. which
                   introduces clique topology and verifies its applicability to
                   neural feature extraction by showing that neural
                   correlations in the rat hippocampus are determined by
                   geometric structure of hippocampal circuits, rather than
                   being a consequence of positional coding.",
  month         =  aug,
  year          =  2016,
  archivePrefix = "arXiv",
  eprint        = "1608.03463",
  primaryClass  = "q-bio.NC",
  arxivid       = "1608.03463"
}

@ARTICLE{Giusti2016-st,
  title    = "Two's company, three (or more) is a simplex :
              Algebraic-topological tools for understanding higher-order
              structure in neural data",
  author   = "Giusti, Chad and Ghrist, Robert and Bassett, Danielle S",
  abstract = "The language of graph theory, or network science, has proven to
              be an exceptional tool for addressing myriad problems in
              neuroscience. Yet, the use of networks is predicated on a
              critical simplifying assumption: that the quintessential unit of
              interest in a brain is a dyad - two nodes (neurons or brain
              regions) connected by an edge. While rarely mentioned, this
              fundamental assumption inherently limits the types of neural
              structure and function that graphs can be used to model. Here, we
              describe a generalization of graphs that overcomes these
              limitations, thereby offering a broad range of new possibilities
              in terms of modeling and measuring neural phenomena.
              Specifically, we explore the use of simplicial complexes: a
              structure developed in the field of mathematics known as
              algebraic topology, of increasing applicability to real data due
              to a rapidly growing computational toolset. We review the
              underlying mathematical formalism as well as the budding
              literature applying simplicial complexes to neural data, from
              electrophysiological recordings in animal models to hemodynamic
              fluctuations in humans. Based on the exceptional flexibility of
              the tools and recent ground-breaking insights into neural
              function, we posit that this framework has the potential to
              eclipse graph theory in unraveling the fundamental mysteries of
              cognition.",
  journal  = "J. Comput. Neurosci.",
  volume   =  41,
  number   =  1,
  pages    = "1--14",
  month    =  aug,
  year     =  2016,
  keywords = "Filtration; Networks; Simplicial complex; Topology",
  language = "en",
  issn     = "0929-5313, 1573-6873",
  pmid     = "27287487",
  doi      = "10.1007/s10827-016-0608-6",
  pmc      = "PMC4927616"
}

@ARTICLE{Waters1937-tc,
  title     = "The Principle of Least Effort in Learning",
  author    = "Waters, R H",
  journal   = "J. Gen. Psychol.",
  publisher = "Routledge",
  volume    =  16,
  number    =  1,
  pages     = "3--20",
  month     =  jan,
  year      =  1937,
  issn      = "0022-1309",
  doi       = "10.1080/00221309.1937.9917938"
}

@ARTICLE{De_Camp1920-jm,
  title     = "Relative distance as a factor in the white rat's selection of a
               path",
  author    = "De Camp, Joseph Edgar",
  abstract  = "Elimination of errors and decrease in length of path from
               starting point to goal (usually food) are characteristic of
               animal learning. Of two paths leading to food, one being longer,
               the animal soon chooses the shorter. This has been observed with
               white rats in their learning of mazes. This article is a report
               of an attempt to study this selection by the white rat of the
               shorter of two paths.(PsycINFO Database Record (c) 2017 APA, all
               rights reserved)",
  journal   = "Psychobiology",
  publisher = "Williams \& Wilkins Company",
  volume    =  2,
  number    =  3,
  pages     = "245",
  year      =  1920,
  issn      = "0889-6313"
}

@ARTICLE{Gengerelli1930-zo,
  title     = "The principle of maxima and minima in animal learning",
  author    = "Gengerelli, J A",
  abstract  = "A series of experiments were performed with blinded and normal
               white rats to determine the nature of the path which the animals
               would eventually select from an indefinite number of possible
               paths leading to food. The animals entered by one corner of the
               platform 6 ft. by 6 ft. which was enclosed on all sides by a 5
               in. wall and covered with wire mesh. Food was placed at the
               diagonally opposite corner to the entrance corner, in a small
               food box which was outside of the platform and which the animal
               entered by means of a short alley leading to it. Both food and
               observer were invisible to the animal. It was found in
               practically all cases that the path finally chosen by the
               animals (both normal and blinded), when all possibility of
               olfactory orientation was eliminated, was the path of ``least
               effort,'' namely, the path whose distance was a minimum. In the
               experiments where there were no obstructions on the platform,
               the actual path finally chosen was the diagonal from the
               entrance corner to the food corner. The behavior of the rats can
               be most accurately described by stating that the path which the
               animals finally chose served as a limit to which they
               approximated more and more closely with each successive trail.
               (PsycINFO Database Record (c) 2016 APA, all rights reserved)",
  journal   = "J. Comp. Psychol.",
  publisher = "psycnet.apa.org",
  volume    =  11,
  number    =  2,
  pages     = "193--236",
  month     =  dec,
  year      =  1930,
  issn      = "0093-4127",
  doi       = "10.1037/h0075607"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{W_R_Boyce_Gibson1900-dh,
  title     = "The Principle of Least Action as a Psychological Principle",
  author    = "{W. R. Boyce Gibson}",
  abstract  = "Action, Leipzig, 1877. 2lMYcanique Analytique, p. 246.'In this
               respect the Principle of Least Action is found wanting;* f.
               Bartholomew Price, Infinitesimal Calculus, vol. iv., p. 150.
               4Lagrange,(UEluvres, ed. Serret, vol. i., p. 365), in a sequel
               to a paper of his Essai d'unte nouvelle methode pour determiner
               le. s maxima et les minima des formules intJgrales indefinies. 5
               H. v. Helmholtz,`` Iber die physikalische Bedentung des Princips
               der Kleinsten Wirkung,'' Journal ffir die reine und angewandte
               Mathemiatik (usually known as Crelle's …",
  journal   = "Mind",
  publisher = "[Oxford University Press, Mind Association]",
  volume    =  9,
  number    =  36,
  pages     = "469--495",
  year      =  1900,
  issn      = "0026-4423, 1460-2113"
}

@ARTICLE{Buel1935-sn,
  title     = "Differential errors in animal mazes",
  author    = "Buel, J",
  abstract  = "93 different possible factors that may determine the
               differential errors made in maze-running are drawn from a
               literature of 111 titles, and grouped under the headings:
               genetic make-up, physiological determiners, physical
               determiners, route and blind preferences, goal functions,
               emotional factors, extra-maze, pre-maze, and temporal factors,
               maze structure and pattern, general orientation, expectancy,
               organizing factors. A discussion by the author follows.
               (PsycINFO Database Record (c) 2016 APA, all rights reserved)",
  journal   = "Psychol. Bull.",
  publisher = "psycnet.apa.org",
  volume    =  32,
  number    =  1,
  pages     = "67--99",
  month     =  jan,
  year      =  1935,
  issn      = "0033-2909, 1939-1455",
  doi       = "10.1037/h0056085"
}

@ARTICLE{Harris2019-ht,
  title    = "Hierarchical organization of cortical and thalamic connectivity",
  author   = "Harris, Julie A and Mihalas, Stefan and Hirokawa, Karla E and
              Whitesell, Jennifer D and Choi, Hannah and Bernard, Amy and Bohn,
              Phillip and Caldejon, Shiella and Casal, Linzy and Cho, Andrew
              and Feiner, Aaron and Feng, David and Gaudreault, Nathalie and
              Gerfen, Charles R and Graddis, Nile and Groblewski, Peter A and
              Henry, Alex M and Ho, Anh and Howard, Robert and Knox, Joseph E
              and Kuan, Leonard and Kuang, Xiuli and Lecoq, Jerome and Lesnar,
              Phil and Li, Yaoyao and Luviano, Jennifer and McConoughey,
              Stephen and Mortrud, Marty T and Naeemi, Maitham and Ng, Lydia
              and Oh, Seung Wook and Ouellette, Benjamin and Shen, Elise and
              Sorensen, Staci A and Wakeman, Wayne and Wang, Quanxin and Wang,
              Yun and Williford, Ali and Phillips, John W and Jones, Allan R
              and Koch, Christof and Zeng, Hongkui",
  abstract = "The mammalian cortex is a laminar structure containing many areas
              and cell types that are densely interconnected in complex ways,
              and for which generalizable principles of organization remain
              mostly unknown. Here we describe a major expansion of the Allen
              Mouse Brain Connectivity Atlas resource1, involving around a
              thousand new tracer experiments in the cortex and its main
              satellite structure, the thalamus. We used Cre driver lines (mice
              expressing Cre recombinase) to comprehensively and selectively
              label brain-wide connections by layer and class of projection
              neuron. Through observations of axon termination patterns, we
              have derived a set of generalized anatomical rules to describe
              corticocortical, thalamocortical and corticothalamic projections.
              We have built a model to assign connection patterns between areas
              as either feedforward or feedback, and generated testable
              predictions of hierarchical positions for individual cortical and
              thalamic areas and for cortical network modules. Our results show
              that cell-class-specific connections are organized in a shallow
              hierarchy within the mouse corticothalamic network.",
  journal  = "Nature",
  month    =  oct,
  year     =  2019,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "31666704",
  doi      = "10.1038/s41586-019-1716-z"
}

@ARTICLE{Giusti2015-fa,
  title     = "Clique topology reveals intrinsic geometric structure in neural
               correlations",
  author    = "Giusti, Chad and Pastalkova, Eva and Curto, Carina and Itskov,
               Vladimir",
  abstract  = "Detecting meaningful structure in neural activity and
               connectivity data is challenging in the presence of hidden
               nonlinearities, where traditional eigenvalue-based methods may
               be misleading. We introduce a novel approach to matrix analysis,
               called clique topology, that extracts features of the data
               invariant under nonlinear monotone transformations. These
               features can be used to detect both random and geometric
               structure, and depend only on the relative ordering of matrix
               entries. We then analyzed the activity of pyramidal neurons in
               rat hippocampus, recorded while the animal was exploring a 2D
               environment, and confirmed that our method is able to detect
               geometric organization using only the intrinsic pattern of
               neural correlations. Remarkably, we found similar results during
               nonspatial behaviors such as wheel running and rapid eye
               movement (REM) sleep. This suggests that the geometric structure
               of correlations is shaped by the underlying hippocampal circuits
               and is not merely a consequence of position coding. We propose
               that clique topology is a powerful new tool for matrix analysis
               in biological settings, where the relationship of observed
               quantities to more meaningful variables is often nonlinear and
               unknown.",
  journal   = "Proc. Natl. Acad. Sci. U. S. A.",
  publisher = "National Acad Sciences",
  volume    =  112,
  number    =  44,
  pages     = "13455--13460",
  month     =  nov,
  year      =  2015,
  keywords  = "Betti curves; clique topology; neural coding; structure of
               neural correlation; topological data analysis",
  language  = "en",
  issn      = "0027-8424, 1091-6490",
  pmid      = "26487684",
  doi       = "10.1073/pnas.1506407112",
  pmc       = "PMC4640785"
}

@ARTICLE{Curto2008-cc,
  title     = "Cell groups reveal structure of stimulus space",
  author    = "Curto, Carina and Itskov, Vladimir",
  abstract  = "An important task of the brain is to represent the outside
               world. It is unclear how the brain may do this, however, as it
               can only rely on neural responses and has no independent access
               to external stimuli in order to ``decode'' what those responses
               mean. We investigate what can be learned about a space of
               stimuli using only the action potentials (spikes) of cells with
               stereotyped -- but unknown -- receptive fields. Using
               hippocampal place cells as a model system, we show that one can
               (1) extract global features of the environment and (2) construct
               an accurate representation of space, up to an overall scale
               factor, that can be used to track the animal's position. Unlike
               previous approaches to reconstructing position from place cell
               activity, this information is derived without knowing place
               fields or any other functions relating neural responses to
               position. We find that simply knowing which groups of cells fire
               together reveals a surprising amount of structure in the
               underlying stimulus space; this may enable the brain to
               construct its own internal representations.",
  journal   = "PLoS Comput. Biol.",
  publisher = "journals.plos.org",
  volume    =  4,
  number    =  10,
  pages     = "e1000205",
  month     =  oct,
  year      =  2008,
  language  = "en",
  issn      = "1553-734X, 1553-7358",
  pmid      = "18974826",
  doi       = "10.1371/journal.pcbi.1000205",
  pmc       = "PMC2565599"
}

@ARTICLE{Krim2016-el,
  title    = "Discovering the Whole by the Coarse: A topological paradigm for
              data analysis",
  author   = "Krim, H and Gentimis, T and Chintakunta, H",
  abstract = "The increasing interest in big data applications is ushering in a
              large effort in seeking new, efficient, and adapted data models
              to reduce complexity, while preserving maximal intrinsic
              information. Graph-based models have recently been getting a lot
              of attention on account of their intuitive and direct connection
              to the data [43]. The cost of these models, however, is to some
              extent giving up geometric insight as well as algebraic
              flexibility.",
  journal  = "IEEE Signal Process. Mag.",
  volume   =  33,
  number   =  2,
  pages    = "95--104",
  month    =  mar,
  year     =  2016,
  keywords = "Big Data;data analysis;data models;graph theory;Big Data
              application;adapted data model;graph-based model;data
              analysis;Topology;Three-dimensional displays;Data analysis;Big
              data;Time series analysis;Delays",
  doi      = "10.1109/MSP.2015.2510703"
}

@ARTICLE{Snygg1935-tx,
  title     = "Mazes in Which Rats Take the Longer Path to Food",
  author    = "Snygg, Donald",
  journal   = "J. Psychol.",
  publisher = "Routledge",
  volume    =  1,
  number    =  1,
  pages     = "153--166",
  month     =  jan,
  year      =  1935,
  issn      = "0022-3980",
  doi       = "10.1080/00223980.1935.9917250"
}

@ARTICLE{Yoshioka1928-ob,
  title     = "Pattern Versus Frequency and Recency Factors in Maze Learning: A
               Preliminary Study",
  author    = "Yoshioka, Joseph G",
  abstract  = "*Received for publication by Calvin P. Stone .of the Editorial
               Board, April 2, 1928.",
  journal   = "The Pedagogical Seminary and Journal of Genetic Psychology",
  publisher = "Routledge",
  volume    =  35,
  number    =  2,
  pages     = "193--200",
  month     =  jun,
  year      =  1928,
  issn      = "0885-6559",
  doi       = "10.1080/08856559.1928.10532152"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Yoshioka1929-bn,
  title     = "Weber's law in the discrimination of maze distance by the white
               rat",
  author    = "Yoshioka, Joseph Geno",
  abstract  = "Using the method of wrong and right cases and two specially
               constructed mazes which allowed the lengths of the alleys to be
               altered, the author attempted to determine whether Weber's Law
               holds for the discrimination of maze distance by the white
               rat.`` Maze I was so constructed that two paths visually similar
               were offered for choice. One path was 211 inches long and kept
               constant, while the other could be shortened by steps of 13
               inches. Maze II was similarly constructed, but magnified by two.
               Five short paths were used in each maze …",
  journal   = "Publ. Psychol.",
  publisher = "psycnet.apa.org",
  year      =  1929
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Snygg1936-xx,
  title     = "Maze Learning as Perception",
  author    = "Snygg, Donald",
  abstract  = "Because of the growing tendency to think of problems of
               perception and learning as identical, it seems desirable to
               examine empirically the utility of such a viewpoint. The
               systematic advantages of such a simplification of laws and
               entities are tempting; but the ultimate test of the assumption
               of likeness between learning and perception must be its
               usefulness. During a recent investigation (6) of the relative
               difficulty of various patterns of ten- section Warden multiple-U
               mazes it was found that the relative ilumber of entries into the
               …",
  journal   = "The Pedagogical Seminary and Journal of Genetic Psychology",
  publisher = "Routledge",
  volume    =  49,
  number    =  1,
  pages     = "231--239",
  month     =  sep,
  year      =  1936,
  issn      = "0885-6559",
  doi       = "10.1080/08856559.1936.10533761"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Clements1928-ph,
  title     = "The effect of time on distance discrimination in the albino rat",
  author    = "Clements, Forrest E",
  abstract  = "An asymmetrical T-shaped apparatus with paths giving a distance
               ratio of 1:10 was constructed in such a manner that the rat
               could be detained for varying lengths of time immediately after
               making a choice. One group of rats were allowed to make their
               choice of either alley and continue without delay while the
               other three groups were delayed for 30 seconds, 60 seconds, and
               120 seconds, respectively. The experiment aimed to determine if
               the time spent in running the pathway was as effective as time
               spent in waiting. Without a delay learning begins immediately
               and proceeds rapidly. But when a time interval exists between
               the moment of choice and the continuation of the path to food
               learning does not commence immediately. ``For several days each
               animal apparently learns nothing, his choice of path seeming due
               to chance. Suddenly, however, he begins to learn and from that
               point on his learning proceeds at approximately the same rate as
               that of those animals where there was no detention. The longer
               the detention the longer the initial period of no apparent
               progress. If the detention is long enough… the animals are
               probably unable ever to make the discrimination.'' The group
               which had been delayed 120 seconds ran for 25 days with no signs
               of learning to discriminate the shorter path. On the 26th day
               the detention was removed for three of these rats, whereupon
               they learned it in much shorter time than the animals with no
               detention and no previous acquaintance with the apparatus. ``The
               longer the detention the longer it takes the rat to 'get the
               idea' until, with a long enough detention, the animal's memory
               is perhaps not long enough to span the gap between turning a
               particular way and the 'realization' of the preferential
               character (shortness) of that way.'' (PsycINFO Database Record
               (c) 2017 APA, all rights reserved)",
  journal   = "J. Comp. Psychol.",
  publisher = "psycnet.apa.org",
  volume    =  8,
  number    =  4,
  pages     = "317--324",
  month     =  oct,
  year      =  1928,
  issn      = "0093-4127",
  doi       = "10.1037/h0073341"
}

@ARTICLE{Sams1925-ng,
  title     = "Time discrimination in white rats",
  author    = "Sams, C F and Tolman, E C",
  abstract  = "With two alternative paths in a maze equal in every respect
               except that the animal was detained in a detention chamber 1
               minute before being allowed to enter one alley and 6 minutes
               before allowed to enter the other alley, with the food now
               reachable by path one and now by path two, the investigators
               discovered that almost invariably the animal will learn to seek
               food through that path, the entrance to which has been delayed
               for the shorter period of time. A threshold of difference of
               delay was worked out for one animal; it was a ratio between 1:4
               and 1:5 minutes. (PsycINFO Database Record (c) 2016 APA, all
               rights reserved)",
  journal   = "J. Comp. Psychol.",
  publisher = "psycnet.apa.org",
  volume    =  5,
  number    =  3,
  pages     = "255--263",
  month     =  jun,
  year      =  1925,
  issn      = "0093-4127",
  doi       = "10.1037/h0074866"
}

@ARTICLE{Hull1932-hs,
  title     = "The goal-gradient hypothesis and maze learning",
  author    = "Hull, C L",
  abstract  = "The hypothesis, which is an extension of Hull's goal reaction
               hypothesis, is that the goal reaction gets conditioned most
               strongly to the stimuli preceding it, and the other reactions in
               the sequence get conditioned to their stimuli, with a strength
               inversely proportional to their temporal or spatial remoteness
               from the goal reaction. Since this assumes a gradient, which is
               related to the goal, he calls it a goal-gradient. The shape of
               this gradient is shown, by reference to Yoshioka's experiment in
               selection of maze pathways by the rat, to be positively
               accelerated, and to conform to the logarithmic law. The author
               deduces ten actual behavior phenomena from his principle, such
               as choice of shorter path, order of elimination of blind alleys,
               relative rates of locomotion in different parts of the maze,
               etc. (PsycINFO Database Record (c) 2016 APA, all rights
               reserved)",
  journal   = "Psychol. Rev.",
  publisher = "psycnet.apa.org",
  volume    =  39,
  number    =  1,
  pages     = "25--43",
  month     =  jan,
  year      =  1932,
  issn      = "0033-295X, 1939-1471",
  doi       = "10.1037/h0072640"
}

@BOOK{Lewin2013-rw,
  title     = "Principles of Topological Psychology",
  author    = "Lewin, Kurt",
  abstract  = "This antiquarian text contains a comprehensive treatise on
               topological psychology, being a detailed exposition of its
               principles written by Kurt Lewin. Written in clear, plain
               language and full of information fundamental to understanding
               this branch of psychology, this text will be of considerable
               utility to the student, and it would make for a great addition
               to collections of allied literature. The chapters of this book
               include: 'The Present State of Psychology', 'Formulation of Laws
               and Representations of General Situations', 'Considerations
               About Representing Life Space', 'Context and Extent of the
               Psychological Life Space', 'Causal Interconnections in
               Psychology', etcetera. We are republishing this vintage book now
               complete with a specially commissioned new biography of the
               author.",
  publisher = "Read Books Ltd",
  month     =  apr,
  year      =  2013,
  keywords  = "books",
  language  = "en",
  isbn      = "9781446547137"
}

@ARTICLE{Hull1951-zh,
  title     = "Essentials of behavior",
  author    = "Hull, Clark L",
  abstract  = "``This volume is designed to present briefly and in an
               intelligible manner the basic laws [postulates and corollaries]
               of mammalian behavior, and to serve as a useful introduction to
               the current aspects of behavior theory.'' The history of the
               present set of postulates is given in the notes. Glossary of
               symbols. 79-item bibliography. (PsycINFO Database Record (c)
               2016 APA, all rights reserved)",
  publisher = "Yale University Press Essentials of behavior.",
  volume    =  145,
  year      =  1951,
  address   = "New Haven, CT, US",
  keywords  = "books"
}

@ARTICLE{Kendler1943-np,
  title     = "The influence of a sub-goal on maze behavior",
  author    = "Kendler, H H",
  abstract  = "The writer reports an experiment designed to determine the
               effect upon learning of a simple distance discrimination of
               varying the ratio of the total distance to the final turn while
               keeping the absolute distance from starting point to goal
               constant. One group of rats was trained on a maze pattern with a
               ratio of 2.33 to the final turn, the other group being trained
               with a ratio of 1.36. The first group (ratio 2.33) took
               significantly less trials and made significantly less errors in
               reaching the criterion of learning. The author feels that the
               results may be interpreted as being in some way attributable to
               the secondary reinforcing characteristics of the final turn or
               ``sub-goal.'' (PsycINFO Database Record (c) 2016 APA, all rights
               reserved)",
  journal   = "J. Comp. Psychol.",
  publisher = "psycnet.apa.org",
  volume    =  36,
  number    =  2,
  pages     = "67--73",
  month     =  oct,
  year      =  1943,
  issn      = "0093-4127",
  doi       = "10.1037/h0060076"
}

@ARTICLE{Richards2019-sy,
  title    = "A deep learning framework for neuroscience",
  author   = "Richards, Blake A and Lillicrap, Timothy P and Beaudoin, Philippe
              and Bengio, Yoshua and Bogacz, Rafal and Christensen, Amelia and
              Clopath, Claudia and Costa, Rui Ponte and de Berker, Archy and
              Ganguli, Surya and Gillon, Colleen J and Hafner, Danijar and
              Kepecs, Adam and Kriegeskorte, Nikolaus and Latham, Peter and
              Lindsay, Grace W and Miller, Kenneth D and Naud, Richard and
              Pack, Christopher C and Poirazi, Panayiota and Roelfsema, Pieter
              and Sacramento, Jo{\~a}o and Saxe, Andrew and Scellier, Benjamin
              and Schapiro, Anna C and Senn, Walter and Wayne, Greg and Yamins,
              Daniel and Zenke, Friedemann and Zylberberg, Joel and Therien,
              Denis and Kording, Konrad P",
  abstract = "Systems neuroscience seeks explanations for how the brain
              implements a wide variety of perceptual, cognitive and motor
              tasks. Conversely, artificial intelligence attempts to design
              computational systems based on the tasks they will have to solve.
              In artificial neural networks, the three components specified by
              design are the objective functions, the learning rules and the
              architectures. With the growing success of deep learning, which
              utilizes brain-inspired architectures, these three designed
              components have increasingly become central to how we model,
              engineer and optimize complex artificial learning systems. Here
              we argue that a greater focus on these components would also
              benefit systems neuroscience. We give examples of how this
              optimization-based framework can drive theoretical and
              experimental progress in neuroscience. We contend that this
              principled perspective on systems neuroscience will help to
              generate more rapid progress.",
  journal  = "Nat. Neurosci.",
  volume   =  22,
  number   =  11,
  pages    = "1761--1770",
  month    =  nov,
  year     =  2019,
  keywords = "RNN To read;RNN",
  issn     = "1097-6256, 1546-1726",
  doi      = "10.1038/s41593-019-0520-2"
}

@ARTICLE{Hebert2019-gx,
  title    = "Inexperienced preys know when to flee or to freeze in front of a
              threat",
  author   = "H{\'e}bert, Marie and Versace, Elisabetta and Vallortigara,
              Giorgio",
  abstract = "Using appropriate antipredatory responses is crucial for
              survival. While slowing down reduces the chances of being
              detected from distant predators, fleeing away is advantageous in
              front of an approaching predator. Whether appropriate responses
              depend on experience with moving objects is still an open
              question. To clarify whether adopting appropriate fleeing or
              freezing responses requires previous experience, we investigated
              responses of chicks naive to movement. When exposed to the moving
              cues mimicking an approaching predator (a rapidly expanding,
              looming stimulus), chicks displayed a fast escape response. In
              contrast, when presented with a distal threat (a small stimulus
              sweeping overhead) they decreased their speed, a maneuver useful
              to avoid detection. The fast expansion of the stimulus toward the
              subject, rather than its size per se or change in luminance,
              triggered the escape response. These results show that young
              animals, in the absence of previous experience, can use motion
              cues to select the appropriate responses to different threats.
              The adaptive needs of young preys are thus matched by spontaneous
              defensive mechanisms that do not require learning.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  month    =  oct,
  year     =  2019,
  keywords = "antipredatory behaviors; defense strategies; motion cues; naive
              animals; threat detection",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "31659039",
  doi      = "10.1073/pnas.1915504116"
}

@ARTICLE{Shin2019-hi,
  title     = "Dynamics of Awake {Hippocampal-Prefrontal} Replay for Spatial
               Learning and {Memory-Guided} Decision Making",
  author    = "Shin, Justin D and Tang, Wenbo and Jadhav, Shantanu P",
  abstract  = "SummarySpatial learning requires remembering and choosing paths
               to goals. Hippocampal place cells replay spatial paths during
               immobility in reverse and forward order, offering a potential
               mechanism. However, how replay supports both goal-directed
               learning and memory-guided decision making is unclear. We
               therefore continuously tracked awake replay in the same
               hippocampal-prefrontal ensembles throughout learning of a
               spatial alternation task. We found that, during pauses between
               behavioral trajectories, reverse and forward hippocampal replay
               supports an internal cognitive search of available past and
               future possibilities and exhibits opposing learning gradients
               for prediction of past and future behavioral paths,
               respectively. Coordinated hippocampal-prefrontal replay
               distinguished correct past and future paths from alternative
               choices, suggesting a role in recall of past paths to guide
               planning of future decisions for spatial working memory. Our
               findings reveal a learning shift from hippocampal
               reverse-replay-based retrospective evaluation to
               forward-replay-based prospective planning, with prefrontal
               readout of memory-guided paths for learning and decision making.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  0,
  number    =  0,
  month     =  oct,
  year      =  2019,
  keywords  = "hippocampus; prefrontal cortex; replay; sharp-wave ripple;
               spatial learning; decision making; working memory; prospection;
               retrospection; planning",
  language  = "en",
  issn      = "0896-6273",
  doi       = "10.1016/j.neuron.2019.09.012"
}

@ARTICLE{Tenenbaum2000-kv,
  title    = "A global geometric framework for nonlinear dimensionality
              reduction",
  author   = "Tenenbaum, J B and de Silva, V and Langford, J C",
  abstract = "Scientists working with large volumes of high-dimensional data,
              such as global climate patterns, stellar spectra, or human gene
              distributions, regularly confront the problem of dimensionality
              reduction: finding meaningful low-dimensional structures hidden
              in their high-dimensional observations. The human brain confronts
              the same problem in everyday perception, extracting from its
              high-dimensional sensory inputs-30,000 auditory nerve fibers or
              10(6) optic nerve fibers-a manageably small number of
              perceptually relevant features. Here we describe an approach to
              solving dimensionality reduction problems that uses easily
              measured local metric information to learn the underlying global
              geometry of a data set. Unlike classical techniques such as
              principal component analysis (PCA) and multidimensional scaling
              (MDS), our approach is capable of discovering the nonlinear
              degrees of freedom that underlie complex natural observations,
              such as human handwriting or images of a face under different
              viewing conditions. In contrast to previous algorithms for
              nonlinear dimensionality reduction, ours efficiently computes a
              globally optimal solution, and, for an important class of data
              manifolds, is guaranteed to converge asymptotically to the true
              structure.",
  journal  = "Science",
  volume   =  290,
  number   =  5500,
  pages    = "2319--2323",
  month    =  dec,
  year     =  2000,
  language = "en",
  issn     = "0036-8075",
  pmid     = "11125149",
  doi      = "10.1126/science.290.5500.2319"
}

@ARTICLE{Dabaghian2012-lc,
  title    = "A topological paradigm for hippocampal spatial map formation
              using persistent homology",
  author   = "Dabaghian, Y and M{\'e}moli, F and Frank, L and Carlsson, G",
  abstract = "An animal's ability to navigate through space rests on its
              ability to create a mental map of its environment. The
              hippocampus is the brain region centrally responsible for such
              maps, and it has been assumed to encode geometric information
              (distances, angles). Given, however, that hippocampal output
              consists of patterns of spiking across many neurons, and
              downstream regions must be able to translate those patterns into
              accurate information about an animal's spatial environment, we
              hypothesized that 1) the temporal pattern of neuronal firing,
              particularly co-firing, is key to decoding spatial information,
              and 2) since co-firing implies spatial overlap of place fields, a
              map encoded by co-firing will be based on connectivity and
              adjacency, i.e., it will be a topological map. Here we test this
              topological hypothesis with a simple model of hippocampal
              activity, varying three parameters (firing rate, place field
              size, and number of neurons) in computer simulations of rat
              trajectories in three topologically and geometrically distinct
              test environments. Using a computational algorithm based on
              recently developed tools from Persistent Homology theory in the
              field of algebraic topology, we find that the patterns of
              neuronal co-firing can, in fact, convey topological information
              about the environment in a biologically realistic length of time.
              Furthermore, our simulations reveal a ``learning region'' that
              highlights the interplay between the parameters in combining to
              produce hippocampal states that are more or less adept at map
              formation. For example, within the learning region a lower number
              of neurons firing can be compensated by adjustments in firing
              rate or place field size, but beyond a certain point map
              formation begins to fail. We propose that this learning region
              provides a coherent theoretical lens through which to view
              conditions that impair spatial learning by altering place cell
              firing rates or spatial specificity.",
  journal  = "PLoS Comput. Biol.",
  volume   =  8,
  number   =  8,
  pages    = "e1002581",
  month    =  aug,
  year     =  2012,
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "22912564",
  doi      = "10.1371/journal.pcbi.1002581",
  pmc      = "PMC3415417"
}

@ARTICLE{Wilson2018-yh,
  title     = "{Three-Dimensional} Representation of Motor Space in the Mouse
               Superior Colliculus",
  author    = "Wilson, Jonathan J and Alexandre, Nicolas and Trentin, Caterina
               and Tripodi, Marco",
  abstract  = "From the act of exploring an environment to that of grasping a
               cup of tea, animals must put in register their motor acts with
               their surrounding space. In the motor domain, this is likely to
               be defined by a register of three-dimensional (3D) displacement
               vectors, whose recruitment allows motion in the direction of a
               target. One such spatially targeted action is seen in the head
               reorientation behavior of mice, yet the neural mechanisms
               underlying these 3D behaviors remain unknown. Here, by
               developing a head-mounted inertial sensor for studying 3D head
               rotations and combining it with electrophysiological recordings,
               we show that neurons in the mouse superior colliculus are either
               individually or conjunctively tuned to the three Eulerian
               components of head rotation. The average displacement vectors
               associated with motor-tuned colliculus neurons remain stable
               over time and are unaffected by changes in firing rate or the
               duration of spike trains. Finally, we show that the motor tuning
               of collicular neurons is largely independent from visual or
               landmark cues. By describing the 3D nature of motor tuning in
               the superior colliculus, we contribute to long-standing debate
               on the dimensionality of collicular motor decoding; furthermore,
               by providing an experimental paradigm for the study of the
               metric of motor tuning in mice, this study also paves the way to
               the genetic dissection of the circuits underlying spatially
               targeted motion.",
  journal   = "Curr. Biol.",
  publisher = "Elsevier",
  volume    =  28,
  number    =  11,
  pages     = "1744--1755.e12",
  month     =  jun,
  year      =  2018,
  keywords  = "3D; motor control; space encoding; superior colliculus",
  language  = "en",
  issn      = "0960-9822, 1879-0445",
  pmid      = "29779875",
  doi       = "10.1016/j.cub.2018.04.021",
  pmc       = "PMC5988568"
}

@ARTICLE{Masullo2019-mk,
  title     = "Genetically Defined Functional Modules for Spatial Orienting in
               the Mouse Superior Colliculus",
  author    = "Masullo, Laura and Mariotti, Letizia and Alexandre, Nicolas and
               Freire-Pritchett, Paula and Boulanger, Jerome and Tripodi, Marco",
  abstract  = "Summary In order to explore and interact with their
               surroundings, animals need to orient toward specific positions
               in space. Throughout the animal kingdom, head movements
               represent a primary form of orienting behavior. The superior
               colliculus (SC) is a fundamental structure for the generation of
               orienting responses, but how genetically distinct groups of
               collicular neurons contribute to these spatially tuned behaviors
               remains largely to be defined. Here, through the genetic
               dissection of the murine SC, we identify a functionally and
               genetically homogeneous subclass of glutamatergic neurons
               defined by the expression of the paired-like homeodomain
               transcription factor Pitx2. We show that the optogenetic
               stimulation of Pitx2ON neurons drives three-dimensional head
               displacements characterized by stepwise, saccade-like
               kinematics. Furthermore, during naturalistic foraging behavior,
               the activity of Pitx2ON neurons precedes and predicts the onset
               of spatially tuned head movements. Intriguingly, we reveal that
               Pitx2ON neurons are clustered in an orderly array of anatomical
               modules that tile the entire intermediate layer of the SC. Such
               a modular organization gives origin to a discrete and
               discontinuous representation of the motor space, with each
               Pitx2ON module subtending a defined portion of the animal's
               egocentric space. The modularity of Pitx2ON neurons provides an
               anatomical substrate for the convergence of spatially coherent
               sensory and motor signals of cortical and subcortical origins,
               thereby promoting the recruitment of appropriate movement
               vectors. Overall, these data support the view of the superior
               colliculus as a selectively addressable and modularly organized
               spatial-motor register.",
  journal   = "Curr. Biol.",
  publisher = "Elsevier",
  volume    =  29,
  number    =  17,
  pages     = "2892--2904.e8",
  month     =  sep,
  year      =  2019,
  keywords  = "superior colliculus; Pitx2; motor control; head movement;
               orienting behaviour",
  issn      = "0960-9822",
  doi       = "10.1016/j.cub.2019.07.083"
}

@ARTICLE{Dean1986-of,
  title    = "Head and body movements produced by electrical stimulation of
              superior colliculus in rats: effects of interruption of crossed
              tectoreticulospinal pathway",
  author   = "Dean, P and Redgrave, P and Sahibzada, N and Tsuji, K",
  abstract = "Stimulation of the superior colliculus in rats produces movements
              of the head and body that resemble either orientation and
              approach towards a contralateral stimulus, or avoidance of, or
              escape from, such a stimulus. A variety of evidence indicates
              that the crossed descending pathway, which runs in the
              contralateral predorsal bundle to the pontomedullary reticular
              formation and the spinal cord, is involved in orienting
              movements. The nature of this involvement was investigated, by
              assessing the effects on tectally-elicited movements of midbrain
              knife-cuts intended to section the pathway as it crosses midline
              in the dorsal tegmental decussation. As expected, ipsilateral
              movements resembling avoidance or escape were little affected by
              dorsal tegmental decussation section, whereas contralateral
              circling movements of the body were almost abolished. However,
              contralateral movements of the head in response to electrical
              stimulation were not eliminated, nor were orienting head
              movements to visual or tactile stimuli. There was some suggestion
              that section of the dorsal tegmental decussation increased the
              latency of head movements from electrical stimulation at lateral
              sites, and decreased the accuracy of orienting movements to
              sensory stimuli. These results support the view that the crossed
              tectoreticulospinal system is concerned with approach rather than
              avoidance movements. However, it appears that other, as yet
              unidentified, tectal efferent systems are also involved in
              orienting head movements. It is possible that this division of
              labour may reflect functional differences between various kinds
              of apparently similar orienting responses. One suggestion is that
              the tectoreticulospinal system is concerned less in open-loop
              orienting responses (that are initiated but not subsequently
              guided by sensory stimuli), than in following or pursuit
              movements.",
  journal  = "Neuroscience",
  volume   =  19,
  number   =  2,
  pages    = "367--380",
  month    =  oct,
  year     =  1986,
  language = "en",
  issn     = "0306-4522",
  pmid     = "3774146",
  doi      = "10.1016/0306-4522(86)90267-8"
}

@ARTICLE{Felsen2008-nl,
  title    = "Neural substrates of sensory-guided locomotor decisions in the
              rat superior colliculus",
  author   = "Felsen, Gidon and Mainen, Zachary F",
  abstract = "Deciding in which direction to move is a ubiquitous feature of
              animal behavior, but the neural substrates of locomotor choices
              are not well understood. The superior colliculus (SC) is a
              midbrain structure known to be important for controlling the
              direction of gaze, particularly when guided by visual or auditory
              cues, but which may play a more general role in behavior
              involving spatial orienting. To test this idea, we recorded and
              manipulated activity in the SC of freely moving rats performing
              an odor-guided spatial choice task. In this context, not only did
              a substantial majority of SC neurons encode choice direction
              during goal-directed locomotion, but many also predicted the
              upcoming choice and maintained selectivity for it after movement
              completion. Unilateral inactivation of SC activity profoundly
              altered spatial choices. These results indicate that the SC
              processes information necessary for spatial locomotion,
              suggesting a broad role for this structure in sensory-guided
              orienting and navigation.",
  journal  = "Neuron",
  volume   =  60,
  number   =  1,
  pages    = "137--148",
  month    =  oct,
  year     =  2008,
  keywords = "Locomotion",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "18940594",
  doi      = "10.1016/j.neuron.2008.09.019",
  pmc      = "PMC2612727"
}

@ARTICLE{Sooksawate2013-hx,
  title    = "Viral vector-mediated selective and reversible blockade of the
              pathway for visual orienting in mice",
  author   = "Sooksawate, Thongchai and Isa, Kaoru and Matsui, Ryosuke and
              Kato, Shigeki and Kinoshita, Masaharu and Kobayashi, Kenta and
              Watanabe, Dai and Kobayashi, Kazuto and Isa, Tadashi",
  abstract = "Recently, by using a combination of two viral vectors, we
              developed a technique for pathway-selective and reversible
              synaptic transmission blockade, and successfully induced a
              behavioral deficit of dexterous hand movements in macaque monkeys
              by affecting a population of spinal interneurons. To explore the
              capacity of this technique to work in other pathways and species,
              and to obtain fundamental methodological information, we tried to
              block the crossed tecto-reticular pathway, which is known to
              control orienting responses to visual targets, in mice. A
              neuron-specific retrograde gene transfer vector with the gene
              encoding enhanced tetanus neurotoxin (eTeNT) tagged with enhanced
              green fluorescent protein (EGFP) under the control of a
              tetracycline responsive element was injected into the left medial
              pontine reticular formation. 7-17 days later, an adeno-associated
              viral vector with a highly efficient Tet-ON sequence, rtTAV16,
              was injected into the right superior colliculus. 5-9 weeks later,
              the daily administration of doxycycline (Dox) was initiated.
              Visual orienting responses toward the left side were impaired 1-4
              days after Dox administration. Anti-GFP immunohistochemistry
              revealed that a number of neurons in the intermediate and deep
              layers of the right superior colliculus were positively stained,
              indicating eTeNT expression. After the termination of Dox
              administration, the anti-GFP staining returned to the baseline
              level within 28 days. A second round of Dox administration,
              starting from 28 days after the termination of the first Dox
              administration, resulted in the reappearance of the behavioral
              impairment. These findings showed that pathway-selective and
              reversible blockade of synaptic transmission also causes
              behavioral effects in rodents, and that the crossed
              tecto-reticular pathway clearly controls visual orienting
              behaviors.",
  journal  = "Front. Neural Circuits",
  volume   =  7,
  pages    = "162",
  month    =  oct,
  year     =  2013,
  keywords = "Tet-ON; mouse; orienting behavior; pontine reticular formation;
              superior colliculus; tetanus neurotoxin; viral vector",
  language = "en",
  issn     = "1662-5110",
  pmid     = "24130520",
  doi      = "10.3389/fncir.2013.00162",
  pmc      = "PMC3795302"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Cooper1998-ii,
  title     = "Superior colliculus and active navigation: Role of visual and
               non-visual cues in controlling cellular representations of space",
  author    = "Cooper, B G and Miya, D Y and Mizumori, S J Y",
  abstract  = "To begin investigation of the contribution of the superior
               colliculus to unrestrained navigation, the nature of behavioral
               representation by individual neurons was identified as rats
               performed a spatial memory task. Similar to what has been
               observed for hippocampus, many superior collicular cells showed
               elevated firing as animals traversed particular locations on the
               maze, and also during directional movement. However, when
               compared to hippocampal place fields, superior collicular
               location fields were found to be more broad …",
  journal   = "Hippocampus",
  publisher = "Wiley Online Library",
  volume    =  8,
  number    =  4,
  pages     = "340--372",
  year      =  1998,
  issn      = "1050-9631"
}

@ARTICLE{McNaughton2004-qd,
  title     = "A two-dimensional neuropsychology of defense: fear/anxiety and
               defensive distance",
  author    = "McNaughton, Neil and Corr, Philip J",
  abstract  = "We present in this paper a picture of the neural systems
               controlling defense that updates and simplifies Gray's
               ``Neuropsychology of Anxiety''. It is based on two behavioural
               dimensions: 'defensive distance' as defined by the Blanchards
               and 'defensive direction'. Defensive direction is a categorical
               dimension with avoidance of threat corresponding to fear and
               approach to threat corresponding to anxiety. These two
               psychological dimensions are mapped to underlying neural
               dimensions. Defensive distance is mapped to neural level, with
               the shortest defensive distances involving the lowest neural
               level (periaqueductal grey) and the largest defensive distances
               the highest neural level (prefrontal cortex). Defensive
               direction is mapped to separate parallel streams that run across
               these levels. A significant departure from prior models is the
               proposal that both fear and anxiety are represented at all
               levels. The theory is presented in a simplified form that does
               not incorporate the interactions that must occur between
               non-adjacent levels of the system. It also requires expansion to
               include the dimension of escapability of threat. Our current
               development and these proposed future extensions do not change
               the core concepts originally proposed by Gray and, we argue,
               demonstrate their enduring value.",
  journal   = "Neurosci. Biobehav. Rev.",
  publisher = "Elsevier",
  volume    =  28,
  number    =  3,
  pages     = "285--305",
  month     =  may,
  year      =  2004,
  language  = "en",
  issn      = "0149-7634",
  pmid      = "15225972",
  doi       = "10.1016/j.neubiorev.2004.03.005"
}

@ARTICLE{Kim2019-fo,
  title    = "Generation of stable heading representations in diverse visual
              scenes",
  author   = "Kim, Sung Soo and Hermundstad, Ann M and Romani, Sandro and
              Abbott, L F and Jayaraman, Vivek",
  abstract = "Many animals rely on an internal heading representation when
              navigating in varied environments1--10. How this representation
              is linked to the sensory cues that define different surroundings
              is unclear. In the fly brain, heading is represented by `compass'
              neurons that innervate a ring-shaped structure known as the
              ellipsoid body3,11,12. Each compass neuron receives inputs from
              `ring' neurons that are selective for particular visual
              features13--16; this combination provides an ideal substrate for
              the extraction of directional information from a visual scene.
              Here we combine two-photon calcium imaging and optogenetics in
              tethered flying flies with circuit modelling, and show how the
              correlated activity of compass and visual neurons drives
              plasticity17--22, which flexibly transforms two-dimensional
              visual cues into a stable heading representation. We also
              describe how this plasticity enables the fly to convert a partial
              heading representation, established from orienting within part of
              a novel setting, into a complete heading representation. Our
              results provide mechanistic insight into the memory-related
              computations that are essential for flexible navigation in varied
              surroundings.",
  journal  = "Nature",
  month    =  nov,
  year     =  2019,
  issn     = "0028-0836, 1476-4687",
  doi      = "10.1038/s41586-019-1767-1"
}

@ARTICLE{Steinmetz2019-av,
  title     = "Distributed coding of choice, action and engagement across the
               mouse brain",
  author    = "Steinmetz, Nicholas A and Zatka-Haas, Peter and Carandini,
               Matteo and Harris, Kenneth D",
  abstract  = "Vision, choice, action and behavioural engagement arise from
               neuronal activity that may be distributed across brain regions.
               Here we delineate the spatial distribution of neurons underlying
               these processes. We used Neuropixels probes1,2 to record from
               approximately 30,000 neurons in 42 brain regions of mice
               performing a visual discrimination task3. Neurons in nearly all
               regions responded non-specifically when the mouse initiated an
               action. By contrast, neurons encoding visual stimuli and
               upcoming choices occupied restricted regions in the neocortex,
               basal ganglia and midbrain. Choice signals were rare and emerged
               with indistinguishable timing across regions. Midbrain neurons
               were activated before contralateral choices and were suppressed
               before ipsilateral choices, whereas forebrain neurons could
               prefer either side. Brain-wide pre-stimulus activity predicted
               engagement in individual trials and in the overall task, with
               enhanced subcortical but suppressed neocortical activity during
               engagement. These results reveal organizing principles for the
               distribution of neurons encoding behaviourally relevant
               variables across the mouse brain.",
  journal   = "Nature",
  publisher = "Nature Publishing Group",
  pages     = "1--8",
  month     =  nov,
  year      =  2019,
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "31776518",
  doi       = "10.1038/s41586-019-1787-x"
}

@ARTICLE{Kraskov2004-de,
  title    = "Estimating mutual information",
  author   = "Kraskov, Alexander and St{\"o}gbauer, Harald and Grassberger,
              Peter",
  abstract = "We present two classes of improved estimators for mutual
              information M(X,Y), from samples of random points distributed
              according to some joint probability density mu(x,y). In contrast
              to conventional estimators based on binnings, they are based on
              entropy estimates from k -nearest neighbor distances. This means
              that they are data efficient (with k=1 we resolve structures down
              to the smallest possible scales), adaptive (the resolution is
              higher where data are more numerous), and have minimal bias.
              Indeed, the bias of the underlying entropy estimates is mainly
              due to nonuniformity of the density at the smallest resolved
              scale, giving typically systematic errors which scale as
              functions of k/N for N points. Numerically, we find that both
              families become exact for independent distributions, i.e. the
              estimator M(X,Y) vanishes (up to statistical fluctuations) if
              mu(x,y)=mu(x)mu(y). This holds for all tested marginal
              distributions and for all dimensions of x and y. In addition, we
              give estimators for redundancies between more than two random
              variables. We compare our algorithms in detail with existing
              algorithms. Finally, we demonstrate the usefulness of our
              estimators for assessing the actual independence of components
              obtained from independent component analysis (ICA), for improving
              ICA, and for estimating the reliability of blind source
              separation.",
  journal  = "Phys. Rev. E Stat. Nonlin. Soft Matter Phys.",
  volume   =  69,
  number   = "6 Pt 2",
  pages    = "066138",
  month    =  jun,
  year     =  2004,
  language = "en",
  issn     = "1539-3755",
  pmid     = "15244698",
  doi      = "10.1103/PhysRevE.69.066138"
}

@ARTICLE{Mobbs2018-li,
  title    = "Foraging for foundations in decision neuroscience: insights from
              ethology",
  author   = "Mobbs, Dean and Trimmer, Pete C and Blumstein, Daniel T and
              Dayan, Peter",
  abstract = "Modern decision neuroscience offers a powerful and broad account
              of human behaviour using computational techniques that link
              psychological and neuroscientific approaches to the ways that
              individuals can generate near-optimal choices in complex
              controlled environments. However, until recently, relatively
              little attention has been paid to the extent to which the
              structure of experimental environments relates to natural
              scenarios, and the survival problems that individuals have
              evolved to solve. This situation not only risks leaving
              decision-theoretic accounts ungrounded but also makes various
              aspects of the solutions, such as hard-wired or Pavlovian
              policies, difficult to interpret in the natural world. Here, we
              suggest importing concepts, paradigms and approaches from the
              fields of ethology and behavioural ecology, which concentrate on
              the contextual and functional correlates of decisions made about
              foraging and escape and address these lacunae.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  19,
  number   =  7,
  pages    = "419--427",
  month    =  jul,
  year     =  2018,
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "29752468",
  doi      = "10.1038/s41583-018-0010-7",
  pmc      = "PMC6786488"
}

@ARTICLE{Liang2016-po,
  title    = "Terminations of reticulospinal fibers originating from the
              gigantocellular reticular formation in the mouse spinal cord",
  author   = "Liang, Huazheng and Watson, Charles and Paxinos, George",
  abstract = "The present study investigated the projections of the
              gigantocellular reticular nucleus (Gi) and its neighbors--the
              dorsal paragigantocellular reticular nucleus (DPGi), the
              alpha/ventral part of the gigantocellular reticular nucleus
              (GiA/V), and the lateral paragigantocellular reticular nucleus
              (LPGi)--to the mouse spinal cord by injecting the anterograde
              tracer biotinylated dextran amine (BDA) into the Gi, DPGi,
              GiA/GiV, and LPGi. The Gi projected to the entire spinal cord
              bilaterally with an ipsilateral predominance. Its fibers traveled
              in both the ventral and lateral funiculi with a greater presence
              in the ventral funiculus. As the fibers descended in the spinal
              cord, their density in the lateral funiculus increased. The
              terminals were present mainly in laminae 7-10 with a dorsolateral
              expansion caudally. In the lumbar and sacral cord, a considerable
              number of terminals were also present in laminae 5 and 6.
              Contralateral fibers shared a similar pattern to their
              ipsilateral counterparts and some fibers were seen to cross the
              midline. Fibers arising from the DPGi were similarly distributed
              in the spinal cord except that there was no dorsolateral
              expansion in the lumbar and sacral segments and there were fewer
              fiber terminals. Fibers arising from GiA/V predominantly traveled
              in the ventral and lateral funiculi ipsilaterally. Ipsilaterally,
              the density of fibers in the ventral funiculus decreased along
              the rostrocaudal axis, whereas the density of fibers in the
              lateral funiculus increased. They terminate mainly in the medial
              ventral horn and lamina 10 with a smaller number of fibers in the
              dorsal horn. Fibers arising from the LPGi traveled in both the
              ventral and lateral funiculi and the density of these fibers in
              the ventral and lateral funiculi decreased dramatically in the
              lumbar and sacral segments. Their terminals were present in the
              ventral horn with a large portion of them terminating in the
              motor neuron columns. The present study is the first
              demonstration of the termination pattern of fibers arising from
              the Gi, DPGi, GiA/GiV, and LPGi in the mouse spinal cord. It
              provides an anatomical foundation for those who are conducting
              spinal cord injury and locomotion related research.",
  journal  = "Brain Struct. Funct.",
  volume   =  221,
  number   =  3,
  pages    = "1623--1633",
  month    =  apr,
  year     =  2016,
  keywords = "Blood pressure control; Gigantocellular reticular nucleus;
              Locomotion; Medullary reticulospinal tract; Paragigantocellular
              nucleus; Spinal cord",
  language = "en",
  issn     = "1863-2653, 1863-2661",
  pmid     = "25633472",
  doi      = "10.1007/s00429-015-0993-z"
}

@ARTICLE{Martin2011-fc,
  title    = "Molecular and neuroanatomical characterization of single neurons
              in the mouse medullary gigantocellular reticular nucleus",
  author   = "Martin, E M and Devidze, N and Shelley, D N and Westberg, L and
              Fontaine, C and Pfaff, D W",
  abstract = "Medullary gigantocellular reticular nucleus (mGi) neurons have
              been ascribed a variety of behaviors, many of which may fall
              under the concepts of either arousal or motivation. Despite this,
              many details of the connectivity of mGi neurons, particularly in
              reference to those neurons with ascending axons, remain unknown.
              To provide a neuroanatomical and molecular characterization of
              these cells, with reference to arousal and level-setting systems,
              large medullary reticular neurons were characterized with
              retrograde dye techniques and with real-time reverse
              transcriptase PCR (RT-PCR) analyses of single-neuron mRNA
              expression in the mouse. We have shown that receptors consistent
              with participation in generalized arousal are expressed by single
              mGi neurons and that receptors from different families of
              arousal-related neurotransmitters are rarely coexpressed. Through
              retrograde labeling, we have shown that neurons with ascending
              axons and neurons with descending axons tend to form
              like-with-like clusters, a finding that is consistent across age
              and gender. In comparing the two groups of retrogradely labeled
              neurons in neonatal animals, those neurons with axons that ascend
              to the midbrain show markers for GABAergic or coincident
              GABAergic and glutamatergic function; in contrast, approximately
              60\% of the neurons with axons that descend to the spinal cord
              are glutamatergic. We discuss the mGi's relationship to the
              voluntary and emotional motor systems and speculate that neurons
              in the mGi may represent a mammalian analogue to Mauthner cells,
              with a separation of function for neurons with ascending and
              descending axons.",
  journal  = "J. Comp. Neurol.",
  volume   =  519,
  number   =  13,
  pages    = "2574--2593",
  month    =  sep,
  year     =  2011,
  language = "en",
  issn     = "0021-9967, 1096-9861",
  pmid     = "21456014",
  doi      = "10.1002/cne.22639"
}

@ARTICLE{Yu2009-pm,
  title    = "Gaussian-process factor analysis for low-dimensional single-trial
              analysis of neural population activity",
  author   = "Yu, Byron M and Cunningham, John P and Santhanam, Gopal and Ryu,
              Stephen I and Shenoy, Krishna V and Sahani, Maneesh",
  abstract = "We consider the problem of extracting smooth, low-dimensional
              neural trajectories that summarize the activity recorded
              simultaneously from many neurons on individual experimental
              trials. Beyond the benefit of visualizing the high-dimensional,
              noisy spiking activity in a compact form, such trajectories can
              offer insight into the dynamics of the neural circuitry
              underlying the recorded activity. Current methods for extracting
              neural trajectories involve a two-stage process: the spike trains
              are first smoothed over time, then a static
              dimensionality-reduction technique is applied. We first describe
              extensions of the two-stage methods that allow the degree of
              smoothing to be chosen in a principled way and that account for
              spiking variability, which may vary both across neurons and
              across time. We then present a novel method for extracting neural
              trajectories-Gaussian-process factor analysis (GPFA)-which
              unifies the smoothing and dimensionality-reduction operations in
              a common probabilistic framework. We applied these methods to the
              activity of 61 neurons recorded simultaneously in macaque
              premotor and motor cortices during reach planning and execution.
              By adopting a goodness-of-fit metric that measures how well the
              activity of each neuron can be predicted by all other recorded
              neurons, we found that the proposed extensions improved the
              predictive ability of the two-stage methods. The predictive
              ability was further improved by going to GPFA. From the extracted
              trajectories, we directly observed a convergence in neural state
              during motor planning, an effect that was shown indirectly by
              previous studies. We then show how such methods can be a powerful
              tool for relating the spiking activity across a neural population
              to the subject's behavior on a single-trial basis. Finally, to
              assess how well the proposed methods characterize neural
              population activity when the underlying time course is known, we
              performed simulations that revealed that GPFA performed tens of
              percent better than the best two-stage method.",
  journal  = "J. Neurophysiol.",
  volume   =  102,
  number   =  1,
  pages    = "614--635",
  month    =  jul,
  year     =  2009,
  language = "en",
  issn     = "0022-3077",
  pmid     = "19357332",
  doi      = "10.1152/jn.90941.2008",
  pmc      = "PMC2712272"
}

@ARTICLE{Pandarinath2018-lc,
  title    = "Inferring single-trial neural population dynamics using
              sequential auto-encoders",
  author   = "Pandarinath, Chethan and O'Shea, Daniel J and Collins, Jasmine
              and Jozefowicz, Rafal and Stavisky, Sergey D and Kao, Jonathan C
              and Trautmann, Eric M and Kaufman, Matthew T and Ryu, Stephen I
              and Hochberg, Leigh R and Henderson, Jaimie M and Shenoy, Krishna
              V and Abbott, L F and Sussillo, David",
  abstract = "Neuroscience is experiencing a revolution in which simultaneous
              recording of thousands of neurons is revealing population
              dynamics that are not apparent from single-neuron responses. This
              structure is typically extracted from data averaged across many
              trials, but deeper understanding requires studying phenomena
              detected in single trials, which is challenging due to incomplete
              sampling of the neural population, trial-to-trial variability,
              and fluctuations in action potential timing. We introduce latent
              factor analysis via dynamical systems, a deep learning method to
              infer latent dynamics from single-trial neural spiking data. When
              applied to a variety of macaque and human motor cortical
              datasets, latent factor analysis via dynamical systems accurately
              predicts observed behavioral variables, extracts precise firing
              rate estimates of neural dynamics on single trials, infers
              perturbations to those dynamics that correlate with behavioral
              choices, and combines data from non-overlapping recording
              sessions spanning months to improve inference of underlying
              dynamics.",
  journal  = "Nat. Methods",
  volume   =  15,
  number   =  10,
  pages    = "805--815",
  month    =  oct,
  year     =  2018,
  keywords = "To Read;BCI",
  language = "en",
  issn     = "1548-7091, 1548-7105",
  pmid     = "30224673",
  doi      = "10.1038/s41592-018-0109-9",
  pmc      = "PMC6380887"
}

@ARTICLE{Comoli2012-li,
  title    = "Segregated anatomical input to sub-regions of the rodent superior
              colliculus associated with approach and defense",
  author   = "Comoli, Eliane and Das Neves Favaro, Pl{\'\i}nio and Vautrelle,
              Nicolas and Leriche, Mariana and Overton, Paul G and Redgrave,
              Peter",
  abstract = "The superior colliculus (SC) is responsible for sensorimotor
              transformations required to direct gaze toward or away from
              unexpected, biologically salient events. Significant changes in
              the external world are signaled to SC through primary
              multisensory afferents, spatially organized according to a
              retinotopic topography. For animals, where an unexpected event
              could indicate the presence of either predator or prey, early
              decisions to approach or avoid are particularly important.
              Rodents' ecology dictates predators are most often detected
              initially as movements in upper visual field (mapped in medial
              SC), while appetitive stimuli are normally found in lower visual
              field (mapped in lateral SC). Our purpose was to exploit this
              functional segregation to reveal neural sites that can bias or
              modulate initial approach or avoidance responses. Small
              injections of Fluoro-Gold were made into medial or lateral
              sub-regions of intermediate and deep layers of SC (SCm/SCl). A
              remarkable segregation of input to these two functionally defined
              areas was found. (i) There were structures that projected only to
              SCm (e.g., specific cortical areas, lateral geniculate and
              suprageniculate thalamic nuclei, ventromedial and premammillary
              hypothalamic nuclei, and several brainstem areas) or SCl (e.g.,
              primary somatosensory cortex representing upper body parts and
              vibrissae and parvicellular reticular nucleus in the brainstem).
              (ii) Other structures projected to both SCm and SCl but from
              topographically segregated populations of neurons (e.g., zona
              incerta and substantia nigra pars reticulata). (iii) There were a
              few brainstem areas in which retrogradely labeled neurons were
              spatially overlapping (e.g., pedunculopontine nucleus and locus
              coeruleus). These results indicate significantly more structures
              across the rat neuraxis are in a position to modulate defense
              responses evoked from SCm, and that neural mechanisms modulating
              SC-mediated defense or appetitive behavior are almost entirely
              segregated.",
  journal  = "Front. Neuroanat.",
  volume   =  6,
  pages    = "9",
  month    =  apr,
  year     =  2012,
  keywords = "approach; defense; segregated anatomical inputs; superior
              colliculus",
  language = "en",
  issn     = "1662-5129",
  pmid     = "22514521",
  doi      = "10.3389/fnana.2012.00009",
  pmc      = "PMC3324116"
}

@ARTICLE{Wilting2019-lp,
  title    = "25 years of criticality in neuroscience - established results,
              open controversies, novel concepts",
  author   = "Wilting, J and Priesemann, V",
  abstract = "Twenty-five years ago, Dunkelmann and Radons (1994) showed that
              neural networks can self-organize to a critical state. In models,
              the critical state offers a number of computational advantages.
              Thus this hypothesis, and in particular the experimental work by
              Beggs and Plenz (2003), has triggered an avalanche of research,
              with thousands of studies referring to it. Nonetheless,
              experimental results are still contradictory. How is it possible,
              that a hypothesis has attracted active research for decades, but
              nonetheless remains controversial? We discuss the experimental
              and conceptual controversy, and then present a parsimonious
              solution that (i) unifies the contradictory experimental results,
              (ii) avoids disadvantages of a critical state, and (iii) enables
              rapid, adaptive tuning of network properties to task
              requirements.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  58,
  pages    = "105--111",
  month    =  oct,
  year     =  2019,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "31546053",
  doi      = "10.1016/j.conb.2019.08.002"
}

@ARTICLE{Engel2019-qn,
  title    = "New perspectives on dimensionality and variability from
              large-scale cortical dynamics",
  author   = "Engel, Tatiana A and Steinmetz, Nicholas A",
  abstract = "The neocortex is a multi-scale network, with intricate local
              circuitry interwoven into a global mesh of long-range
              connections. Neural activity propagates within this network on a
              wide range of temporal and spatial scales. At the micro scale,
              neurophysiological recordings reveal coordinated dynamics in
              local neural populations, which support behaviorally relevant
              computations. At the macro scale, neuroimaging modalities measure
              global activity fluctuations organized into spatiotemporal
              patterns across the entire brain. Here we review recent advances
              linking the local and global scales of cortical dynamics and
              their relationship to behavior. We argue that diverse
              experimental observations on the dimensionality and variability
              of neural activity can be reconciled by considering how activity
              propagates in space and time on multiple spatial scales.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  58,
  pages    = "181--190",
  month    =  oct,
  year     =  2019,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "31585331",
  doi      = "10.1016/j.conb.2019.09.003",
  pmc      = "PMC6859189"
}

@ARTICLE{Kao2019-wk,
  title    = "Neuroscience out of control: control-theoretic perspectives on
              neural circuit dynamics",
  author   = "Kao, Ta-Chu and Hennequin, Guillaume",
  abstract = "A major challenge in systems neuroscience is to understand how
              the dynamics of neural circuits give rise to behaviour. Analysis
              of complex dynamical systems is also at the heart of control
              engineering, where it is central to the design of robust control
              strategies. Although a rich engineering literature has grown over
              decades to facilitate the analysis of such systems, little of it
              has percolated into neuroscience so far. Here, we give a brief
              introduction to a number of core control-theoretic concepts that
              provide useful perspectives on neural circuit dynamics. We
              introduce important mathematical tools related to these concepts,
              and establish connections to neural circuit analysis, focusing on
              a number of themes that have arisen from the modern 'state-space'
              view on neural population dynamics.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  58,
  pages    = "122--129",
  month    =  oct,
  year     =  2019,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "31563084",
  doi      = "10.1016/j.conb.2019.09.001"
}

@ARTICLE{Sharpee2019-zx,
  title    = "An argument for hyperbolic geometry in neural circuits",
  author   = "Sharpee, Tatyana O",
  abstract = "This review connects several lines of research to argue that
              hyperbolic geometry should be broadly applicable to neural
              circuits as well as other biological circuits. The reason for
              this is that networks that conform to hyperbolic geometry are
              maximally responsive to external and internal perturbations.
              These networks also allow for efficient communication under
              conditions where nodes are added or removed. We will argue that
              one of the signatures of hyperbolic geometry is the celebrated
              Zipf's law (also sometimes known as the Pareto distribution) that
              states that the probability to observe a given pattern is
              inversely related to its rank. Zipf's law is observed in a
              variety of biological systems - from protein sequences, neural
              networks to economics. These observations provide further
              evidence for the ubiquity of networks with an underlying
              hyperbolic metric structure. Recent studies in neuroscience
              specifically point to the relevance of a three-dimensional
              hyperbolic space for neural signaling. The three-dimensional
              hyperbolic space may confer additional robustness compared to
              other dimensions. We illustrate how the use of hyperbolic
              coordinates revealed a novel topographic organization within the
              olfactory system. The use of such coordinates may facilitate
              representation of relevant signals elsewhere in the brain.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  58,
  pages    = "101--104",
  month    =  oct,
  year     =  2019,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "31476550",
  doi      = "10.1016/j.conb.2019.07.008"
}

@ARTICLE{Whiteway2019-fp,
  title    = "The quest for interpretable models of neural population activity",
  author   = "Whiteway, Matthew R and Butts, Daniel A",
  abstract = "Many aspects of brain function arise from the coordinated
              activity of large populations of neurons. Recent developments in
              neural recording technologies are providing unprecedented access
              to the activity of such populations during increasingly complex
              experimental contexts; however, extracting scientific insights
              from such recordings requires the concurrent development of
              analytical tools that relate this population activity to
              system-level function. This is a primary motivation for latent
              variable models, which seek to provide a low-dimensional
              description of population activity that can be related to
              experimentally controlled variables, as well as uncontrolled
              variables such as internal states (e.g. attention and arousal)
              and elements of behavior. While deriving an understanding of
              function from traditional latent variable methods relies on
              low-dimensional visualizations, new approaches are targeting more
              interpretable descriptions of the components underlying
              system-level function.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  58,
  pages    = "86--93",
  month    =  oct,
  year     =  2019,
  keywords = "to\_read\_for\_review",
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "31426024",
  doi      = "10.1016/j.conb.2019.07.004"
}

@ARTICLE{Curto2019-ar,
  title    = "Relating network connectivity to dynamics: opportunities and
              challenges for theoretical neuroscience",
  author   = "Curto, Carina and Morrison, Katherine",
  abstract = "We review recent work relating network connectivity to the
              dynamics of neural activity. While concepts stemming from network
              science provide a valuable starting point, the interpretation of
              graph-theoretic structures and measures can be highly dependent
              on the dynamics associated to the network. Properties that are
              quite meaningful for linear dynamics, such as random walk and
              network flow models, may be of limited relevance in the
              neuroscience setting. Theoretical and computational neuroscience
              are playing a vital role in understanding the relationship
              between network connectivity and the nonlinear dynamics
              associated to neural networks.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  58,
  pages    = "11--20",
  month    =  oct,
  year     =  2019,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "31319287",
  doi      = "10.1016/j.conb.2019.06.003",
  pmc      = "PMC6859200"
}

@ARTICLE{Bassett2017-qa,
  title    = "Network neuroscience",
  author   = "Bassett, Danielle S and Sporns, Olaf",
  abstract = "Despite substantial recent progress, our understanding of the
              principles and mechanisms underlying complex brain function and
              cognition remains incomplete. Network neuroscience proposes to
              tackle these enduring challenges. Approaching brain structure and
              function from an explicitly integrative perspective, network
              neuroscience pursues new ways to map, record, analyze and model
              the elements and interactions of neurobiological systems. Two
              parallel trends drive the approach: the availability of new
              empirical tools to create comprehensive maps and record dynamic
              patterns among molecules, neurons, brain areas and social
              systems; and the theoretical framework and computational tools of
              modern network science. The convergence of empirical and
              computational advances opens new frontiers of scientific inquiry,
              including network dynamics, manipulation and control of brain
              networks, and integration of network processes across
              spatiotemporal domains. We review emerging trends in network
              neuroscience and attempt to chart a path toward a better
              understanding of the brain as a multiscale networked system.",
  journal  = "Nat. Neurosci.",
  volume   =  20,
  number   =  3,
  pages    = "353--364",
  month    =  feb,
  year     =  2017,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "28230844",
  doi      = "10.1038/nn.4502",
  pmc      = "PMC5485642"
}

@ARTICLE{Cunningham2014-aw,
  title    = "Dimensionality reduction for large-scale neural recordings",
  author   = "Cunningham, John P and Yu, Byron M",
  abstract = "Most sensory, cognitive and motor functions depend on the
              interactions of many neurons. In recent years, there has been
              rapid development and increasing use of technologies for
              recording from large numbers of neurons, either sequentially or
              simultaneously. A key question is what scientific insight can be
              gained by studying a population of recorded neurons beyond
              studying each neuron individually. Here, we examine three
              important motivations for population studies: single-trial
              hypotheses requiring statistical power, hypotheses of population
              response structure and exploratory analyses of large data sets.
              Many recent studies have adopted dimensionality reduction to
              analyze these populations and to find features that are not
              apparent at the level of individual neurons. We describe the
              dimensionality reduction methods commonly applied to population
              activity and offer practical advice about selecting methods and
              interpreting their outputs. This review is intended for
              experimental and computational researchers who seek to understand
              the role dimensionality reduction has had and can have in systems
              neuroscience, and who seek to apply these methods to their own
              data.",
  journal  = "Nat. Neurosci.",
  volume   =  17,
  number   =  11,
  pages    = "1500--1509",
  month    =  nov,
  year     =  2014,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "25151264",
  doi      = "10.1038/nn.3776",
  pmc      = "PMC4433019"
}

@ARTICLE{Economo2018-pj,
  title    = "Distinct descending motor cortex pathways and their roles in
              movement",
  author   = "Economo, Michael N and Viswanathan, Sarada and Tasic, Bosiljka
              and Bas, Erhan and Winnubst, Johan and Menon, Vilas and Graybuck,
              Lucas T and Nguyen, Thuc Nghi and Smith, Kimberly A and Yao,
              Zizhen and Wang, Lihua and Gerfen, Charles R and Chandrashekar,
              Jayaram and Zeng, Hongkui and Looger, Loren L and Svoboda, Karel",
  abstract = "Activity in the motor cortex predicts movements, seconds before
              they are initiated. This preparatory activity has been observed
              across cortical layers, including in descending pyramidal tract
              neurons in layer 5. A key question is how preparatory activity is
              maintained without causing movement, and is ultimately converted
              to a motor command to trigger appropriate movements. Here, using
              single-cell transcriptional profiling and axonal reconstructions,
              we identify two types of pyramidal tract neuron. Both types
              project to several targets in the basal ganglia and brainstem.
              One type projects to thalamic regions that connect back to motor
              cortex; populations of these neurons produced early preparatory
              activity that persisted until the movement was initiated. The
              second type projects to motor centres in the medulla and mainly
              produced late preparatory activity and motor commands. These
              results indicate that two types of motor cortex output neurons
              have specialized roles in motor control.",
  journal  = "Nature",
  volume   =  563,
  number   =  7729,
  pages    = "79--84",
  month    =  nov,
  year     =  2018,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "30382200",
  doi      = "10.1038/s41586-018-0642-9"
}

@ARTICLE{Wang2020-ee,
  title    = "Egocentric and allocentric representations of space in the rodent
              brain",
  author   = "Wang, Cheng and Chen, Xiaojing and Knierim, James J",
  abstract = "Spatial signals are prevalent within the hippocampus and its
              neighboring regions. It is generally accepted that these signals
              are defined with respect to the external world (i.e., a
              world-centered, or allocentric, frame of reference). Recently,
              evidence of egocentric processing (i.e., self-centered, defined
              relative to the subject) in the extended hippocampal system has
              accumulated. These results support the idea that egocentric
              sensory information, derived from primary sensory cortical areas,
              may be transformed to allocentric representations that interact
              with the allocentric hippocampal system. We propose a framework
              to explain the implications of the egocentric-allocentric
              transformations to the functions of the medial temporal lobe
              memory system.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  60,
  pages    = "12--20",
  month    =  feb,
  year     =  2020,
  issn     = "0959-4388",
  doi      = "10.1016/j.conb.2019.11.005"
}

@ARTICLE{Osten2013-ze,
  title    = "Mapping brain circuitry with a light microscope",
  author   = "Osten, Pavel and Margrie, Troy W",
  abstract = "The beginning of the 21st century has seen a renaissance in light
              microscopy and anatomical tract tracing that together are rapidly
              advancing our understanding of the form and function of neuronal
              circuits. The introduction of instruments for automated imaging
              of whole mouse brains, new cell type--specific and trans-synaptic
              tracers, and computational methods for handling the whole-brain
              data sets has opened the door to neuroanatomical studies at an
              unprecedented scale. We present an overview of the present state
              and future opportunities in charting long-range and local
              connectivity in the entire mouse brain and in linking brain
              circuits to function.",
  journal  = "Nat. Methods",
  volume   =  10,
  number   =  6,
  pages    = "515--523",
  month    =  jun,
  year     =  2013,
  language = "en",
  issn     = "1548-7091, 1548-7105",
  pmid     = "23722211",
  doi      = "10.1038/nmeth.2477",
  pmc      = "PMC3982327"
}

@ARTICLE{Lein2007-di,
  title     = "Genome-wide atlas of gene expression in the adult mouse brain",
  author    = "Lein, Ed S and Hawrylycz, Michael J and Ao, Nancy and Ayres,
               Mikael and Bensinger, Amy and Bernard, Amy and Boe, Andrew F and
               Boguski, Mark S and Brockway, Kevin S and Byrnes, Emi J and
               Chen, Lin and Chen, Li and Chen, Tsuey-Ming and Chin, Mei Chi
               and Chong, Jimmy and Crook, Brian E and Czaplinska, Aneta and
               Dang, Chinh N and Datta, Suvro and Dee, Nick R and Desaki, Aimee
               L and Desta, Tsega and Diep, Ellen and Dolbeare, Tim A and
               Donelan, Matthew J and Dong, Hong-Wei and Dougherty, Jennifer G
               and Duncan, Ben J and Ebbert, Amanda J and Eichele, Gregor and
               Estin, Lili K and Faber, Casey and Facer, Benjamin A and Fields,
               Rick and Fischer, Shanna R and Fliss, Tim P and Frensley, Cliff
               and Gates, Sabrina N and Glattfelder, Katie J and Halverson,
               Kevin R and Hart, Matthew R and Hohmann, John G and Howell,
               Maureen P and Jeung, Darren P and Johnson, Rebecca A and Karr,
               Patrick T and Kawal, Reena and Kidney, Jolene M and Knapik,
               Rachel H and Kuan, Chihchau L and Lake, James H and Laramee,
               Annabel R and Larsen, Kirk D and Lau, Christopher and Lemon,
               Tracy A and Liang, Agnes J and Liu, Ying and Luong, Lon T and
               Michaels, Jesse and Morgan, Judith J and Morgan, Rebecca J and
               Mortrud, Marty T and Mosqueda, Nerick F and Ng, Lydia L and Ng,
               Randy and Orta, Geralyn J and Overly, Caroline C and Pak, Tu H
               and Parry, Sheana E and Pathak, Sayan D and Pearson, Owen C and
               Puchalski, Ralph B and Riley, Zackery L and Rockett, Hannah R
               and Rowland, Stephen A and Royall, Joshua J and Ruiz, Marcos J
               and Sarno, Nadia R and Schaffnit, Katherine and Shapovalova,
               Nadiya V and Sivisay, Taz and Slaughterbeck, Clifford R and
               Smith, Simon C and Smith, Kimberly A and Smith, Bryan I and
               Sodt, Andy J and Stewart, Nick N and Stumpf, Kenda-Ruth and
               Sunkin, Susan M and Sutram, Madhavi and Tam, Angelene and
               Teemer, Carey D and Thaller, Christina and Thompson, Carol L and
               Varnam, Lee R and Visel, Axel and Whitlock, Ray M and Wohnoutka,
               Paul E and Wolkey, Crissa K and Wong, Victoria Y and Wood,
               Matthew and Yaylaoglu, Murat B and Young, Rob C and Youngstrom,
               Brian L and Yuan, Xu Feng and Zhang, Bin and Zwingman, Theresa A
               and Jones, Allan R",
  abstract  = "Molecular approaches to understanding the functional circuitry
               of the nervous system promise new insights into the relationship
               between genes, brain and behaviour. The cellular diversity of
               the brain necessitates a cellular resolution approach towards
               understanding the functional genomics of the nervous system. We
               describe here an anatomically comprehensive digital atlas
               containing the expression patterns of approximately 20,000 genes
               in the adult mouse brain. Data were generated using automated
               high-throughput procedures for in situ hybridization and data
               acquisition, and are publicly accessible online. Newly developed
               image-based informatics tools allow global genome-scale
               structural analysis and cross-correlation, as well as
               identification of regionally enriched genes. Unbiased
               fine-resolution analysis has identified highly specific cellular
               markers as well as extensive evidence of cellular heterogeneity
               not evident in classical neuroanatomical atlases. This highly
               standardized atlas provides an open, primary data resource for a
               wide variety of further studies concerning brain organization
               and function.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  445,
  number    =  7124,
  pages     = "168--176",
  month     =  jan,
  year      =  2007,
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "17151600",
  doi       = "10.1038/nature05453"
}

@ARTICLE{Sunkin2013-ap,
  title     = "Allen Brain Atlas: an integrated spatio-temporal portal for
               exploring the central nervous system",
  author    = "Sunkin, Susan M and Ng, Lydia and Lau, Chris and Dolbeare, Tim
               and Gilbert, Terri L and Thompson, Carol L and Hawrylycz,
               Michael and Dang, Chinh",
  abstract  = "The Allen Brain Atlas (http://www.brain-map.org) provides a
               unique online public resource integrating extensive gene
               expression data, connectivity data and neuroanatomical
               information with powerful search and viewing tools for the adult
               and developing brain in mouse, human and non-human primate.
               Here, we review the resources available at the Allen Brain
               Atlas, describing each product and data type [such as in situ
               hybridization (ISH) and supporting histology, microarray, RNA
               sequencing, reference atlases, projection mapping and magnetic
               resonance imaging]. In addition, standardized and unique
               features in the web applications are described that enable users
               to search and mine the various data sets. Features include both
               simple and sophisticated methods for gene searches, colorimetric
               and fluorescent ISH image viewers, graphical displays of ISH,
               microarray and RNA sequencing data, Brain Explorer software for
               3D navigation of anatomy and gene expression, and an interactive
               reference atlas viewer. In addition, cross data set searches
               enable users to query multiple Allen Brain Atlas data sets
               simultaneously. All of the Allen Brain Atlas resources can be
               accessed through the Allen Brain Atlas data portal.",
  journal   = "Nucleic Acids Res.",
  publisher = "academic.oup.com",
  volume    =  41,
  number    = "Database issue",
  pages     = "D996--D1008",
  month     =  jan,
  year      =  2013,
  language  = "en",
  issn      = "0305-1048, 1362-4962",
  pmid      = "23193282",
  doi       = "10.1093/nar/gks1042",
  pmc       = "PMC3531093"
}

@ARTICLE{Kuan2015-mt,
  title     = "Neuroinformatics of the Allen Mouse Brain Connectivity Atlas",
  author    = "Kuan, Leonard and Li, Yang and Lau, Chris and Feng, David and
               Bernard, Amy and Sunkin, Susan M and Zeng, Hongkui and Dang,
               Chinh and Hawrylycz, Michael and Ng, Lydia",
  abstract  = "The Allen Mouse Brain Connectivity Atlas is a mesoscale whole
               brain axonal projection atlas of the C57Bl/6J mouse brain.
               Anatomical trajectories throughout the brain were mapped into a
               common 3D space using a standardized platform to generate a
               comprehensive and quantitative database of inter-areal and
               cell-type-specific projections. This connectivity atlas has
               several desirable features, including brain-wide coverage,
               validated and versatile experimental techniques, a single
               standardized data format, a quantifiable and integrated
               neuroinformatics resource, and an open-access public online
               database (http://connectivity.brain-map.org/). Meaningful
               informatics data quantification and comparison is key to
               effective use and interpretation of connectome data. This relies
               on successful definition of a high fidelity atlas template and
               framework, mapping precision of raw data sets into the 3D
               reference framework, accurate signal detection and quantitative
               connection strength algorithms, and effective presentation in an
               integrated online application. Here we describe key informatics
               pipeline steps in the creation of the Allen Mouse Brain
               Connectivity Atlas and include basic application use cases.",
  journal   = "Methods",
  publisher = "Elsevier",
  volume    =  73,
  pages     = "4--17",
  month     =  feb,
  year      =  2015,
  keywords  = "Digital atlas; Image registration; Mouse connectivity atlas;
               Neuronal projection; Signal detection",
  language  = "en",
  issn      = "1046-2023, 1095-9130",
  pmid      = "25536338",
  doi       = "10.1016/j.ymeth.2014.12.013"
}

@ARTICLE{Ragan2012-yo,
  title     = "Serial two-photon tomography for automated ex vivo mouse brain
               imaging",
  author    = "Ragan, Timothy and Kadiri, Lolahon R and Venkataraju, Kannan
               Umadevi and Bahlmann, Karsten and Sutin, Jason and Taranda,
               Julian and Arganda-Carreras, Ignacio and Kim, Yongsoo and Seung,
               H Sebastian and Osten, Pavel",
  abstract  = "Here we describe an automated method, named serial two-photon
               (STP) tomography, that achieves high-throughput fluorescence
               imaging of mouse brains by integrating two-photon microscopy and
               tissue sectioning. STP tomography generates high-resolution
               datasets that are free of distortions and can be readily warped
               in three dimensions, for example, for comparing multiple
               anatomical tracings. This method opens the door to routine
               systematic studies of neuroanatomy in mouse models of human
               brain disorders.",
  journal   = "Nat. Methods",
  publisher = "nature.com",
  volume    =  9,
  number    =  3,
  pages     = "255--258",
  month     =  jan,
  year      =  2012,
  language  = "en",
  issn      = "1548-7091, 1548-7105",
  pmid      = "22245809",
  doi       = "10.1038/nmeth.1854",
  pmc       = "PMC3297424"
}

@ARTICLE{Winnubst2019-eo,
  title    = "Reconstruction of 1,000 Projection Neurons Reveals New Cell Types
              and Organization of {Long-Range} Connectivity in the Mouse Brain",
  author   = "Winnubst, Johan and Bas, Erhan and Ferreira, Tiago A and Wu,
              Zhuhao and Economo, Michael N and Edson, Patrick and Arthur, Ben
              J and Bruns, Christopher and Rokicki, Konrad and Schauder, David
              and Olbris, Donald J and Murphy, Sean D and Ackerman, David G and
              Arshadi, Cameron and Baldwin, Perry and Blake, Regina and
              Elsayed, Ahmad and Hasan, Mashtura and Ramirez, Daniel and Dos
              Santos, Bruno and Weldon, Monet and Zafar, Amina and Dudman,
              Joshua T and Gerfen, Charles R and Hantman, Adam W and Korff,
              Wyatt and Sternson, Scott M and Spruston, Nelson and Svoboda,
              Karel and Chandrashekar, Jayaram",
  abstract = "Neuronal cell types are the nodes of neural circuits that
              determine the flow of information within the brain. Neuronal
              morphology, especially the shape of the axonal arbor, provides an
              essential descriptor of cell type and reveals how individual
              neurons route their output across the brain. Despite the
              importance of morphology, few projection neurons in the mouse
              brain have been reconstructed in their entirety. Here we present
              a robust and efficient platform for imaging and reconstructing
              complete neuronal morphologies, including axonal arbors that span
              substantial portions of the brain. We used this platform to
              reconstruct more than 1,000 projection neurons in the motor
              cortex, thalamus, subiculum, and hypothalamus. Together, the
              reconstructed neurons constitute more than 85 meters of axonal
              length and are available in a searchable online database. Axonal
              shapes revealed previously unknown subtypes of projection neurons
              and suggest organizational principles of long-range connectivity.",
  journal  = "Cell",
  volume   =  179,
  number   =  1,
  pages    = "268--281.e13",
  month    =  sep,
  year     =  2019,
  keywords = "automated reconstruction; axonal morphology; long-range
              projections; morphology database; neuronal cell types; neuronal
              connectivity; projection neurons; single-cell reconstruction;
              whole brain",
  language = "en",
  issn     = "0092-8674, 1097-4172",
  pmid     = "31495573",
  doi      = "10.1016/j.cell.2019.07.042",
  pmc      = "PMC6754285"
}

@ARTICLE{Hoy2019-jh,
  title    = "Defined Cell Types in Superior Colliculus Make Distinct
              Contributions to Prey Capture Behavior in the Mouse",
  author   = "Hoy, Jennifer L and Bishop, Hannah I and Niell, Cristopher M",
  abstract = "The superior colliculus (SC) plays a highly conserved role in
              visual processing and mediates visual orienting behaviors across
              species, including both overt motor orienting [1, 2] and
              orienting of attention [3, 4]. To determine the specific circuits
              within the superficial superior colliculus (sSC) that drive
              orienting and approach behavior toward appetitive stimuli, we
              explored the role of three genetically defined cell types in
              mediating prey capture in mice. Chemogenetic inactivation of two
              classically defined cell types, the wide-field (WF) and
              narrow-field (NF) vertical neurons, revealed that they are
              involved in distinct aspects of prey capture. WF neurons were
              required for rapid prey detection and distant approach
              initiation, whereas NF neurons were required for accurate
              orienting during pursuit as well as approach initiation and
              continuity. In contrast, prey capture did not require
              parvalbumin-expressing (PV) neurons that have previously been
              implicated in fear responses. The visual coding and projection
              targets of WF and NF cells were consistent with their roles in
              prey detection versus pursuit, respectively. Thus, our studies
              link specific neural circuit connectivity and function with
              stimulus detection and orienting behavior, providing insight into
              visuomotor and attentional mechanisms mediated by superior
              colliculus.",
  journal  = "Curr. Biol.",
  month    =  nov,
  year     =  2019,
  keywords = "mouse vision; prey capture; receptive fields; superior colliculus",
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "31761701",
  doi      = "10.1016/j.cub.2019.10.017"
}

@UNPUBLISHED{Plitt2019-hy,
  title    = "Experience dependent contextual codes in the hippocampus",
  author   = "Plitt, Mark H and Giocomo, Lisa M",
  abstract = "The hippocampus is a medial temporal lobe brain structure that
              contains circuitry and neural representations capable of
              supporting declarative memory. Hippocampal place cells fire in
              one or few restricted spatial locations in a given environment.
              Between environmental contexts, place cell firing fields remap
              (turning on/off or moving to a new spatial location), providing a
              unique population-wide neural code for context specificity.
              However, the manner by which features associated with a given
              context combine to drive place cell remapping remains a matter of
              debate. Here we show that remapping of neural representations in
              region CA1 of the hippocampus is strongly driven by prior beliefs
              about the frequency of certain contexts, and that remapping is
              equivalent to an optimal estimate of the identity of the current
              context under that prior. This prior-driven remapping is learned
              early in training and remains robust to changes in behavioral
              task-demands. Furthermore, a simple associative learning
              mechanism is sufficient to reproduce these results. Our findings
              demonstrate that place cell remapping is a generalization of
              representing an animal9s location. Rather than simply
              representing location in physical space, the hippocampus
              represents an optimal estimate of location in a multi-dimensional
              stimulus space.",
  journal  = "bioRxiv",
  pages    = "864090",
  month    =  dec,
  year     =  2019,
  language = "en",
  doi      = "10.1101/864090"
}

@ARTICLE{Jude2020-mq,
  title         = "Hippocampal representations emerge when training recurrent
                   neural networks on a memory dependent maze navigation task",
  author        = "Jude, Justin and Hennig, Matthias H",
  abstract      = "Can neural networks learn goal-directed behaviour using
                   similar strategies to the brain, by combining the
                   relationships between the current state of the organism and
                   the consequences of future actions? Recent work has shown
                   that recurrent neural networks trained on goal based tasks
                   can develop representations resembling those found in the
                   brain, entorhinal cortex grid cells, for instance. Here we
                   explore the evolution of the dynamics of their internal
                   representations and compare this with experimental data. We
                   observe that once a recurrent network is trained to learn
                   the structure of its environment solely based on sensory
                   prediction, an attractor based landscape forms in the
                   network's representation, which parallels hippocampal place
                   cells in structure and function. Next, we extend the
                   predictive objective to include Q-learning for a reward
                   task, where rewarding actions are dependent on delayed cue
                   modulation. Mirroring experimental findings in hippocampus
                   recordings in rodents performing the same task, this
                   training paradigm causes nonlocal neural activity to sweep
                   forward in space at decision points, anticipating the future
                   path to a rewarded location. Moreover, prevalent choice and
                   cue-selective neurons form in this network, again
                   recapitulating experimental findings. Together, these
                   results indicate that combining predictive, unsupervised
                   learning of the structure of an environment with
                   reinforcement learning can help understand the formation of
                   hippocampus-like representations containing both spatial and
                   task-relevant information.",
  month         =  dec,
  year          =  2020,
  keywords      = "RNN;RNN To read",
  archivePrefix = "arXiv",
  eprint        = "2012.01328",
  primaryClass  = "q-bio.NC",
  arxivid       = "2012.01328"
}

@ARTICLE{Fieseler2020-ne,
  title         = "Unsupervised learning of control signals and their encodings
                   in $\textit{C. elegans}$ whole-brain recordings",
  author        = "Fieseler, Charles and Zimmer, Manuel and Nathan Kutz, J",
  abstract      = "Recent whole brain imaging experiments on $\textit\{C.
                   elegans\}$ has revealed that the neural population dynamics
                   encode motor commands and stereotyped transitions between
                   behaviors on low dimensional manifolds. Efforts to
                   characterize the dynamics on this manifold have used
                   piecewise linear models to describe the entire state space,
                   but it is unknown how a single, global dynamical model can
                   generate the observed dynamics. Here, we propose a control
                   framework to achieve such a global model of the dynamics,
                   whereby underlying linear dynamics is actuated by sparse
                   control signals. This method learns the control signals in
                   an unsupervised way from data, then uses $\textit\{ Dynamic
                   Mode Decomposition with control\}$ (DMDc) to create the
                   first global, linear dynamical system that can reconstruct
                   whole-brain imaging data. These control signals are shown to
                   be implicated in transitions between behaviors. In addition,
                   we analyze the time-delay encoding of these control signals,
                   showing that these transitions can be predicted from neurons
                   previously implicated in behavioral transitions, but also
                   additional neurons previously unidentified. Moreover, our
                   decomposition method allows one to understand the observed
                   nonlinear global dynamics instead as linear dynamics with
                   control. The proposed mathematical framework is generic and
                   can be generalized to other neurosensory systems,
                   potentially revealing transitions and their encodings in a
                   completely unsupervised way.",
  month         =  jan,
  year          =  2020,
  archivePrefix = "arXiv",
  eprint        = "2001.08346",
  primaryClass  = "q-bio.QM",
  arxivid       = "2001.08346"
}

@ARTICLE{Stone2017-ix,
  title    = "An Anatomically Constrained Model for Path Integration in the Bee
              Brain",
  author   = "Stone, Thomas and Webb, Barbara and Adden, Andrea and Weddig,
              Nicolai Ben and Honkanen, Anna and Templin, Rachel and Wcislo,
              William and Scimeca, Luca and Warrant, Eric and Heinze, Stanley",
  abstract = "Path integration is a widespread navigational strategy in which
              directional changes and distance covered are continuously
              integrated on an outward journey, enabling a straight-line return
              to home. Bees use vision for this task-a celestial-cue-based
              visual compass and an optic-flow-based visual odometer-but the
              underlying neural integration mechanisms are unknown. Using
              intracellular electrophysiology, we show that
              polarized-light-based compass neurons and optic-flow-based
              speed-encoding neurons converge in the central complex of the bee
              brain, and through block-face electron microscopy, we identify
              potential integrator cells. Based on plausible output targets for
              these cells, we propose a complete circuit for path integration
              and steering in the central complex, with anatomically identified
              neurons suggested for each processing step. The resulting model
              circuit is thus fully constrained biologically and provides a
              functional interpretation for many previously unexplained
              architectural features of the central complex. Moreover, we show
              that the receptive fields of the newly discovered speed neurons
              can support path integration for the holonomic motion (i.e., a
              ground velocity that is not precisely aligned with body
              orientation) typical of bee flight, a feature not captured in any
              previously proposed model of path integration. In a broader
              context, the model circuit presented provides a general mechanism
              for producing steering signals by comparing current and desired
              headings-suggesting a more basic function for central complex
              connectivity, from which path integration may have evolved.",
  journal  = "Curr. Biol.",
  volume   =  27,
  number   =  20,
  pages    = "3069--3085.e11",
  month    =  oct,
  year     =  2017,
  keywords = "central complex; circuit modeling; compass orientation; insect
              brain; navigation; neuroanatomy; optic flow; path integration;
              polarized light; robotics",
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "28988858",
  doi      = "10.1016/j.cub.2017.08.052",
  pmc      = "PMC6196076"
}

@ARTICLE{Perry2016-px,
  title    = "Deciphering the Locomotor Network : The Role of Spinal Cord
              Interneurons",
  author   = "Perry, S",
  abstract = "In the spinal cord, an intricate neural network generates and
              coordinates the patterning of limb movements during locomotion.
              This network, known as the locomotor central pattern generator
              (CPG), c ...",
  journal  = "undefined",
  year     =  2016,
  keywords = "Locomotion"
}

@UNPUBLISHED{Kietzmann2018-ou,
  title    = "Deep Neural Networks in Computational Neuroscience",
  author   = "Kietzmann, Tim C and McClure, Patrick and Kriegeskorte, Nikolaus",
  abstract = "Summary The goal of computational neuroscience is to find
              mechanistic explanations of how the nervous system processes
              information to give rise to cognitive function and behaviour. At
              the heart of the field are its models, i.e. mathematical and
              computational descriptions of the system being studied, which map
              sensory stimuli to neural responses and/or neural to behavioural
              responses. These models range from simple to complex. Recently,
              deep neural networks (DNNs) have come to dominate several domains
              of artificial intelligence (AI). As the term ``neural network''
              suggests, these models are inspired by biological brains.
              However, current DNNs neglect many details of biological neural
              networks. These simplifications contribute to their computational
              efficiency, enabling them to perform complex feats of
              intelligence, ranging from perceptual (e.g. visual object and
              auditory speech recognition) to cognitive tasks (e.g. machine
              translation), and on to motor control (e.g. playing computer
              games or controlling a robot arm). In addition to their ability
              to model complex intelligent behaviours, DNNs excel at predicting
              neural responses to novel sensory stimuli with accuracies well
              beyond any other currently available model type. DNNs can have
              millions of parameters, which are required to capture the domain
              knowledge needed for successful task performance. Contrary to the
              intuition that this renders them into impenetrable black boxes,
              the computational properties of the network units are the result
              of four directly manipulable elements: input statistics, network
              structure, functional objective, and learning algorithm. With
              full access to the activity and connectivity of all units,
              advanced visualization techniques, and analytic tools to map
              network representations to neural data, DNNs represent a powerful
              framework for building task-performing models and will drive
              substantial insights in computational neuroscience.",
  journal  = "bioRxiv",
  pages    = "133504",
  month    =  jun,
  year     =  2018,
  language = "en",
  doi      = "10.1101/133504"
}

@UNPUBLISHED{Isa2019-ww,
  title    = "Difference in context-dependency between orienting and
              defense-like responses induced by the superior colliculus",
  author   = "Isa, Kaoru and Sooksawate, Thongchai and Kobayashi, Kenta and
              Kobayashi, Kazuto and Redgrave, Peter and Isa, Tadashi",
  abstract = "Abstract Previous electrical stimulation and lesion experiments
              have suggested that the crossed descending output pathway from
              the deeper layers (SCd) of superior colliculus (SC) controls
              orienting responses, while the uncrossed pathway mediates
              defense-like behavior. Here we extended these investigations by
              using selective optogenetic activation of each pathway in mice
              with channelrhodopsin 2 expression by double viral vector
              techniques. Brief photo-stimulation of the crossed pathway evoked
              short latency contraversive orienting-like head turns, while
              extended stimulation induced contraversive circling responses. In
              contrast, stimulation of uncrossed pathway induced short-latency
              upward head movements followed by longer-latency defense-like
              behaviors including retreat and flight. The novel discovery was
              that the evoked defense-like responses varied depending on the
              environment, suggesting that uncrossed output can be influenced
              by top-down modification of the SC or its downstream. This
              further suggests that the SCd-defense system can be profoundly
              modulated by non-motor, affective and cognitive components, in
              addition to direct sensory inputs.",
  journal  = "bioRxiv",
  pages    = "729772",
  month    =  aug,
  year     =  2019,
  language = "en",
  doi      = "10.1101/729772"
}

@UNPUBLISHED{Finkelstein2019-ne,
  title    = "Attractor dynamics gate cortical information flow during
              decision-making",
  author   = "Finkelstein, Arseny and Fontolan, Lorenzo and Economo, Michael N
              and Li, Nuo and Romani, Sandro and Svoboda, Karel",
  abstract = "Decisions about future actions are held in memory until enacted,
              making them vulnerable to distractors. The neural mechanisms
              controlling decision robustness to distractors remain unknown. We
              trained mice to report optogenetic stimulation of somatosensory
              cortex, with a delay separating sensation and action. Distracting
              stimuli influenced behavior less when delivered later during
              delay --- demonstrating temporal gating of sensory information
              flow. Gating occurred even though distractor-evoked activity
              percolated through the cortex without attenuation. Instead,
              choice-related dynamics in frontal cortex became progressively
              robust to distractors as time passed. Reverse-engineering of
              neural networks trained to reproduce frontal-cortex activity
              revealed that chosen actions were stabilized via attractor
              dynamics, which gated out distracting stimuli. Our results reveal
              a dynamic gating mechanism that operates by controlling the
              degree of commitment to a chosen course of action.",
  journal  = "bioRxiv",
  pages    = "2019.12.14.876425",
  month    =  dec,
  year     =  2019,
  language = "en",
  doi      = "10.1101/2019.12.14.876425"
}

@ARTICLE{Perreault2019-da,
  title    = "Diversity of reticulospinal systems in mammals",
  author   = "Perreault, Marie-Claude and Giorgi, Andrea",
  abstract = "Reticulospinal (RS) neurons provide the spinal cord with the
              executive signals for a large repertoire of motor and autonomic
              functions, ensuring at the same time that these functions are
              adapted to the different behavioral contexts. This requires the
              coordinated action of many RS neurons. In this mini-review, we
              examine how the RS neurons that carry out specific functions
              distribute across the three parts of the brain stem. Extensive
              overlap between populations suggests a need to explore
              multi-functionality at the single cell-level. We next contrast
              functional diversity and homogeneity in transmitter phenotype.
              Then, we examine the molecular genetic mechanisms that specify
              brain stem development and likely contribute to RS neurons
              identities. We advocate that a better knowledge of the
              developmental lineage of the RS neurons and a better knowledge of
              RS neuron activity across multiple behaviors will help uncover
              the fundamental principles behind the diversity of RS systems in
              mammals.",
  journal  = "Curr Opin Physiol",
  volume   =  8,
  pages    = "161--169",
  month    =  apr,
  year     =  2019,
  keywords = "Brain Stem; Control of Movement and Bodily Functions; Reticular
              Formation; Reticulospinal",
  language = "en",
  issn     = "2468-8673",
  pmid     = "31763514",
  doi      = "10.1016/j.cophys.2019.03.001",
  pmc      = "PMC6874378"
}

@ARTICLE{Lefler2019-ke,
  title    = "The role of the periaqueductal gray in escape behavior",
  author   = "Lefler, Yaara and Campagner, Dario and Branco, Tiago",
  abstract = "Escape behavior is a defensive action deployed by animals in
              response to imminent threats. In mammalian species, a variety of
              different brain circuits are known to participate in this crucial
              survival behavior. One of these circuits is the periaqueductal
              gray, a midbrain structure that can command a variety of
              instinctive behaviors. Recent experiments using modern systems
              neuroscience techniques have begun to elucidate the specific role
              of the periaqueductal gray in controlling escape. These have
              shown that periaqueductal gray neurons are crucial units for
              gating and commanding the initiation of escape, specifically
              activated in situations of imminent, escapable threat. In
              addition, it is becoming clear that the periaqueductal gray
              integrates brain-wide information that can modulate escape
              initiation to generate flexible defensive behaviors.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  60,
  pages    = "115--121",
  month    =  dec,
  year     =  2019,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "31864105",
  doi      = "10.1016/j.conb.2019.11.014"
}

@ARTICLE{Mearns2019-md,
  title     = "Deconstructing Hunting Behavior Reveals a Tightly Coupled
               {Stimulus-Response} Loop",
  author    = "Mearns, Duncan S and Donovan, Joseph C and Fernandes,
               Ant{\'o}nio M and Semmelhack, Julia L and Baier, Herwig",
  abstract  = "SummaryAnimal behavior often forms sequences, built from simple
               stereotyped actions and shaped by environmental cues. A
               comprehensive characterization of the interplay between an
               animal's movements and its environment is necessary to
               understand the sensorimotor transformations performed by the
               brain. Here, we use unsupervised methods to study behavioral
               sequences in zebrafish larvae. We generate a map of swim bouts,
               revealing that fish modulate their tail movements along a
               continuum. During prey capture, larvae produce stereotyped
               sequences using a subset of bouts from a broader behavioral
               repertoire. These sequences exhibit low-order transition
               dynamics and immediately respond to changes in visual cues.
               Chaining of prey capture bouts is disrupted in visually impaired
               (lakritz and blumenkohl) mutants, and removing the prey stimulus
               during ongoing behavior in closed-loop virtual reality causes
               larvae to immediately abort the hunting sequence. These results
               suggest that the continuous integration of sensory information
               is necessary to structure the behavior. This stimulus-response
               loop serves to bring prey into the anterior dorsal visual field
               of the larvae. Fish then release a capture strike maneuver
               comprising a stereotyped jaw movement and tail movements
               fine-tuned to the distance of the prey. Fish with only one
               intact eye fail to correctly position the prey in the strike
               zone, but are able to produce the strike itself. Our analysis
               shows that short-term integration of binocular visual cues
               shapes the behavioral dynamics of hunting, thus uncovering the
               temporal organization of a goal-directed behavior in a
               vertebrate.",
  journal   = "Curr. Biol.",
  publisher = "Elsevier",
  volume    =  0,
  number    =  0,
  month     =  dec,
  year      =  2019,
  keywords  = "zebrafish; ethology; prey capture; unsupervised machine
               learning; behavioral sequences",
  language  = "en",
  issn      = "0960-9822",
  pmid      = "31866365",
  doi       = "10.1016/j.cub.2019.11.022"
}

@UNPUBLISHED{Sanchez-Bellot2019-me,
  title    = "Push-pull regulation of exploratory behavior by two opposing
              hippocampal to prefrontal cortex pathways",
  author   = "S{\'a}nchez-Bellot, Candela and MacAskill, Andrew F",
  abstract = "We found that the hippocampal projection to prefrontal cortex is
              composed of two parallel circuits located in the superficial or
              deep hippocampal pyramidal layers. These circuits have unique
              upstream and downstream connectivity, and are differentially
              active during exploration of a potentially threatening
              environment. Artificial activation of the superficial circuit
              promotes exploration via preferential recruitment of PFC
              inhibition, while activation of the deep circuit promotes
              avoidance via direct excitation.",
  journal  = "bioRxiv",
  pages    = "2019.12.18.880831",
  month    =  dec,
  year     =  2019,
  language = "en",
  doi      = "10.1101/2019.12.18.880831"
}

@ARTICLE{Marques2019-dw,
  title    = "Internal state dynamics shape brainwide activity and foraging
              behaviour",
  author   = "Marques, Jo{\~a}o C and Li, Meng and Schaak, Diane and Robson,
              Drew N and Li, Jennifer M",
  abstract = "The brain has persistent internal states that can modulate every
              aspect of an animal's mental experience1-4. In complex tasks such
              as foraging, the internal state is dynamic5-8. Caenorhabditis
              elegans alternate between local search and global dispersal5.
              Rodents and primates exhibit trade-offs between exploitation and
              exploration6,7. However, fundamental questions remain about how
              persistent states are maintained in the brain, which upstream
              networks drive state transitions and how state-encoding neurons
              exert neuromodulatory effects on sensory perception and
              decision-making to govern appropriate behaviour. Here, using
              tracking microscopy to monitor whole-brain neuronal activity at
              cellular resolution in freely moving zebrafish larvae9, we show
              that zebrafish spontaneously alternate between two persistent
              internal states during foraging for live prey (Paramecia). In the
              exploitation state, the animal inhibits locomotion and promotes
              hunting, generating small, localized trajectories. In the
              exploration state, the animal promotes locomotion and suppresses
              hunting, generating long-ranging trajectories that enhance
              spatial dispersion. We uncover a dorsal raphe subpopulation with
              persistent activity that robustly encodes the exploitation state.
              The exploitation-state-encoding neurons, together with a
              multimodal trigger network that is associated with state
              transitions, form a stochastically activated nonlinear dynamical
              system. The activity of this oscillatory network correlates with
              a global retuning of sensorimotor transformations during foraging
              that leads to marked changes in both the motivation to hunt for
              prey and the accuracy of motor sequences during hunting. This
              work reveals an important hidden variable that shapes the
              temporal structure of motivation and decision-making.",
  journal  = "Nature",
  month    =  dec,
  year     =  2019,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "31853063",
  doi      = "10.1038/s41586-019-1858-z"
}

@ARTICLE{Wang2019-ot,
  title    = "Zona Incerta: An Integrative Node for Global Behavioral
              Modulation",
  author   = "Wang, Xiyue and Chou, Xiao-Lin and Zhang, Li I and Tao, Huizhong
              Whit",
  abstract = "Zona incerta (ZI) is a largely inhibitory subthalamic region
              connecting with many brain areas. Early studies have suggested
              involvement of ZI in various functions such as visceral
              activities, arousal, attention, and locomotion, but the specific
              roles of different ZI subdomains or cell types have not been well
              examined. Recent studies combining optogenetics, behavioral
              assays, neural tracing, and neural activity-recording reveal
              novel functional roles of ZI depending on specific input-output
              connectivity patterns. Here, we review these studies and
              summarize functions of ZI into four categories: sensory
              integration, behavioral output control, motivational drive, and
              neural plasticity. In view of these new findings, we propose that
              ZI serves as an integrative node for global modulation of
              behaviors and physiological states.",
  journal  = "Trends Neurosci.",
  month    =  dec,
  year     =  2019,
  keywords = "animal behavior; gain modulation; inhibitory nucleus;
              input/output pattern; motivation; neural plasticity;
              physiological state; processing node; subthalamic region",
  language = "en",
  issn     = "0166-2236, 1878-108X",
  pmid     = "31864676",
  doi      = "10.1016/j.tins.2019.11.007"
}

@ARTICLE{Kao2019-hv,
  title    = "Considerations in using recurrent neural networks to probe neural
              dynamics",
  author   = "Kao, Jonathan C",
  abstract = "Recurrent neural networks (RNNs) are increasingly being used to
              model complex cognitive and motor tasks performed by behaving
              animals. RNNs are trained to reproduce animal behavior while also
              capturing key statistics of empirically recorded neural activity.
              In this manner, the RNN can be viewed as an in silico circuit
              whose computational elements share similar motifs with the
              cortical area it is modeling. Furthermore, because the RNN's
              governing equations and parameters are fully known, they can be
              analyzed to propose hypotheses for how neural populations
              compute. In this context, we present important considerations
              when using RNNs to model motor behavior in a delayed reach task.
              First, by varying the network's nonlinear activation and rate
              regularization, we show that RNNs reproducing single-neuron
              firing rate motifs may not adequately capture important
              population motifs. Second, we find that even when RNNs reproduce
              key neurophysiological features on both the single neuron and
              population levels, they can do so through distinctly different
              dynamical mechanisms. To distinguish between these mechanisms, we
              show that an RNN consistent with a previously proposed dynamical
              mechanism is more robust to input noise. Finally, we show that
              these dynamics are sufficient for the RNN to generalize to tasks
              it was not trained on. Together, these results emphasize
              important considerations when using RNN models to probe neural
              dynamics.NEW \& NOTEWORTHY Artificial neurons in a recurrent
              neural network (RNN) may resemble empirical single-unit activity
              but not adequately capture important features on the neural
              population level. Dynamics of RNNs can be visualized in
              low-dimensional projections to provide insight into the RNN's
              dynamical mechanism. RNNs trained in different ways may reproduce
              neurophysiological motifs but do so with distinctly different
              mechanisms. RNNs trained to only perform a delayed reach task can
              generalize to perform tasks where the target is switched or the
              target location is changed.",
  journal  = "J. Neurophysiol.",
  volume   =  122,
  number   =  6,
  pages    = "2504--2521",
  month    =  dec,
  year     =  2019,
  keywords = "artificial neural network; motor cortex; neural computation;
              neural dynamics; recurrent neural network;RNN To
              read;RNN;to\_read\_for\_review",
  language = "en",
  issn     = "0022-3077, 1522-1598",
  pmid     = "31619125",
  doi      = "10.1152/jn.00467.2018"
}

@ARTICLE{Woon2019-lj,
  title    = "Involvement of the rodent prelimbic and medial orbitofrontal
              cortices in goal-directed action: A brief review",
  author   = "Woon, Ellen P and Sequeira, Michelle K and Barbee, Britton R and
              Gourley, Shannon L",
  abstract = "Goal-directed action refers to selecting behaviors based on the
              expectation that they will be reinforced with desirable outcomes.
              It is typically conceptualized as opposing habit-based behaviors,
              which are instead supported by stimulus-response associations and
              insensitive to consequences. The prelimbic prefrontal cortex (PL)
              is positioned along the medial wall of the rodent prefrontal
              cortex. It is indispensable for action-outcome-driven
              (goal-directed) behavior, consolidating action-outcome
              relationships and linking contextual information with
              instrumental behavior. In this brief review, we will discuss the
              growing list of molecular factors involved in PL function.
              Ventral to the PL is the medial orbitofrontal cortex (mOFC). We
              will also summarize emerging evidence from rodents (complementing
              existing literature describing humans) that it too is involved in
              action-outcome conditioning. We describe experiments using
              procedures that quantify responding based on reward value, the
              likelihood of reinforcement, or effort requirements, touching
              also on experiments assessing food consumption more generally. We
              synthesize these findings with the argument that the mOFC is
              essential to goal-directed action when outcome value information
              is not immediately observable and must be recalled and inferred.",
  journal  = "J. Neurosci. Res.",
  month    =  dec,
  year     =  2019,
  keywords = "action-outcome; contingency degradation; devaluation; habit;
              mouse; rat; response-outcome; review; reward",
  language = "en",
  issn     = "0360-4012, 1097-4547",
  pmid     = "31820488",
  doi      = "10.1002/jnr.24567"
}

@ARTICLE{Yoo2019-jz,
  title    = "The Transition from Evaluation to Selection Involves Neural
              Subspace Reorganization in Core Reward Regions",
  author   = "Yoo, Seng Bum Michael and Hayden, Benjamin Y",
  abstract = "Economic choice proceeds from evaluation, in which we contemplate
              options, to selection, in which we weigh options and choose one.
              These stages must be differentiated so that decision makers do
              not proceed to selection before evaluation is complete. We
              examined responses of neurons in two core reward regions,
              orbitofrontal (OFC) and ventromedial prefrontal cortex (vmPFC),
              during two-option choice with asynchronous offer presentation.
              Our data suggest that neurons selective during the first
              (presumed evaluation) and second (presumed comparison and
              selection) offer epochs come from a single pool. Stage transition
              is accompanied by a shift toward orthogonality in the
              low-dimensional population response manifold. Nonetheless, the
              relative position of each option in driving responses in the
              population subspace is preserved. The orthogonalization we
              observe supports the hypothesis that the transition from
              evaluation to selection leads to reorganization of response
              subspace and suggests a mechanism by which value-related signals
              are prevented from prematurely driving choice.",
  journal  = "Neuron",
  month    =  nov,
  year     =  2019,
  keywords = "comparison; covariance matrix; neuroeconomics; orbitofrontal
              cortex; orthogonalization; valuation; ventromedial prefrontal
              cortex",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "31836322",
  doi      = "10.1016/j.neuron.2019.11.013"
}

@UNPUBLISHED{Nallapu2019-wq,
  title    = "Interacting roles of lateral and medial Orbitofrontal cortex in
              decision-making and learning : A system-level computational model",
  author   = "Nallapu, Bhargav Teja and Alexandre, Fr{\'e}d{\'e}ric",
  abstract = "In the context of flexible and adaptive animal behavior, the
              orbitofrontal cortex (OFC) is found to be one of the crucial
              regions in the prefrontal cortex (PFC) influencing the downstream
              processes of decision-making and learning in the sub-cortical
              regions. Although OFC has been implicated to be important in a
              variety of related behavioral processes, the exact mechanisms are
              unclear, through which the OFC encodes or processes information
              related to decision-making and learning. Here, we propose a
              systems-level view of the OFC, positioning it at the nexus of
              sub-cortical systems and other prefrontal regions. Particularly
              we focus on one of the most recent implications of
              neuroscientific evidences regarding the OFC - possible functional
              dissociation between two of its sub-regions : lateral and medial.
              We present a system-level computational model of decision-making
              and learning involving the two sub-regions taking into account
              their individual roles as commonly implicated in neuroscientific
              studies. We emphasize on the role of the interactions between the
              sub-regions within the OFC as well as the role of other
              sub-cortical structures which form a network with them. We
              leverage well-known computational architecture of
              thalamo-cortical basal ganglia loops, accounting for recent
              experimental findings on monkeys with lateral and medial OFC
              lesions, performing a 3-arm bandit task. First we replicate the
              seemingly dissociate effects of lesions to lateral and medial OFC
              during decision-making as a function of value-difference of the
              presented options. Further we demonstrate and argue that such an
              effect is not necessarily due to the dissociate roles of both the
              subregions, but rather a result of complex temporal dynamics
              between the interacting networks in which they are involved.
              Author summary We first highlight the role of the Orbitofrontal
              Cortex (OFC) in value-based decision making and goal-directed
              behavior in primates. We establish the position of OFC at the
              intersection of cortical mechanisms and thalamo-basal ganglial
              circuits. In order to understand possible mechanisms through
              which the OFC exerts emotional control over behavior, among
              several other possibilities, we consider the case of dissociate
              roles of two of its topographical subregions - lateral and medial
              parts of OFC. We gather predominant roles of each of these
              sub-regions as suggested by numerous experimental evidences in
              the form of a system-level computational model that is based on
              existing neuronal architectures. We argue that besides possible
              dissociation, there could be possible interaction of these
              sub-regions within themselves and through other sub-cortical
              structures, in distinct mechanisms of choice and learning. The
              computational framework described accounts for experimental data
              and can be extended to more comprehensive detail of
              representations required to understand the processes of
              decision-making, learning and the role of OFC and subsequently
              the regions of prefrontal cortex in general.",
  journal  = "bioRxiv",
  pages    = "867515",
  month    =  dec,
  year     =  2019,
  language = "en",
  doi      = "10.1101/867515"
}

@ARTICLE{Reinhard2019-zc,
  title    = "A projection specific logic to sampling visual inputs in mouse
              superior colliculus",
  author   = "Reinhard, Katja and Li, Chen and Do, Quan and Burke, Emily G and
              Heynderickx, Steven and Farrow, Karl",
  abstract = "Using sensory information to trigger different behaviors relies
              on circuits that pass through brain regions. The rules by which
              parallel inputs are routed to downstream targets are poorly
              understood. The superior colliculus mediates a set of innate
              behaviors, receiving input from >30 retinal ganglion cell types
              and projecting to behaviorally important targets including the
              pulvinar and parabigeminal nucleus. Combining transsynaptic
              circuit tracing with in vivo and ex vivo electrophysiological
              recordings, we observed a projection-specific logic where each
              collicular output pathway sampled a distinct set of retinal
              inputs. Neurons projecting to the pulvinar or the parabigeminal
              nucleus showed strongly biased sampling from four cell types
              each, while six others innervated both pathways. The visual
              response properties of retinal ganglion cells correlated well
              with those of their disynaptic targets. These findings open the
              possibility that projection-specific sampling of retinal inputs
              forms a basis for the selective triggering of behaviors by the
              superior colliculus.",
  journal  = "Elife",
  volume   =  8,
  month    =  nov,
  year     =  2019,
  keywords = "mouse; neuroscience; parabigeminal nucleus; pulvinar; retina;
              superior colliculus; visual circuits",
  language = "en",
  issn     = "2050-084X",
  pmid     = "31750831",
  doi      = "10.7554/eLife.50697",
  pmc      = "PMC6872211"
}

@UNPUBLISHED{Sabatini2019-zw,
  title    = "The impact of reporter kinetics on the interpretation of data
              gathered with fluorescent reporters",
  author   = "Sabatini, Bernardo L",
  abstract = "Abstract Fluorescent reporters of biological functions are used
              to monitor biochemical events and signals in cells and tissue.
              For neurobiology, these have been particularly useful for
              monitoring signals in the brains of behaving animals. In order to
              enhance signal-to-noise, fluorescent reporters typically have
              kinetics that are slower than that of the underlying biological
              process. This low-pass filtering by the reporter renders the
              fluorescence transient a leaking integrated version of the
              biological signal. Here I discuss the effects that low-pass
              filtering, or more precisely of integrating by convolving with an
              exponentially decaying kernel, has on the interpretation of the
              relationship between the reporter fluorescence transient and the
              events that underlie it. Unfortunately, when the biological
              events being monitored are impulse-like, such as the firing of an
              action potential or the release of neurotransmitter, filtering
              greatly reduces the maximum correlation coefficient that can be
              found between the events and the fluorescence signal. This can
              erroneously support the conclusion that the fluorescence
              transient and the biological signal that it reports are only
              weakly related. Furthermore, when examining the encoding of
              behavioral state variables by nervous system, filtering by the
              reporter kinetics will favor the interpretation that fluorescence
              transients encode integrals of measured variables as opposed to
              the variables themselves. For these reasons, it is necessary to
              take into account the filtering effects of the indicator by
              deconvolving with the convolution kernel and recovering the
              underlying biological events before making conclusions about what
              is encoded in the signals emitted by fluorescent reporters.",
  journal  = "bioRxiv",
  pages    = "834895",
  month    =  nov,
  year     =  2019,
  language = "en",
  doi      = "10.1101/834895"
}

@UNPUBLISHED{Shamash2018-ky,
  title    = "A tool for analyzing electrode tracks from slice histology",
  author   = "Shamash, Philip and Carandini, Matteo and Harris, Kenneth and
              Steinmetz, Nick",
  abstract = "It is now possible to record from hundreds of neurons across
              multiple brain regions in a single electrophysiology experiment.
              An essential step in the ensuing data analysis is to assign
              recorded neurons to the correct brain regions. Brain regions are
              typically identified after the recordings by comparing images of
              brain slices to a reference atlas by eye. This introduces error,
              in particular when slices are not cut at a perfectly coronal
              angle or when electrode tracks span multiple slices. Here we
              introduce SHARP-Track, a tool to localize regions of interest and
              plot the brain regions they pass through. SHARP-Track offers a
              MATLAB user interface to explore the Allen Mouse Brain Atlas,
              register asymmetric slice images to the atlas using manual input,
              and interactively analyze electrode tracks. We find that it
              reduces error compared to localizing electrodes in a reference
              atlas by eye. See [github.com/cortex-lab/allenCCF][1] for the
              software and wiki. [1]: http://github.com/cortex-lab/allenCCF",
  journal  = "bioRxiv",
  pages    = "447995",
  month    =  oct,
  year     =  2018,
  language = "en",
  doi      = "10.1101/447995"
}

@ARTICLE{Sussillo2009-tf,
  title    = "Generating coherent patterns of activity from chaotic neural
              networks",
  author   = "Sussillo, David and Abbott, L F",
  abstract = "Neural circuits display complex activity patterns both
              spontaneously and when responding to a stimulus or generating a
              motor output. How are these two forms of activity related? We
              develop a procedure called FORCE learning for modifying synaptic
              strengths either external to or within a model neural network to
              change chaotic spontaneous activity into a wide variety of
              desired activity patterns. FORCE learning works even though the
              networks we train are spontaneously chaotic and we leave feedback
              loops intact and unclamped during learning. Using this approach,
              we construct networks that produce a wide variety of complex
              output patterns, input-output transformations that require
              memory, multiple outputs that can be switched by control inputs,
              and motor patterns matching human motion capture data. Our
              results reproduce data on premovement activity in motor and
              premotor cortex, and suggest that synaptic plasticity may be a
              more rapid and powerful modulator of network activity than
              generally appreciated.",
  journal  = "Neuron",
  volume   =  63,
  number   =  4,
  pages    = "544--557",
  month    =  aug,
  year     =  2009,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "19709635",
  doi      = "10.1016/j.neuron.2009.07.018",
  pmc      = "PMC2756108"
}

@UNPUBLISHED{Cadena2019-ly,
  title    = "How well do deep neural networks trained on object recognition
              characterize the mouse visual system?",
  author   = "Cadena, Santiago A and Sinz, Fabian H and Muhammad, Taliah and
              Froudarakis, Emmanouil and Cobos, Erick and Walker, Edgar Y and
              Reimer, Jake and Bethge, Matthias and Tolias, Andreas and Ecker,
              Alexander S",
  abstract = "Recent work on modeling neural responses in the primate visual
              system has benefited from deep neural networks trained on
              large-scale object recognition, and found a hierarchical
              correspondence between layers of the artificial neural network
              and brain areas along the ventral visual stream. However, we
              neither know whether such task-optimized networks enable equally
              good models of the rodent visual system, nor if a similar
              hierarchical correspondence exists. Here, we address these
              questions in the mouse visual system by extracting features at
              several layers of a convolutional neural network (CNN) trained on
              ImageNet to predict the responses of thousands of neurons in four
              visual areas (V1, LM, AL, RL) to natural images. We found that
              the CNN features outperform classical subunit energy models, but
              found no evidence for an order of the areas we recorded via a
              correspondence to the hierarchy of CNN layers. Moreover, the same
              CNN but with random weights provided an equivalently useful
              feature space for predicting neural responses. Our results
              suggest that object recognition as a high-level task does not
              provide more discriminative features to characterize the mouse
              visual system than a random network. Unlike in the primate,
              training on ethologically relevant visually guided behaviors --
              beyond static object recognition -- may be needed to unveil the
              functional organization of the mouse visual cortex.",
  month    =  sep,
  year     =  2019
}

@ARTICLE{Claudi2020-go,
  title    = "{BrainGlobe} Atlas {API}: a common interface for neuroanatomical
              atlases",
  author   = "Claudi, Federico and Petrucco, Luigi and Tyson, Adam and Branco,
              Tiago and Margrie, Troy and Portugues, Ruben",
  abstract = "Software archive",
  journal  = "JOSS",
  volume   =  5,
  number   =  54,
  pages    = "2668",
  month    =  oct,
  year     =  2020,
  issn     = "2475-9066",
  doi      = "10.21105/joss.02668"
}

@ARTICLE{Sauerbrei2019-uc,
  title    = "Cortical pattern generation during dexterous movement is
              input-driven",
  author   = "Sauerbrei, Britton A and Guo, Jian-Zhong and Cohen, Jeremy D and
              Mischiati, Matteo and Guo, Wendy and Kabra, Mayank and Verma,
              Nakul and Mensh, Brett and Branson, Kristin and Hantman, Adam W",
  abstract = "The motor cortex controls skilled arm movement by sending
              temporal patterns of activity to lower motor centres1. Local
              cortical dynamics are thought to shape these patterns throughout
              movement execution2-4. External inputs have been implicated in
              setting the initial state of the motor cortex5,6, but they may
              also have a pattern-generating role. Here we dissect the
              contribution of local dynamics and inputs to cortical pattern
              generation during a prehension task in mice. Perturbing cortex to
              an aberrant state prevented movement initiation, but after the
              perturbation was released, cortex either bypassed the normal
              initial state and immediately generated the pattern that controls
              reaching or failed to generate this pattern. The difference in
              these two outcomes was probably a result of external inputs. We
              directly investigated the role of inputs by inactivating the
              thalamus; this perturbed cortical activity and disrupted limb
              kinematics at any stage of the movement. Activation of
              thalamocortical axon terminals at different frequencies disrupted
              cortical activity and arm movement in a graded manner.
              Simultaneous recordings revealed that both thalamic activity and
              the current state of cortex predicted changes in cortical
              activity. Thus, the pattern generator for dexterous arm movement
              is distributed across multiple, strongly interacting brain
              regions.",
  journal  = "Nature",
  month    =  dec,
  year     =  2019,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "31875851",
  doi      = "10.1038/s41586-019-1869-9"
}

@ARTICLE{Angelaki2019-ky,
  title    = "The head direction cell network: attractor dynamics, integration
              within the navigation system, and three-dimensional properties",
  author   = "Angelaki, Dora E and Laurens, Jean",
  abstract = "Knowledge of head direction cell function has progressed
              remarkably in recent years. The predominant theory that they form
              an attractor has been confirmed by several experiments. Candidate
              pathways that may convey visual input have been identified. The
              pre-subicular circuitry that conveys head direction signals to
              the medial entorhinal cortex, potentially sustaining path
              integration by grid cells, has been resolved. Although the
              neuronal substrate of the attractor remains unknown in mammals, a
              simple head direction network, whose structure is astoundingly
              similar to neuronal models theorized decades earlier, has been
              identified in insects. Finally, recent experiments have revealed
              that these cells do not encode head direction in the horizontal
              plane only, but also in vertical planes, thus providing a 3D
              orientation signal.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  60,
  pages    = "136--144",
  month    =  dec,
  year     =  2019,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "31877492",
  doi      = "10.1016/j.conb.2019.12.002"
}

@ARTICLE{Lomber2001-zl,
  title    = "Role of the superior colliculus in analyses of space: superficial
              and intermediate layer contributions to visual orienting,
              auditory orienting, and visuospatial discriminations during
              unilateral and bilateral deactivations",
  author   = "Lomber, S G and Payne, B R and Cornwell, P",
  abstract = "The superior colliculus (SC) has been implicated in spatial
              analyses of the environment, although few behavioral studies have
              explicitly tested this role. To test its imputed role in spatial
              analyses, we used a battery of four spatial tasks combined with
              unilateral and bilateral cooling deactivation of the upper and
              intermediate layers of the superior colliculus. We tested the
              abilities of cats to orient to three different stimuli: (1)
              moving visual, (2) stationary visual, (3) stationary white-noise
              aural. Furthermore, we tested the ability of the cats to
              discriminate the relative spatial position of a landmark.
              Unilateral cooling deactivation of the superficial layers of the
              SC induced a profound neglect of both moving and stationary
              visual stimuli presented in, and landmark objects located within,
              the contralateral hemifield. However, responses to auditory
              stimuli were unimpaired. Unilateral cooling deactivation of both
              the superficial and intermediate layers induced a profound
              contralateral neglect of the auditory stimulus. Additional and
              equivalent deactivation of the opposite SC largely restored
              orienting to either moving visual or auditory stimuli, and
              restored landmark position reporting to normal levels. However,
              during bilateral SC deactivation, orienting to the static visual
              stimulus was abolished throughout the entire visual field.
              Overall, unilateral SC deactivation results show that the upper
              and intermediate layers of the SC contribute in different ways to
              guiding behavioral responses to visual and auditory stimuli cues.
              Finally, bilateral superior colliculus deactivations reveal that
              other structures are sufficient to support spatial analyses and
              guide visual behaviors in the absence of neural operations in the
              superior colliculus, but only under certain circumstances.",
  journal  = "J. Comp. Neurol.",
  volume   =  441,
  number   =  1,
  pages    = "44--57",
  month    =  dec,
  year     =  2001,
  language = "en",
  issn     = "0021-9967",
  pmid     = "11745634",
  doi      = "10.1002/cne.1396"
}

@ARTICLE{Savage2017-un,
  title    = "Segregated fronto-cortical and midbrain connections in the mouse
              and their relation to approach and avoidance orienting behaviors",
  author   = "Savage, Michael Anthony and McQuade, Richard and Thiele,
              Alexander",
  abstract = "The orchestration of orienting behaviors requires the interaction
              of many cortical and subcortical areas, for example the superior
              colliculus (SC), as well as prefrontal areas responsible for
              top-down control. Orienting involves different behaviors, such as
              approach and avoidance. In the rat, these behaviors are at least
              partially mapped onto different SC subdomains, the lateral (SCl)
              and medial (SCm), respectively. To delineate the circuitry
              involved in the two types of orienting behavior in mice, we
              injected retrograde tracer into the intermediate and deep layers
              of the SCm and SCl, and thereby determined the main input
              structures to these subdomains. Overall the SCm receives larger
              numbers of afferents compared to the SCl. The prefrontal
              cingulate area (Cg), visual, oculomotor, and auditory areas
              provide strong input to the SCm, while prefrontal motor area 2
              (M2), and somatosensory areas provide strong input to the SCl.
              The prefrontal areas Cg and M2 in turn connect to different
              cortical and subcortical areas, as determined by anterograde
              tract tracing. Even though connectivity pattern often overlap,
              our labeling approaches identified segregated neural circuits
              involving SCm, Cg, secondary visual cortices, auditory areas, and
              the dysgranular retrospenial cortex likely to be involved in
              avoidance behaviors. Conversely, SCl, M2, somatosensory cortex,
              and the granular retrospenial cortex comprise a network likely
              involved in approach/appetitive behaviors.",
  journal  = "J. Comp. Neurol.",
  volume   =  525,
  number   =  8,
  pages    = "1980--1999",
  month    =  jun,
  year     =  2017,
  keywords = "RRID:SCR\_013672; approach behaviors; avoidance behaviors;
              cingulate area; motor cortex area 2; superior colliculus",
  language = "en",
  issn     = "0021-9967, 1096-9861",
  pmid     = "28177526",
  doi      = "10.1002/cne.24186",
  pmc      = "PMC5396297"
}

@BOOK{Steven_L_Brunton2017-bi,
  title    = "Data Driven Science \& Engineering",
  author   = "Steven L. Brunton, J Nathan Kutz",
  year     =  2017,
  keywords = "books"
}

@ARTICLE{Dean1986-hf,
  title    = "Head and body movements produced by electrical stimulation of
              superior colliculus in rats: effects of interruption of crossed
              tectoreticulospinal pathway",
  author   = "Dean, P and Redgrave, P and Sahibzada, N and Tsuji, K",
  abstract = "Stimulation of the superior colliculus in rats produces movements
              of the head and body that resemble either orientation and
              approach towards a contralateral stimulus, or avoidance of, or
              escape from, such a stimulus. A variety of evidence indicates
              that the crossed descending pathway, which runs in the
              contralateral predorsal bundle to the pontomedullary reticular
              formation and the spinal cord, is involved in orienting
              movements. The nature of this involvement was investigated, by
              assessing the effects on tectally-elicited movements of midbrain
              knife-cuts intended to section the pathway as it crosses midline
              in the dorsal tegmental decussation. As expected, ipsilateral
              movements resembling avoidance or escape were little affected by
              dorsal tegmental decussation section, whereas contralateral
              circling movements of the body were almost abolished. However,
              contralateral movements of the head in response to electrical
              stimulation were not eliminated, nor were orienting head
              movements to visual or tactile stimuli. There was some suggestion
              that section of the dorsal tegmental decussation increased the
              latency of head movements from electrical stimulation at lateral
              sites, and decreased the accuracy of orienting movements to
              sensory stimuli. These results support the view that the crossed
              tectoreticulospinal system is concerned with approach rather than
              avoidance movements. However, it appears that other, as yet
              unidentified, tectal efferent systems are also involved in
              orienting head movements. It is possible that this division of
              labour may reflect functional differences between various kinds
              of apparently similar orienting responses. One suggestion is that
              the tectoreticulospinal system is concerned less in open-loop
              orienting responses (that are initiated but not subsequently
              guided by sensory stimuli), than in following or pursuit
              movements.",
  journal  = "Neuroscience",
  volume   =  19,
  number   =  2,
  pages    = "367--380",
  month    =  oct,
  year     =  1986,
  language = "en",
  issn     = "0306-4522",
  pmid     = "3774146",
  doi      = "10.1016/0306-4522(86)90267-8"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Kleinman2019-ks,
  title     = "Recurrent neural network models of multi-area computation
               underlying decision-making",
  author    = "Kleinman, M and Chandrasekaran, C and Kao, J C",
  abstract  = "Cognition emerges from the coordination of computations in
               multiple brain areas. However, elucidating these coordinated
               computations within and across brain regions is challenging
               because intra-and inter-areal connectivity are typically
               unknown. Testable hypotheses about …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2019
}

@ARTICLE{Grillner2020-uq,
  title     = "Current Principles of Motor Control, with Special Reference to
               Vertebrate Locomotion",
  author    = "Grillner, Sten and El Manira, Abdeljabbar",
  abstract  = "The vertebrate control of locomotion involves all levels of the
               nervous system from cortex to the spinal cord. Here, we aim to
               cover all main aspects of this complex behavior, from the
               operation of the microcircuits in the spinal cord to the systems
               and behavioral levels and extend from mammalian locomotion to
               the basic undulatory movements of lamprey and fish. The cellular
               basis of propulsion represents the core of the control system,
               and it involves the spinal central pattern generator networks
               (CPGs) controlling the timing of different muscles, the sensory
               compensation for perturbations, and the brain stem command
               systems controlling the level of activity of the CPGs and the
               speed of locomotion. The forebrain and in particular the basal
               ganglia are involved in determining which motor programs should
               be recruited at a given point of time and can both initiate and
               stop locomotor activity. The propulsive control system needs to
               be integrated with the postural control system to maintain body
               orientation. Moreover, the locomotor movements need to be
               steered so that the subject approaches the goal of the locomotor
               episode, or avoids colliding with elements in the environment or
               simply escapes at high speed. These different aspects will all
               be covered in the review.",
  journal   = "Physiol. Rev.",
  publisher = "physiology.org",
  volume    =  100,
  number    =  1,
  pages     = "271--320",
  month     =  jan,
  year      =  2020,
  keywords  = "basal ganglia; central pattern generators; cerebellum; spinal
               cord; vestibular; visuomotor;Locomotion",
  language  = "en",
  issn      = "0031-9333, 1522-1210",
  pmid      = "31512990",
  doi       = "10.1152/physrev.00015.2019"
}

@ARTICLE{Bretzner2013-si,
  title     = "{Lhx3-Chx10} reticulospinal neurons in locomotor circuits",
  author    = "Bretzner, Fr{\'e}d{\'e}ric and Brownstone, Robert M",
  abstract  = "Motor behaviors result from the interplay between the brain and
               the spinal cord. Reticulospinal neurons, situated between the
               supraspinal structures that initiate motor movements and the
               spinal cord that executes them, play key integrative roles in
               these behaviors. However, the molecular identities of mammalian
               reticular formation neurons that mediate motor behaviors have
               not yet been determined, thus limiting their study in health and
               disease. In the medullary reticular formation of the mouse, we
               identified neurons that express the transcription factors Lhx3
               and/or Chx10, and demonstrate that these neurons form a
               significant component of glutamatergic reticulospinal pathways.
               Lhx3-positive medullary reticular formation neurons express Fos
               following a locomotor task in the adult, indicating that they
               are active during walking. Furthermore, they receive functional
               inputs from the mesencephalic locomotor region and have
               electrophysiological properties to support tonic repetitive
               firing, both of which are necessary for neurons that mediate the
               descending command for locomotion. Together, these results
               suggest that Lhx3/Chx10 medullary reticular formation neurons
               are involved in locomotion.",
  journal   = "J. Neurosci.",
  publisher = "Soc Neuroscience",
  volume    =  33,
  number    =  37,
  pages     = "14681--14692",
  month     =  sep,
  year      =  2013,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "0270-6474, 1529-2401",
  pmid      = "24027269",
  doi       = "10.1523/JNEUROSCI.5231-12.2013",
  pmc       = "PMC6705172"
}

@ARTICLE{Ito2017-gi,
  title     = "Segregation of Visual Response Properties in the Mouse Superior
               Colliculus and Their Modulation during Locomotion",
  author    = "Ito, Shinya and Feldheim, David A and Litke, Alan M",
  abstract  = "The superior colliculus (SC) receives direct input from the
               retina and integrates it with information about sound, touch,
               and state of the animal that is relayed from other parts of the
               brain to initiate specific behavioral outcomes. The superficial
               SC layers (sSC) contain cells that respond to visual stimuli,
               whereas the deep SC layers (dSC) contain cells that also respond
               to auditory and somatosensory stimuli. Here, we used a
               large-scale silicon probe recording system to examine the visual
               response properties of SC cells of head-fixed and alert male
               mice. We found cells with diverse response properties including:
               (1) orientation/direction-selective (OS/DS) cells with a firing
               rate that is suppressed by drifting sinusoidal gratings
               (negative OS/DS cells); (2) suppressed-by-contrast cells; (3)
               cells with complex-like spatial summation nonlinearity; and (4)
               cells with Y-like spatial summation nonlinearity. We also found
               specific response properties that are enriched in different
               depths of the SC. The sSC is enriched with cells with small RFs,
               high evoked firing rates (FRs), and sustained temporal
               responses, whereas the dSC is enriched with the negative OS/DS
               cells and with cells with large RFs, low evoked FRs, and
               transient temporal responses. Locomotion modulates the activity
               of the SC cells both additively and multiplicatively and changes
               the preferred spatial frequency of some SC cells. These results
               provide the first description of the negative OS/DS cells and
               demonstrate that the SC segregates cells with different response
               properties and that the behavioral state of a mouse affects SC
               activity.SIGNIFICANCE STATEMENT The superior colliculus (SC)
               receives visual input from the retina in its superficial layers
               (sSC) and induces eye/head-orientating movements and innate
               defensive responses in its deeper layers (dSC). Despite their
               importance, very little is known about the visual response
               properties of dSC neurons. Using high-density electrode
               recordings and novel model-based analysis, we found several
               novel visual response properties of the SC cells, including
               encoding of a cell's preferred orientation or direction by
               suppression of the firing rate. The sSC and the dSC are enriched
               with cells with different visual response properties. Locomotion
               modulates the cells in the SC. These findings contribute to our
               understanding of how the SC processes visual inputs, a critical
               step in comprehending visually guided behaviors.",
  journal   = "J. Neurosci.",
  publisher = "Soc Neuroscience",
  volume    =  37,
  number    =  35,
  pages     = "8428--8443",
  month     =  aug,
  year      =  2017,
  keywords  = "mouse; silicon probe; superior colliculus; vision",
  language  = "en",
  issn      = "0270-6474, 1529-2401",
  pmid      = "28760858",
  doi       = "10.1523/JNEUROSCI.3689-16.2017",
  pmc       = "PMC5577856"
}

@ARTICLE{Weldon1983-oz,
  title     = "Rotational behavior following cholinergic stimulation of the
               superior colliculus in rats",
  author    = "Weldon, D A and Calabrese, L C and Nicklaus, K J",
  abstract  = "Rate which received microinjections of carbachol into the
               superior colliculus exhibited pronounced dose-dependent
               rotational behavior contralateral to the site of injection
               (Experiment 1). Wet dog shakes were also observed in some
               animals. Similar injections in the midbrain reticular formation
               produced immobility with slight contralateral flexion of the
               neck. Convulsions were observed in some rats after injections
               into either anatomical location. In Experiment 2, circling
               induced by carbachol in the superior colliculus was blocked by
               prior injection of either the muscarinic receptor antagonist
               scopolamine or the nicotinic receptor antagonist mecamylamine,
               suggesting that both nicotinic and muscarinic receptors are
               involved in the effect. In Experiment 3 contralateral rotational
               behavior was induced by intracollicular microinjections of the
               combination of acetylcholine chloride and physostigmine. The
               results suggest that collicular mediation of contralateral
               rotational behavior, and perhaps orientation, might involve
               cholinergic receptors.",
  journal   = "Pharmacol. Biochem. Behav.",
  publisher = "Elsevier",
  volume    =  19,
  number    =  5,
  pages     = "813--820",
  month     =  nov,
  year      =  1983,
  language  = "en",
  issn      = "0091-3057",
  pmid      = "6647515",
  doi       = "10.1016/0091-3057(83)90086-2"
}

@ARTICLE{Geula1984-sq,
  title     = "Circling and bodily asymmetry induced by injection of {GABA}
               agonists and antagonists into the superior colliculus",
  author    = "Geula, C and Asdourian, D",
  abstract  = "The observation that ipsiversive circling follows unilateral
               lesions of the deep layers of the superior colliculus (DLSC),
               combined with the recent demonstration of an ipsilateral
               inhibitory GABAergic projection from substantia nigra pars
               reticulata (SNr) to the DLSC suggests a role for tectal GABA in
               circling behavior. In the present experiment, GABA, the GABA
               agonist muscimol, and the GABA antagonists picrotoxin and
               bicuculline were injected into the DLSC through chronic
               cannulae. GABA and muscimol produced significantly higher
               ipsiversive circling and bodily asymmetry than saline
               injections. Picrotoxin and bicuculline resulted in significantly
               higher contraversive circling and asymmetry than saline
               injections. All drugs except bicuculline produced dose-dependent
               circling. GABA injections were also made into the mesencephalic
               reticular formation (MRF) and the periaqueductal gray (PAG). The
               MRF injections produced the same degree of circling and
               asymmetry as the DLSC injections. The PAG injections resulted in
               significantly lower amounts of circling than the DLSC GABA
               injections, but they resulted in equivalent measures of
               asymmetry. These results demonstrate that DLSC GABA produces
               circling and asymmetry, and suggest that the DLSC as well as the
               MRF serve as output stations for the expression of circling
               behavior initiated at the striatum.",
  journal   = "Pharmacol. Biochem. Behav.",
  publisher = "Elsevier",
  volume    =  21,
  number    =  6,
  pages     = "853--858",
  month     =  dec,
  year      =  1984,
  language  = "en",
  issn      = "0091-3057",
  pmid      = "6522415",
  doi       = "10.1016/s0091-3057(84)80064-7"
}

@ARTICLE{Kardamakis2015-yc,
  title    = "Tectal microcircuit generating visual selection commands on
              gaze-controlling neurons",
  author   = "Kardamakis, Andreas A and Saitoh, Kazuya and Grillner, Sten",
  abstract = "The optic tectum (called superior colliculus in mammals) is
              critical for eye-head gaze shifts as we navigate in the terrain
              and need to adapt our movements to the visual scene. The neuronal
              mechanisms underlying the tectal contribution to stimulus
              selection and gaze reorientation remains, however, unclear at the
              microcircuit level. To analyze this complex--yet phylogenetically
              conserved--sensorimotor system, we developed a novel in vitro
              preparation in the lamprey that maintains the eye and midbrain
              intact and allows for whole-cell recordings from prelabeled
              tectal gaze-controlling cells in the deep layer, while visual
              stimuli are delivered. We found that receptive field activation
              of these cells provide monosynaptic retinal excitation followed
              by local GABAergic inhibition (feedforward). The entire remaining
              retina, on the other hand, elicits only inhibition (surround
              inhibition). If two stimuli are delivered simultaneously, one
              inside and one outside the receptive field, the former excitatory
              response is suppressed. When local inhibition is
              pharmacologically blocked, the suppression induced by competing
              stimuli is canceled. We suggest that this rivalry between visual
              areas across the tectal map is triggered through long-range
              inhibitory tectal connections. Selection commands conveyed via
              gaze-controlling neurons in the optic tectum are, thus, formed
              through synaptic integration of local retinotopic excitation and
              global tectal inhibition. We anticipate that this mechanism not
              only exists in lamprey but is also conserved throughout
              vertebrate evolution.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  112,
  number   =  15,
  pages    = "E1956--65",
  month    =  apr,
  year     =  2015,
  keywords = "GABAergic inhibition; evolution; gaze control; optic tectum;
              superior colliculus",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "25825743",
  doi      = "10.1073/pnas.1504866112",
  pmc      = "PMC4403191"
}

@ARTICLE{Helmbrecht2018-ux,
  title    = "Topography of a Visuomotor Transformation",
  author   = "Helmbrecht, Thomas O and Dal Maschio, Marco and Donovan, Joseph C
              and Koutsouli, Styliani and Baier, Herwig",
  abstract = "The brain converts perceptual information into appropriate
              patterns of muscle activity depending on the categorization and
              localization of sensory cues. Sensorimotor information might
              either be encoded by distributed networks or by ``labeled lines''
              connecting sensory channels to dedicated behavioral pathways.
              Here we investigate, in the context of natural behavior, how the
              tectum of larval zebrafish can inform downstream premotor areas.
              Optogenetic mapping revealed a tectal motor map underlying
              locomotor maneuvers for escape and approach. Single-cell
              reconstructions and high-resolution functional imaging showed
              that two spatially segregated and uncrossed descending axon
              tracts selectively transmit approach and escape signals to the
              hindbrain. Moreover, the approach pathway conveys information
              about retinotopic target coordinates to specific premotor
              ensembles via spatially ordered axonal projections. This
              topographic organization supports a tectum-generated space code
              sufficient to steer orienting movements. We conclude that
              specific labeled lines guide object-directed behavior in the
              larval zebrafish brain.",
  journal  = "Neuron",
  volume   =  100,
  number   =  6,
  pages    = "1429--1445.e4",
  month    =  dec,
  year     =  2018,
  keywords = "hindbrain; motor map; optic tectum; optogenetics; reticular
              formation; space code; superior colliculus; tectal projectome;
              visuomotor transformation; zebrafish",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "30392799",
  doi      = "10.1016/j.neuron.2018.10.021"
}

@ARTICLE{DePasquale2018-on,
  title    = "{full-FORCE}: A target-based method for training recurrent
              networks",
  author   = "DePasquale, Brian and Cueva, Christopher J and Rajan, Kanaka and
              Escola, G Sean and Abbott, L F",
  abstract = "Trained recurrent networks are powerful tools for modeling
              dynamic neural computations. We present a target-based method for
              modifying the full connectivity matrix of a recurrent network to
              train it to perform tasks involving temporally complex
              input/output transformations. The method introduces a second
              network during training to provide suitable ``target'' dynamics
              useful for performing the task. Because it exploits the full
              recurrent connectivity, the method produces networks that perform
              tasks with fewer neurons and greater noise robustness than
              traditional least-squares (FORCE) approaches. In addition, we
              show how introducing additional input signals into the
              target-generating network, which act as task hints, greatly
              extends the range of tasks that can be learned and provides
              control over the complexity and nature of the dynamics of the
              trained, task-performing network.",
  journal  = "PLoS One",
  volume   =  13,
  number   =  2,
  pages    = "e0191527",
  month    =  feb,
  year     =  2018,
  language = "en",
  issn     = "1932-6203",
  pmid     = "29415041",
  doi      = "10.1371/journal.pone.0191527",
  pmc      = "PMC5802861"
}

@ARTICLE{Athalye2019-gr,
  title    = "Neural reinforcement: re-entering and refining neural dynamics
              leading to desirable outcomes",
  author   = "Athalye, Vivek R and Carmena, Jose M and Costa, Rui M",
  abstract = "How do organisms learn to do again, on-demand, a behavior that
              led to a desirable outcome? Dopamine-dependent cortico-striatal
              plasticity provides a framework for learning behavior's value,
              but it is less clear how it enables the brain to re-enter desired
              behaviors and refine them over time. Reinforcing behavior is
              achieved by re-entering and refining the neural patterns that
              produce it. We review studies using brain-machine interfaces
              which reveal that reinforcing cortical population activity
              requires cortico-basal ganglia circuits. Then, we propose a
              formal framework for how reinforcement in cortico-basal ganglia
              circuits acts on the neural dynamics of cortical populations. We
              propose two parallel mechanisms: i) fast reinforcement which
              selects the inputs that permit the re-entrance of the particular
              cortical population dynamics which naturally produced the desired
              behavior, and ii) slower reinforcement which leads to refinement
              of cortical population dynamics and more reliable production of
              neural trajectories driving skillful behavior on-demand.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  60,
  pages    = "145--154",
  month    =  dec,
  year     =  2019,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "31877493",
  doi      = "10.1016/j.conb.2019.11.023"
}

@ARTICLE{Mante2013-yl,
  title    = "Context-dependent computation by recurrent dynamics in prefrontal
              cortex",
  author   = "Mante, Valerio and Sussillo, David and Shenoy, Krishna V and
              Newsome, William T",
  abstract = "Prefrontal cortex is thought to have a fundamental role in
              flexible, context-dependent behaviour, but the exact nature of
              the computations underlying this role remains largely unknown. In
              particular, individual prefrontal neurons often generate
              remarkably complex responses that defy deep understanding of
              their contribution to behaviour. Here we study prefrontal cortex
              activity in macaque monkeys trained to flexibly select and
              integrate noisy sensory inputs towards a choice. We find that the
              observed complexity and functional roles of single neurons are
              readily understood in the framework of a dynamical process
              unfolding at the level of the population. The population dynamics
              can be reproduced by a trained recurrent neural network, which
              suggests a previously unknown mechanism for selection and
              integration of task-relevant inputs. This mechanism indicates
              that selection and integration are two aspects of a single
              dynamical process unfolding within the same prefrontal circuits,
              and potentially provides a novel, general framework for
              understanding context-dependent computations.",
  journal  = "Nature",
  volume   =  503,
  number   =  7474,
  pages    = "78--84",
  month    =  nov,
  year     =  2013,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "24201281",
  doi      = "10.1038/nature12742",
  pmc      = "PMC4121670"
}

@ARTICLE{Werbos1990-qo,
  title    = "Backpropagation through time: what it does and how to do it",
  author   = "Werbos, P J",
  abstract = "Basic backpropagation, which is a simple method now being widely
              used in areas like pattern recognition and fault diagnosis, is
              reviewed. The basic equations for backpropagation through time,
              and applications to areas like pattern recognition involving
              dynamic systems, systems identification, and control are
              discussed. Further extensions of this method, to deal with
              systems other than neural networks, systems involving
              simultaneous equations, or true recurrent networks, and other
              practical issues arising with the method are described.
              Pseudocode is provided to clarify the algorithms. The chain rule
              for ordered derivatives-the theorem which underlies
              backpropagation-is briefly discussed. The focus is on designing a
              simpler version of backpropagation which can be translated into
              computer code and applied directly by neutral network users.",
  journal  = "Proc. IEEE",
  volume   =  78,
  number   =  10,
  pages    = "1550--1560",
  month    =  oct,
  year     =  1990,
  keywords = "identification;neural nets;pattern recognition;pseudocode;pattern
              recognition;fault diagnosis;backpropagation;systems
              identification;neural networks;Backpropagation;Artificial neural
              networks;Supervised learning;Pattern recognition;Neural
              networks;Power system modeling;Equations;Control systems;Fluid
              dynamics;Books",
  issn     = "1558-2256",
  doi      = "10.1109/5.58337"
}

@ARTICLE{Sussillo2013-ey,
  title     = "Opening the black box: low-dimensional dynamics in
               high-dimensional recurrent neural networks",
  author    = "Sussillo, David and Barak, Omri",
  abstract  = "Recurrent neural networks (RNNs) are useful tools for learning
               nonlinear relationships between time-varying inputs and outputs
               with complex temporal dependencies. Recently developed
               algorithms have been successful at training RNNs to perform a
               wide variety of tasks, but the resulting networks have been
               treated as black boxes: their mechanism of operation remains
               unknown. Here we explore the hypothesis that fixed points, both
               stable and unstable, and the linearized dynamics around them,
               can reveal crucial aspects of how RNNs implement their
               computations. Further, we explore the utility of linearization
               in areas of phase space that are not true fixed points but
               merely points of very slow movement. We present a simple
               optimization technique that is applied to trained RNNs to find
               the fixed and slow points of their dynamics. Linearization
               around these slow regions can be used to explore, or
               reverse-engineer, the behavior of the RNN. We describe the
               technique, illustrate it using simple examples, and finally
               showcase it on three high-dimensional RNN examples: a 3-bit
               flip-flop device, an input-dependent sine wave generator, and a
               two-point moving average. In all cases, the mechanisms of
               trained networks could be inferred from the sets of fixed and
               slow points and the linearized dynamics around them.",
  journal   = "Neural Comput.",
  publisher = "MIT Press",
  volume    =  25,
  number    =  3,
  pages     = "626--649",
  month     =  mar,
  year      =  2013,
  keywords  = "RNN",
  language  = "en",
  issn      = "0899-7667, 1530-888X",
  pmid      = "23272922",
  doi       = "10.1162/NECO\_a\_00409"
}

@ARTICLE{Shang2019-nm,
  title    = "A subcortical excitatory circuit for sensory-triggered predatory
              hunting in mice",
  author   = "Shang, Congping and Liu, Aixue and Li, Dapeng and Xie, Zhiyong
              and Chen, Zijun and Huang, Meizhu and Li, Yang and Wang, Yi and
              Shen, Wei L and Cao, Peng",
  abstract = "Predatory hunting plays a fundamental role in animal survival.
              Little is known about the neural circuits that convert sensory
              cues into neural signals to drive this behavior. Here we
              identified an excitatory subcortical neural circuit from the
              superior colliculus to the zona incerta that triggers predatory
              hunting. The superior colliculus neurons that form this pathway
              integrate motion-related visual and vibrissal somatosensory cues
              of prey. During hunting, these neurons send out neural signals
              that are temporally correlated with predatory attacks, but not
              with feeding after prey capture. Synaptic inactivation of this
              pathway selectively blocks hunting for prey without impairing
              other sensory-triggered behaviors. These data reveal a
              subcortical neural circuit that is specifically engaged in
              translating sensory cues into neural signals to provoke predatory
              hunting.",
  journal  = "Nat. Neurosci.",
  volume   =  22,
  number   =  6,
  pages    = "909--920",
  month    =  jun,
  year     =  2019,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "31127260",
  doi      = "10.1038/s41593-019-0405-4"
}

@UNPUBLISHED{Tyson2020-mq,
  title    = "A deep learning algorithm for {3D} cell detection in whole mouse
              brain image datasets",
  author   = "Tyson, Adam L and Rousseau, Charly V and Niedworok, Christian J
              and Keshavarzi, Sepiedeh and Tsitoura, Chryssanthi and Margrie,
              Troy W",
  abstract = "Understanding the function of the nervous system necessitates
              mapping the spatial distributions of its constituent cells
              defined by function, anatomy or gene expression. Recently,
              developments in tissue preparation and microscopy allow cellular
              populations to be imaged throughout the entire rodent brain.
              However, mapping these neurons manually is prone to bias and is
              often impractically time consuming. Here we present an
              open-source algorithm for fully automated 3D detection of
              neuronal somata in mouse whole-brain microscopy images using
              standard desktop computer hardware. We demonstrate the
              applicability and power of our approach by mapping the brain-wide
              locations of large populations of cells labeled with cytoplasmic
              fluorescent proteins expressed via retrograde trans-synaptic
              viral infection. \#\#\# Competing Interest Statement The authors
              have declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2020.10.21.348771",
  month    =  oct,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.10.21.348771"
}

@MISC{noauthor_undated-dh,
  title = "Two wheeled robot thesis chapter from some gui"
}

@ARTICLE{Bates2020-fa,
  title    = "The natverse, a versatile toolbox for combining and analysing
              neuroanatomical data",
  author   = "Bates, Alexander Shakeel and Manton, James D and Jagannathan,
              Sridhar R and Costa, Marta and Schlegel, Philipp and Rohlfing,
              Torsten and Jefferis, Gregory Sxe",
  abstract = "To analyse neuron data at scale, neuroscientists expend
              substantial effort reading documentation, installing dependencies
              and moving between analysis and visualisation environments. To
              facilitate this, we have developed a suite of interoperable
              open-source R packages called the natverse. The natverse allows
              users to read local and remote data, perform popular analyses
              including visualisation and clustering and graph-theoretic
              analysis of neuronal branching. Unlike most tools, the natverse
              enables comparison across many neurons of morphology and
              connectivity after imaging or co-registration within a common
              template space. The natverse also enables transformations between
              different template spaces and imaging modalities. We demonstrate
              tools that integrate the vast majority of Drosophila
              neuroanatomical light microscopy and electron microscopy
              connectomic datasets. The natverse is an easy-to-use environment
              for neuroscientists to solve complex, large-scale analysis
              challenges as well as an open platform to create new code and
              packages to share with the community.",
  journal  = "Elife",
  volume   =  9,
  month    =  apr,
  year     =  2020,
  keywords = "D. melanogaster; analysis software; computational biology;
              connectomics; mouse; neural circuits; neuroanatomy; neuronal
              morphology; neuroscience; open-source; systems biology; zebrafish",
  language = "en",
  issn     = "2050-084X",
  pmid     = "32286229",
  doi      = "10.7554/eLife.53350",
  pmc      = "PMC7242028"
}

@ARTICLE{Rigotti2013-ls,
  title    = "The importance of mixed selectivity in complex cognitive tasks",
  author   = "Rigotti, Mattia and Barak, Omri and Warden, Melissa R and Wang,
              Xiao-Jing and Daw, Nathaniel D and Miller, Earl K and Fusi,
              Stefano",
  abstract = "Single-neuron activity in the prefrontal cortex (PFC) is tuned to
              mixtures of multiple task-related aspects. Such mixed selectivity
              is highly heterogeneous, seemingly disordered and therefore
              difficult to interpret. We analysed the neural activity recorded
              in monkeys during an object sequence memory task to identify a
              role of mixed selectivity in subserving the cognitive functions
              ascribed to the PFC. We show that mixed selectivity neurons
              encode distributed information about all task-relevant aspects.
              Each aspect can be decoded from the population of neurons even
              when single-cell selectivity to that aspect is eliminated.
              Moreover, mixed selectivity offers a significant computational
              advantage over specialized responses in terms of the repertoire
              of input-output functions implementable by readout neurons. This
              advantage originates from the highly diverse nonlinear
              selectivity to mixtures of task-relevant variables, a signature
              of high-dimensional neural representations. Crucially, this
              dimensionality is predictive of animal behaviour as it collapses
              in error trials. Our findings recommend a shift of focus for
              future studies from neurons that have easily interpretable
              response tuning to the widely observed, but rarely analysed,
              mixed selectivity neurons.",
  journal  = "Nature",
  volume   =  497,
  number   =  7451,
  pages    = "585--590",
  month    =  may,
  year     =  2013,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "23685452",
  doi      = "10.1038/nature12160",
  pmc      = "PMC4412347"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Spellman2015-qp,
  title     = "Hippocampal--prefrontal input supports spatial encoding in
               working memory",
  author    = "Spellman, T and Rigotti, M and Ahmari, S E and Fusi, S and
               Gogos, J A and {others}",
  abstract  = "Spatial working memory, the caching of behaviourally relevant
               spatial cues on a timescale of seconds, is a fundamental
               constituent of cognition. Although the prefrontal cortex and
               hippocampus are known to contribute jointly to successful
               spatial working memory, the …",
  journal   = "Nature",
  publisher = "nature.com",
  year      =  2015,
  issn      = "0028-0836"
}

@ARTICLE{Stringer2019-nc,
  title    = "High-dimensional geometry of population responses in visual
              cortex",
  author   = "Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas
              and Carandini, Matteo and Harris, Kenneth D",
  abstract = "A neuronal population encodes information most efficiently when
              its stimulus responses are high-dimensional and uncorrelated, and
              most robustly when they are lower-dimensional and correlated.
              Here we analysed the dimensionality of the encoding of natural
              images by large populations of neurons in the visual cortex of
              awake mice. The evoked population activity was high-dimensional,
              and correlations obeyed an unexpected power law: the nth
              principal component variance scaled as 1/n. This scaling was not
              inherited from the power law spectrum of natural images, because
              it persisted after stimulus whitening. We proved mathematically
              that if the variance spectrum was to decay more slowly then the
              population code could not be smooth, allowing small changes in
              input to dominate population activity. The theory also predicts
              larger power-law exponents for lower-dimensional stimulus
              ensembles, which we validated experimentally. These results
              suggest that coding smoothness may represent a fundamental
              constraint that determines correlations in neural population
              codes.",
  journal  = "Nature",
  volume   =  571,
  number   =  7765,
  pages    = "361--365",
  month    =  jul,
  year     =  2019,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "31243367",
  doi      = "10.1038/s41586-019-1346-5",
  pmc      = "PMC6642054"
}

@ARTICLE{Stringer2019-fm,
  title    = "Spontaneous behaviors drive multidimensional, brainwide activity",
  author   = "Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas
              and Reddy, Charu Bai and Carandini, Matteo and Harris, Kenneth D",
  abstract = "Neuronal populations in sensory cortex produce variable responses
              to sensory stimuli and exhibit intricate spontaneous activity
              even without external sensory input. Cortical variability and
              spontaneous activity have been variously proposed to represent
              random noise, recall of prior experience, or encoding of ongoing
              behavioral and cognitive variables. Recording more than 10,000
              neurons in mouse visual cortex, we observed that spontaneous
              activity reliably encoded a high-dimensional latent state, which
              was partially related to the mouse's ongoing behavior and was
              represented not just in visual cortex but also across the
              forebrain. Sensory inputs did not interrupt this ongoing signal
              but added onto it a representation of external stimuli in
              orthogonal dimensions. Thus, visual cortical population activity,
              despite its apparently noisy structure, reliably encodes an
              orthogonal fusion of sensory and multidimensional behavioral
              information.",
  journal  = "Science",
  volume   =  364,
  number   =  6437,
  pages    = "255",
  month    =  apr,
  year     =  2019,
  language = "en",
  issn     = "0036-8075, 1095-9203",
  pmid     = "31000656",
  doi      = "10.1126/science.aav7893",
  pmc      = "PMC6525101"
}

@ARTICLE{Krumin2018-yz,
  title    = "Decision and navigation in mouse parietal cortex",
  author   = "Krumin, Michael and Lee, Julie J and Harris, Kenneth D and
              Carandini, Matteo",
  abstract = "Posterior parietal cortex (PPC) has been implicated in
              navigation, in the control of movement, and in visually-guided
              decisions. To relate these views, we measured activity in PPC
              while mice performed a virtual navigation task driven by visual
              decisions. PPC neurons were selective for specific combinations
              of the animal's spatial position and heading angle. This
              selectivity closely predicted both the activity of individual PPC
              neurons, and the arrangement of their collective firing patterns
              in choice-selective sequences. These sequences reflected PPC
              encoding of the animal's navigation trajectory. Using decision as
              a predictor instead of heading yielded worse fits, and using it
              in addition to heading only slightly improved the fits.
              Alternative models based on visual or motor variables were
              inferior. We conclude that when mice use vision to choose their
              trajectories, a large fraction of parietal cortex activity can be
              predicted from simple attributes such as spatial position and
              heading.",
  journal  = "Elife",
  volume   =  7,
  month    =  nov,
  year     =  2018,
  keywords = "cortex; decision; mouse; navigation; neuroscience; visual
              processing",
  language = "en",
  issn     = "2050-084X",
  pmid     = "30468146",
  doi      = "10.7554/eLife.42583",
  pmc      = "PMC6300355"
}

@BOOK{Aston_Zhang_Zachary_C_Lipton_Mu_Li_and_Alexander_J_Smola_undated-lf,
  title    = "Dive into Deep Learning",
  author   = "{Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola}",
  keywords = "books"
}

@ARTICLE{Hanwell2015-wl,
  title    = "The Visualization Toolkit ({VTK)}: Rewriting the rendering code
              for modern graphics cards",
  author   = "Hanwell, Marcus D and Martin, Kenneth M and Chaudhary, Aashish
              and Avila, Lisa S",
  abstract = "The Visualization Toolkit (VTK) is an open source, permissively
              licensed, cross-platform toolkit for scientific data processing,
              visualization, and data analysis. It is over two decades old,
              originally developed for a very different graphics card
              architecture. Modern graphics cards feature fully programmable,
              highly parallelized architectures with large core counts. VTK's
              rendering code was rewritten to take advantage of modern graphics
              cards, maintaining most of the toolkit's programming interfaces.
              This offers the opportunity to compare the performance of old and
              new rendering code on the same systems/cards. Significant
              improvements in rendering speeds and memory footprints mean that
              scientific data can be visualized in greater detail than ever
              before. The widespread use of VTK means that these improvements
              will reap significant benefits.",
  journal  = "SoftwareX",
  volume   = "1-2",
  pages    = "9--12",
  month    =  sep,
  year     =  2015,
  keywords = "Visualization; Toolkit; Data analysis; Scientific data",
  issn     = "2352-7110",
  doi      = "10.1016/j.softx.2015.04.001"
}

@ARTICLE{Grillner2002-si,
  title    = "Cellular bases of a vertebrate locomotor system-steering,
              intersegmental and segmental co-ordination and sensory control",
  author   = "Grillner, Sten and Wall{\'e}n, Peter",
  abstract = "The isolated brainstem-spinal cord of the lamprey is used as an
              experimental model in the analysis of the cellular bases of
              vertebrate locomotor behaviour. In this article we review the
              neural mechanisms involved in the control of steering,
              intersegmental co-ordination, as well as the segmental burst
              generation and the sensory contribution to motor pattern
              generation. Within these four components of the control system
              for locomotion, we now have good knowledge of not only the
              neurones that take part and their synaptic interactions, but also
              the membrane properties of these neurones, including ion channel
              subtypes, and their contribution to motor pattern generation.",
  journal  = "Brain Res. Brain Res. Rev.",
  volume   =  40,
  number   = "1-3",
  pages    = "92--106",
  month    =  oct,
  year     =  2002,
  keywords = "Locomotion",
  language = "en",
  pmid     = "12589909",
  doi      = "10.1016/s0165-0173(02)00193-5"
}

@ARTICLE{Mobbs2020-vp,
  title     = "Space, Time, and Fear: Survival Computations along Defensive
               Circuits",
  author    = "Mobbs, Dean and Headley, Drew B and Ding, Weilun and Dayan,
               Peter",
  abstract  = "Naturalistic observations show that decisions to avoid or escape
               predators occur at different spatiotemporal scales and that they
               are supported by different computations and neural circuits. At
               their extremes, proximal threats are addressed by a limited
               repertoire of reflexive and myopic actions, reflecting reduced
               decision and state spaces and model-free (MF) architectures.
               Conversely, distal threats allow increased information
               processing supported by model-based (MB) operations, including
               affective prospection, replay, and planning. However, MF and MB
               computations are often intertwined, and under conditions of
               safety the foundations for future effective reactive execution
               can be laid through MB instruction of MF control. Together,
               these computations are associated with distinct population codes
               embedded within a distributed defensive circuitry whose goal is
               to determine and realize the best policy.",
  journal   = "Trends Cogn. Sci.",
  publisher = "Elsevier",
  volume    =  0,
  number    =  0,
  month     =  feb,
  year      =  2020,
  keywords  = "fear; anxiety; threat imminence continuum; periaqueductal gray;
               hippocampus; prefrontal cortex; model free; model based; Dyna",
  language  = "en",
  issn      = "1364-6613, 1879-307X",
  doi       = "10.1016/j.tics.2019.12.016"
}

@ARTICLE{Barabasi2019-ou,
  title    = "A Genetic Model of the Connectome",
  author   = "Barab{\'a}si, D{\'a}niel L and Barab{\'a}si,
              Albert-L{\'a}szl{\'o}",
  abstract = "The connectomes of organisms of the same species show remarkable
              architectural and often local wiring similarity, raising the
              question: where and how is neuronal connectivity encoded? Here,
              we start from the hypothesis that the genetic identity of neurons
              guides synapse and gap-junction formation and show that such
              genetically driven wiring predicts the existence of specific
              biclique motifs in the connectome. We identify a family of large,
              statistically significant biclique subgraphs in the connectomes
              of three species and show that within many of the observed
              bicliques the neurons share statistically significant expression
              patterns and morphological characteristics, supporting our
              expectation of common genetic factors that drive the synapse
              formation within these subgraphs. The proposed connectome model
              offers a self-consistent framework to link the genetics of an
              organism to the reproducible architecture of its connectome,
              offering experimentally falsifiable predictions on the genetic
              factors that drive the formation of individual neuronal circuits.",
  journal  = "Neuron",
  month    =  nov,
  year     =  2019,
  keywords = "Brain Networks; C. elegans; Connectomics; Generative Model;
              Theory; development; encoding",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "31806491",
  doi      = "10.1016/j.neuron.2019.10.031"
}

@ARTICLE{Mendes-Gomes2020-de,
  title    = "Defensive behaviors and brain regional activation changes in rats
              confronting a snake",
  author   = "Mendes-Gomes, Joyce and Motta, Simone Cristina and Passoni Bindi,
              Ricardo and de Oliveira, Amanda Ribeiro and Ullah, Farhad and
              Baldo, Marcus Vinicius C and Coimbra, Norberto Cysne and
              Canteras, Newton Sabino and Blanchard, D Caroline",
  abstract = "In the present study, we examined behavioral and brain regional
              activation changes of rats). To a nonmammalian predator, a wild
              rattler snake (Crotalus durissus terrificus). Accordingly, during
              snake threat, rat subjects showed a striking and highly
              significant behavioral response of freezing, stretch attend, and,
              especially, spatial avoidance of this threat. The brain regional
              activation patterns for these rats were in broad outline similar
              to those of rats encountering other predator threats, showing Fos
              activation of sites in the amygdala, hypothalamus, and
              periaqueductal gray matter. In the amygdala, only the lateral
              nucleus showed significant activation, although the medial
              nucleus, highly responsive to olfaction, also showed higher
              activation. Importantly, the hypothalamus, in particular, was
              somewhat different, with significant Fos increases in the
              anterior and central parts of the ventromedial hypothalamic
              nucleus (VMH), in contrast to patterns of enhanced Fos expression
              in the dorsomedial VMH to cat predators, and in the ventrolateral
              VMH to an attacking conspecific. In addition, the
              juxtodorsalmedial region of the lateral hypothalamus showed
              enhanced Fos activation, where inputs from the septo-hippocampal
              system may suggest the potential involvement of hippocampal
              boundary cells in the very strong spatial avoidance of the snake
              and the area it occupied. Notably, these two hypothalamic paths
              appear to merge into the dorsomedial part of the dorsal
              premammillary nucleus and dorsomedial and lateral parts of the
              periaqueductal gray, all of which present significant increases
              in Fos expression and are likely to be critical for the
              expression of defensive behaviors in responses to the snake
              threat.",
  journal  = "Behav. Brain Res.",
  volume   =  381,
  pages    = "112469",
  month    =  mar,
  year     =  2020,
  keywords = "Amygdala; Antipredatory defense; Hippocampus; Hypothalamus;
              Periaqueductal gray; Prey versus rattlesnake confrontation
              paradigm",
  language = "en",
  issn     = "0166-4328, 1872-7549",
  pmid     = "31917239",
  doi      = "10.1016/j.bbr.2020.112469"
}

@ARTICLE{Hasson2020-zv,
  title     = "Direct Fit to Nature: An Evolutionary Perspective on Biological
               and Artificial Neural Networks",
  author    = "Hasson, Uri and Nastase, Samuel A and Goldstein, Ariel",
  abstract  = "SummaryEvolution is a blind fitting process by which organisms
               become adapted to their environment. Does the brain use similar
               brute-force fitting processes to learn how to perceive and act
               upon the world? Recent advances in artificial neural networks
               have exposed the power of optimizing millions of synaptic
               weights over millions of observations to operate robustly in
               real-world contexts. These models do not learn simple,
               human-interpretable rules or representations of the world;
               rather, they use local computations to interpolate over
               task-relevant manifolds in a high-dimensional parameter space.
               Counterintuitively, similar to evolutionary processes,
               over-parameterized models can be simple and parsimonious, as
               they provide a versatile, robust solution for learning a diverse
               set of functions. This new family of direct-fit models present a
               radical challenge to many of the theoretical assumptions in
               psychology and neuroscience. At the same time, this shift in
               perspective establishes unexpected links with developmental and
               ecological psychology.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  105,
  number    =  3,
  pages     = "416--434",
  month     =  feb,
  year      =  2020,
  keywords  = "evolution; experimental design; interpolation; learning; neural
               networks",
  language  = "en",
  issn      = "0896-6273",
  doi       = "10.1016/j.neuron.2019.12.002"
}

@UNPUBLISHED{Guitchounts2020-xj,
  title    = "Encoding of {3D} Head Orienting Movements in Primary Visual
              Cortex",
  author   = "Guitchounts, Grigori and Masis, Javier and Wolff, Steffen B E and
              Cox, David",
  abstract = "Animals actively sample from the sensory world by generating
              complex patterns of movement that evolve in three dimensions. At
              least some of these movements have been shown to influence neural
              codes in sensory areas. For example, in primary visual cortex
              (V1), locomotion-related neural activity influences sensory gain,
              encodes running speed, and predicts the direction of visual flow.
              As most experiments exploring movement-related modulation of V1
              have been performed in head-fixed animals, it remains unclear
              whether or how the naturalistic movements used to interact with
              sensory stimuli--like head orienting--influence visual
              processing. Here we show that 3D head orienting movements
              modulate V1 neuronal activity in a direction-specific manner that
              also depends on the presence or absence of light. We identify two
              largely independent populations of movement-direction-tuned
              neurons that support this modulation, one of which is
              direction-tuned in the dark and the other in the light. Finally,
              we demonstrate that V1 gains access to a motor efference copy
              related to orientation from secondary motor cortex, which has
              been shown to control head orienting movements. These results
              suggest a mechanism through which sensory signals generated by
              purposeful movement can be distinguished from those arising in
              the outside world, and reveal a pervasive role of 3D movement in
              shaping sensory cortical dynamics.",
  journal  = "bioRxiv",
  pages    = "2020.01.16.909473",
  month    =  jan,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.01.16.909473"
}

@ARTICLE{Kaplan2019-zb,
  title    = "Nested Neuronal Dynamics Orchestrate a Behavioral Hierarchy
              across Timescales",
  author   = "Kaplan, Harris S and Salazar Thula, Oriana and Khoss, Niklas and
              Zimmer, Manuel",
  abstract = "Classical and modern ethological studies suggest that animal
              behavior is organized hierarchically across timescales, such that
              longer-timescale behaviors are composed of specific
              shorter-timescale actions. Despite progress relating neuronal
              dynamics to single-timescale behavior, it remains unclear how
              different timescale dynamics interact to give rise to such
              higher-order behavioral organization. Here, we show, in the
              nematode Caenorhabditis elegans, that a behavioral hierarchy
              spanning three timescales is implemented by nested neuronal
              dynamics. At the uppermost hierarchical level, slow neuronal
              population dynamics spanning brain and motor periphery control
              two faster motor neuron oscillations, toggling them between
              different activity states and functional roles. At lower
              hierarchical levels, these faster oscillations are further nested
              in a manner that enables flexible behavioral control in an
              otherwise rigid hierarchical framework. Our findings establish
              nested neuronal activity patterns as a repeated dynamical motif
              of the C. elegans nervous system, which together implement a
              controllable hierarchical organization of behavior.",
  journal  = "Neuron",
  month    =  nov,
  year     =  2019,
  keywords = "C. elegans neuroscience; behavior organization; behavioral
              hierarchy; ethology; hierarchical organization; motor control;
              neuronal dynamics; neuronal oscillations; quantitative behavior;
              whole-brain imaging",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "31786012",
  doi      = "10.1016/j.neuron.2019.10.037"
}

@ARTICLE{Niedworok2016-wj,
  title    = "{aMAP} is a validated pipeline for registration and segmentation
              of high-resolution mouse brain data",
  author   = "Niedworok, Christian J and Brown, Alexander P Y and Jorge
              Cardoso, M and Osten, Pavel and Ourselin, Sebastien and Modat,
              Marc and Margrie, Troy W",
  abstract = "The validation of automated image registration and segmentation
              is crucial for accurate and reliable mapping of brain
              connectivity and function in three-dimensional (3D) data sets.
              While validation standards are necessarily high and routinely met
              in the clinical arena, they have to date been lacking for
              high-resolution microscopy data sets obtained from the rodent
              brain. Here we present a tool for optimized automated mouse atlas
              propagation (aMAP) based on clinical registration software
              (NiftyReg) for anatomical segmentation of high-resolution 3D
              fluorescence images of the adult mouse brain. We empirically
              evaluate aMAP as a method for registration and subsequent
              segmentation by validating it against the performance of expert
              human raters. This study therefore establishes a benchmark
              standard for mapping the molecular function and cellular
              connectivity of the rodent brain.",
  journal  = "Nat. Commun.",
  volume   =  7,
  pages    = "11879",
  month    =  jul,
  year     =  2016,
  language = "en",
  issn     = "2041-1723",
  pmid     = "27384127",
  doi      = "10.1038/ncomms11879",
  pmc      = "PMC4941048"
}

@ARTICLE{Muller2015-ws,
  title    = "Python in neuroscience",
  author   = "Muller, Eilif and Bednar, James A and Diesmann, Markus and
              Gewaltig, Marc-Oliver and Hines, Michael and Davison, Andrew P",
  journal  = "Front. Neuroinform.",
  volume   =  9,
  pages    = "11",
  month    =  apr,
  year     =  2015,
  keywords = "collaboration; interoperability; python language; scientific
              computing; software development",
  language = "en",
  issn     = "1662-5196",
  pmid     = "25926788",
  doi      = "10.3389/fninf.2015.00011",
  pmc      = "PMC4396193"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ascoli2007-hp,
  title     = "{NeuroMorpho.Org}: a central resource for neuronal morphologies",
  author    = "Ascoli, Giorgio A and Donohue, Duncan E and Halavi, Maryam",
  abstract  = "The structure of dendrites and axons plays fundamental roles in
               synaptic integration and network connectivity. Synergistic
               advances in neurobiology (eg, intracellular injections,
               fluorescent protein expression), microscopy (eg, multiphoton
               laser scanning, computer controllers), and imaging software (eg,
               Neurolucida tracing, blind deconvolution) are rapidly
               transforming the three-dimensional (3D) reconstruction of
               neuronal morphology into a mainstream technique. In the course
               of electrophysiological, pharmacological, or …",
  journal   = "J. Neurosci.",
  publisher = "Soc Neuroscience",
  volume    =  27,
  number    =  35,
  pages     = "9247--9251",
  month     =  aug,
  year      =  2007,
  language  = "en",
  issn      = "0270-6474, 1529-2401",
  pmid      = "17728438",
  doi       = "10.1523/JNEUROSCI.2055-07.2007",
  pmc       = "PMC6673130"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Maaten2008-tv,
  title     = "Visualizing Data using {t-SNE}",
  author    = "Maaten, Laurens van der and Hinton, Geoffrey",
  abstract  = "We present a new technique called`` t-SNE'' that visualizes
               high-dimensional data by giving each datapoint a location in a
               two or three-dimensional map. The technique is a variation of
               Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is
               much easier to optimize …",
  journal   = "J. Mach. Learn. Res.",
  publisher = "jmlr.org",
  volume    =  9,
  number    = "Nov",
  pages     = "2579--2605",
  year      =  2008,
  issn      = "1532-4435, 1533-7928"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INCOLLECTION{Belkin2002-ei,
  title     = "Laplacian Eigenmaps and Spectral Techniques for Embedding and
               Clustering",
  booktitle = "Advances in Neural Information Processing Systems 14",
  author    = "Belkin, Mikhail and Niyogi, Partha",
  editor    = "Dietterich, T G and Becker, S and Ghahramani, Z",
  abstract  = "Drawing on the correspondence between the graph Laplacian, the
               Laplace-Beltrami operator on a manifold, and the connections to
               the heat equation, we propose a geometrically motivated
               algorithm for constructing a representation for data sampled
               from a low dimensional manifold embedded in a higher dimensional
               space. The algorithm provides a computationally efficient
               approach to nonlinear dimensionality reduction that has locality
               preserving properties and a natural connection to clustering.
               Several applications are …",
  publisher = "MIT Press",
  pages     = "585--591",
  year      =  2002
}

@ARTICLE{Kuwabara2020-qm,
  title    = "Neural mechanisms of economic choices in mice",
  author   = "Kuwabara, Masaru and Kang, Ningdong and Holy, Timothy E and
              Padoa-Schioppa, Camillo",
  abstract = "Economic choices entail computing and comparing subjective
              values. Evidence from primates indicates that this behavior
              relies on the orbitofrontal cortex. Conversely, previous work in
              rodents provided conflicting results. Here we present a mouse
              model of economic choice behavior, and we show that the lateral
              orbital (LO) area is intimately related to the decision process.
              In the experiments, mice chose between different juices offered
              in variable amounts. Choice patterns closely resembled those
              measured in primates. Optogenetic inactivation of LO dramatically
              disrupted choices by inducing erratic changes of relative value
              and by increasing choice variability. Neuronal recordings
              revealed that different groups of cells encoded the values of
              individual options, the binary choice outcome and the chosen
              value. These groups match those previously identified in
              primates, except that the neuronal representation in mice is
              spatial (in monkeys it is good-based). Our results lay the
              foundations for a circuit-level analysis of economic decisions.",
  journal  = "Elife",
  volume   =  9,
  month    =  feb,
  year     =  2020,
  keywords = "mouse; neuroscience",
  language = "en",
  issn     = "2050-084X",
  pmid     = "32096761",
  doi      = "10.7554/eLife.49669"
}

@ARTICLE{Kobak2019-se,
  title     = "The art of using {t-SNE} for single-cell transcriptomics",
  author    = "Kobak, Dmitry and Berens, Philipp",
  abstract  = "Single-cell transcriptomics yields ever growing data sets
               containing RNA expression levels for thousands of genes from up
               to millions of cells. Common data analysis pipelines include a
               dimensionality reduction step for visualising the data in two
               dimensions, most frequently performed using t-distributed
               stochastic neighbour embedding (t-SNE). It excels at revealing
               local structure in high-dimensional data, but naive applications
               often suffer from severe shortcomings, e.g. the global structure
               of the data is not represented accurately. Here we describe how
               to circumvent such pitfalls, and develop a protocol for creating
               more faithful t-SNE visualisations. It includes PCA
               initialisation, a high learning rate, and multi-scale similarity
               kernels; for very large data sets, we additionally use
               exaggeration and downsampling-based initialisation. We use
               published single-cell RNA-seq data sets to demonstrate that this
               protocol yields superior results compared to the naive
               application of t-SNE.",
  journal   = "Nat. Commun.",
  publisher = "nature.com",
  volume    =  10,
  number    =  1,
  pages     = "5416",
  month     =  nov,
  year      =  2019,
  language  = "en",
  issn      = "2041-1723",
  pmid      = "31780648",
  doi       = "10.1038/s41467-019-13056-x",
  pmc       = "PMC6882829"
}

@ARTICLE{McInnes2018-dg,
  title         = "{UMAP}: Uniform Manifold Approximation and Projection for
                   Dimension Reduction",
  author        = "McInnes, Leland and Healy, John and Melville, James",
  abstract      = "UMAP (Uniform Manifold Approximation and Projection) is a
                   novel manifold learning technique for dimension reduction.
                   UMAP is constructed from a theoretical framework based in
                   Riemannian geometry and algebraic topology. The result is a
                   practical scalable algorithm that applies to real world
                   data. The UMAP algorithm is competitive with t-SNE for
                   visualization quality, and arguably preserves more of the
                   global structure with superior run time performance.
                   Furthermore, UMAP has no computational restrictions on
                   embedding dimension, making it viable as a general purpose
                   dimension reduction technique for machine learning.",
  month         =  feb,
  year          =  2018,
  archivePrefix = "arXiv",
  eprint        = "1802.03426",
  primaryClass  = "stat.ML",
  arxivid       = "1802.03426"
}

@UNPUBLISHED{Liu2020-pe,
  title    = "Accurate localization of linear probe electrodes across multiple
              brains",
  author   = "Liu, Liu D and Chen, Susu and Economo, Michael N and Li, Nuo and
              Svoboda, Karel",
  abstract = "Recently developed silicon probes have large numbers of recording
              electrodes on long linear shanks. Specifically, Neuropixels
              probes have 960 recording electrodes distributed over 9.6 mm
              shanks. Because of their length, Neuropixels probe recordings in
              rodents naturally span multiple brain areas. Typical studies
              collate recordings across several recording sessions and animals.
              Neurons recorded in different sessions and animals have to be
              aligned to each other and to a standardized brain coordinate
              system. Here we report a workflow for accurate localization of
              individual electrodes in standardized coordinates and aligned
              across individual brains. This workflow relies on imaging brains
              with fluorescent probe tracks and warping 3-dimensional image
              stacks to standardized brain atlases. Electrophysiological
              features are then used to anchor particular electrodes along the
              reconstructed tracks to specific locations in the brain atlas and
              therefore to specific brain structures. We performed ground-truth
              experiments, in which motor cortex outputs are labelled with ChR2
              and a fluorescence protein. Recording from brain regions targeted
              by these outputs reveals better than 100 $\mu$m accuracy for
              electrode localization.",
  journal  = "bioRxiv",
  pages    = "2020.02.25.965210",
  month    =  feb,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.02.25.965210"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Balasubramanian2002-ly,
  title     = "The isomap algorithm and topological stability",
  author    = "Balasubramanian, Mukund and Schwartz, Eric L",
  abstract  = "Tenenbaum et al.(1) presented an algorithm, Isomap , for
               computing a quasi-isometric, low- dimensional embedding of a set
               of high-dimensional data points. Two issues need to be raised
               concerning this work. First, the basic approach presented by
               Tenenbaum et al. is not …",
  journal   = "Science",
  publisher = "science.sciencemag.org",
  volume    =  295,
  number    =  5552,
  pages     = "7",
  month     =  jan,
  year      =  2002,
  language  = "en",
  issn      = "0036-8075",
  pmid      = "11778013",
  doi       = "10.1126/science.295.5552.7a"
}

@ARTICLE{Zhou2018-fo,
  title    = "Efficient and accurate extraction of in vivo calcium signals from
              microendoscopic video data",
  author   = "Zhou, Pengcheng and Resendez, Shanna L and Rodriguez-Romaguera,
              Jose and Jimenez, Jessica C and Neufeld, Shay Q and Giovannucci,
              Andrea and Friedrich, Johannes and Pnevmatikakis, Eftychios A and
              Stuber, Garret D and Hen, Rene and Kheirbek, Mazen A and
              Sabatini, Bernardo L and Kass, Robert E and Paninski, Liam",
  abstract = "In vivo calcium imaging through microendoscopic lenses enables
              imaging of previously inaccessible neuronal populations deep
              within the brains of freely moving animals. However, it is
              computationally challenging to extract single-neuronal activity
              from microendoscopic data, because of the very large background
              fluctuations and high spatial overlaps intrinsic to this
              recording modality. Here, we describe a new constrained matrix
              factorization approach to accurately separate the background and
              then demix and denoise the neuronal signals of interest. We
              compared the proposed method against previous independent
              components analysis and constrained nonnegative matrix
              factorization approaches. On both simulated and experimental data
              recorded from mice, our method substantially improved the quality
              of extracted cellular signals and detected more well-isolated
              neural signals, especially in noisy data regimes. These advances
              can in turn significantly enhance the statistical power of
              downstream analyses, and ultimately improve scientific
              conclusions derived from microendoscopic data.",
  journal  = "Elife",
  volume   =  7,
  month    =  feb,
  year     =  2018,
  keywords = "calcium imaging; microendoscope; mouse; neuroscience; source
              extraction",
  language = "en",
  issn     = "2050-084X",
  pmid     = "29469809",
  doi      = "10.7554/eLife.28728",
  pmc      = "PMC5871355"
}

@ARTICLE{Becht2018-hp,
  title     = "Dimensionality reduction for visualizing single-cell data using
               {UMAP}",
  author    = "Becht, Etienne and McInnes, Leland and Healy, John and Dutertre,
               Charles-Antoine and Kwok, Immanuel W H and Ng, Lai Guan and
               Ginhoux, Florent and Newell, Evan W",
  abstract  = "Advances in single-cell technologies have enabled
               high-resolution dissection of tissue composition. Several tools
               for dimensionality reduction are available to analyze the large
               number of parameters generated in single-cell studies. Recently,
               a nonlinear dimensionality-reduction technique, uniform manifold
               approximation and projection (UMAP), was developed for the
               analysis of any type of high-dimensional data. Here we apply it
               to biological data, using three well-characterized mass
               cytometry and single-cell RNA sequencing datasets. Comparing the
               performance of UMAP with five other tools, we find that UMAP
               provides the fastest run times, highest reproducibility and the
               most meaningful organization of cell clusters. The work
               highlights the use of UMAP for improved visualization and
               interpretation of single-cell data.",
  journal   = "Nat. Biotechnol.",
  publisher = "nature.com",
  month     =  dec,
  year      =  2018,
  language  = "en",
  issn      = "1087-0156, 1546-1696",
  pmid      = "30531897",
  doi       = "10.1038/nbt.4314"
}

@UNPUBLISHED{Essig2020-br,
  title    = "Inhibitory midbrain neurons mediate decision making",
  author   = "Essig, Jaclyn and Hunt, Joshua B and Felsen, Gidon",
  abstract = "Decision making is critical for survival but its neural basis is
              unclear. Here we examine how functional neural circuitry in the
              output layers of the midbrain superior colliculus (SC) mediates
              spatial choice, an SC-dependent tractable form of decision
              making. We focus on the role of inhibitory SC neurons, using
              optogenetics to record and manipulate their activity in behaving
              mice. Based on data from SC slice experiments and on a canonical
              role of inhibitory neurons in cortical microcircuits, we
              hypothesized that inhibitory SC neurons locally inhibit premotor
              output neurons that represent contralateral targets. However, our
              experimental results refuted this hypothesis. An attractor model
              revealed that our results were instead consistent with inhibitory
              neurons providing long-range inhibition between the two SCs, and
              terminal activation experiments supported this architecture. Our
              study provides mechanistic evidence for competitive inhibition
              between populations representing discrete choices, a common motif
              in theoretical models of decision making.",
  journal  = "bioRxiv",
  pages    = "2020.02.25.965699",
  month    =  feb,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.02.25.965699"
}

@ARTICLE{Doykos2020-or,
  title     = "Monosynaptic inputs to specific cell types of the intermediate
               and deep layers of the superior colliculus",
  author    = "Doykos, Ted K and Gilmer, Jesse I and Person, Abigail L and
               Felsen, Gidon",
  abstract  = "The intermediate and deep layers of the midbrain superior
               colliculus (SC) are a key locus for several critical functions,
               including spatial attention, multisensory integration, and
               behavioral responses. While the SC is known to integrate input
               from a variety of brain regions, progress in understanding how
               these inputs contribute to SC-dependent functions has been
               hindered by the paucity of data on innervation patterns to
               specific types of SC neurons. Here, we use G-deleted rabies
               virus-mediated monosynaptic tracing to identify inputs to
               excitatory and inhibitory neurons of the intermediate and deep
               SC. We observed stronger and more numerous projections to
               excitatory than inhibitory SC neurons. However, a subpopulation
               of excitatory neurons thought to mediate behavioral output
               received weaker inputs, from far fewer brain regions, than the
               overall population of excitatory neurons. Additionally,
               extrinsic inputs tended to target rostral excitatory and
               inhibitory SC neurons more strongly than their caudal
               counterparts, and commissural SC neurons tended to project to
               similar rostrocaudal positions in the other SC. Our findings
               support the view that active intrinsic processes are critical to
               SC-dependent functions, and will enable the examination of how
               specific inputs contribute to these functions.",
  journal   = "J. Comp. Neurol.",
  publisher = "Wiley Online Library",
  month     =  feb,
  year      =  2020,
  keywords  = "RRIDs: FIJI software: SCR\_002285; RRIDs: ImageJ software:
               SCR\_003070; RRIDs: Jackson labs heterozygous Gad2-Cre mice:
               IMSR\_JAX:010802; RRIDs: Jackson labs homozygous Vglut2-Cre
               mice: IMSR\_JAX:028863; RRIDs: MATLAB Computer Vision System
               Toolbox software: SCR\_017581; RRIDs: MATLAB software:
               SCR\_001622; RRIDs: Thermo Fisher Scientific Nissl: AB\_2572212;
               RRIDs: $\mu$Manager software: SCR\_016865; excitatory;
               inhibitory; monosynaptic; neuroanatomy; rabies; sensorimotor;
               superior colliculus",
  language  = "en",
  issn      = "0021-9967, 1096-9861",
  pmid      = "32080842",
  doi       = "10.1002/cne.24888"
}

@UNPUBLISHED{Coletta2020-gb,
  title    = "Network structure of the mouse brain connectome with voxel
              resolution",
  author   = "Coletta, Ludovico and Pagani, Marco and Whitesell, Jennifer D and
              Harris, Julie A and Bernhardt, Boris and Gozzi, Alessandro",
  abstract = "Fine-grained descriptions of brain connectivity are fundamental
              for understanding how neural information is processed and relayed
              across spatial scales. Prior investigations of the mouse brain
              connectome have employed discrete anatomical parcellations,
              limiting spatial resolution and potentially concealing network
              attributes critical to the organization of the mammalian
              connectome. Here we provide a voxel-level description of the
              network and hierarchical structure of the directed mouse
              connectome, unconstrained by regional partitioning. We show that
              integrative hub regions can be directionally segregated into
              neural sinks and sources, defining a hierarchical axis. We
              describe a set of structural communities that spatially
              reconstitute previously described fMRI networks of the mouse
              brain, and document that neuromodulatory nuclei are strategically
              wired as critical orchestrators of inter-modular and network
              communicability. Notably, like in primates, the directed mouse
              connectome is organized along two superimposed cortical gradients
              reflecting unimodal-transmodal functional processing and a
              modality-specific sensorimotor axis. These structural features
              can be related to patterns of intralaminar connectivity and to
              the spatial topography of dynamic fMRI brain states,
              respectively. Together, our results reveal a high-resolution
              structural scaffold linking mesoscale connectome topography to
              its macroscale functional organization, and create opportunities
              for identifying targets of interventions to modulate brain
              function in a physiologically-accessible species.",
  journal  = "bioRxiv",
  pages    = "2020.03.06.973164",
  month    =  mar,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.03.06.973164"
}

@ARTICLE{Stubblefield2013-dj,
  title     = "Optogenetic investigation of the role of the superior colliculus
               in orienting movements",
  author    = "Stubblefield, Elizabeth A and Costabile, Jamie D and Felsen,
               Gidon",
  abstract  = "In vivo studies have demonstrated that the superior colliculus
               (SC) integrates sensory information and plays a role in
               controlling orienting motor output. However, how the complex
               microcircuitry within the SC, as documented by slice studies,
               subserves these functions is unclear. Optogenetics affords the
               potential to examine, in behaving animals, the functional roles
               of specific neuron types that comprise heterogeneous nuclei. As
               a first step toward understanding how SC microcircuitry
               underlies motor output, we applied optogenetics to mice
               performing an odor discrimination task in which sensory
               decisions are reported by either a leftward or rightward
               SC-dependent orienting movement. We unilaterally expressed
               either channelrhodopsin-2 or halorhodopsin in the SC and
               delivered light in order to excite or inhibit motor-related SC
               activity as the movement was planned. We found that manipulating
               SC activity predictably affected the direction of the selected
               movement in a manner that depended on the difficulty of the odor
               discrimination. This study demonstrates that the SC plays a
               similar role in directional orienting movements in mice as it
               does in other species, and provides a framework for future
               investigations into how specific SC cell types contribute to
               motor control.",
  journal   = "Behav. Brain Res.",
  publisher = "Elsevier",
  volume    =  255,
  pages     = "55--63",
  month     =  oct,
  year      =  2013,
  keywords  = "ChR2; Channelrhodopsin-2; Decision making; Halorhodopsin;
               Midbrain; Motor planning; Mouse behavior; NpHR; SC;
               channelrhodopsin-2; contra.; contraversive; halorhodopsin;
               ipsi.; ipsiversive; mW/mm(2); milliwatts per millimeter squared
               (power output measured at optic fiber tip); superior colliculus",
  language  = "en",
  issn      = "0166-4328, 1872-7549",
  pmid      = "23643689",
  doi       = "10.1016/j.bbr.2013.04.040",
  pmc       = "PMC3796036"
}

@ARTICLE{Wang2018-gi,
  title    = "Flexible timing by temporal scaling of cortical responses",
  author   = "Wang, Jing and Narain, Devika and Hosseini, Eghbal A and
              Jazayeri, Mehrdad",
  abstract = "Musicians can perform at different tempos, speakers can control
              the cadence of their speech, and children can flexibly vary their
              temporal expectations of events. To understand the neural basis
              of such flexibility, we recorded from the medial frontal cortex
              of nonhuman primates trained to produce different time intervals
              with different effectors. Neural responses were heterogeneous,
              nonlinear, and complex, and they exhibited a remarkable form of
              temporal invariance: firing rate profiles were temporally scaled
              to match the produced intervals. Recording from downstream
              neurons in the caudate and from thalamic neurons projecting to
              the medial frontal cortex indicated that this phenomenon
              originates within cortical networks. Recurrent neural network
              models trained to perform the task revealed that temporal scaling
              emerges from nonlinearities in the network and that the degree of
              scaling is controlled by the strength of external input. These
              findings demonstrate a simple and general mechanism for
              conferring temporal flexibility upon sensorimotor and cognitive
              functions.",
  journal  = "Nat. Neurosci.",
  volume   =  21,
  number   =  1,
  pages    = "102--110",
  month    =  jan,
  year     =  2018,
  keywords = "RNN",
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "29203897",
  doi      = "10.1038/s41593-017-0028-6",
  pmc      = "PMC5742028"
}

@ARTICLE{Song2016-cr,
  title    = "Training {Excitatory-Inhibitory} Recurrent Neural Networks for
              Cognitive Tasks: A Simple and Flexible Framework",
  author   = "Song, H Francis and Yang, Guangyu R and Wang, Xiao-Jing",
  abstract = "The ability to simultaneously record from large numbers of
              neurons in behaving animals has ushered in a new era for the
              study of the neural circuit mechanisms underlying cognitive
              functions. One promising approach to uncovering the dynamical and
              computational principles governing population responses is to
              analyze model recurrent neural networks (RNNs) that have been
              optimized to perform the same tasks as behaving animals. Because
              the optimization of network parameters specifies the desired
              output but not the manner in which to achieve this output,
              ``trained'' networks serve as a source of mechanistic hypotheses
              and a testing ground for data analyses that link neural
              computation to behavior. Complete access to the activity and
              connectivity of the circuit, and the ability to manipulate them
              arbitrarily, make trained networks a convenient proxy for
              biological circuits and a valuable platform for theoretical
              investigation. However, existing RNNs lack basic biological
              features such as the distinction between excitatory and
              inhibitory units (Dale's principle), which are essential if RNNs
              are to provide insights into the operation of biological
              circuits. Moreover, trained networks can achieve the same
              behavioral performance but differ substantially in their
              structure and dynamics, highlighting the need for a simple and
              flexible framework for the exploratory training of RNNs. Here, we
              describe a framework for gradient descent-based training of
              excitatory-inhibitory RNNs that can incorporate a variety of
              biological knowledge. We provide an implementation based on the
              machine learning library Theano, whose automatic differentiation
              capabilities facilitate modifications and extensions. We validate
              this framework by applying it to well-known experimental
              paradigms such as perceptual decision-making, context-dependent
              integration, multisensory integration, parametric working memory,
              and motor sequence generation. Our results demonstrate the wide
              range of neural activity patterns and behavior that can be
              modeled, and suggest a unified setting in which diverse cognitive
              computations and mechanisms can be studied.",
  journal  = "PLoS Comput. Biol.",
  volume   =  12,
  number   =  2,
  pages    = "e1004792",
  month    =  feb,
  year     =  2016,
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "26928718",
  doi      = "10.1371/journal.pcbi.1004792",
  pmc      = "PMC4771709"
}

@ARTICLE{Remington2018-aw,
  title    = "A Dynamical Systems Perspective on Flexible Motor Timing",
  author   = "Remington, Evan D and Egger, Seth W and Narain, Devika and Wang,
              Jing and Jazayeri, Mehrdad",
  abstract = "A hallmark of higher brain function is the ability to rapidly and
              flexibly adjust behavioral responses based on internal and
              external cues. Here, we examine the computational principles that
              allow decisions and actions to unfold flexibly in time. We adopt
              a dynamical systems perspective and outline how temporal
              flexibility in such a system can be achieved through
              manipulations of inputs and initial conditions. We then review
              evidence from experiments in nonhuman primates that support this
              interpretation. Finally, we explore the broader utility and
              limitations of the dynamical systems perspective as a general
              framework for addressing open questions related to the temporal
              control of movements, as well as in the domains of learning and
              sequence generation.",
  journal  = "Trends Cogn. Sci.",
  volume   =  22,
  number   =  10,
  pages    = "938--952",
  month    =  oct,
  year     =  2018,
  keywords = "dynamical systems; flexible timing; learning; movement planning;
              movement sequences; sensorimotor control",
  language = "en",
  issn     = "1364-6613, 1879-307X",
  pmid     = "30266152",
  doi      = "10.1016/j.tics.2018.07.010",
  pmc      = "PMC6166486"
}

@INPROCEEDINGS{Pascanu2013-zg,
  title      = "On the difficulty of training recurrent neural networks",
  booktitle  = "International Conference on Machine Learning",
  author     = "Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua",
  abstract   = "There are two widely known issues with properly training
                recurrent neural networks, the vanishing and the exploding
                gradient problems detailed in Bengio et al. (1994). In this
                paper we attempt to i...",
  publisher  = "jmlr.org",
  pages      = "1310--1318",
  month      =  feb,
  year       =  2013,
  language   = "en",
  conference = "International Conference on Machine Learning"
}

@UNPUBLISHED{Galgali2021-mv,
  title    = "Residual dynamics resolves recurrent contributions to neural
              computation",
  author   = "Galgali, Aniruddh R and Sahani, Maneesh and Mante, Valerio",
  abstract = "Relating neural activity to behavior requires an understanding of
              how neural computations arise from the coordinated dynamics of
              distributed, recurrently connected neural populations. However,
              inferring the nature of recurrent dynamics from partial
              recordings of a neural circuit presents significant challenges.
              Here, we show that some of these challenges can be overcome by a
              fine-grained analysis of the dynamics of neural residuals, i.e.
              trial-by-trial variability around the mean neural population
              trajectory for a given task condition. Residual dynamics in
              macaque pre-frontal cortex (PFC) in a saccade-based perceptual
              decision-making task reveals recurrent dynamics that is
              time-dependent, but consistently stable, and implies that
              pronounced rotational structure in PFC trajectories during
              saccades are driven by inputs from upstream areas. The properties
              of residual dynamics restrict the possible contributions of PFC
              to decision-making and saccade generation, and suggest a path
              towards fully characterizing distributed neural computations with
              large-scale neural recordings and targeted causal perturbations.
              \#\#\# Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.07.19.452951",
  month    =  jul,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.07.19.452951"
}

@ARTICLE{Tombaz2020-tl,
  title    = "Action representation in the mouse parieto-frontal network",
  author   = "Tombaz, Tuce and Dunn, Benjamin A and Hovde, Karoline and Cubero,
              Ryan John and Mimica, Bartul and Mamidanna, Pranav and Roudi,
              Yasser and Whitlock, Jonathan R",
  abstract = "The posterior parietal cortex (PPC) and frontal motor areas
              comprise a cortical network supporting goal-directed behaviour,
              with functions including sensorimotor transformations and
              decision making. In primates, this network links performed and
              observed actions via mirror neurons, which fire both when
              individuals perform an action and when they observe the same
              action performed by a conspecific. Mirror neurons are believed to
              be important for social learning, but it is not known whether
              mirror-like neurons occur in similar networks in other social
              species, such as rodents, or if they can be measured in such
              models using paradigms where observers passively view a
              demonstrator. Therefore, we imaged Ca2+ responses in PPC and
              secondary motor cortex (M2) while mice performed and observed
              pellet-reaching and wheel-running tasks, and found that cell
              populations in both areas robustly encoded several naturalistic
              behaviours. However, neural responses to the same set of observed
              actions were absent, although we verified that observer mice were
              attentive to performers and that PPC neurons responded reliably
              to visual cues. Statistical modelling also indicated that
              executed actions outperformed observed actions in predicting
              neural responses. These results raise the possibility that
              sensorimotor action recognition in rodents could take place
              outside of the parieto-frontal circuit, and underscore that
              detecting socially-driven neural coding depends critically on the
              species and behavioural paradigm used.",
  journal  = "Sci. Rep.",
  volume   =  10,
  number   =  1,
  pages    = "5559",
  month    =  mar,
  year     =  2020,
  language = "en",
  issn     = "2045-2322",
  pmid     = "32221342",
  doi      = "10.1038/s41598-020-62089-6"
}

@ARTICLE{Andalman2019-zi,
  title     = "Neuronal Dynamics Regulating Brain and Behavioral State
               Transitions",
  author    = "Andalman, Aaron S and Burns, Vanessa M and Lovett-Barron,
               Matthew and Broxton, Michael and Poole, Ben and Yang, Samuel J
               and Grosenick, Logan and Lerner, Talia N and Chen, Ritchie and
               Benster, Tyler and Mourrain, Philippe and Levoy, Marc and Rajan,
               Kanaka and Deisseroth, Karl",
  abstract  = "Prolonged behavioral challenges can cause animals to switch from
               active to passive coping strategies to manage effort-expenditure
               during stress; such normally adaptive behavioral state
               transitions can become maladaptive in psychiatric disorders such
               as depression. The underlying neuronal dynamics and brainwide
               interactions important for passive coping have remained unclear.
               Here, we develop a paradigm to study these behavioral state
               transitions at cellular-resolution across the entire vertebrate
               brain. Using brainwide imaging in zebrafish, we observed that
               the transition to passive coping is manifested by progressive
               activation of neurons in the ventral (lateral) habenula.
               Activation of these ventral-habenula neurons suppressed
               downstream neurons in the serotonergic raphe nucleus and caused
               behavioral passivity, whereas inhibition of these neurons
               prevented passivity. Data-driven recurrent neural network
               modeling pointed to altered intra-habenula interactions as a
               contributory mechanism. These results demonstrate ongoing
               encoding of experience features in the habenula, which guides
               recruitment of downstream networks and imposes a passive coping
               behavioral strategy.",
  journal   = "Cell",
  publisher = "Elsevier",
  volume    =  177,
  number    =  4,
  pages     = "970--985.e20",
  month     =  may,
  year      =  2019,
  language  = "en",
  issn      = "0092-8674, 1097-4172",
  pmid      = "31031000",
  doi       = "10.1016/j.cell.2019.02.037",
  pmc       = "PMC6726130"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Hsu2019-jc,
  title     = "{B-SOiD}: An Open Source Unsupervised Algorithm for Discovery of
               Spontaneous Behaviors",
  author    = "Hsu, A I and Yttri, E A",
  abstract  = "The motivation, control, and selection of actions comprising
               naturalistic behaviors remains a tantalizing but difficult field
               of study. Detailed and unbiased quantification is critical.
               Interpreting the positions of animals and their limbs can be
               useful in studying behavior, and significant recent advances
               have made this step straightforward. However, body position
               alone does not provide a grasp of the dynamic range of
               naturalistic behaviors. Behavioral Segmentation of Open-field In
               DeepLabCut, or B-SOiD (`` B-side''), is an unsupervised …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2019
}

@UNPUBLISHED{Rayshubskiy2020-ad,
  title    = "Neural control of steering in walking Drosophila",
  author   = "Rayshubskiy, Aleksandr and Holtz, Stephen L and D'Alessandro,
              Isabel and Li, Anna A and Vanderbeck, Quinn X and Haber, Isabel S
              and Gibb, Peter W and Wilson, Rachel I",
  abstract = "During navigation, the brain must continuously integrate external
              guidance cues with internal spatial maps to update steering
              commands. However, it has been difficult to link spatial maps
              with motor control. Here we identify 9descending steering9
              neurons in the Drosophila brain that lie two synapses downstream
              from the brain9s heading direction map in the central complex.
              These steering neurons predict behavioral turns caused by
              microstimulation of the spatial map. Moreover, these neurons
              receive 9direct9 sensory input that bypasses the central complex,
              and they predict steering evoked by multimodal stimuli.
              Unilateral activation of these neurons can promote turning, while
              bilateral silencing interferes with body and leg movements. In
              short, these neurons combine internal maps with external cues to
              predict and influence steering. They represent a key link between
              cognitive maps, which use an abstract coordinate frame, and motor
              commands, which use a body-centric coordinate frame.",
  journal  = "bioRxiv",
  pages    = "2020.04.04.024703",
  month    =  apr,
  year     =  2020,
  keywords = "Locomotion",
  language = "en",
  doi      = "10.1101/2020.04.04.024703"
}

@ARTICLE{Dolensek2020-dn,
  title    = "Facial expressions of emotion states and their neuronal
              correlates in mice",
  author   = "Dolensek, Nejc and Gehrlach, Daniel A and Klein, Alexandra S and
              Gogolla, Nadine",
  abstract = "Understanding the neurobiological underpinnings of emotion relies
              on objective readouts of the emotional state of an individual,
              which remains a major challenge especially in animal models. We
              found that mice exhibit stereotyped facial expressions in
              response to emotionally salient events, as well as upon targeted
              manipulations in emotion-relevant neuronal circuits. Facial
              expressions were classified into distinct categories using
              machine learning and reflected the changing intrinsic value of
              the same sensory stimulus encountered under different homeostatic
              or affective conditions. Facial expressions revealed emotion
              features such as intensity, valence, and persistence. Two-photon
              imaging uncovered insular cortical neuron activity that
              correlated with specific facial expressions and may encode
              distinct emotions. Facial expressions thus provide a means to
              infer emotion states and their neuronal correlates in mice.",
  journal  = "Science",
  volume   =  368,
  number   =  6486,
  pages    = "89--94",
  month    =  apr,
  year     =  2020,
  language = "en",
  issn     = "0036-8075, 1095-9203",
  pmid     = "32241948",
  doi      = "10.1126/science.aaz9468"
}

@ARTICLE{Pnevmatikakis2017-qi,
  title    = "{NoRMCorre}: An online algorithm for piecewise rigid motion
              correction of calcium imaging data",
  author   = "Pnevmatikakis, Eftychios A and Giovannucci, Andrea",
  abstract = "BACKGROUND: Motion correction is a challenging pre-processing
              problem that arises early in the analysis pipeline of calcium
              imaging data sequences. The motion artifacts in two-photon
              microscopy recordings can be non-rigid, arising from the finite
              time of raster scanning and non-uniform deformations of the brain
              medium. NEW METHOD: We introduce an algorithm for fast Non-Rigid
              Motion Correction (NoRMCorre) based on template matching.
              NoRMCorre operates by splitting the field of view (FOV) into
              overlapping spatial patches along all directions. The patches are
              registered at a sub-pixel resolution for rigid translation
              against a regularly updated template. The estimated alignments
              are subsequently up-sampled to create a smooth motion field for
              each frame that can efficiently approximate non-rigid artifacts
              in a piecewise-rigid manner. EXISTING METHODS: Existing
              approaches either do not scale well in terms of computational
              performance or are targeted to non-rigid artifacts arising just
              from the finite speed of raster scanning, and thus cannot correct
              for non-rigid motion observable in datasets from a large FOV.
              RESULTS: NoRMCorre can be run in an online mode resulting in
              comparable to or even faster than real time motion registration
              of streaming data. We evaluate its performance with simple yet
              intuitive metrics and compare against other non-rigid
              registration methods on simulated data and in vivo two-photon
              calcium imaging datasets. Open source Matlab and Python code is
              also made available. CONCLUSIONS: The proposed method and
              accompanying code can be useful for solving large scale image
              registration problems in calcium imaging, especially in the
              presence of non-rigid deformations.",
  journal  = "J. Neurosci. Methods",
  volume   =  291,
  pages    = "83--94",
  month    =  nov,
  year     =  2017,
  keywords = "Calcium imaging; Image registration; Motion correction",
  language = "en",
  issn     = "0165-0270, 1872-678X",
  pmid     = "28782629",
  doi      = "10.1016/j.jneumeth.2017.07.031"
}

@INCOLLECTION{Sorscher2019-xx,
  title     = "A unified theory for the origin of grid cells through the lens
               of pattern formation",
  booktitle = "Advances in Neural Information Processing Systems 32",
  author    = "Sorscher, Ben and Mel, Gabriel and Ganguli, Surya and Ocko,
               Samuel",
  editor    = "Wallach, H and Larochelle, H and Beygelzimer, A and
               d\textbackslashtextquotesingle Alch{\'e}-Buc, F and Fox, E and
               Garnett, R",
  publisher = "Curran Associates, Inc.",
  pages     = "10003--10013",
  year      =  2019
}

@ARTICLE{Crane_undated-dr,
  title  = "{D} {ISCRETE} {D} {IFFERENTIAL} {G} {EOMETRY}: A {N} A {PPLIED} {I}
            {NTRODUCTION}",
  author = "Crane, Keenan"
}

@ARTICLE{Munteanu2016-dx,
  title    = "Take the long way home: Behaviour of a neotropical frog,
              Allobates femoralis, in a detour task",
  author   = "Munteanu, Alexandru Marian and Starnberger, Iris and Pa{\v
              s}ukonis, Andrius and Bugnyar, Thomas and H{\"o}dl, Walter and
              Fitch, William Tecumseh",
  abstract = "Detour behaviour, an individual's ability to reach its goal by
              taking an indirect route, has been used to test spatial cognitive
              abilities across a variety of taxa. Although many amphibians show
              a strong homing ability, there is currently little evidence of
              amphibian spatial cognitive flexibility. We tested whether a
              territorial frog, Allobates femoralis, can flexibly adjust its
              homing path when faced with an obstacle. We displaced male frogs
              from their calling sites into the centre of circular arenas and
              recorded their escape routes. In the first experiment we provided
              an arena with equally high walls. In the second experiment we
              doubled the height of the homeward facing wall. Finally, we
              provided a tube as a shortcut through the high wall. In the
              equal-height arena, most frogs chose to escape via the quadrant
              facing their former calling site. However, when challenged with
              different heights, nearly all frogs chose the low wall, directing
              their movements away from the calling site. In the ``escape
              tunnel'' experiment most frogs still chose the low wall. Our
              results show that displaced A. femoralis males can flexibly
              adjust their homing path and avoid (presumably energetically
              costly) obstacles, providing experimental evidence of spatial
              cognitive flexibility in an amphibian.",
  journal  = "Behav. Processes",
  volume   =  126,
  pages    = "71--75",
  month    =  may,
  year     =  2016,
  keywords = "Amphibian behaviour; Dendrobatidae; Homing; Obstacle avoidance;
              Spatial cognitive flexibility",
  language = "en",
  issn     = "0376-6357, 1872-8308",
  pmid     = "26997105",
  doi      = "10.1016/j.beproc.2016.03.009",
  pmc      = "PMC5458138"
}

@ARTICLE{Kim2017-no,
  title     = "Ring attractor dynamics in the Drosophila central brain",
  author    = "Kim, Sung Soo and Rouault, Herv{\'e} and Druckmann, Shaul and
               Jayaraman, Vivek",
  abstract  = "Ring attractors are a class of recurrent networks hypothesized
               to underlie the representation of heading direction. Such
               network structures, schematized as a ring of neurons whose
               connectivity depends on their heading preferences, can sustain a
               bump-like activity pattern whose location can be updated by
               continuous shifts along either turn direction. We recently
               reported that a population of fly neurons represents the
               animal's heading via bump-like activity dynamics. We combined
               two-photon calcium imaging in head-fixed flying flies with
               optogenetics to overwrite the existing population representation
               with an artificial one, which was then maintained by the circuit
               with naturalistic dynamics. A network with local excitation and
               global inhibition enforces this unique and persistent heading
               representation. Ring attractor networks have long been invoked
               in theoretical work; our study provides physiological evidence
               of their existence and functional architecture.",
  journal   = "Science",
  publisher = "science.sciencemag.org",
  volume    =  356,
  number    =  6340,
  pages     = "849--853",
  month     =  may,
  year      =  2017,
  language  = "en",
  issn      = "0036-8075, 1095-9203",
  pmid      = "28473639",
  doi       = "10.1126/science.aal4835"
}

@ARTICLE{lx_undated-hq,
  title  = "{'$HWK\ODWLRQ$WODVRIWKHRXVH\%UDLQDWLQJOH\&HOOHVROXWLRQ}",
  author = "/lx, +dqtlqj and =krx, -Lqjwldq and /xr, Krqj\textbackslashxdq and
            \%duwohww, \$qqd and \$ogulgjh, \$qguhz",
  doi    = "10.1101/2020.04.30.069377"
}

@ARTICLE{Taube2007-if,
  title     = "The head direction signal: origins and sensory-motor integration",
  author    = "Taube, Jeffrey S",
  abstract  = "Navigation first requires accurate perception of one's spatial
               orientation within the environment, which consists of knowledge
               about location and directional heading. Cells within several
               limbic system areas of the mammalian brain discharge
               allocentrically as a function of the animal's directional
               heading, independent of the animal's location and ongoing
               behavior. These cells are referred to as head direction (HD)
               cells and are believed to encode the animal's perceived
               directional heading with respect to its environment. Although HD
               cells are found in several areas, the principal circuit for
               generating this signal originates in the dorsal tegmental
               nucleus and projects serially, with some reciprocal connections,
               to the lateral mammillary nucleus --> anterodorsal thalamus -->
               PoS, and terminates in the entorhinal cortex. HD cells receive
               multimodal information about landmarks and self-generated
               movements. Vestibular information appears critical for
               generating the directional signal, but motor/proprioceptive and
               landmark information are important for updating it.",
  journal   = "Annu. Rev. Neurosci.",
  publisher = "annualreviews.org",
  volume    =  30,
  pages     = "181--207",
  year      =  2007,
  keywords  = "navigation",
  language  = "en",
  issn      = "0147-006X",
  pmid      = "17341158",
  doi       = "10.1146/annurev.neuro.29.051605.112854"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{DeAngelis2020-hn,
  title     = "Correction: The manifold structure of limb coordination in
               walking Drosophila",
  author    = "DeAngelis, Brian D and Zavatone-Veth, Jacob A and Clark, Damon A",
  abstract  = "Terrestrial locomotion requires animals to coordinate their limb
               movements to efficiently traverse their environment. While
               previous studies in hexapods have reported that limb
               coordination patterns can vary substantially, the structure of
               this variability is not yet well understood. Here, we
               characterized the symmetric and asymmetric components of
               variation in walking kinematics in the genetic model organism
               Drosophila. We found that Drosophila use a single continuum of
               coordination patterns without evidence for preferred …",
  journal   = "Elife",
  publisher = "elifesciences.org",
  volume    =  9,
  month     =  dec,
  year      =  2020,
  keywords  = "neuroscience;Locomotion",
  language  = "en",
  issn      = "2050-084X",
  pmid      = "33275100",
  doi       = "10.7554/eLife.65214",
  pmc       = "PMC7717899"
}

@ARTICLE{Bellardita2015-ut,
  title     = "Phenotypic characterization of speed-associated gait changes in
               mice reveals modular organization of locomotor networks",
  author    = "Bellardita, Carmelo and Kiehn, Ole",
  abstract  = "Studies of locomotion in mice suggest that circuits controlling
               the alternating between left and right limbs may have a modular
               organization with distinct locomotor circuits being recruited at
               different speeds. It is not clear, however, whether such a
               modular organization reflects specific behavioral outcomes
               expressed at different speeds of locomotion. Here, we use
               detailed kinematic analyses to search for signatures of a
               modular organization of locomotor circuits in intact and
               genetically modified mice moving at different speeds of
               locomotion. We show that wild-type mice display three distinct
               gaits: two alternating, walk and trot, and one synchronous,
               bound. Each gait is expressed in distinct ranges of speed with
               phenotypic inter-limb and intra-limb coordination. A fourth
               gait, gallop, closely resembled bound in most of the locomotor
               parameters but expressed diverse inter-limb coordination.
               Genetic ablation of commissural V0V neurons completely removed
               the expression of one alternating gait, trot, but left intact
               walk, gallop, and bound. Ablation of commissural V0V and V0D
               neurons led to a loss of walk, trot, and gallop, leaving bound
               as the default gait. Our study provides a benchmark for studies
               of the neuronal control of locomotion in the full range of
               speeds. It provides evidence that gait expression depends upon
               selection of different modules of neuronal ensembles.",
  journal   = "Curr. Biol.",
  publisher = "Elsevier",
  volume    =  25,
  number    =  11,
  pages     = "1426--1436",
  month     =  jun,
  year      =  2015,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "0960-9822, 1879-0445",
  pmid      = "25959968",
  doi       = "10.1016/j.cub.2015.04.005",
  pmc       = "PMC4469368"
}

@ARTICLE{Carmelo_Bellardita_undated-rj,
  title    = "Phenotypic Characterization of {Speed-Associated} Gait Changes in
              Mice Reveals Modular Organization of Locomotor Networks",
  author   = "Carmelo Bellardita, Ole Kiehn",
  keywords = "Locomotion"
}

@ARTICLE{Wang2020-lz,
  title     = "The Allen Mouse Brain Common Coordinate Framework: A {3D}
               Reference Atlas",
  author    = "Wang, Quanxin and Ding, Song-Lin and Li, Yang and Royall, Josh
               and Feng, David and Lesnar, Phil and Graddis, Nile and Naeemi,
               Maitham and Facer, Benjamin and Ho, Anh and Dolbeare, Tim and
               Blanchard, Brandon and Dee, Nick and Wakeman, Wayne and
               Hirokawa, Karla E and Szafer, Aaron and Sunkin, Susan M and Oh,
               Seung Wook and Bernard, Amy and Phillips, John W and Hawrylycz,
               Michael and Koch, Christof and Zeng, Hongkui and Harris, Julie A
               and Ng, Lydia",
  abstract  = "SummaryRecent large-scale collaborations are generating major
               surveys of cell types and connections in the mouse brain,
               collecting large amounts of data across modalities, spatial
               scales, and brain areas. Successful integration of these data
               requires a standard 3D reference atlas. Here, we present the
               Allen Mouse Brain Common Coordinate Framework (CCFv3) as such a
               resource. We constructed an average template brain at 10 $\mu$m
               voxel resolution by interpolating high resolution in-plane
               serial two-photon tomography images with 100 $\mu$m z-sampling
               from 1,675 young adult C57BL/6J mice. Then, using multimodal
               reference data, we parcellated the entire brain directly in 3D,
               labeling every voxel with a brain structure spanning 43
               isocortical areas and their layers, 329 subcortical gray matter
               structures, 81 fiber tracts, and 8 ventricular structures. CCFv3
               can be used to analyze, visualize, and integrate multimodal and
               multiscale datasets in 3D and is openly accessible
               (https://atlas.brain-map.org/).",
  journal   = "Cell",
  publisher = "Elsevier",
  volume    =  0,
  number    =  0,
  month     =  may,
  year      =  2020,
  keywords  = "average mouse brain; reference atlas; 3D brain atlas; brain
               parcellation; brain anatomy; mouse cortex; common coordinate
               framework; CCFv3; fiber tracts; transgenic mice",
  language  = "en",
  issn      = "0092-8674, 1097-4172",
  doi       = "10.1016/j.cell.2020.04.007"
}

@ARTICLE{Cregg2020-ie,
  title    = "Brainstem neurons that command mammalian locomotor asymmetries",
  author   = "Cregg, Jared M and Leiras, Roberto and Montalant, Alexia and
              Wanken, Paulina and Wickersham, Ian R and Kiehn, Ole",
  abstract = "Descending command neurons instruct spinal networks to execute
              basic locomotor functions, such as gait and speed. The command
              functions for gait and speed are symmetric, implying that a
              separate unknown system directs asymmetric movements, including
              the ability to move left or right. In the present study, we
              report that Chx10-lineage reticulospinal neurons act to control
              the direction of locomotor movements in mammals. Chx10 neurons
              exhibit mainly ipsilateral projection, and their selective
              unilateral activation causes ipsilateral turning movements in
              freely moving mice. Unilateral inhibition of Chx10 neurons causes
              contralateral turning movements. Paired left--right motor
              recordings identified distinct mechanisms for directional
              movements mediated via limb and axial spinal circuits. Finally,
              we identify sensorimotor brain regions that project on to Chx10
              reticulospinal neurons, and demonstrate that their unilateral
              activation can impart left--right directional commands. Together
              these data identify the descending motor system that commands
              left--right locomotor asymmetries in mammals.",
  journal  = "Nat. Neurosci.",
  month    =  may,
  year     =  2020,
  issn     = "1097-6256, 1546-1726",
  doi      = "10.1038/s41593-020-0633-7"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Neuroscience_undated-xp,
  title  = "Zhe Chen · Sridevi V. Sarma Editors",
  author = "Neuroscience, Dynamic"
}

@ARTICLE{Glaser_undated-nx,
  title  = "Machine learning for neural decoding",
  author = "Glaser, Joshua I and Benjamin, Ari S and Chowdhury, Raeed H and
            Perich, Matthew G and Miller, Lee E and Kording, Konrad P"
}

@ARTICLE{Dineen_undated-da,
  title    = "Springer Undergraduate Mathematics Series",
  author   = "Dineen, Se{\'a}n",
  keywords = "books"
}

@ARTICLE{Axler_undated-rn,
  title    = "Undergraduate Texts in Mathematics",
  author   = "Axler, Sheldon",
  keywords = "books"
}

@ARTICLE{Abbott_undated-xy,
  title    = "Undergraduate Texts in Mathematics",
  author   = "Abbott, Stephen",
  keywords = "books"
}

@MISC{noauthor_undated-wk,
  title    = "{2009\_Book\_TheElementsOfStatisticalLearni.pdf}",
  keywords = "books"
}

@MISC{noauthor_undated-vy,
  title    = "{2015\_Book\_IntroductionToEvolutionaryComp.pdf}",
  keywords = "books"
}

@MISC{noauthor_undated-we,
  title    = "{2015\_Book\_MethodsOfMathematicalModelling.pdf}",
  keywords = "books"
}

@MISC{noauthor_undated-gv,
  title    = "{2018\_Book\_AppliedLinearAlgebra.pdf}",
  keywords = "books"
}

@MISC{noauthor_undated-ic,
  title    = "{2016\_Book\_IntroductionToPartialDifferent.pdf}",
  keywords = "books"
}

@MISC{noauthor_undated-wv,
  title    = "{2016\_Book\_IntroductionToStatisticsAndDat.pdf}",
  keywords = "books"
}

@UNPUBLISHED{Kaplan2017-ez,
  title    = "Planning and navigation as active inference",
  author   = "Kaplan, Raphael and Friston, Karl J",
  abstract = "Abstract This paper introduces an active inference formulation of
              planning and navigation. It illustrates how the
              exploitation--exploration dilemma is dissolved by acting to
              minimise uncertainty (i.e., expected surprise or free energy). We
              use simulations of a maze problem to illustrate how agents can
              solve quite complicated problems using context sensitive prior
              preferences to form subgoals. Our focus is on how epistemic
              behaviour -- driven by novelty and the imperative to reduce
              uncertainty about the world -- contextualises pragmatic or
              goal-directed behaviour. Using simulations, we illustrate the
              underlying process theory with synthetic behavioural and
              electrophysiological responses during exploration of a maze and
              subsequent navigation to a target location. An interesting
              phenomenon that emerged from the simulations was a putative
              distinction between `place cells' -- that fire when a subgoal is
              reached -- and `path cells' -- that fire until a subgoal is
              reached.",
  journal  = "bioRxiv",
  pages    = "230599",
  month    =  dec,
  year     =  2017,
  language = "en",
  doi      = "10.1101/230599"
}

@ARTICLE{Li2018-zt,
  title    = "Modulation of Innate Defensive Responses by Locus
              {Coeruleus-Superior} Colliculus Circuit",
  author   = "Li, Lei and Wang, Liping",
  abstract = "Among key survival circuits, defensive response circuits are one
              of the most intensively studied. A consensus is emerging that
              multiple, independent circuitries are involved in different
              conditioned and unconditioned defensive responses. Investigating
              these well-conserved defensive responses would help us to
              decipher the basic working mechanism of the brain at a circuitry
              level and thus shed light on new diagnoses and treatments for
              neural diseases and disorders. We showed that the visually evoked
              innate defensive response was modulated by a locus
              coeruleus-superior colliculus (LC-SC) projection. Our work
              demonstrates that as conserved and instinctive as the survival
              circuits are, they are flexible and subject to fine-tuned
              modulation by experience or internal states of the animals. Here,
              we provide more data to further discuss the possible downstream
              mechanisms of the LC-SC pathway for this important modulation of
              the defensive response, the wide range of flight latency between
              individual flight responses, and the interpretations of our data
              with additional statistical analysis.",
  journal  = "J. Exp. Neurosci.",
  volume   =  12,
  pages    = "1179069518792035",
  month    =  aug,
  year     =  2018,
  keywords = "Locus coeruleus; defensive circuitry; looming; modulation;
              norepinephrine; stress; superior colliculus",
  language = "en",
  issn     = "1179-0695",
  pmid     = "30127637",
  doi      = "10.1177/1179069518792035",
  pmc      = "PMC6090490"
}

@ARTICLE{Bronstein2021-vm,
  title         = "Geometric Deep Learning: Grids, Groups, Graphs, Geodesics,
                   and Gauges",
  author        = "Bronstein, Michael M and Bruna, Joan and Cohen, Taco and
                   Veli{\v c}kovi{\'c}, Petar",
  abstract      = "The last decade has witnessed an experimental revolution in
                   data science and machine learning, epitomised by deep
                   learning methods. Indeed, many high-dimensional learning
                   tasks previously thought to be beyond reach -- such as
                   computer vision, playing Go, or protein folding -- are in
                   fact feasible with appropriate computational scale.
                   Remarkably, the essence of deep learning is built from two
                   simple algorithmic principles: first, the notion of
                   representation or feature learning, whereby adapted, often
                   hierarchical, features capture the appropriate notion of
                   regularity for each task, and second, learning by local
                   gradient-descent type methods, typically implemented as
                   backpropagation. While learning generic functions in high
                   dimensions is a cursed estimation problem, most tasks of
                   interest are not generic, and come with essential
                   pre-defined regularities arising from the underlying
                   low-dimensionality and structure of the physical world. This
                   text is concerned with exposing these regularities through
                   unified geometric principles that can be applied throughout
                   a wide spectrum of applications. Such a 'geometric
                   unification' endeavour, in the spirit of Felix Klein's
                   Erlangen Program, serves a dual purpose: on one hand, it
                   provides a common mathematical framework to study the most
                   successful neural network architectures, such as CNNs, RNNs,
                   GNNs, and Transformers. On the other hand, it gives a
                   constructive procedure to incorporate prior physical
                   knowledge into neural architectures and provide principled
                   way to build future architectures yet to be invented.",
  month         =  apr,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2104.13478",
  primaryClass  = "cs.LG",
  arxivid       = "2104.13478"
}

@UNPUBLISHED{Shamash2021-gk,
  title    = "Mice identify subgoal locations through an action-driven mapping
              process",
  author   = "Shamash, Philip and Branco, Tiago",
  abstract = "Mammals instinctively explore and form mental maps of their
              spatial environments. Models of cognitive mapping in neuroscience
              mostly depict map-learning as a process of random or biased
              diffusion. In practice, however, animals explore spaces using
              structured, purposeful, sensory-guided actions. Here we test the
              hypothesis that executing specific exploratory actions is a key
              strategy for building a cognitive map. Previous work has shown
              that in arenas with obstacles and a shelter, mice spontaneously
              learn efficient multi-step escape routes by memorizing
              allocentric subgoal locations. We thus used threat-evoked escape
              to probe the relationship between ethological exploratory
              behavior and allocentric spatial memory. Using closed-loop neural
              manipulations to interrupt running movements during exploration,
              we found that blocking runs targeting an obstacle edge abolished
              subgoal learning. In contrast, blocking other movements while
              sparing edge-directed runs had no effect on memorizing subgoals.
              Finally, spatial analyses suggest that the decision to use a
              subgoal during escape takes into account the mouse's starting
              position relative to the layout of the environment. We conclude
              that mice use an action-driven learning process to identify
              subgoals and that these subgoals are then integrated into a
              map-based planning process. We suggest a conceptual framework for
              spatial learning that is compatible with the successor
              representation from reinforcement learning and sensorimotor
              enactivism from cognitive science. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.12.14.472688",
  month    =  dec,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.12.14.472688"
}

@UNPUBLISHED{Storchi2020-em,
  title    = "Beyond locomotion: in the mouse the mapping between sensations
              and behaviours unfolds in a higher dimensional space",
  author   = "Storchi, Riccardo and Milosavljevic, Nina and Allen, Annette E
              and Cootes, Timothy F and Lucas, Robert J",
  abstract = "Abstract The ability of specific sensory stimuli to evoke
              spontaneous behavioural responses in the mouse represents a
              powerful approach to study how the mammalian brain processes
              sensory information and selects appropriate motor actions. For
              visually and auditory guided behaviours the relevant action has
              been empirically identified as a change in locomotion state.
              However, the extent to which locomotion alone captures the
              diversity of those behaviours and their sensory specificity is
              unknown.To tackle this problem we developed a method to obtain a
              faithful 3D reconstruction of the mouse body that enabled us to
              quantify a wide variety of movements and changes in postures.
              This higher dimensional description of behaviour revealed that
              responses to different sensory inputs is more stimulus-specific
              than indicated by locomotion data alone. Thus, equivalent
              locomotion patterns evoked by different stimuli (e.g. looming and
              sound evoking locomotion arrest) could be well separated along
              other dimensions. The enhanced stimulus-specificity was explained
              by a surprising diversity of behavioural responses. A clustering
              analysis revealed that distinct combinations of motor actions and
              postures, giving rise to at least 7 different behaviours, were
              required to account for stimulus-specificity. Moreover, each
              stimulus evoked more than one behaviour revealing a robust
              one-to-many mapping between sensations and behaviours that could
              not be detected from locomotion data.Our results challenge the
              current view of visually and auditory guided behaviours as purely
              locomotion-based actions (e.g. freeze, escape) and indicate that
              behavioural diversity and sensory specificity unfold in a higher
              dimensional space spanning multiple motor actions.",
  journal  = "bioRxiv",
  pages    = "2020.02.24.961565",
  month    =  mar,
  year     =  2020,
  keywords = "Locomotion",
  language = "en",
  doi      = "10.1101/2020.02.24.961565"
}

@ARTICLE{Ericson2020-rz,
  title    = "Probing the invariant structure of spatial knowledge: Support for
              the cognitive graph hypothesis",
  author   = "Ericson, Jonathan D and Warren, William H",
  abstract = "We tested four hypotheses about the structure of spatial
              knowledge used for navigation: (1) the Euclidean hypothesis, a
              geometrically consistent map; (2) the Neighborhood hypothesis,
              adjacency relations between spatial regions, based on visible
              boundaries; (3) the Cognitive Graph hypothesis, a network of
              paths between places, labeled with approximate local distances
              and angles; and (4) the Constancy hypothesis, whatever geometric
              properties are invariant during learning. In two experiments,
              different groups of participants learned three virtual hedge
              mazes, which varied specific geometric properties (Euclidean
              Control Maze, Elastic Maze with stretching paths, Swap Maze with
              alternating paths to the same place). Spatial knowledge was then
              tested using three navigation tasks (metric shortcuts on empty
              ground plane, neighborhood shortcuts with visible boundaries,
              route task in corridors). They yielded the following results: (a)
              Metric shortcuts were insensitive to detectable shifts in target
              location, inconsistent with the Euclidean hypothesis. (b)
              Neighborhood shortcuts were constrained by visible boundaries in
              the Elastic Maze, but not in the Swap Maze, contrary to the
              Neighborhood and Constancy hypotheses. (c) The route task
              indicated that a graph of the maze was acquired in all
              environments, including knowledge of local path lengths. We
              conclude that primary spatial knowledge is consistent with the
              Cognitive Graph hypothesis. Neighborhoods are derived from the
              graph, and local distance and angle information is not embedded
              in a geometrically consistent map.",
  journal  = "Cognition",
  volume   =  200,
  pages    = "104276",
  month    =  may,
  year     =  2020,
  keywords = "Cognitive graph; Cognitive map; Human navigation; Spatial
              cognition",
  language = "en",
  issn     = "0010-0277, 1873-7838",
  pmid     = "32450417",
  doi      = "10.1016/j.cognition.2020.104276"
}

@ARTICLE{Warren2019-lv,
  title    = "{Non-Euclidean} navigation",
  author   = "Warren, William H",
  abstract = "A basic set of navigation strategies supports navigational tasks
              ranging from homing to novel detours and shortcuts. To perform
              these last two tasks, it is generally thought that humans,
              mammals and perhaps some insects possess Euclidean cognitive
              maps, constructed on the basis of input from the path integration
              system. In this article, I review the rationale and behavioral
              evidence for this metric cognitive map hypothesis, and find it
              unpersuasive: in practice, there is little evidence for truly
              novel shortcuts in animals, and human performance is highly
              unreliable and biased by environmental features. I develop the
              alternative hypothesis that spatial knowledge is better
              characterized as a labeled graph: a network of paths between
              places augmented with local metric information. What
              distinguishes such a cognitive graph from a metric cognitive map
              is that this local information is not embedded in a global
              coordinate system, so spatial knowledge is often geometrically
              inconsistent. Human path integration appears to be better suited
              to piecewise measurements of path lengths and turn angles than to
              building a consistent map. In a series of experiments in
              immersive virtual reality, we tested human navigation in
              non-Euclidean environments and found that shortcuts manifest
              large violations of the metric postulates. The results are
              contrary to the Euclidean map hypothesis and support the
              cognitive graph hypothesis. Apparently Euclidean behavior, such
              as taking novel detours and approximate shortcuts, can be
              explained by the adaptive use of non-Euclidean strategies.",
  journal  = "J. Exp. Biol.",
  volume   =  222,
  number   = "Pt Suppl 1",
  month    =  feb,
  year     =  2019,
  keywords = "Cognitive graph; Cognitive map; Path integration; Spatial
              cognition; Wayfinding",
  language = "en",
  issn     = "0022-0949, 1477-9145",
  pmid     = "30728233",
  doi      = "10.1242/jeb.187971"
}

@ARTICLE{Rougier_undated-dj,
  title  = "Scientific Visualization: Python + Matplotlib",
  author = "Rougier, Nicolas"
}

@ARTICLE{Drew2004-kl,
  title     = "Cortical and brainstem control of locomotion",
  author    = "Drew, Trevor and Prentice, Stephen and Schepens,
               B{\'e}n{\'e}dicte",
  abstract  = "While a basic locomotor rhythm is centrally generated by spinal
               circuits, descending pathways are critical for ensuring
               appropriate anticipatory modifications of gait to accommodate
               uneven terrain. Neurons in the motor cortex command the changes
               in muscle activity required to modify limb trajectory when
               stepping over obstacles. Simultaneously, neurons in the
               brainstem reticular formation ensure that these modifications
               are superimposed on an appropriate base of postural support.
               Recent experiments suggest that the same neurons in the same
               structures also provide similar information during reaching
               movements. It is suggested that, during both locomotion and
               reaching movements, the final expression of descending signals
               is influenced by the state and excitability of the spinal
               circuits upon which they impinge.",
  journal   = "Prog. Brain Res.",
  publisher = "Elsevier",
  volume    =  143,
  pages     = "251--261",
  year      =  2004,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "0079-6123",
  pmid      = "14653170",
  doi       = "10.1016/S0079-6123(03)43025-2"
}

@ARTICLE{Grillner2008-ev,
  title     = "Neural bases of goal-directed locomotion in vertebrates---An
               overview",
  author    = "Grillner, Sten and Wall{\'e}n, Peter and Saitoh, Kazuya and
               Kozlov, Alexander and Robertson, Brita",
  abstract  = "The different neural control systems involved in goal-directed
               vertebrate locomotion are reviewed. They include not only the
               central pattern generator networks in the spinal cord that
               generate the basic locomotor synergy and the brainstem command
               systems for locomotion but also the control systems for steering
               and control of body orientation (posture) and finally the neural
               structures responsible for determining which motor programs
               should be turned on in a given instant. The role of the basal
               ganglia is considered in this context. The review summarizes the
               available information from a general vertebrate perspective, but
               specific examples are often derived from the lamprey, which
               provides the most detailed information when considering cellular
               and network perspectives.",
  journal   = "Brain Res. Rev.",
  publisher = "Elsevier",
  volume    =  57,
  number    =  1,
  pages     = "2--12",
  month     =  jan,
  year      =  2008,
  keywords  = "Basal ganglia; Lamprey; Central pattern generator; Tectum; Brain
               stem--spinal cord; Modeling;Locomotion",
  issn      = "0165-0173",
  doi       = "10.1016/j.brainresrev.2007.06.027"
}

@ARTICLE{Wolf2015-dq,
  title     = "An integrative role for the superior colliculus in selecting
               targets for movements",
  author    = "Wolf, Andrew B and Lintz, Mario J and Costabile, Jamie D and
               Thompson, John A and Stubblefield, Elizabeth A and Felsen, Gidon",
  abstract  = "A fundamental goal of systems neuroscience is to understand the
               neural mechanisms underlying decision making. The midbrain
               superior colliculus (SC) is known to be central to the selection
               of one among many potential spatial targets for movements, which
               represents an important form of decision making that is
               tractable to rigorous experimental investigation. In this
               review, we first discuss data from mammalian models-including
               primates, cats, and rodents-that inform our understanding of how
               neural activity in the SC underlies the selection of targets for
               movements. We then examine the anatomy and physiology of inputs
               to the SC from three key regions that are themselves implicated
               in motor decisions-the basal ganglia, parabrachial region, and
               neocortex-and discuss how they may influence SC activity related
               to target selection. Finally, we discuss the potential for
               methodological advances to further our understanding of the
               neural bases of target selection. Our overarching goal is to
               synthesize what is known about how the SC and its inputs act
               together to mediate the selection of targets for movements, to
               highlight open questions about this process, and to spur future
               studies addressing these questions.",
  journal   = "J. Neurophysiol.",
  publisher = "physiology.org",
  volume    =  114,
  number    =  4,
  pages     = "2118--2131",
  month     =  oct,
  year      =  2015,
  keywords  = "decision making; laterodorsal tegmental nucleus; motor planning;
               pedunculopontine tegmental nucleus; substantia nigra",
  language  = "en",
  issn      = "0022-3077, 1522-1598",
  pmid      = "26203103",
  doi       = "10.1152/jn.00262.2015",
  pmc       = "PMC4595612"
}

@ARTICLE{Basso2017-nd,
  title     = "Circuits for Action and Cognition: A View from the Superior
               Colliculus",
  author    = "Basso, Michele A and May, Paul J",
  abstract  = "The superior colliculus is one of the most well-studied
               structures in the brain, and with each new report, its proposed
               role in behavior seems to increase in complexity. Forty years of
               evidence show that the colliculus is critical for reorienting an
               organism toward objects of interest. In monkeys, this involves
               saccadic eye movements. Recent work in the monkey colliculus and
               in the homologous optic tectum of the bird extends our
               understanding of the role of the colliculus in higher mental
               functions, such as attention and decision making. In this
               review, we highlight some of these recent results, as well as
               those capitalizing on circuit-based methodologies using
               transgenic mice models, to understand the contribution of the
               colliculus to attention and decision making. The wealth of
               information we have about the colliculus, together with new
               tools, provides a unique opportunity to obtain a detailed
               accounting of the neurons, circuits, and computations that
               underlie complex behavior.",
  journal   = "Annu Rev Vis Sci",
  publisher = "annualreviews.org",
  volume    =  3,
  pages     = "197--226",
  month     =  sep,
  year      =  2017,
  keywords  = "attention; decision making; movement; normalization; orienting;
               population coding; saccades; vision",
  language  = "en",
  issn      = "2374-4650, 2374-4642",
  pmid      = "28617660",
  doi       = "10.1146/annurev-vision-102016-061234",
  pmc       = "PMC5752317"
}

@ARTICLE{Ryczko2013-pw,
  title     = "The multifunctional mesencephalic locomotor region",
  author    = "Ryczko, Dimitri and Dubuc, R{\'e}jean",
  abstract  = "In 1966, Shik, Severin and Orlovskii discovered that electrical
               stimulation of a region at the junction between the midbrain and
               hindbrain elicited controlled walking and running in the cat.
               The region was named Mesencephalic Locomotor Region (MLR). Since
               then, this locomotor center was shown to control locomotion in
               various vertebrate species, including the lamprey, salamander,
               stingray, rat, guinea-pig, rabbit or monkey. In human subjects
               asked to imagine they are walking, there is an increased
               activity in brainstem nuclei corresponding to the MLR (i.e.
               pedunculopontine, cuneiform and subcuneiform nuclei). Clinicians
               are now stimulating (deep brain stimulation) structures
               considered to be part of the MLR to alleviate locomotor symptoms
               of patients with Parkinson's disease. However, the anatomical
               constituents of the MLR still remain a matter of debate,
               especially relative to the pedunculopontine, cuneiform and
               subcuneiform nuclei. Furthermore, recent studies in lampreys
               have revealed that the MLR is more complex than a simple relay
               in a serial descending pathway activating the spinal locomotor
               circuits. It has multiple functions. Our goal is to review the
               current knowledge relative to the anatomical constituents of the
               MLR, and its physiological role, from lamprey to man. We will
               discuss these results in the context of the recent clinical
               studies involving stimulation of the MLR in patients with
               Parkinson's disease.",
  journal   = "Curr. Pharm. Des.",
  publisher = "ingentaconnect.com",
  volume    =  19,
  number    =  24,
  pages     = "4448--4470",
  year      =  2013,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "1381-6128, 1873-4286",
  pmid      = "23360276",
  doi       = "10.2174/1381612811319240011"
}

@ARTICLE{Kaneshige2018-cg,
  title     = "A Descending Circuit Derived From the Superior Colliculus
               Modulates Vibrissal Movements",
  author    = "Kaneshige, Miki and Shibata, Ken-Ichi and Matsubayashi, Jun and
               Mitani, Akira and Furuta, Takahiro",
  abstract  = "The superior colliculus (SC) is an essential structure for the
               control of eye movements. In rodents, the SC is also considered
               to play an important role in whisking behavior, in which animals
               actively move their vibrissae (mechanosensors) to gather tactile
               information about the space around them during exploration. We
               investigated how the SC contributes to vibrissal movement
               control. We found that when the SC was unilaterally lesioned,
               the resting position of the vibrissae shifted backward on the
               side contralateral to the lesion. The unilateral SC lesion also
               induced an increase in the whisking amplitude on the
               contralateral side. To explore the anatomical basis for SC
               involvement in vibrissal movement control, we then
               quantitatively evaluated axonal projections from the SC to the
               brainstem using neuronal labeling with a virus vector. Neurons
               of the SC mainly sent axons to the contralateral side in the
               lower brainstem. We found that the facial nucleus received input
               directly from the SC, and that the descending projections from
               the SC also reached the intermediate reticular formation and
               pre-B{\"o}tzinger complex, which are both considered to contain
               neural oscillators generating rhythmic movements of the
               vibrissae. Together, these results indicate the existence of a
               neural circuit in which the SC modulates vibrissal movements
               mainly on the contralateral side, via direct connections to
               motoneurons, and via indirect connections including the central
               pattern generators.",
  journal   = "Front. Neural Circuits",
  publisher = "frontiersin.org",
  volume    =  12,
  pages     = "100",
  month     =  nov,
  year      =  2018,
  keywords  = "CPGs; anterograde tracing; kinematic analysis; premotor neurons;
               rat; whisker",
  language  = "en",
  issn      = "1662-5110",
  pmid      = "30524249",
  doi       = "10.3389/fncir.2018.00100",
  pmc       = "PMC6262173"
}

@ARTICLE{Jordan2008-dx,
  title     = "Descending command systems for the initiation of locomotion in
               mammals",
  author    = "Jordan, Larry M and Liu, Jun and Hedlund, Peter B and Akay,
               Turgay and Pearson, Keir G",
  abstract  = "Neurons in the brainstem implicated in the initiation of
               locomotion include glutamatergic, noradrenergic (NA),
               dopaminergic (DA), and serotonergic (5-HT) neurons giving rise
               to descending tracts. Glutamate antagonists block mesencephalic
               locomotor region-induced and spontaneous locomotion, and
               glutamatergic agonists induce locomotion in spinal animals. NA
               and 5-HT inputs to the spinal cord originate in the brainstem,
               while the descending dopaminergic pathway originates in the
               hypothalamus. Agonists acting at NA, DA or 5-HT receptors
               facilitate or induce locomotion in spinal animals. 5-HT neurons
               located in the parapyramidal region (PPR) produce locomotion
               when stimulated in the isolated neonatal rat brainstem-spinal
               cord preparation, and they constitute the first anatomically
               discrete group of spinally-projecting neurons demonstrated to be
               involved in the initiation of locomotion in mammals. Neurons in
               the PPR are activated during treadmill locomotion in adult rats.
               Locomotion evoked from the PPR is mediated by 5-HT(7) and
               5-HT(2A) receptors, and 5-HT(7) antagonists block locomotion in
               cat, rat and mouse preparations, but have little effect in mice
               lacking 5-HT(7) receptors. 5-HT induced activity in 5-HT(7)
               knockout mice is rhythmic, but coordination among flexor and
               extensor motor nuclei and left and right sides of the spinal
               cord is disrupted. In the adult wild-type mouse, 5-HT(7)
               receptor antagonists impair locomotion, producing patterns of
               activity resembling those induced by 5-HT in 5-HT(7) knockout
               mice. 5-HT(7) receptor antagonists have a reduced effect on
               locomotion in adult 5-HT(7) receptor knockout mice. We conclude
               that the PPR is the source of a descending 5-HT command pathway
               that activates the CPG via 5-HT(7) and 5-HT(2A) receptors.
               Further experiments are necessary to define the putative
               glutamatergic, DA, and NA command pathways.",
  journal   = "Brain Res. Rev.",
  publisher = "Elsevier",
  volume    =  57,
  number    =  1,
  pages     = "183--191",
  month     =  jan,
  year      =  2008,
  language  = "en",
  issn      = "0165-0173",
  pmid      = "17928060",
  doi       = "10.1016/j.brainresrev.2007.07.019"
}

@ARTICLE{Olson2020-lm,
  title     = "Secondary Motor Cortex Transforms Spatial Information into
               Planned Action during Navigation",
  author    = "Olson, Jacob M and Li, Jamie K and Montgomery, Sarah E and Nitz,
               Douglas A",
  abstract  = "Fluid navigation requires constant updating of planned movements
               to adapt to evolving obstacles and goals. For that reason, a
               neural substrate for navigation demands spatial and
               environmental information and the ability to effect actions
               through efferents. The secondary motor cortex (M2) is a prime
               candidate for this role given its interconnectivity with
               association cortices that encode spatial relationships and its
               projection to the primary motor cortex. Here, we report that M2
               neurons robustly encode both planned and current left/right
               turning actions across multiple turn locations in a multi-route
               navigational task. Comparisons within a common statistical
               framework reveal that M2 neurons differentiate contextual
               factors, including environmental position, route, action
               sequence, orientation, and choice availability. Despite
               significant modulation by environmental factors, action
               planning, and execution are the dominant output signals of M2
               neurons. These results identify the M2 as a structure
               integrating spatial information toward the updating of planned
               movements.",
  journal   = "Curr. Biol.",
  publisher = "Elsevier",
  volume    =  30,
  number    =  10,
  pages     = "1845--1854.e4",
  month     =  may,
  year      =  2020,
  keywords  = "M2; action; allocentric; cortical circuits; decision making;
               egocentric; in vivo electrophysiology; navigation; parietal
               cortex; retrosplenial cortex; systems neuroscience;Locomotion",
  language  = "en",
  issn      = "0960-9822, 1879-0445",
  pmid      = "32302586",
  doi       = "10.1016/j.cub.2020.03.016"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@UNPUBLISHED{Kawabata2020-yt,
  title    = "Geometrical model explains multiple preferred escape trajectories
              of fish",
  author   = "Kawabata, Yuuki and Akada, Hideyuki and Shimatani, Ken-Ichiro and
              Nishihara, Gregory N and Kimura, Hibiki and Nozomi, Nishiumi and
              Domenici, Paolo",
  abstract = "Abstract To evade predators, many prey perform rapid escape
              movements. The resulting escape trajectory (ET) -- measured as
              the angle of escape direction relative to the predator's approach
              path -- plays a major role in avoiding predation. Previous
              geometrical models predict a single ET; however, many animals
              (fish and other animal taxa) show highly variable ETs with
              multiple preferred directions. Although such a high ET
              variability may confer unpredictability, preventing predators
              from adopting counter-strategies, the reasons why animals prefer
              specific multiple ETs remain unclear. Here, we constructed a
              novel geometrical model in which Tdiff (the time difference
              between the prey entering the safety zone and the predator
              reaching that entry point) is expected to be maximized. We tested
              this prediction by analyzing the escape responses of Pagrus major
              attacked by a dummy predator. At each initial body orientation of
              the prey relative to the predator, our model predicts a
              multimodal ET with an optimal ET at the maximum Tdiff (Tdiff,1)
              and a suboptimal ET at a second local maximum of Tdiff (Tdiff,2).
              Our experiments show that when Tdiff, 1--Tdiff, 2 is negligible,
              the prey uses optimal or suboptimal ETs to a similar extent, in
              line with the idea of unpredictability. The experimentally
              observed ET distribution is consistent with the model, showing
              two large peaks at 110--130° and 170--180° away from the
              predator. Because various animal taxa show multiple preferred ETs
              similar to those observed here, this behavioral phenotype may
              result from convergent evolution that combines maximal Tdiff with
              a high level of unpredictability.Significance Statement Animals
              from many taxa escape from suddenly approaching threats, such as
              ambush predators, by using multiple preferred escape
              trajectories. However, the reason why these multiple preferred
              escape trajectories are used is still unknown. By fitting a newly
              constructed model to the empirical escape response data, we show
              that the seemingly complex multiple preferred escape trajectories
              can arise from a simple geometrical rule which maximizes the time
              difference between when the prey enters the safety zone and when
              the predator reaches that entry point. Our results open new
              avenues of investigation for understanding how animals choose
              their escape trajectories from behavioral and neurosensory
              perspectives.",
  journal  = "bioRxiv",
  pages    = "2020.04.27.049833",
  month    =  apr,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.04.27.049833"
}

@UNPUBLISHED{Vale2020-yy,
  title    = "A cortico-collicular circuit for accurate orientation to shelter
              during escape",
  author   = "Vale, Ruben and Campagner, Dario and Iordanidou, Panagiota and
              Arocas, Oriol Pav{\'o}n and Tan, Yu Lin and Vanessa Stempel, A
              and Keshavarzi, Sepideh and Petersen, Rasmus S and Margrie, Troy
              W and Branco, Tiago",
  abstract = "When faced with predatorial threats, escaping towards shelter is
              an adaptive action that offers long-term protection against the
              attacker. From crustaceans to mammals, animals rely on knowledge
              of safe locations in the environment to rapidly execute
              shelter-directed escape actions[1][1]--[3][2]. While previous
              work has identified neural mechanisms of instinctive
              escape[4][3]--[9][4], it is not known how the escape circuit
              incorporates spatial information to execute rapid and accurate
              flights to safety. Here we show that mouse retrosplenial cortex
              (RSP) and superior colliculus (SC) form a monosynaptic circuit
              that continuously encodes the shelter direction. Inactivation of
              SC-projecting RSP neurons decreases SC shelter-direction tuning
              while preserving SC motor function. Moreover, specific
              inactivation of RSP input onto SC neurons disrupts orientation
              and subsequent escapes to shelter, but not orientation accuracy
              to a sensory cue. We conclude that the RSC-SC circuit supports an
              egocentric representation of shelter direction and is necessary
              for optimal shelter-directed escapes. This cortical-subcortical
              interface may be a general blueprint for increasing the
              sophistication and flexibility of instinctive behaviours. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest. [1]: \#ref-1 [2]: \#ref-3 [3]: \#ref-4 [4]:
              \#ref-9",
  journal  = "bioRxiv",
  pages    = "2020.05.26.117598",
  month    =  may,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.05.26.117598"
}

@UNPUBLISHED{Sutton2018-vu,
  title    = "Born to run? Quantifying the balance of prior bias and new
              information in prey escape decisions",
  author   = "Sutton, Nicholas M and O'Dwyer, James P",
  abstract = "Abstract Animal behaviors can often be challenging to model and
              predict, though optimality theory has improved our ability to do
              so. While many qualitative predictions of behavior exist,
              accurate quantitative models, tested by empirical data, are often
              lacking. This is likely due to variation in biases across
              individuals and variation in the way new information is gathered
              and used. We propose a modeling framework based on a novel
              interpretation of Bayes' theorem to integrate optimization of
              energetic constraints with both prior biases and specific sources
              of new information gathered by individuals. We present methods
              for inferring distributions of prior biases within populations
              rather than assuming known priors, as is common in Bayesian
              approaches to modelling behavior, and for evaluating the goodness
              of fit of overall model descriptions. We apply this framework to
              predict optimal escape during predator-prey encounters, based on
              prior biases and variation in what information prey use. Using
              this approach we collected and analyzed data characterizing
              white-tailed deer (Odocoileus virginianus) escape behavior in
              response to human approaches. We found that distance to predator
              alone was not sufficient for predicting deer flight response, and
              have shown that the inclusion of additional information is
              necessary. Additionally, we compared differences in the inferred
              distributions of prior biases across different populations and
              discuss the possible role of human activity in influencing these
              distributions.",
  journal  = "bioRxiv",
  pages    = "297218",
  month    =  apr,
  year     =  2018,
  language = "en",
  doi      = "10.1101/297218"
}

@UNPUBLISHED{Seidenbecher2019-im,
  title    = "Foraging fruit flies mix navigational and learning-based
              decision-making strategies",
  author   = "Seidenbecher, Sophie E and Sanders, Joshua I and von Philipsborn,
              Anne C and Kvitsiani, Duda",
  abstract = "Abstract Animals often navigate environments that are uncertain,
              volatile and complex, making it challenging to locate reliable
              food sources. Therefore, it is not surprising that many species
              evolved multiple, parallel and complementary foraging strategies
              to survive. Current research on animal behavior is largely driven
              by a reductionist approach and attempts to study one particular
              aspect of behavior in isolation. This is justified by the huge
              success of past and current research in understanding neural
              circuit mechanisms of behaviors. But focusing on only one aspect
              of behaviors obscures their inherent multidimensional nature. To
              fill this gap we aimed to identify and characterize distinct
              behavioral modules using a simple reward foraging assay. For this
              we developed a single-animal, trial-based probabilistic foraging
              task, where freely walking fruit flies experience optogenetic
              sugar-receptor neuron stimulation. By carefully analyzing the
              walking trajectories of flies, we were able to dissect the
              animals foraging decisions into multiple underlying systems. We
              show that flies perform local searches, cue-based navigation and
              learn task relevant contingencies. Using probabilistic reward
              delivery allowed us to bid several competing reinforcement
              learning (RL) models against each other. We discover that flies
              accumulate chosen option values, forget unchosen option values
              and seek novelty. We further show that distinct behavioral
              modules -learning and navigation-based systems-cooperate,
              suggesting that reinforcement learning in flies operates on
              dimensionality reduced representations. We therefore argue that
              animals will apply combinations of multiple behavioral strategies
              to generate foraging decisions.",
  journal  = "bioRxiv",
  pages    = "842096",
  month    =  nov,
  year     =  2019,
  language = "en",
  doi      = "10.1101/842096"
}

@MISC{Dvorkin2010-js,
  title    = "Knots: Attractive Places with High Path Tortuosity in Mouse Open
              Field Exploration",
  author   = "Dvorkin, Anna and Szechtman, Henry and Golani, Ilan",
  editor   = "Bourne, Philip E",
  abstract = "When introduced into a novel environment, mammals establish in it
              a preferred place marked by the highest number of visits and
              highest cumulative time spent in it. Examination of exploratory
              behavior in reference to this ``home base'' highlights important
              features of its organization. It might therefore be fruitful to
              search for other types of marked places in mouse exploratory
              behavior and examine their influence on overall
              behavior.Examination of path curvatures of mice exploring a large
              empty arena revealed the presence of circumscribed locales marked
              by the performance of tortuous paths full of twists and turns. We
              term these places knots, and the behavior performed in
              them-knot-scribbling. There is typically no more than one knot
              per session; it has distinct boundaries and it is maintained both
              within and across sessions. Knots are mostly situated in the
              place of introduction into the arena, here away from walls. Knots
              are not characterized by the features of a home base, except for
              a high speed during inbound and a low speed during outbound
              paths. The establishment of knots is enhanced by injecting the
              mouse with saline and placing it in an exposed portion of the
              arena, suggesting that stress and the arousal associated with it
              consolidate a long-term contingency between a particular locale
              and knot-scribbling.In an environment devoid of proximal cues
              mice mark a locale associated with arousal by twisting and
              turning in it. This creates a self-generated, often centrally
              located landmark. The tortuosity of the path traced during the
              behavior implies almost concurrent multiple views of the
              environment. Knot-scribbling could therefore function as a way to
              obtain an overview of the entire environment, allowing
              re-calibration of the mouse's locale map and compass directions.
              The rich vestibular input generated by scribbling could improve
              the interpretation of the visual scene.",
  month    =  jan,
  year     =  2010,
  doi      = "10.1371/journal.pcbi.1000638"
}

@ARTICLE{Gentry1964-sw,
  title     = "Homing in the {Old-Field} Mouse",
  author    = "Gentry, John B",
  abstract  = "Abstract. Homing was successful in 31 of 39 old-field mice
               (Peromyscus polionotus) released from the center of a 9-acre
               plowed field 340 to 640 feet from trap",
  journal   = "J. Mammal.",
  publisher = "Oxford Academic",
  volume    =  45,
  number    =  2,
  pages     = "276--283",
  month     =  may,
  year      =  1964,
  issn      = "0022-2372",
  doi       = "10.2307/1376992"
}

@ARTICLE{Egnor2017-sl,
  title    = "Spatial Memory: Mice Quickly Learn a Safe Haven",
  author   = "Egnor, S E Roian",
  abstract = "New work on innate escape behavior shows that mice spontaneously
              form a spatially precise memory of the location of shelter, which
              is laid down quickly and updated continuously.",
  journal  = "Curr. Biol.",
  volume   =  27,
  number   =  10,
  pages    = "R388--R390",
  month    =  may,
  year     =  2017,
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "28535390",
  doi      = "10.1016/j.cub.2017.04.007"
}

@MISC{noauthor_undated-wh,
  title = "{PIC88.pdf}"
}

@ARTICLE{Tchernichovski1995-qv,
  title    = "A phase plane representation of rat exploratory behavior",
  author   = "Tchernichovski, O and Golani, I",
  abstract = "Rat spontaneous spatial behavior is considered to be stochastic
              and is therefore commonly analyzed in terms of cumulative
              measures. Here, we suggest a method which generates a
              moment-to-moment representation of this behavior. It has been
              proposed earlier that rat spatial behavior can be partitioned
              into natural units termed excursions (round trips) performed from
              a reference place termed the rat's home base. We offer a phase
              plane representation of excursions (plotting the rat's momentary
              location against its momentary velocity). The results reveal a
              geometrical pattern, typical of young age and early exposure. It
              consists of low velocity and intermittent progression while
              moving away from the home base (upstream segment), and high
              velocity while moving back to it (downstream segment). The
              asymmetry between the two segments defines a field of
              significance in the rat's operational world. This field undergoes
              regular transformations, revealing thereby the rat's strategy of
              occupancy of the environment. The presented dynamics could
              provide a framework for the interpretation of concurrent neural
              events associated with navigation and spatial memory.",
  journal  = "J. Neurosci. Methods",
  volume   =  62,
  number   = "1-2",
  pages    = "21--27",
  month    =  nov,
  year     =  1995,
  language = "en",
  issn     = "0165-0270",
  pmid     = "8750081",
  doi      = "10.1016/0165-0270(95)00050-x"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Barthas2017-zs,
  title     = "Secondary motor cortex: where `sensory'meets `motor'in the
               rodent frontal cortex",
  author    = "Barthas, Florent and Kwan, Alex C",
  abstract  = "In rodents, the medial aspect of the secondary motor cortex (M2)
               is known by other names, including medial agranular cortex
               (AGm), medial precentral cortex (PrCm), and frontal orienting
               field (FOF). As a subdivision of the medial prefrontal cortex
               (mPFC), M2 can be defined by a distinct set of afferent and
               efferent connections, microstimulation responses, and lesion
               outcomes. However, the behavioral role of M2 remains mysterious.
               Here, we focus on evidence from rodent studies, highlighting
               recent findings of early and context …",
  journal   = "Trends Neurosci.",
  publisher = "Elsevier",
  volume    =  40,
  number    =  3,
  pages     = "181--193",
  year      =  2017,
  issn      = "0166-2236"
}

@ARTICLE{Husak2006-yq,
  title     = "Does survival depend on how fast you can run or how fast you do
               run?",
  author    = "Husak, J F",
  abstract  = "Summary 1 Natural selection is generally thought to operate on
               organisms? maximal abilities to perform ecological tasks in
               nature (i.e. whole-animal performance). However, selection may
               instead operate on the manner in which that performance trait is
               used (i.e. ?ecological performance?). 2 I tested whether
               survival of adult Collared Lizards (Crotaphytus collaris)
               depended on maximal sprint speed capacity or on the speed at
               which they actually performed two important ecological tasks:
               chasing a prey item and escaping a predator. 3 Maximal sprint
               speed did not significantly predict annual survival as
               determined by daily censuses of the site the following season,
               nor did speed while foraging, but speed while escaping a
               predator did. Survival also was positively related to the
               proportion of maximal capacity used while escaping. 4 These
               results suggest that selection may operate on ecological
               performance that is constrained, but not necessarily determined,
               by maximal performance capacity, suggesting that researchers
               should consider how organisms utilize maximal performance in
               nature when testing for a performance?survival relationship.",
  journal   = "Funct. Ecol.",
  publisher = "Wiley Online Library",
  volume    =  20,
  number    =  6,
  pages     = "1080--1086",
  month     =  dec,
  year      =  2006,
  issn      = "0269-8463, 1365-2435",
  doi       = "10.1111/j.1365-2435.2006.01195.x"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Domenici2010-ma,
  title     = "Context-dependent variability in the components of fish escape
               response: integrating locomotor performance and behavior",
  author    = "Domenici, Paolo",
  abstract  = "Escape responses are used by most fish species in order to avoid
               predation. Escape responses include a number of behavioral and
               kinematic components, such as responsiveness, reaction distance,
               escape latency, directionality, and distance‐derived
               performance. All of these components can contribute to escape
               success. Work on the context‐dependent variability has focused
               on reaction distance, and suggests that this component is
               largely determined by the relative cost and benefits of escaping
               (economic …",
  journal   = "J. Exp. Zool. A Ecol. Genet. Physiol.",
  publisher = "Wiley Online Library",
  volume    =  313,
  number    =  2,
  pages     = "59--79",
  year      =  2010,
  issn      = "1932-5223"
}

@ARTICLE{Cooper1997-wy,
  title     = "Escape by a refuging prey, the broad-headed skink (Eumeces
               laticeps)",
  author    = "Cooper, Jr., William E",
  abstract  = "Factors influencing escape to refuge by the broad-headed skink
               (Eumeces laticeps) were examined by multiple regression and
               correlation of quantitative escape variables and distance and
               direction to refuge. I simulated a predator by walking toward a
               lizard and recorded aspects of escape. Approach distance
               (distance from me when escape began) increased with distance and
               angle to refuge, suggesting that the skinks assessed that risk
               increased with relative times required for prey and predator to
               reach the refuge. Distance fled was affected jointly by distance
               from the predator when escape began and distance to refuge; it
               increased with distance to refuge. It also increased with the
               angle between the predator's path and refuge due to declining
               distance from the predator per unit distance fled. Direction to
               the nearest refuge and direction fled were nearly identical.
               Distance and direction to refuge should strongly affect escape
               behaviour in prey that are active some distance from refuges but
               rely on them to avoid predation. These relationships may be
               weaker or absent in anachoric species (those nearly continuously
               occupying refuges) and those remaining close to refuges, as well
               as in species relying more on speed and fleeing for long
               distances than on refuges.",
  journal   = "Can. J. Zool.",
  publisher = "NRC Research Press",
  volume    =  75,
  number    =  6,
  pages     = "943--947",
  month     =  jun,
  year      =  1997,
  issn      = "0008-4301",
  doi       = "10.1139/z97-113"
}

@ARTICLE{Tajima2019-xa,
  title     = "Optimal policy for multi-alternative decisions",
  author    = "Tajima, Satohiro and Drugowitsch, Jan and Patel, Nisheet and
               Pouget, Alexandre",
  abstract  = "Everyday decisions frequently require choosing among multiple
               alternatives. Yet the optimal policy for such decisions is
               unknown. Here we derive the normative policy for general
               multi-alternative decisions. This strategy requires evidence
               accumulation to nonlinear, time-dependent bounds that trigger
               choices. A geometric symmetry in those boundaries allows the
               optimal strategy to be implemented by a simple neural circuit
               involving normalization with fixed decision bounds and an
               urgency signal. The model captures several key features of the
               response of decision-making neurons as well as the increase in
               reaction time as a function of the number of alternatives, known
               as Hick's law. In addition, we show that in the presence of
               divisive normalization and internal variability, our model can
               account for several so-called 'irrational' behaviors, such as
               the similarity effect as well as the violation of both the
               independence of irrelevant alternatives principle and the
               regularity principle.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  22,
  number    =  9,
  pages     = "1503--1511",
  month     =  sep,
  year      =  2019,
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "31384015",
  doi       = "10.1038/s41593-019-0453-9"
}

@ARTICLE{Mattingly2005-qc,
  title    = "The choice of arboreal escape paths and its consequences for the
              locomotor behaviour of four species of Anolis lizards",
  author   = "Mattingly, W Brett and Jayne, Bruce C",
  abstract = "The direction and speed of escape locomotion can affect the
              ability of an animal to evade a predator, and variation in
              habitat structure often affects speed. Consequently, the escape
              paths chosen by animals may affect their performance and
              subsequent survival. Arboreal locomotion is well suited for
              gaining insight into the choice of escape routes because of the
              discrete paths formed by branches. Decreased branch diameter and
              increased angles between branches can significantly decrease
              locomotor speeds, but no previous study has determined whether
              arboreal lizards selectively choose alternative paths. We
              quantified choice of escape paths and locomotor performance of
              four syntopic species of arboreal Anolis lizards in their natural
              habitat and in the laboratory. In the field, species with shorter
              limbs occurred more commonly on narrow perches than did
              long-limbed species, but all species favoured escape paths with
              larger-diameter perches and straighter interperch angles. Thus,
              short-limbed species used narrower perches than long-limbed
              species merely as a result of what they encountered, rather than
              as a result of a biased choice at branching points. In natural
              vegetation, choosing branches with the largest diameter often
              results in the straightest path. However, in the laboratory, most
              lizards preferred large-diameter perches with a sharp turn to
              continuing a straight path onto a small-diameter perch. Although
              an overriding preference for larger perch diameter may optimize
              escape speed within a single perch, a maladaptive side-effect
              could be a compromise of the overall rate of gaining distance
              from starting points in paths with turns.",
  journal  = "Anim. Behav.",
  volume   =  70,
  number   =  6,
  pages    = "1239--1250",
  month    =  dec,
  year     =  2005,
  issn     = "0003-3472",
  doi      = "10.1016/j.anbehav.2005.02.013"
}

@ARTICLE{Kopena2015-jl,
  title     = "Escape strategy of Schreiber's green lizards (Lacerta
               schreiberi) is determined by environment but not season or sex",
  author    = "Kopena, Ren{\'a}ta and Herczeg, G{\'a}bor and L{\'o}pez, Pilar
               and Mart{\'\i}n, Jos{\'e}",
  abstract  = "Antipredator escape behaviour varies with several
               well-established sources of variation ranging from the physical
               environment to reproductive status. However, the relative roles
               of these sources are rarely assessed together. We measured (i)
               the distance to the nearest refuge that Schreiber's green
               lizards, Lacerta schreiberi, maintained before an attack (refuge
               distance) and (ii) the distance lizards allowed a simulated
               predator to approach before fleeing (flight initiation distance,
               FID). Refuge distance was unaffected by studied variables.
               However, FID was positively related to refuge distance on
               grassy, but not on rocky substrates. Furthermore, refuge
               distance and escape angle interacted in a substrate-independent
               manner: lizards allowed predators close when refuges were close
               or when lizards had to flee towards the predator. In contrast,
               neither mating season nor sex affected FID. We suggest that the
               escape strategy of L. schreiberi is determined more by the
               physical environment than by sex or reproductive condition.",
  journal   = "Behaviour",
  publisher = "Brill",
  volume    =  152,
  number    =  11,
  pages     = "1527--1542",
  month     =  jan,
  year      =  2015,
  keywords  = "Biology \& Environmental Sciences; Biology; Journal",
  language  = "en",
  issn      = "0005-7959, 1568-539X",
  doi       = "10.1163/1568539X-00003290"
}

@ARTICLE{Cooper1999-nv,
  title     = "Escape behavior by prey blocked from entering the nearest refuge",
  author    = "{Cooper} and {Jr.} and William, E",
  abstract  = "Current models of optimal antipredation behavior do not apply to
               prey blocked by a predator from access to the primary refuge
               because the predator is closer than the optimal approach
               distance and flight toward the refuge would increase risk. If
               other alternative refuges are available, the prey should flee
               toward the best alternative one. I studied the effect of an
               approaching human simulated predator interposed between prey and
               refuge on the use of alternative refuges and on
               flight-initiation distance in the keeled earless lizard,
               Holbrookia propinqua. When the predator approached on a line
               between a lizard and its closest refuge, the lizard invariably
               fled to or toward an alternative refuge. Lizards were
               significantly more likely to use alternative refuges than
               lizards approached on a line connecting the closest refuge,
               prey, and predator, but with the lizard between the predator and
               the refuge. Flight-initiation distance was significantly greater
               for lizards having free access to the closest refuge than for
               those blocked from it, perhaps because of the time required to
               assess the new risk posed by blockage of the closest refuge, to
               select the best alternative refuge, or to wait for the predator
               to commit to a closing pattern before choosing the best flight
               option.",
  journal   = "Can. J. Zool.",
  publisher = "NRC Research Press",
  volume    =  77,
  number    =  4,
  pages     = "671--674",
  month     =  sep,
  year      =  1999,
  issn      = "0008-4301",
  doi       = "10.1139/z99-046"
}

@ARTICLE{Floreano2010-wg,
  title    = "Evolution of adaptive behaviour in robots by means of Darwinian
              selection",
  author   = "Floreano, Dario and Keller, Laurent",
  journal  = "PLoS Biol.",
  volume   =  8,
  number   =  1,
  pages    = "e1000292",
  month    =  jan,
  year     =  2010,
  language = "en",
  issn     = "1544-9173, 1545-7885",
  pmid     = "20126252",
  doi      = "10.1371/journal.pbio.1000292",
  pmc      = "PMC2811146"
}

@ARTICLE{Nesterova2009-em,
  title    = "Simple and integrated detours: field tests with Columbian ground
              squirrels",
  author   = "Nesterova, Anna Pavlovna and Hansen, Frank",
  abstract = "An internal representation of space offers flexibility to animals
              during orientation and allows execution of short cuts and
              detours. We tested the ability of 19 free-ranging Columbian
              ground squirrels (Spermophilus columbianus) to perform integrated
              detours that required travelling under- and aboveground.
              Squirrels were individually tested on their territories (2 tests)
              and in an arena (7 tests). During tests, animals could reach food
              by running aboveground and then through tunnels. For the
              territory tests, natural tunnels were available. For the arena
              tests, animals used artificial tunnels within a fenced-in part of
              the meadow. For the last arena test, tubes were placed
              aboveground replicating the underground structure. In this test
              animals were asked to make a simple detour, when the full path to
              the goal was visible. On their territories, 41\% of squirrels
              performed detours. All animals reached the food in the arena.
              When choosing an arena detour, squirrels based their decision on
              the proximity of the burrow as well as on whether it led to food.
              On the last arena test, more squirrels performed correct detours
              on the first attempt compared to other tests. The results suggest
              that ground squirrels can perform simple and integrated detours,
              but animals perform better if the full path is visible.",
  journal  = "Anim. Cogn.",
  volume   =  12,
  number   =  5,
  pages    = "655--670",
  month    =  sep,
  year     =  2009,
  language = "en",
  issn     = "1435-9448, 1435-9456",
  pmid     = "19396478",
  doi      = "10.1007/s10071-009-0224-1"
}

@MISC{noauthor_undated-ot,
  title        = "The travelling sales Rat",
  howpublished = "\url{https://iopscience.iop.org/article/10.1088/1741-2560/8/6/065010/pdf?casa_token=9NbJ5AY4fAcAAAAA:wtKCXaD6lR9nIMBH4wCuthuuSp_UhnchIGvU7UldVIyT_Za-XIUFdiascZx3rgBaslD4Py_dQw}",
  note         = "Accessed: 2020-6-4"
}

@ARTICLE{Morellini2013-qr,
  title    = "Spatial memory tasks in rodents: what do they model?",
  author   = "Morellini, Fabio",
  abstract = "The analysis of spatial learning and memory in rodents is
              commonly used to investigate the mechanisms underlying certain
              forms of human cognition and to model their dysfunction in
              neuropsychiatric and neurodegenerative diseases. Proper
              interpretation of rodent behavior in terms of spatial memory and
              as a model of human cognitive functions is only possible if
              various navigation strategies and factors controlling the
              performance of the animal in a spatial task are taken into
              consideration. The aim of this review is to describe the
              experimental approaches that are being used for the study of
              spatial memory in rats and mice and the way that they can be
              interpreted in terms of general memory functions. After an
              introduction to the classification of memory into various
              categories and respective underlying neuroanatomical substrates,
              I explain the concept of spatial memory and its measurement in
              rats and mice by analysis of their navigation strategies.
              Subsequently, I describe the most common paradigms for spatial
              memory assessment with specific focus on methodological issues
              relevant for the correct interpretation of the results in terms
              of cognitive function. Finally, I present recent advances in the
              use of spatial memory tasks to investigate episodic-like memory
              in mice.",
  journal  = "Cell Tissue Res.",
  volume   =  354,
  number   =  1,
  pages    = "273--286",
  month    =  oct,
  year     =  2013,
  language = "en",
  issn     = "0302-766X, 1432-0878",
  pmid     = "23793547",
  doi      = "10.1007/s00441-013-1668-9"
}

@ARTICLE{Grieves2013-ji,
  title     = "Cognitive maps and spatial inference in animals: Rats fail to
               take a novel shortcut, but can take a previously experienced one",
  author    = "Grieves, Roderick M and Dudchenko, Paul A",
  abstract  = "Previous work has shown that children are able to make a spatial
               inference about adjacent locations that have only been
               experienced indirectly (Hazen, Lockman, \& Pick, 1978). We
               sought to replicate this finding in rats, on a conceptually
               analogous task. In a first experiment, rats (n=8) were given 110
               training trials on a task in which they entered a series of four
               square environments via connecting alleyways. Following
               training, we conducted a probe session in which the original
               training route was blocked and three novel routes were
               introduced, one of which led directly to the food reward.
               Surprisingly, rats failed to choose this shortcut route over the
               alternative routes. In a second experiment, following additional
               training with a series of platforms that were visible from one
               another, rats again failed to take a shortcut when given the
               opportunity to do so. In a third experiment with naive rats
               (n=11), a shortcut was chosen, but only by rats that were given
               unrewarded preexposure to the shortcut route. These tests
               suggest that, despite their dedicated neural representations of
               location and direction, rats lack the capacity for a novel
               spatial inference. For rats, the use of a shortcut requires
               learning.",
  journal   = "Learn. Motiv.",
  publisher = "Elsevier",
  volume    =  44,
  number    =  2,
  pages     = "81--92",
  month     =  may,
  year      =  2013,
  keywords  = "Tolman; Maier; Cognitive map; Shortcutting; Intramaze landmarks;
               Extramaze landmarks; Spatial inference",
  issn      = "0023-9690",
  doi       = "10.1016/j.lmot.2012.08.001"
}

@ARTICLE{Roberts2007-ec,
  title    = "Rats take correct novel routes and shortcuts in an enclosed maze",
  author   = "Roberts, William A and Cruz, Catherine and Tremblay, Joseph",
  abstract = "In 3 experiments, rats were allowed to travel selected routes
              along the internal alleys of a cross-maze that led from one
              distinctive end box to another. The maze and procedures used were
              designed to control the rats' ability to use intrinsic and
              extrinsic cues to their location in the maze; thus, only the
              internal geometry of the maze could be learned and used to travel
              between one end box and another. After an initial exploration
              phase, rats were given novel routes and shortcut tests that
              involved peripheral alleys not before traveled. Rats chose the
              correct novel path or shortcut significantly above chance on some
              tests in Experiments 1 and 2 and significantly better than a
              control group in Experiment 3. The findings suggest that rats
              were able to compute novel routes and shortcuts within the maze
              on the basis of limited experience with the internal geometry of
              the maze.",
  journal  = "J. Exp. Psychol. Anim. Behav. Process.",
  volume   =  33,
  number   =  2,
  pages    = "79--91",
  month    =  apr,
  year     =  2007,
  language = "en",
  issn     = "0097-7403",
  pmid     = "17469957",
  doi      = "10.1037/0097-7403.33.2.79"
}

@ARTICLE{Fellini2011-wd,
  title     = "Geometric information is required for allothetic navigation in
               mice",
  author    = "Fellini, Laetitia and Morellini, Fabio",
  abstract  = "In tasks for allothetic navigation, animals should orientate by
               means of distal cues. We have previously shown that mice use
               several forms of information to navigate, among which geometry,
               i.e. the shape of the environment, seems to play an important
               role. Here we investigated whether geometric features of the
               environment are necessary for allothetic navigation in mice.
               Mice were trained to navigate in a circular water maze by means
               of four distal landmarks distributed either symmetrically
               (symmetry group) or asymmetrically (asymmetry group) around the
               maze. Thus, mice could locate a hidden platform by either
               differentiating the landmarks based on their intrinsic features
               (symmetry group) or in addition by geometric information, i.e.
               based on the relative distances between landmarks (asymmetry
               group). Data indicated that place learning occurred only in the
               asymmetry group. The results support the idea that mice navigate
               by using the relational properties between distal landmarks and
               that geometric information is required for proper allothetic
               navigation in this species.",
  journal   = "Behav. Brain Res.",
  publisher = "Elsevier",
  volume    =  222,
  number    =  2,
  pages     = "380--384",
  month     =  sep,
  year      =  2011,
  language  = "en",
  issn      = "0166-4328, 1872-7549",
  pmid      = "21440573",
  doi       = "10.1016/j.bbr.2011.03.040"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Eason2019-sm,
  title    = "Squirrels Do the Math: Flight Trajectories in Eastern Gray
              Squirrels (Sciurus carolinensis)",
  author   = "Eason, Perri K and Nason, Lindsay D and Alexander, Jr., James E",
  abstract = "Animals are under strong selective pressures to make correct
              decisions when attempting to escape an approaching predator, and
              not surprisingly many studies have shown that animals adjust
              their flight initiation behavior in response to risk. However, we
              have a poor understanding of animals' capability to select an
              appropriate flight trajectory. We investigated whether eastern
              gray squirrels would adjust their flight trajectory based on the
              relative locations of the squirrel, the approaching threat, and
              potential refuges. We used a person running toward a focal
              squirrel (N = 122) as the threat and considered the three trees
              nearest the squirrel and taller than 8 m to be potential refuges.
              Squirrels were strongly affected by the angle () formed by the
              locations of person, squirrel, and the three nearest trees. A
              squirrel was less likely to run to the nearest tree (Tree 1) when
              1 was relatively acute, but also less likely to run to Tree 1
              when 2 was obtuse, making Tree 2 a more attractive refuge. A
              squirrel was more likely to run to Tree 1 if it was close and if
              Tree 2 was relatively far. Subtle differences in the effects of
              1 versus 2 on squirrel refuge choice support the idea that
              squirrels prefer a nearby refuge. Squirrels were more likely to
              select Trees 2 and 3 rather than Tree 1 only when 2 was obtuse
              (105). In contrast, most squirrels chose to run to Tree 1 when
              1 was greater than 65; thus squirrels were more likely to
              choose Tree 1 even when doing so required running at least partly
              toward the approaching threat. The decisions made by focal
              squirrels provide evidence that this species' assessment of risk
              is highly nuanced. A great deal of variation has been reported in
              responses to predators within species. While part of the
              variation may be due to strategic unpredictability on the part of
              the prey, part of it may also be due to differences in flight
              trajectory and refuge preferences that have not been well
              studied.",
  month    =  mar,
  year     =  2019,
  doi      = "10.3389/fevo.2019.00066"
}

@ARTICLE{Herberholz2012-ib,
  title    = "Decision Making and Behavioral Choice during Predator Avoidance",
  author   = "Herberholz, Jens and Marquart, Gregory D",
  abstract = "One of the most important decisions animals have to make is how
              to respond to an attack from a potential predator. The response
              must be prompt and appropriate to ensure survival. Invertebrates
              have been important models in studying the underlying
              neurobiology of the escape response due to their accessible
              nervous systems and easily quantifiable behavioral output.
              Moreover, invertebrates provide opportunities for investigating
              these processes at a level of analysis not available in most
              other organisms. Recently, there has been a renewed focus in
              understanding how value-based calculations are made on the level
              of the nervous system, i.e., when decisions are made under
              conflicting circumstances, and the most desirable choice must be
              selected by weighing the costs and benefits for each behavioral
              choice. This article reviews samples from the current literature
              on anti-predator decision making in invertebrates, from single
              neurons to complex behaviors. Recent progress in understanding
              the mechanisms underlying value-based behavioral decisions is
              also discussed.",
  journal  = "Front. Neurosci.",
  volume   =  6,
  pages    = "125",
  month    =  aug,
  year     =  2012,
  keywords = "behavioral choice; decision making; escape; neural circuits;
              predation",
  language = "en",
  issn     = "1662-4548, 1662-453X",
  pmid     = "22973187",
  doi      = "10.3389/fnins.2012.00125",
  pmc      = "PMC3428584"
}

@ARTICLE{Eaton1991-cg,
  title     = "How stimulus direction determines the trajectory of the
               Mauthner-initiated escape response in a teleost fish",
  author    = "Eaton, R C and Emberley, D S",
  abstract  = "Fishes use the Mauthner-initiated C-start for short-latency
               evasion of predators. C-starts consist of a sudden turn (stage
               1) and a rapid acceleration (stage 2). We analyzed high-speed
               cin{\'e} films of goldfish C-starts elicited by dropping a ball
               into the water. It was previously thought that stage 1 angle
               does not vary concomitantly with the angle of the threatening
               stimulus relative to the position of the fish. We found,
               however, a significant inverse relationship between the
               direction of the impact of the ball and the angle turned by the
               end of stage 1. When starting near a wall, or when its usual
               trajectory was blocked by a wall, the fish used an escape route
               that was not predictable from the stimulus angle. The fish did
               not appear to correct its trajectory if it began to turn towards
               the ball. This behavioral evidence supports the previous notion
               that the underlying neural command is ballistic and does not use
               sensory information from the stimulus once the movement begins.
               If this is so, the fish probably utilizes information on
               obstacle location in the interval leading up to the trigger
               stimulus.",
  journal   = "J. Exp. Biol.",
  publisher = "jeb.biologists.org",
  volume    =  161,
  pages     = "469--487",
  month     =  nov,
  year      =  1991,
  language  = "en",
  issn      = "0022-0949",
  pmid      = "1757775"
}

@ARTICLE{Hennig1976-es,
  title    = "The Effect of Distance Between Predator and Prey and the
              Opportunity to Escape on Tonic Immobility in Anolis Carolinensis",
  author   = "Hennig, Charles W and Dunlap, William P and Gallup, Gordon G",
  abstract = "The idea that tonic immobility (TI) may be a reaction to
              predation has received increasing support in recent years. It
              follows, from this view, that distance between predator and prey
              and opportunity for escape should have predictable effects on
              immobility. The first experiment showed that the presence of
              large bushes, as an explicit escape manipulation, reduced
              immobility durations in anoles (Anolis carolinensis) in
              comparison to what occurred when they were immobilized in an open
              area, with the effect being most evident the closer the predator
              was to the prey. In the second experiment it was shown that close
              proximity between anoles and the experimenter produced longer
              durations of immobility in an open area, while a third experiment
              showed that with bushes nearby this relationship was reversed;
              that is, shorter durations of TI with anoles in close proximity
              to the experimenter.",
  journal  = "Psychol. Rec.",
  volume   =  26,
  number   =  3,
  pages    = "312--320",
  month    =  jul,
  year     =  1976,
  issn     = "0033-2933, 2163-3452",
  doi      = "10.1007/BF03394393"
}

@ARTICLE{Kimchi2003-xz,
  title     = "Detours by the blind mole-rat follow assessment of location and
               physical properties of underground obstacles",
  author    = "Kimchi, Tali and Terkel, Joseph",
  abstract  = "Orientation by an animal inhabiting an underground environment
               must be extremely efficient if it is to contend effectively with
               the high energetic costs of excavating soil for a tunnel system.
               We examined, in the field, the ability of a fossorial rodent,
               the blind mole-rat, Spalax ehrenbergi, to detour different types
               of obstacles blocking its tunnel and rejoin the disconnected
               tunnel section. To create obstacles, we dug ditches, which we
               either left open or filled with stone or wood. Most (77\%)
               mole-rats reconnected the two parts of their tunnel and
               accurately returned to their orginal path by digging a parallel
               bypass tunnel around the obstacle at a distance of 10--20cm from
               the open ditch boundaries or 3--8cm from the filled ditch
               boundaries. When the ditch was placed asymmetrically across the
               tunnel, the mole-rats detoured around the shorter side. These
               findings demonstrate that mole-rats seem to be able to assess
               the nature of an obstacle ahead and their own distance from the
               obstacle boundaries, as well as the relative location of the far
               section of disconnected tunnel. We suggest that mole-rats mainly
               use reverberating self-produced seismic vibrations as a
               mechanism to determine the size, nature and location of the
               obstacle, as well as internal self-generated references to
               determine their location relative to the disconnected tunnel
               section. Copyright 2003 The Association for the Study of Animal
               Behaviour. Published by Elsevier Ltd. All rights reserved.",
  journal   = "Anim. Behav.",
  publisher = "Elsevier",
  volume    =  66,
  number    =  5,
  pages     = "885--891",
  month     =  nov,
  year      =  2003,
  issn      = "0003-3472",
  doi       = "10.1006/anbe.2003.2267"
}

@ARTICLE{Kimchi2001-oj,
  title     = "Spatial learning and memory in the blind mole-rat in comparison
               with the laboratory rat and Levant vole",
  author    = "Kimchi, Tali and Terkel, Joseph",
  abstract  = "Studies dealing with spatial orientation in mammals have mostly
               dealt with surface-dwelling species. We studied the ability of a
               subterranean rodent to orient in space and compared it with two
               species of rodents that spend most of their lives above ground.
               The solitary blind mole-rat, Spalax ehrenbergi, inhabits an
               extensive, branching tunnel system that it digs itself and in
               which it spends its entire life. We examined its ability to
               learn and remember a winding path towards a goal in a multiple
               labyrinth and compared it with Levant voles, Microtus guentheri,
               and laboratory rats, Rattus norvegicus. The mole-rats learned
               significantly faster than the rats and voles. Furthermore, their
               ability to remember the maze was significantly better than that
               of the rats after 2, 7, 30 and 60 days from the end of the
               learning experiment and significantly better than the voles
               after 120 days. The mole-rats still retained ca. 45\% of their
               optimal performance at the end of the learning experiment after
               4 months compared with 20\% for the voles after 4 months and
               less than 20\% for the rats after 2 months. Despite having lost
               its vision, the mole-rat was thus more able to orient in a
               complex maze than the surface-dwelling vole and laboratory rat.
               We suggest that the mole-rat compensates for the sensory
               limitations imposed by the subterranean niche and for its loss
               of vision by relying on the Earth's magnetic field and internal
               cues to steer its course efficiently. We discuss the possible
               mechanisms of orientation. Copyright 2001 The Association for
               the Study of Animal Behaviour.",
  journal   = "Anim. Behav.",
  publisher = "Elsevier",
  volume    =  61,
  number    =  1,
  pages     = "171--180",
  month     =  jan,
  year      =  2001,
  language  = "en",
  issn      = "0003-3472",
  pmid      = "11170707",
  doi       = "10.1006/anbe.2000.1565"
}

@ARTICLE{Kafkafi2005-es,
  title    = "Texture of locomotor path: a replicable characterization of a
              complex behavioral phenotype",
  author   = "Kafkafi, N and Elmer, G I",
  abstract = "A database of mouse locomotor path in spatial tests can be used
              to search in silico for behavioral measures that better
              discriminate between genotypes and are more replicable across
              laboratories. In this study, software for the exploration of
              exploration (SEE) was used to search a large database for a novel
              behavioral measure that would characterize complex movement
              paths. The database included mouse open-field behavior assessed
              in 3 laboratories, 7 inbred strains, several pharmacological
              treatments and hundreds of animals. The new behavioral measure,
              ``path texture'', was characterized using the local curvature of
              the path (the change of direction per unit distance, in
              degrees/cm) across several spatial scales, starting from scales
              smaller than the animal's body length and up to the scale of the
              arena size. Path texture analysis differs from fractal dimension
              analysis in that it does not assume self-similarity across
              scales. Path texture was found to discriminate inbred strains
              with relatively high broad-sense heritability (43\%-71\%) and
              high replicability across laboratories. Even genotypes that had
              similar path curvatures in some scales usually differed in other
              scales, and self-similarity across scales was not displayed by
              all genotypes. Amphetamine decreased the path curvature of
              C57BL/6 mice in small and medium scales, while having no effect
              on DBA/2J mice. Diazepam dose-dependently decreased the curvature
              of C57BL/6 mice across all scales, while 2 anxiogenic drugs,
              FG-7142 and pentylenetetrazole, increased it. Path texture thus
              has high potential for behavioral phenotyping and the study of
              drug effects in the mouse.",
  journal  = "Genes Brain Behav.",
  volume   =  4,
  number   =  7,
  pages    = "431--443",
  month    =  oct,
  year     =  2005,
  language = "en",
  issn     = "1601-1848, 1601-183X",
  pmid     = "16176389",
  doi      = "10.1111/j.1601-183X.2005.00126.x"
}

@ARTICLE{Hein2020-gg,
  title     = "An Algorithmic Approach to Natural Behavior",
  author    = "Hein, Andrew M and Altshuler, Douglas L and Cade, David E and
               Liao, James C and Martin, Benjamin T and Taylor, Graham K",
  abstract  = "SummaryUncovering the mechanisms and implications of natural
               behavior is a goal that unites many fields of biology. Yet, the
               diversity, flexibility, and multi-scale nature of these
               behaviors often make understanding elusive. Here, we review
               studies of animal pursuit and evasion --- two special classes of
               behavior where theory-driven experiments and new modeling
               techniques are beginning to uncover the general control
               principles underlying natural behavior. A key finding of these
               studies is that intricate sequences of pursuit and evasion
               behavior can often be constructed through simple, repeatable
               rules that link sensory input to motor output: we refer to these
               rules as behavioral algorithms. Identifying and mathematically
               characterizing these algorithms has led to important insights,
               including the discovery of guidance rules that attacking
               predators use to intercept mobile prey, and coordinated neural
               and biomechanical mechanisms that animals use to avoid impending
               collisions. Here, we argue that algorithms provide a good
               starting point for studies of natural behavior more generally.
               Rather than beginning at the neural or ecological levels of
               organization, we advocate starting in the middle, where the
               algorithms that link sensory input to behavioral output can
               provide a solid foundation from which to explore both the
               implementation and the ecological outcomes of behavior. We
               review insights that have been gained through such an
               algorithmic approach to pursuit and evasion behaviors. From
               these, we synthesize theoretical principles and lay out key
               modeling tools needed to apply an algorithmic approach to the
               study of other complex natural behaviors.",
  journal   = "Curr. Biol.",
  publisher = "Elsevier",
  volume    =  30,
  number    =  11,
  pages     = "R663--R675",
  month     =  jun,
  year      =  2020,
  language  = "en",
  issn      = "0960-9822",
  doi       = "10.1016/j.cub.2020.04.018"
}

@ARTICLE{Carandini2012-xx,
  title    = "From circuits to behavior: a bridge too far?",
  author   = "Carandini, Matteo",
  abstract = "Neuroscience seeks to understand how neural circuits lead to
              behavior. However, the gap between circuits and behavior is too
              wide. An intermediate level is one of neural computations, which
              occur in individual neurons and populations of neurons. Some
              computations seem to be canonical: repeated and combined in
              different ways across the brain. To understand neural
              computations, we must record from a myriad of neurons in multiple
              brain regions. Understanding computation guides research in the
              underlying circuits and provides a language for theories of
              behavior.",
  journal  = "Nat. Neurosci.",
  volume   =  15,
  number   =  4,
  pages    = "507--509",
  month    =  mar,
  year     =  2012,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "22449960",
  doi      = "10.1038/nn.3043"
}

@ARTICLE{De_Oca2007-jy,
  title    = "Brief flight to a familiar enclosure in response to a conditional
              stimulus in rats",
  author   = "de Oca, Beatrice M and Minor, Thomas R and Fanselow, Michael S",
  abstract = "The authors observed brief, directed movement to a familiar
              enclosure in rats to determine whether this behavior is part of a
              rat's defensive repertoire when exposed to a conditional-fear
              stimulus. In Experiment 1, upon exposure to the compound
              conditional-fear stimulus of tone and light, only rats that
              received paired presentations of the conditional stimuli and
              shock fled into a small, familiar enclosure where they then
              froze. Rats that had received unpaired presentations did not
              enter the enclosure in significant amounts when later tested. In
              Experiment 2, the authors observed rats' freezing and use of
              either a familiar or an unfamiliar enclosure when tested with a
              conditional-fear stimulus. Rats tested with a familiar enclosure
              entered it more quickly than did rats without prior exposure to
              the enclosure. Freezing was greatest when both training and
              testing environments were similar with respect to access to the
              enclosure. The results of these 2 experiments support the idea
              that brief, directed flight in rats is a component of the
              postencounter stage of predatory imminence (M. S. Fanselow \& L.
              S. Lester, 1988) and is compatible with freezing.",
  journal  = "J. Gen. Psychol.",
  volume   =  134,
  number   =  2,
  pages    = "153--172",
  month    =  apr,
  year     =  2007,
  language = "en",
  issn     = "0022-1309",
  pmid     = "17503692",
  doi      = "10.3200/GENP.134.2.153-172"
}

@ARTICLE{Lecca2020-xk,
  title   = "Heterogeneous Habenular Neuronal Ensembles during Selection of
             Defensive Behaviors",
  author  = "Lecca, Salvatore and Namboodiri, Vijay M K and Restivo, Leonardo
             and Gervasi, Nicolas and Pillolla, Giuliano and Stuber, Garret D
             and Mameli, Manuel",
  journal = "Cell Rep.",
  volume  =  31,
  number  =  10,
  pages   = "107752",
  month   =  jun,
  year    =  2020,
  issn    = "2211-1247",
  doi     = "10.1016/j.celrep.2020.107752"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Fiker2020-kd,
  title    = "Visual Gait Lab: A user-friendly approach to gait analysis",
  author   = "Fiker, Robert and Kim, Linda H and Molina, Leonardo A and
              Chomiak, Taylor and Whelan, Patrick J",
  abstract = "BACKGROUND: Gait analysis forms a critical part of many lab
              workflows, ranging from those interested in preclinical
              neurological models to others who use locomotion as part of a
              standard battery of tests. Unfortunately, while paw detection can
              be semi-automated, it becomes generally a time-consuming process
              with error corrections. Improvement in paw tracking would aid in
              better gait analysis performance and experience. NEW METHOD: Here
              we show the use of Visual Gait Lab (VGL), a high-level software
              with an intuitive, easy to use interface, that is built on
              DeepLabCut™. VGL is optimized to generate gait metrics and allows
              for quick manual error corrections. VGL comes with a single
              executable, streamlining setup on Windows systems. We demonstrate
              the use of VGL to analyze gait. RESULTS: Training and evaluation
              of VGL were conducted using 200 frames (80/20 train-test split)
              of video from mice walking on a treadmill. The trained network
              was then used to visually track paw placements to compute gait
              metrics. These are processed and presented on the screen where
              the user can rapidly identify and correct errors. COMPARISON WITH
              EXISTING METHODS: Gait analysis remains cumbersome, even with
              commercial software due to paw detection errors. DeepLabCut™ is
              an alternative that can improve visual tracking but is not
              optimized for gait analysis functionality. CONCLUSIONS: VGL
              allows for gait analysis to be performed in a rapid, unbiased
              manner, with a set-up that can be easily implemented and executed
              by those without a background in computer programming.",
  journal  = "J. Neurosci. Methods",
  volume   =  341,
  pages    = "108775",
  month    =  may,
  year     =  2020,
  keywords = "DeepLabCut™; Gait analysis; Gait tracking system; Motor control;
              Mouse locomotion",
  language = "en",
  issn     = "0165-0270, 1872-678X",
  pmid     = "32428621",
  doi      = "10.1016/j.jneumeth.2020.108775"
}

@ARTICLE{Hein2018-el,
  title    = "Conserved behavioral circuits govern high-speed decision-making
              in wild fish shoals",
  author   = "Hein, Andrew M and Gil, Michael A and Twomey, Colin R and Couzin,
              Iain D and Levin, Simon A",
  abstract = "To evade their predators, animals must quickly detect potential
              threats, gauge risk, and mount a response. Putative neural
              circuits responsible for these tasks have been isolated in
              laboratory studies. However, it is unclear whether and how these
              circuits combine to generate the flexible, dynamic sequences of
              evasion behavior exhibited by wild, freely moving animals. Here,
              we report that evasion behavior of wild fish on a coral reef is
              generated through a sequence of well-defined decision rules that
              convert visual sensory input into behavioral actions. Using an
              automated system to present visual threat stimuli to fish in
              situ, we show that individuals initiate escape maneuvers in
              response to the perceived size and expansion rate of an oncoming
              threat using a decision rule that matches dynamics of known
              loom-sensitive neural circuits. After initiating an evasion
              maneuver, fish adjust their trajectories using a control rule
              based on visual feedback to steer away from the threat and toward
              shelter. These decision rules accurately describe evasion
              behavior of fish from phylogenetically distant families,
              illustrating the conserved nature of escape decision-making. Our
              results reveal how the flexible behavioral responses required for
              survival can emerge from relatively simple, conserved
              decision-making mechanisms.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  115,
  number   =  48,
  pages    = "12224--12228",
  month    =  nov,
  year     =  2018,
  keywords = "decision-making; evasion; neural circuit; neuroethology;
              predator--prey interactions",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "30420510",
  doi      = "10.1073/pnas.1809140115",
  pmc      = "PMC6275531"
}

@UNPUBLISHED{Alonso2020-is,
  title    = "The {HexMaze}: A previous knowledge and schema task for mice",
  author   = "Alonso, Alejandra and Bokeria, Levan and van der Meij, Jacqueline
              and Samanta, Anumita and Eichler, Ronny and Spooner, Patrick and
              Lobato, Irene Navarro and Genzel, Lisa",
  abstract = "Abstract New information is rarely learned in isolation, instead
              most of what we experience can be incorporated into or uses
              previous knowledge networks in some form. However, most rodent
              laboratory tasks assume the animal to be na{\"\i}ve with no
              previous experience influencing the results. Previous knowledge
              in form of a schema can facilitate knowledge acquisition and
              accelerate systems consolidation: memories become more rapidly
              hippocampal independent and instead rely more on the prefrontal
              cortex. Here, we developed a new spatial navigation task where
              food locations are learned in a large, gangway maze -- the
              HexMaze. Analysing performance across sessions as well as on
              specific trials, we can show simple memory effects as well as
              multiple effects of previous knowledge accelerating both online
              learning and performance increases over offline periods.
              Importantly, we are the first to show that schema build-up is
              dependent on how much time passes, not how often the animal is
              trained.",
  journal  = "bioRxiv",
  pages    = "441048",
  month    =  mar,
  year     =  2020,
  language = "en",
  doi      = "10.1101/441048"
}

@ARTICLE{Kabadayi2018-pq,
  title    = "The detour paradigm in animal cognition",
  author   = "Kabadayi, Can and Bobrowicz, Katarzyna and Osvath, Mathias",
  abstract = "In this paper, we review one of the oldest paradigms used in
              animal cognition: the detour paradigm. The paradigm presents the
              subject with a situation where a direct route to the goal is
              blocked and a detour must be made to reach it. Often being an
              ecologically valid and a versatile tool, the detour paradigm has
              been used to study diverse cognitive skills like insight, social
              learning, inhibitory control and route planning. Due to the
              relative ease of administrating detour tasks, the paradigm has
              lately been used in large-scale comparative studies in order to
              investigate the evolution of inhibitory control. Here we review
              the detour paradigm and some of its cognitive requirements, we
              identify various ecological and contextual factors that might
              affect detour performance, we also discuss developmental and
              neurological underpinnings of detour behaviors, and we suggest
              some methodological approaches to make species comparisons more
              robust.",
  journal  = "Anim. Cogn.",
  volume   =  21,
  number   =  1,
  pages    = "21--35",
  month    =  jan,
  year     =  2018,
  keywords = "Comparative psychology; Detour behavior; Inhibitory control;
              Route planning",
  language = "en",
  issn     = "1435-9448, 1435-9456",
  pmid     = "29234898",
  doi      = "10.1007/s10071-017-1152-0",
  pmc      = "PMC5756264"
}

@ARTICLE{Uribe-Marino2012-pw,
  title    = "Anti-aversive effects of cannabidiol on innate fear-induced
              behaviors evoked by an ethological model of panic attacks based
              on a prey vs the wild snake Epicrates cenchria crassus
              confrontation paradigm",
  author   = "Uribe-Mari{\~n}o, Andr{\'e}s and Francisco, Audrey and
              Castiblanco-Urbina, Maria Ang{\'e}lica and Twardowschy, Andr{\'e}
              and Salgado-Rohner, Carlos Jos{\'e} and Crippa, Jos{\'e}
              Alexandre S and Hallak, Jaime Eduardo Cec{\'\i}lio and Zuardi,
              Ant{\^o}nio Waldo and Coimbra, Norberto Cysne",
  abstract = "Several pharmacological targets have been proposed as modulators
              of panic-like reactions. However, interest should be given to
              other potential therapeutic neurochemical agents. Recent
              attention has been given to the potential anxiolytic properties
              of cannabidiol, because of its complex actions on the
              endocannabinoid system together with its effects on other
              neurotransmitter systems. The aim of this study was to
              investigate the effects of cannabidiol on innate fear-related
              behaviors evoked by a prey vs predator paradigm. Male Swiss mice
              were submitted to habituation in an arena containing a burrow and
              subsequently pre-treated with intraperitoneal administrations of
              vehicle or cannabidiol. A constrictor snake was placed inside the
              arena, and defensive and non-defensive behaviors were recorded.
              Cannabidiol caused a clear anti-aversive effect, decreasing
              explosive escape and defensive immobility behaviors outside and
              inside the burrow. These results show that cannabidiol modulates
              defensive behaviors evoked by the presence of threatening
              stimuli, even in a potentially safe environment following a fear
              response, suggesting a panicolytic effect.",
  journal  = "Neuropsychopharmacology",
  volume   =  37,
  number   =  2,
  pages    = "412--421",
  month    =  jan,
  year     =  2012,
  language = "en",
  issn     = "0893-133X, 1740-634X",
  pmid     = "21918503",
  doi      = "10.1038/npp.2011.188",
  pmc      = "PMC3242302"
}

@MISC{Juszczak2016-fk,
  title    = "Detour Behavior of Mice Trained with Transparent, Semitransparent
              and Opaque Barriers",
  author   = "Juszczak, Grzegorz R and Miller, Michal",
  editor   = "Burne, Thomas H J",
  abstract = "Detour tasks are commonly used to study problem solving skills
              and inhibitory control in canids and primates. However, there is
              no comparable detour test designed for rodents despite its
              significance for studying the development of executive skills.
              Furthermore, mice offer research opportunities that are not
              currently possible to achieve when primates are used. Therefore,
              the aim of the study was to translate the classic detour task to
              mice and to compare obtained data with key findings obtained
              previously in other mammals. The experiment was performed with
              V-shaped barriers and was based on the water escape paradigm. The
              study showed that an apparently simple task requiring mice to
              move around a small barrier constituted in fact a challenge that
              was strongly affected by the visibility of the target. The most
              difficult task involved a completely transparent barrier, which
              forced the mice to resolve a conflict between vision and tactile
              perception. The performance depended both on the inhibitory
              skills and on previous experiences. Additionally, all mice
              displayed a preference for one side of the barrier and most of
              them relied on the egocentric strategy. Obtained results show for
              the first time that the behavior of mice subjected to the detour
              task is comparable to the behavior of other mammals tested
              previously with free-standing barriers. This detailed
              characterization of the detour behavior of mice constitutes the
              first step toward the substitution of rodents for primates in
              laboratory experiments employing the detour task.",
  month    =  sep,
  year     =  2016,
  doi      = "10.1371/journal.pone.0162018"
}

@ARTICLE{Jackson2020-te,
  title    = "Many Paths to the Same Goal: Balancing Exploration and
              Exploitation during Probabilistic Route Planning",
  author   = "Jackson, Brian J and Fatima, Gusti Lulu and Oh, Sujean and Gire,
              David H",
  abstract = "During self-guided behaviors, animals identify constraints of the
              problems they face and adaptively employ appropriate strategies
              (Marsh, 2002). In the case of foraging, animals must balance
              sensory-guided exploration of an environment with memory-guided
              exploitation of known resource locations. Here, we show that
              animals adaptively shift cognitive resources between sensory and
              memory systems during foraging to optimize route planning under
              uncertainty. We demonstrate this using a new, laboratory-based
              discovery method to define the strategies used to solve a
              difficult route optimization scenario, the probabilistic
              ``traveling salesman'' problem (Raman and Gill, 2017; Fuentes et
              al., 2018; Mukherjee et al., 2019). Using this system, we
              precisely manipulated the strength of prior information as well
              as the complexity of the problem. We find that rats are capable
              of efficiently solving this route-planning problem, even under
              conditions with unreliable prior information and a large space of
              possible solutions. Through analysis of animals' trajectories, we
              show that they shift the balance between exploiting known
              locations and searching for new locations of rewards based on the
              predictability of reward locations. When compared with a Bayesian
              search, we found that animal performance is consistent with an
              approach that adaptively allocates cognitive resources between
              sensory processing and memory, enhancing sensory acuity and
              reducing memory load under conditions in which prior information
              is unreliable. Our findings establish new approaches to
              understand neural substrates of natural behavior as well as the
              rational development of biologically inspired approaches for
              complex real-world optimization.",
  journal  = "eNeuro",
  volume   =  7,
  number   =  3,
  month    =  jun,
  year     =  2020,
  keywords = "Bayesian; foraging; navigation",
  language = "en",
  issn     = "2373-2822",
  pmid     = "32414790",
  doi      = "10.1523/ENEURO.0536-19.2020",
  pmc      = "PMC7294469"
}

@UNPUBLISHED{Metz2017-xq,
  title    = "Evolution and genetics of precocious burrowing behavior in
              Peromyscus mice",
  author   = "Metz, Hillery C and Bedford, Nicole L and Pan, Linda and
              Hoekstra, Hopi E",
  abstract = "Summary A central challenge in biology is to understand how
              innate behaviors evolve between closely related species. One way
              to elucidate how differences arise is to compare the development
              of behavior in species with distinct adult traits. Here, we
              report that Peromyscus polionotus is strikingly precocious with
              regard to burrowing behavior, but not other behaviors, compared
              to its sister species P. maniculatus. In P. polionotus, burrows
              were excavated as early as 17 days of age, while P. maniculatus
              did not build burrows until 10 days later. Moreover, the
              well-known differences in burrow architecture between adults of
              these species---P. polionotus adults excavate long burrows with
              an escape tunnel, while P. maniculatus dig short, single-tunnel
              burrows---were intact in juvenile burrowers. To test whether this
              juvenile behavior is influenced by early-life environment, pups
              of both species were reciprocally cross-fostered. Fostering did
              not alter the characteristic burrowing behavior of either
              species, suggesting these differences are genetic. In backcross
              F2 hybrids, we show that precocious burrowing and adult tunnel
              length are genetically correlated, and that a single P.
              polionotus allele in a genomic region linked to adult tunnel
              length is predictive of precocious burrow construction. The
              co-inheritance of developmental and adult traits indicates the
              same genetic region---either a single gene with pleiotropic
              effects, or closely linked genes--- acts on distinct aspects of
              the same behavior across life stages. Such genetic variants
              likely affect behavioral drive (i.e. motivation) to burrow, and
              thereby affect both the development and adult expression of
              burrowing behavior.Highlights Juvenile P. polionotus construct
              burrows precociously compared to its sister species P.
              maniculatusCross-fostering does not alter species-specific
              burrowing behaviorA QTL linked to adult tunnel length predicts
              developmental onset of burrow construction in hybridsPleiotropic
              genetic variant(s) may affect behavioral drive across life stages",
  journal  = "bioRxiv",
  pages    = "150243",
  month    =  jun,
  year     =  2017,
  language = "en",
  doi      = "10.1101/150243"
}

@ARTICLE{Collett1982-hv,
  title   = "Do Toads Plan Routes ? A Study of the Detour Behaviour of Bufo
             viridis",
  author  = "Collett, T S",
  journal = "J. Comp. Physiol.",
  volume  =  146,
  pages   = "261--271",
  year    =  1982
}

@INCOLLECTION{Chapuis1987-dz,
  title     = "Detour and Shortcut Abilities in Several Species of Mammals",
  booktitle = "Cognitive Processes and Spatial Orientation in Animal and Man:
               Volume {I} Experimental Animal Psychology and Ethology",
  author    = "Chapuis, Nicole",
  editor    = "Ellen, Paul and Thinus-Blanc, Catherine",
  abstract  = "This study is concerned with two properties of cognitive
               mapping. The first is plasticity, by which I mean the ability of
               an animal to reorganize its previous experience of a given
               situation. Thus, for example, when modifications are introduced
               into a familiar spatial task, some animals can find original
               solutions; they do not become lost and they can still reach the
               goal. The second property is optimalization. It entails the
               choice and the planning of the best adapted solution: for
               example, taking the most direct of several possible ways to
               reach a goal.",
  publisher = "Springer Netherlands",
  pages     = "97--106",
  year      =  1987,
  address   = "Dordrecht",
  isbn      = "9789400935310",
  doi       = "10.1007/978-94-009-3531-0\_7"
}

@ARTICLE{Kunst2019-dy,
  title    = "A {Cellular-Resolution} Atlas of the Larval Zebrafish Brain",
  author   = "Kunst, Michael and Laurell, Eva and Mokayes, Nouwar and Kramer,
              Anna and Kubo, Fumi and Fernandes, Ant{\'o}nio M and F{\"o}rster,
              Dominique and Dal Maschio, Marco and Baier, Herwig",
  abstract = "Understanding brain-wide neuronal dynamics requires a detailed
              map of the underlying circuit architecture. We built an
              interactive cellular-resolution atlas of the zebrafish brain at 6
              days post-fertilization (dpf) based on the reconstructions of
              over 2,000 individually GFP-labeled neurons. We clustered our
              dataset in ``morphotypes,'' establishing a unique database of
              quantitatively described neuronal morphologies together with
              their spatial coordinates in vivo. Over 100 transgene expression
              patterns were imaged separately and co-registered with the
              single-neuron atlas. By annotating 72 non-overlapping brain
              regions, we generated from our dataset an inter-areal wiring
              diagram of the larval brain, which serves as ground truth for
              synapse-scale, electron microscopic reconstructions.
              Interrogating our atlas by ``virtual tract tracing'' has already
              revealed previously unknown wiring principles in the tectum and
              the cerebellum. In conclusion, we present here an evolving
              computational resource and visualization tool, which will be
              essential to map function to structure in a vertebrate brain.
              VIDEO ABSTRACT.",
  journal  = "Neuron",
  volume   =  103,
  number   =  1,
  pages    = "21--38.e5",
  month    =  jul,
  year     =  2019,
  keywords = "brain networks; cerebellum; connectomics; digital atlas;
              neuroanatomy; single-cell tracing; tectum; tissue clearing",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "31147152",
  doi      = "10.1016/j.neuron.2019.04.034"
}

@MISC{Tyson2020-tt,
  title  = "brainreg: automated {3D} brain registration with support for
            multiple species and atlases",
  author = "Tyson, Adam L and Rousseau, Charly V and Margrie, Troy W",
  month  =  aug,
  year   =  2020,
  doi    = "10.5281/zenodo.3991718"
}

@ARTICLE{Burt_de_Perera2008-ki,
  title     = "Rapid learning of shelter position in an intertidal fish, the
               shanny Lipophrys pholis {L}",
  author    = "Burt de Perera, T and Guilford, T C",
  abstract  = "The homing ability of an intertidal fish, the shanny Lipophrys
               pholis, was investigated using two experiments that were based
               on the shanny?s natural propensity to home to a refuge. A
               displacement experiment demonstrated that the fish were able to
               accurately locate the previous position of a refuge once the
               shelter itself had been removed so that it could not be used as
               a cue to directly signal the goal location. This shows that the
               shanny can encode information about its familiar surroundings
               into a spatial map and use this information to home. A second
               experiment in which the cues internal and external to the
               experimental tank were put in conflict with one another
               suggested that the shanny can encode cues that are both intra-
               and external-tank cues in its representation of space, but that
               there is individual variation in the type of cues that are used,
               or memorized.",
  journal   = "J. Fish Biol.",
  publisher = "Wiley Online Library",
  volume    =  72,
  number    =  6,
  pages     = "1386--1392",
  month     =  apr,
  year      =  2008,
  issn      = "0022-1112, 1095-8649",
  doi       = "10.1111/j.1095-8649.2008.01804.x"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Markel1994-dh,
  title     = "An adaptive value of spatial learning and memory in the blackeye
               goby, Coryphopterus nicholsi",
  author    = "Markel, Russell W",
  abstract  = "The adaptive value of spatial learning and memory has been
               demonstrated in birds and mammals (eg Shettleworth \& Krebs
               1983; Clarke et al. 1993), but few investigations have found
               evidence of similar learning abilities in fish. The goa{\l} of
               this project was to demonstrate spatial learning and memory in
               blackeye gobies, Coryphopterus nicholsi in a context in which it
               may be adaptive, namely predator evasion. Fish can learn spatial
               relationships among rel-evant features of their environments
               (Aronson 1951, 1971; Roitblat …",
  journal   = "Anim. Behav.",
  publisher = "Elsevier",
  volume    =  47,
  number    =  6,
  pages     = "1462--1464",
  month     =  jun,
  year      =  1994,
  issn      = "0003-3472",
  doi       = "10.1006/anbe.1994.1194"
}

@ARTICLE{Dodd2000-uu,
  title     = "Use of cues by Lipophrys pholis L. (Teleostei, Blenniidae) in
               learning the position of a refuge",
  author    = "Dodd, J and Gibson, R N and Hughes, R N",
  abstract  = "The ability of Lipophrys pholis to remember the position of a
               refuge was tested in an artificial habitat under the influence
               of different visual clues. L. pholis learned the position of the
               refuge in the presence of a clue consisting only of a small
               black screen. They responded to this clue by moving towards it
               and pressing themselves up against it. Lego towers and a white
               screen clue did not provoke such a response. In a further
               experiment L. pholis continued to respond to the black screen in
               this way when the screen was moved to another location further
               from the refuge. After 12 days L. pholis learned to use the
               black screen in its new position as an indirect clue and
               navigate to the refuge directly without first approaching the
               black screen. These results suggested that when placed in a
               novel habitat the immediate reaction of L. pholis is to move
               quickly towards the first dark area they see but, with
               experience, they can use the position of large objects around
               them to navigate quickly and efficiently to a refuge.",
  journal   = "Behav. Processes",
  publisher = "Elsevier",
  volume    =  49,
  number    =  2,
  pages     = "69--75",
  month     =  apr,
  year      =  2000,
  language  = "en",
  issn      = "0376-6357, 1872-8308",
  pmid      = "10794916",
  doi       = "10.1016/s0376-6357(00)00076-0"
}

@ARTICLE{Mugan2020-bu,
  title    = "Spatial planning with long visual range benefits escape from
              visual predators in complex naturalistic environments",
  author   = "Mugan, Ugurcan and MacIver, Malcolm A",
  abstract = "It is uncontroversial that land animals have more elaborated
              cognitive abilities than their aquatic counterparts such as fish.
              Yet there is no apparent a-priori reason for this. A key
              cognitive faculty is planning. We show that in visually guided
              predator-prey interactions, planning provides a significant
              advantage, but only on land. During animal evolution, the
              water-to-land transition resulted in a massive increase in visual
              range. Simulations of behavior identify a specific type of
              terrestrial habitat, clustered open and closed areas
              (savanna-like), where the advantage of planning peaks. Our
              computational experiments demonstrate how this patchy terrestrial
              structure, in combination with enhanced visual range, can reveal
              and hide agents as a function of their movement and create a
              selective benefit for imagining, evaluating, and selecting among
              possible future scenarios-in short, for planning. The vertebrate
              invasion of land may have been an important step in their
              cognitive evolution.",
  journal  = "Nat. Commun.",
  volume   =  11,
  number   =  1,
  pages    = "3057",
  month    =  jun,
  year     =  2020,
  language = "en",
  issn     = "2041-1723",
  pmid     = "32546681",
  doi      = "10.1038/s41467-020-16102-1",
  pmc      = "PMC7298009"
}

@ARTICLE{Toledo2020-he,
  title     = "Cognitive map--based navigation in wild bats revealed by a new
               high-throughput tracking system",
  author    = "Toledo, Sivan and Shohami, David and Schiffner, Ingo and Lourie,
               Emmanuel and Orchan, Yotam and Bartan, Yoav and Nathan, Ran",
  abstract  = "The presence of a cognitive map is essential to our ability to
               navigate through areas we know because it facilitates the use of
               spatial knowledge to derive new routes. Whether such maps exist
               in nonhuman animals has been debated, largely because of the
               difficulty of demonstrating qualifying components of the map
               outside of a laboratory. In two studies on Egyptian fruit bats,
               Harten et al. and Toledo et al. together show that this
               species's navigational strategies meet the requirements for the
               use of a cognitive map of their environment, confirming that
               this skill occurs outside of humans (see the Perspective by
               Fenton). Science , this issue p. [194][1], p. [188][2]; see also
               p. [142][3] Seven decades of research on the ``cognitive map,''
               the allocentric representation of space, have yielded key
               neurobiological insights, yet field evidence from free-ranging
               wild animals is still lacking. Using a system capable of
               tracking dozens of animals simultaneously at high accuracy and
               resolution, we assembled a large dataset of 172 foraging
               Egyptian fruit bats comprising >18 million localizations
               collected over 3449 bat-nights across 4 years. Detailed track
               analysis, combined with translocation experiments and exhaustive
               mapping of fruit trees, revealed that wild bats seldom exhibit
               random search but instead repeatedly forage in goal-directed,
               long, and straight flights that include frequent shortcuts.
               Alternative, non--map-based strategies were ruled out by
               simulations, time-lag embedding, and other trajectory analyses.
               Our results are consistent with expectations from cognitive
               map--like navigation and support previous neurobiological
               evidence from captive bats. [1]:
               /lookup/doi/10.1126/science.aay3354 [2]:
               /lookup/doi/10.1126/science.aax6904 [3]:
               /lookup/doi/10.1126/science.abd1213",
  journal   = "Science",
  publisher = "American Association for the Advancement of Science",
  volume    =  369,
  number    =  6500,
  pages     = "188--193",
  month     =  jul,
  year      =  2020,
  language  = "en",
  issn      = "0036-8075, 1095-9203",
  doi       = "10.1126/science.aax6904"
}

@ARTICLE{Cheng2005-pv,
  title    = "Is there a geometric module for spatial orientation? Squaring
              theory and evidence",
  author   = "Cheng, Ken and Newcombe, Nora S",
  abstract = "There is evidence, beginning with Cheng (1986), that mobile
              animals may use the geometry of surrounding areas to reorient
              following disorientation. Gallistel (1990) proposed that geometry
              is used to compute the major or minor axes of space and suggested
              that such information might form an encapsulated cognitive
              module. Research reviewed here, conducted on a wide variety of
              species since the initial discovery of the use of geometry and
              the formulation of the modularity claim, has supported some
              aspects of the approach, while casting doubt on others. Three
              possible processing models are presented that vary in the way in
              which (and the extent to which) they instantiate the modularity
              claim. The extant data do not permit us to discriminate among
              them. We propose a modified concept of modularity for which an
              empirical program of research is more tractable.",
  journal  = "Psychon. Bull. Rev.",
  volume   =  12,
  number   =  1,
  pages    = "1--23",
  month    =  feb,
  year     =  2005,
  language = "en",
  issn     = "1069-9384",
  pmid     = "15945200",
  doi      = "10.3758/bf03196346"
}

@UNPUBLISHED{Chen2020-uy,
  title    = "Between-subject prediction reveals a shared representational
              geometry in the rodent hippocampus",
  author   = "Chen, Hung-Tu and Manning, Jeremy R and van der Meer, Matthijs A
              A",
  abstract = "Summary How a memory system encodes related experiences has
              consequences for what operations the system supports. For
              instance, independent coding enables retention of potentially
              important idiosyncratic details by reducing interference, but
              makes it difficult to generalize across experiences. Strikingly,
              the rodent hippocampus constructs statistically independent
              representations across environments (``global remapping'') and
              assigns individual neuron firing fields to locations within an
              environment in an apparently random fashion, processes thought to
              contribute to the role of the hippocampus in episodic memory.
              This random mapping implies that it should be challenging to
              predict hippocampal encoding of a given experience in a one
              subject based on the encoding of that same experience in another
              subject. Contrary to this prediction, we find that by
              constructing a common representational space across rats
              (``hyperalignment''), we can consistently predict data of
              ``right'' trials (R) on a T-maze in a target rat based on 1) the
              ``left'' trials (L) of the target rat, and 2) the relationship
              between L and R trials from a different source rat. These
              cross-subject predictions outperformed a number of control
              mappings, such as those based on permuted data that broke the
              relationship between L and R activity for individual neurons, and
              those based solely on within-subject prediction. This work
              constitutes proof-of-principle for successful cross-subject
              prediction of ensemble activity patterns in the hippocampus. This
              novel approach provides new insights in understanding how
              different experiences are structured, and suggests further work
              identifying what aspects of experience encoding are shared vs.
              unique to an individual.",
  journal  = "bioRxiv",
  pages    = "2020.01.27.922062",
  month    =  jan,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.01.27.922062"
}

@MISC{Wickens2014-bt,
  title    = "The Geometry of Multivariate Statistics",
  author   = "Wickens, Thomas D",
  year     =  2014,
  keywords = "books",
  doi      = "10.4324/9781315806334"
}

@UNPUBLISHED{Arshadi2020-my,
  title    = "{SNT}: A Unifying Toolbox for Quantification of Neuronal Anatomy",
  author   = "Arshadi, Cameron and Eddison, Mark and Gunther, Ulrik A and
              Harrington, Kyle I and Ferreira, Tiago A",
  abstract = "Quantification of neuronal morphology is essential for
              understanding neuronal connectivity and many software tools have
              been developed for neuronal reconstruction and morphometry.
              However, such tools remain domain-specific, tethered to specific
              imaging modalities, and were not designed to accommodate the rich
              metadata generated by recent whole-brain cellular connectomics.
              To address these limitations, we created SNT: a unifying
              framework for neuronal morphometry and analysis of single-cell
              connectomics for the widely used Fiji and ImageJ platforms. We
              demonstrate that SNT -that replaces the popular Simple Neurite
              Tracer software- can be used to tackle important problems in
              contemporary neuroscience, validate its utility, and illustrate
              how it establishes an end-to-end platform for tracing,
              proof-editing, visualization, quantification, and modeling of
              neuroanatomy. With an open and scriptable architecture, a large
              user base, and thorough community-based documentation, SNT is an
              accessible and scalable resource for the broad neuroscience
              community that synergizes well with existing software. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2020.07.13.179325",
  month    =  jul,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.07.13.179325"
}

@ARTICLE{Harris2020-oh,
  title     = "Array programming with {NumPy}",
  author    = "Harris, Charles R and Millman, K Jarrod and van der Walt,
               St{\'e}fan J and Gommers, Ralf and Virtanen, Pauli and
               Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg,
               Sebastian and Smith, Nathaniel J and Kern, Robert and Picus,
               Matti and Hoyer, Stephan and van Kerkwijk, Marten H and Brett,
               Matthew and Haldane, Allan and Del R{\'\i}o, Jaime Fern{\'a}ndez
               and Wiebe, Mark and Peterson, Pearu and G{\'e}rard-Marchant,
               Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser,
               Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant,
               Travis E",
  abstract  = "Array programming provides a powerful, compact and expressive
               syntax for accessing, manipulating and operating on data in
               vectors, matrices and higher-dimensional arrays. NumPy is the
               primary array programming library for the Python language. It
               has an essential role in research analysis pipelines in fields
               as diverse as physics, chemistry, astronomy, geoscience,
               biology, psychology, materials science, engineering, finance and
               economics. For example, in astronomy, NumPy was an important
               part of the software stack used in the discovery of
               gravitational waves1 and in the first imaging of a black hole2.
               Here we review how a few fundamental array concepts lead to a
               simple and powerful programming paradigm for organizing,
               exploring and analysing scientific data. NumPy is the foundation
               upon which the scientific Python ecosystem is constructed. It is
               so pervasive that several projects, targeting audiences with
               specialized needs, have developed their own NumPy-like
               interfaces and array objects. Owing to its central position in
               the ecosystem, NumPy increasingly acts as an interoperability
               layer between such array computation libraries and, together
               with its application programming interface (API), provides a
               flexible framework to support the next decade of scientific and
               industrial analysis.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  585,
  number    =  7825,
  pages     = "357--362",
  month     =  sep,
  year      =  2020,
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "32939066",
  doi       = "10.1038/s41586-020-2649-2"
}

@ARTICLE{Chapuis1987-yd,
  title    = "The role of exploratory experience in a shortcut task by golden
              hamsters (Mesocricetus auratus)",
  author   = "Chapuis, N and Durup, M and Thinus-Blanc, C",
  abstract = "The aim of this experiment was to examine the role of exploratory
              experience on the ability to take a shortcut. In the first phase,
              two subspaces, X and Y, each consisting of two baited tables
              related by a runway, were separately explored by hamsters. In the
              second phase, the experimental group explored a connecting
              pathway between X and Y. The animals were finally submitted to a
              shortcut test during 2 days: in this test, in order to go from X
              to Y, they could choose between the longer familiar pathway and
              two shorter new pathways. In comparison with a control group,
              which did not undergo the second phase, the experimental group
              displayed a significant preference for the shortcut that did not
              cross the linking path with which they had had experience or
              either of the two distant portions whose linkage the animals had
              experienced. These results suggest that, in this simple
              situation, additional experience of a linking element between two
              separated subspaces has a beneficial effect on the setting up of
              spatial relationships between them, and perhaps on the
              representation of the whole situation.",
  journal  = "Anim. Learn. Behav.",
  volume   =  15,
  number   =  2,
  pages    = "174--178",
  month    =  jun,
  year     =  1987,
  issn     = "0090-4996, 1532-5830",
  doi      = "10.3758/BF03204960"
}

@ARTICLE{Bermudez-Contreras2020-wk,
  title    = "The Neuroscience of Spatial Navigation and the Relationship to
              Artificial Intelligence",
  author   = "Bermudez-Contreras, Edgar and Clark, Benjamin J and Wilber, Aaron",
  abstract = "Recent advances in artificial intelligence (AI) and neuroscience
              are impressive. In AI, this includes the development of computer
              programs that can beat a grandmaster at GO or outperform human
              radiologists at cancer detection. A great deal of these
              technological developments are directly related to progress in
              artificial neural networks---initially inspired by our knowledge
              about how the brain carries out computation. In parallel,
              neuroscience has also experienced significant advances in
              understanding the brain. For example, in the field of spatial
              navigation, knowledge about the mechanisms and brain regions
              involved in neural computations of cognitive maps---an internal
              representation of space---recently received the Nobel Prize in
              medicine. Much of the recent progress in neuroscience has partly
              been due to the development of technology used to record from
              very large populations of neurons in multiple regions of the
              brain with exquisite temporal and spatial resolution in behaving
              animals. With the advent of the vast quantities of data that
              these techniques allow us to collect there has been an increased
              interest in the intersection between AI and neuroscience, many of
              these intersections involve using AI as a novel tool to explore
              and analyze these large data sets. However, given the common
              initial motivation point---to understand the brain---these
              disciplines could be more strongly linked. Currently much of this
              potential synergy is not being realized. We propose that spatial
              navigation is an excellent area in which these two disciplines
              can converge to help advance what we know about the brain. In
              this review, we first summarize progress in the neuroscience of
              spatial navigation and reinforcement learning. We then turn our
              attention to discuss how spatial navigation has been modeled
              using descriptive, mechanistic, and normative approaches and the
              use of AI in such models. Next, we discuss how AI can advance
              neuroscience, how neuroscience can advance AI, and the
              limitations of these approaches. We finally conclude by
              highlighting promising lines of research in which spatial
              navigation can be the point of intersection between neuroscience
              and AI and how this can contribute to the advancement of the
              understanding of intelligent behavior.",
  journal  = "Front. Comput. Neurosci.",
  volume   =  14,
  pages    = "63",
  year     =  2020,
  issn     = "1662-5188",
  doi      = "10.3389/fncom.2020.00063"
}

@ARTICLE{Mosheiff2019-lx,
  title    = "Velocity coupling of grid cell modules enables stable embedding
              of a low dimensional variable in a high dimensional neural
              attractor",
  author   = "Mosheiff, Noga and Burak, Yoram",
  abstract = "Grid cells in the medial entorhinal cortex (MEC) encode position
              using a distributed representation across multiple neural
              populations (modules), each possessing a distinct spatial scale.
              The modular structure of the representation confers the grid cell
              neural code with large capacity. Yet, the modularity poses
              significant challenges for the neural circuitry that maintains
              the representation, and updates it based on self motion. Small
              incompatible drifts in different modules, driven by noise, can
              rapidly lead to large, abrupt shifts in the represented position,
              resulting in catastrophic readout errors. Here, we propose a
              theoretical model of coupled modules. The coupling suppresses
              incompatible drifts, allowing for a stable embedding of a
              two-dimensional variable (position) in a higher dimensional
              neural attractor, while preserving the large capacity. We propose
              that coupling of this type may be implemented by recurrent
              synaptic connectivity within the MEC with a relatively simple and
              biologically plausible structure.",
  journal  = "Elife",
  volume   =  8,
  month    =  aug,
  year     =  2019,
  keywords = "entorhinal cortex; grid cells; mouse; neural attractors; neural
              coding; neural networks; neuroscience; rat; short term
              memory;to\_read\_for\_review",
  language = "en",
  issn     = "2050-084X",
  pmid     = "31469365",
  doi      = "10.7554/eLife.48494",
  pmc      = "PMC6756787"
}

@ARTICLE{Linderman2016-pi,
  title         = "Recurrent switching linear dynamical systems",
  author        = "Linderman, Scott W and Miller, Andrew C and Adams, Ryan P
                   and Blei, David M and Paninski, Liam and Johnson, Matthew J",
  abstract      = "Many natural systems, such as neurons firing in the brain or
                   basketball teams traversing a court, give rise to time
                   series data with complex, nonlinear dynamics. We can gain
                   insight into these systems by decomposing the data into
                   segments that are each explained by simpler dynamic units.
                   Building on switching linear dynamical systems (SLDS), we
                   present a new model class that not only discovers these
                   dynamical units, but also explains how their switching
                   behavior depends on observations or continuous latent
                   states. These ``recurrent'' switching linear dynamical
                   systems provide further insight by discovering the
                   conditions under which each unit is deployed, something that
                   traditional SLDS models fail to do. We leverage recent
                   algorithmic advances in approximate inference to make
                   Bayesian inference in these models easy, fast, and scalable.",
  month         =  oct,
  year          =  2016,
  archivePrefix = "arXiv",
  eprint        = "1610.08466",
  primaryClass  = "stat.ML",
  arxivid       = "1610.08466"
}

@ARTICLE{Muryy_undated-jw,
  title  = "Route selection in non-Euclidean virtual environments",
  author = "Muryy, Alexander and Glennerster, Andrew",
  doi    = "10.1101/2020.08.14.250621"
}

@ARTICLE{Ahmad_Abu_Hatab2013-st,
  title   = "Dynamic Modelling of {Differential-Drive} Mobile Robots using
             Lagrange and {Newton-Euler} Methodologies: A Unified Framework",
  author  = "Ahmad Abu Hatab, Rached Dhaouadi",
  journal = "Adv Robot Autom",
  volume  =  02,
  number  =  02,
  year    =  2013,
  issn    = "2168-9695",
  doi     = "10.4172/2168-9695.1000107"
}

@ARTICLE{Kiehn2006-wi,
  title     = "Locomotor circuits in the mammalian spinal cord",
  author    = "Kiehn, Ole",
  abstract  = "Intrinsic spinal networks, known as central pattern generators
               (CPGs), control the timing and pattern of the muscle activity
               underlying locomotion in mammals. This review discusses new
               advances in understanding the mammalian CPGs with a focus on
               experiments that address the overall network structure as well
               as the identification of CPG neurons. I address the
               identification of excitatory CPG neurons and their role in
               rhythm generation, the organization of flexor-extensor networks,
               and the diverse role of commissural interneurons in coordinating
               left-right movements. Molecular and genetic approaches that have
               the potential to elucidate the function of populations of CPG
               interneurons are also discussed.",
  journal   = "Annu. Rev. Neurosci.",
  publisher = "annualreviews.org",
  volume    =  29,
  pages     = "279--306",
  year      =  2006,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "0147-006X",
  pmid      = "16776587",
  doi       = "10.1146/annurev.neuro.29.051605.112910"
}

@ARTICLE{Herbin2007-us,
  title    = "Gait parameters of treadmill versus overground locomotion in
              mouse",
  author   = "Herbin, Marc and Hackert, R{\'e}mi and Gasc, Jean-Pierre and
              Renous, Sabine",
  abstract = "Many studies of interest in motor behaviour and motor impairment
              in mice use equally treadmill or track as a routine test.
              However, the literature in mammals shows a wide difference of
              results between the kinematics of treadmill and overground
              locomotion. To study these discrepancies, we analyzed the
              locomotion of adult SWISS-OF1 mice over a large range of
              velocities using treadmill and overground track. The use of a
              high-speed video camera combined with cinefluoroscopic equipment
              allowed us to quantify in detail the various space and time
              parameters of limb kinematics. The results show that mice
              maintain the same gait pattern in both conditions. However, they
              also demonstrate that during treadmill exercise mice always
              exhibit higher stride frequency and consequently lower stride
              length. The relationship of the stance time and the swing time
              against the stride frequency are still the same in both
              conditions. We conclude that the conflict related to the
              discrepancy between the proprioceptive, vestibular, and visual
              inputs contribute to an increase in the stride frequency during
              the treadmill locomotion.",
  journal  = "Behav. Brain Res.",
  volume   =  181,
  number   =  2,
  pages    = "173--179",
  month    =  aug,
  year     =  2007,
  keywords = "Locomotion",
  language = "en",
  issn     = "0166-4328",
  pmid     = "17521749",
  doi      = "10.1016/j.bbr.2007.04.001"
}

@ARTICLE{Herbin2004-ma,
  title    = "Symmetrical and asymmetrical gaits in the mouse: patterns to
              increase velocity",
  author   = "Herbin, Marc and Gasc, Jean-Pierre and Renous, Sabine",
  abstract = "The gaits of the adult SWISS mice during treadmill locomotion at
              velocities ranging from 15 to 85 cm s(-1) have been analysed
              using a high-speed video camera combined with cinefluoroscopic
              equipment. The sequences of locomotion were analysed to determine
              the various space and time parameters of limb kinematics. We
              found that velocity adjustments are accounted for differently by
              the stride frequency and the stride length if the animal showed a
              symmetrical or an asymmetrical gait. In symmetrical gaits, the
              increase of velocity is provided by an equal increase in the
              stride length and the stride frequency. In asymmetrical gaits,
              the increase in velocity is mainly assured by an increase in the
              stride frequency in velocities ranging from 15 to 29 cm s(-1).
              Above 68 cm s(-1), velocity increase is achieved by stride length
              increase. In velocities ranging from 29 to 68 cm s(-1), the
              contribution of both variables is equal as in symmetrical gaits.
              Both stance time and swing time shortening contributed to the
              increase of the stride frequency in both gaits, though with a
              major contribution from stance time decrease. The pattern of
              locomotion obtained in a normal mouse should be used as a
              template for studying locomotor control deficits after lesions or
              in different mutations affecting the nervous system.",
  journal  = "J. Comp. Physiol. A Neuroethol. Sens. Neural Behav. Physiol.",
  volume   =  190,
  number   =  11,
  pages    = "895--906",
  month    =  nov,
  year     =  2004,
  keywords = "Locomotion",
  language = "en",
  issn     = "0340-7594",
  pmid     = "15449091",
  doi      = "10.1007/s00359-004-0545-0"
}

@ARTICLE{Walter2003-pb,
  title    = "Kinematics of 90 degrees running turns in wild mice",
  author   = "Walter, Rebecca M",
  abstract = "Turning is a requirement for locomotion on the variable terrain
              that most terrestrial animals inhabit and is a deciding factor in
              many predator-prey interactions. Despite this, the kinematics and
              mechanics of quadrupedal turns are not well understood. To gain
              insight to the turning kinematics of small quadrupedal mammals,
              six adult wild mice were videotaped at 250 Hz from below as they
              performed 90 degrees running turns. Four markers placed along the
              sagittal axis were digitized to allow observation of lateral
              bending and body rotation throughout the turn. Ground contact
              periods of the fore- and hindlimbs were also noted for each
              frame. During turning, mice increased their ground contact time,
              but did not change their stride frequency relative to straight
              running at maximum speed. Postcranial body rotation preceded
              deflection in heading, and did not occur in one continuous
              motion, but rather in bouts of 15-53 degrees. These bouts were
              synchronized with the stride cycle, such that the majority of
              rotation occurred during the second half of forelimb support and
              the first half of hindlimb support. In this phase of the stride
              cycle, the trunk was sagittally flexed and rotational inertia was
              65\% of that during maximal extension. By synchronizing body
              rotation with this portion of the stride cycle, mice can achieve
              a given angular acceleration with much lower applied torque.
              Compared with humans running along curved trajectories, mice
              maintained relatively higher speeds at proportionately smaller
              radii. A possible explanation for this difference lies in the
              more crouched limb posture of mice, which increases the
              mechanical advantage for horizontal ground force production. The
              occurrence of body rotation prior to deflection in heading may
              facilitate acceleration in the new direction by making use of the
              relatively greater force production inherent in the parasagittal
              limb posture of mice.",
  journal  = "J. Exp. Biol.",
  volume   =  206,
  number   = "Pt 10",
  pages    = "1739--1749",
  month    =  may,
  year     =  2003,
  language = "en",
  issn     = "0022-0949",
  pmid     = "12682105",
  doi      = "10.1242/jeb.00349"
}

@ARTICLE{Herbin2006-mc,
  title    = "How does a mouse increase its velocity? A model for investigation
              in the control of locomotion",
  author   = "Herbin, Marc and Gasc, Jean-Pierre and Renous, Sabine",
  abstract = "We analysed treadmill locomotion of the adult SWISS-OF1 mice over
              a large range of velocities. The use of a high-speed video camera
              combined with cinefluoroscopic equipment allowed us to quantify
              in detail the various space and time parameters of limb
              kinematics. We find that velocity adjustments depend upon whether
              animal used a symmetrical or non-symmetrical gait. In symmetrical
              gaits, the increase of velocity generally results equally from an
              increase in the stride frequency and the stride length. On the
              other hand, in non-symmetrical gaits, the increase in velocity is
              achieved differently according to the level of velocity used. As
              speed increases, velocity increases first as a consequence of
              increased stride frequency, then as in symmetrical gaits, by an
              equal increase in both variables, and finally at high speed,
              velocity increases through increased stride length. In both
              symmetrical and non-symmetrical gaits, stance and swing-time
              shortening contributed to the increase of the stride frequency,
              with stance time decrease being the major contributor. The
              pattern of locomotion obtained in the present study may be used
              as a model mouse system for studying locomotor deficits resulting
              from specific mutations in the nervous system. To cite this
              article: M. Herbin et al., C. R. Palevol 5 (2006). R{\'e}sum{\'e}
              Comment la souris augmente-elle sa vitesse ? Un mod{\`e}le pour
              la recherche sur le contr{\^o}le moteur de la locomotion. La
              locomotion sur tapis roulant de la souche de souris SWISS-OF1 a
              {\'e}t{\'e} analys{\'e}e {\`a} travers une large gamme de
              vitesses. L'utilisation de la vid{\'e}oradiographie {\`a} grande
              vitesse a permis de quantifier de fa{\c c}on tr{\`e}s
              d{\'e}taill{\'e}e tous les param{\`e}tres de la cin{\'e}matique
              du membre de r{\'e}f{\'e}rence. Les r{\'e}sultats ainsi obtenus
              montrent que la fr{\'e}quence et l'enjamb{\'e}e n'interviennent
              pas de la m{\^e}me fa{\c c}on dans l'augmentation de la vitesse,
              selon l'allure utilis{\'e}e. Lorsque l'animal est en allure
              sym{\'e}trique, l'augmentation de la vitesse est
              g{\'e}n{\'e}ralement obtenue par une {\'e}gale augmentation de la
              fr{\'e}quence et de l'enjamb{\'e}e. En revanche, si la souris
              utilise une allure non sym{\'e}trique, l'augmentation de la
              vitesse est obtenue diff{\'e}remment selon la valeur de cette
              derni{\`e}re. L'augmentation de la vitesse est d'abord surtout
              assur{\'e}e par une augmentation de la fr{\'e}quence, puis par
              l'augmentation {\'e}gale des deux variables et enfin surtout par
              l'augmentation de l'enjamb{\'e}e. L'augmentation de la
              fr{\'e}quence est, en revanche, surtout assur{\'e}e par une
              diminution de la dur{\'e}e du pos{\'e} et cela, quelle que soit
              l'allure utilis{\'e}e. Cette mod{\'e}lisation de la locomotion
              normale de la souris pourra {\^e}tre utilis{\'e}e comme
              r{\'e}f{\'e}rentiel pour les {\'e}tudes portant sur les
              d{\'e}ficits moteurs de certaines souches de souris mutantes ou
              transg{\'e}niques. Pour citer cet article : M. Herbin et al., C.
              R. Palevol 5 (2006).",
  journal  = "C. R. Palevol",
  volume   =  5,
  number   =  3,
  pages    = "531--540",
  month    =  mar,
  year     =  2006,
  keywords = "Stride frequency; Stride length; Treadmill; Locomotion;
              SWISS-OF1; Fr{\'e}quence; Enjamb{\'e}e; Tapis roulant;
              Locomotion; SWISS-OF1;Locomotion",
  issn     = "1631-0683",
  doi      = "10.1016/j.crpv.2005.12.012"
}

@ARTICLE{Lemieux2016-fx,
  title    = "{Speed-Dependent} Modulation of the Locomotor Behavior in Adult
              Mice Reveals Attractor and Transitional Gaits",
  author   = "Lemieux, Maxime and Josset, Nicolas and Roussel, Marie and
              Couraud, S{\'e}bastien and Bretzner, Fr{\'e}d{\'e}ric",
  abstract = "Locomotion results from an interplay between biomechanical
              constraints of the muscles attached to the skeleton and the
              neuronal circuits controlling and coordinating muscle activities.
              Quadrupeds exhibit a wide range of locomotor gaits. Given our
              advances in the genetic identification of spinal and supraspinal
              circuits important to locomotion in the mouse, it is now
              important to get a better understanding of the full repertoire of
              gaits in the freely walking mouse. To assess this range, young
              adult C57BL/6J mice were trained to walk and run on a treadmill
              at different locomotor speeds. Instead of using the classical
              paradigm defining gaits according to their footfall pattern, we
              combined the inter-limb coupling and the duty cycle of the stance
              phase, thus identifying several types of gaits: lateral walk,
              trot, out-of-phase walk, rotary gallop, transverse gallop, hop,
              half-bound, and full-bound. Out-of-phase walk, trot, and
              full-bound were robust and appeared to function as attractor
              gaits (i.e., a state to which the network flows and stabilizes)
              at low, intermediate, and high speeds respectively. In contrast,
              lateral walk, hop, transverse gallop, rotary gallop, and
              half-bound were more transient and therefore considered
              transitional gaits (i.e., a labile state of the network from
              which it flows to the attractor state). Surprisingly, lateral
              walk was less frequently observed. Using graph analysis, we
              demonstrated that transitions between gaits were predictable, not
              random. In summary, the wild-type mouse exhibits a wider
              repertoire of locomotor gaits than expected. Future locomotor
              studies should benefit from this paradigm in assessing transgenic
              mice or wild-type mice with neurotraumatic injury or
              neurodegenerative disease affecting gait.",
  journal  = "Front. Neurosci.",
  volume   =  10,
  pages    = "42",
  month    =  feb,
  year     =  2016,
  keywords = "graph analysis; kinematic; locomotor gaits; mouse; speed;
              steady-state;Locomotion",
  language = "en",
  issn     = "1662-4548, 1662-453X",
  pmid     = "26941592",
  doi      = "10.3389/fnins.2016.00042",
  pmc      = "PMC4763020"
}

@ARTICLE{Josset2018-js,
  title    = "Distinct Contributions of Mesencephalic Locomotor Region Nuclei
              to Locomotor Control in the Freely Behaving Mouse",
  author   = "Josset, Nicolas and Roussel, Marie and Lemieux, Maxime and
              Lafrance-Zoubga, David and Rastqar, Ali and Bretzner, Frederic",
  abstract = "The mesencephalic locomotor region (MLR) has been initially
              identified as a supraspinal center capable of initiating and
              modulating locomotion. Whereas its functional contribution to
              locomotion has been widely documented throughout the phylogeny
              from the lamprey to humans, there is still debate about its exact
              organization. Combining kinematic and electrophysiological
              recordings in mouse genetics, our study reveals that
              glutamatergic neurons of the cuneiform nucleus initiate
              locomotion and induce running gaits, whereas glutamatergic and
              cholinergic neurons of the pedunculopontine nucleus modulate
              locomotor pattern and rhythm, contributing to slow-walking gaits.
              By initiating, modulating, and accelerating locomotion, our study
              identifies and characterizes distinct neuronal populations of
              this functional region important to locomotor command.",
  journal  = "Curr. Biol.",
  volume   =  28,
  number   =  6,
  pages    = "884--901.e3",
  month    =  mar,
  year     =  2018,
  keywords = "cuneiform nucleus; electrophysiology; glutamatergic and
              cholinergic neurons; kinematic analysis; locomotor command;
              locomotor pattern rhythm and gait; mesencephalic locomotor
              region; optogenetic tools; pedunculopontine nucleus;Locomotion",
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "29526593",
  doi      = "10.1016/j.cub.2018.02.007"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Walker2018-qp,
  title    = "A comparison of two types of running wheel in terms of mouse
              preference, health, and welfare",
  author   = "Walker, Michael and Mason, Georgia",
  abstract = "Voluntary wheel running occurs in mice of all strains, sexes, and
              ages. Mice find voluntary wheel running rewarding, and it leads
              to numerous health benefits. For this reason wheels are used both
              to enhance welfare and to create models of exercise. However,
              many designs of running wheel are used. This makes between-study
              comparisons difficult, as this variability could potentially
              affect the amount, pattern, and/or intensity of running
              behaviour, and thence the wheels' effects on welfare and
              exercise-related changes in anatomy and physiology. This study
              therefore evaluated two commercially available models, chosen
              because safe for group-housed mice: Bio Serv\textregistered{}'s
              ``fast-trac'' wheel combo and Ware Manufacturing Inc.'s stainless
              steel mesh 5″ upright wheel. Working with a total of three
              hundred and fifty one female C57BL/6, DBA/2 and BALB/c mice, we
              assessed these wheels' relative utilization by mice when access
              was free; the strength of motivation for each wheel-type when
              access required crossing an electrified grid; and the impact each
              wheel had on mouse well-being (inferred from acoustic startle
              responses and neophobia) and exercise-related anatomical changes
              (BMI; heart and hind limb masses). Mice ran more on the
              ``fast-trac'' wheel regardless of whether both wheel-types were
              available at once, or only if one was present. In terms of
              motivation, subjects required to work to access a single wheel
              worked equally hard for both wheel-types (even if locked and thus
              not useable for running), but if provided with one working wheel
              for free and the other type of wheel (again unlocked) accessible
              via crossing the electrified grid, the ``fast-trac'' wheel
              emerged as more motivating, as the Maximum Price Paid for the
              Ware metal wheel was lower than that paid for the ``fast-trac''
              plastic wheel, at least for C57BL/6s and DBA/2s. No deleterious
              consequences were noted with either wheel in terms of health and
              welfare, but only mice with plastic wheels developed
              significantly larger hearts and hind limbs than control animals
              with locked wheels. Thus, where differences emerged, Bio
              Serv\textregistered{}'s ``fast-trac'' wheel combos appeared to
              better meet the aims of exercise provision than Ware
              Manufacturing's steel upright wheels.",
  journal  = "Physiol. Behav.",
  volume   =  191,
  pages    = "82--90",
  month    =  jul,
  year     =  2018,
  keywords = "Health; Motivation; Mouse; Preference; Welfare; Wheel running",
  language = "en",
  issn     = "0031-9384, 1873-507X",
  pmid     = "29653112",
  doi      = "10.1016/j.physbeh.2018.04.006"
}

@ARTICLE{Driscoll2018-na,
  title    = "Computation through Cortical Dynamics",
  author   = "Driscoll, Laura N and Golub, Matthew D and Sussillo, David",
  abstract = "Population dynamics is emerging as a language for understanding
              high-dimensional neural recordings. Remington et al. (2018)
              explore how inputs to frontal cortex modulate neural dynamics in
              order to implement a computation of interest.",
  journal  = "Neuron",
  volume   =  98,
  number   =  5,
  pages    = "873--875",
  month    =  jun,
  year     =  2018,
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "29879388",
  doi      = "10.1016/j.neuron.2018.05.029"
}

@ARTICLE{Arganda-Carreras2018-pm,
  title    = "A Statistically Representative Atlas for Mapping Neuronal
              Circuits in the Drosophila Adult Brain",
  author   = "Arganda-Carreras, Ignacio and Manoliu, Tudor and Mazuras, Nicolas
              and Schulze, Florian and Iglesias, Juan E and B{\"u}hler, Katja
              and Jenett, Arnim and Rouyer, Fran{\c c}ois and Andrey, Philippe",
  abstract = "Imaging the expression patterns of reporter constructs is a
              powerful tool to dissect the neuronal circuits of perception and
              behavior in the adult brain of Drosophila, one of the major
              models for studying brain functions. To date, several Drosophila
              brain templates and digital atlases have been built to
              automatically analyze and compare collections of expression
              pattern images. However, there has been no systematic comparison
              of performances between alternative atlasing strategies and
              registration algorithms. Here, we objectively evaluated the
              performance of different strategies for building adult Drosophila
              brain templates and atlases. In addition, we used
              state-of-the-art registration algorithms to generate a new
              group-wise inter-sex atlas. Our results highlight the benefit of
              statistical atlases over individual ones and show that the newly
              proposed inter-sex atlas outperformed existing solutions for
              automated registration and annotation of expression patterns.
              Over 3,000 images from the Janelia Farm FlyLight collection were
              registered using the proposed strategy. These registered
              expression patterns can be searched and compared with a new
              version of the BrainBaseWeb system and BrainGazer software. We
              illustrate the validity of our methodology and brain atlas with
              registration-based predictions of expression patterns in a subset
              of clock neurons. The described registration framework should
              benefit to brain studies in Drosophila and other insect species.",
  journal  = "Front. Neuroinform.",
  volume   =  12,
  pages    = "13",
  month    =  mar,
  year     =  2018,
  keywords = "Drosophila adult brain; anatomical atlas; atlas-based image
              segmentation; average brain template; brain mapping; confocal
              microscopy; diffeomorphic image registration",
  language = "en",
  issn     = "1662-5196",
  pmid     = "29628885",
  doi      = "10.3389/fninf.2018.00013",
  pmc      = "PMC5876320"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ding2016-vn,
  title    = "Comprehensive cellular-resolution atlas of the adult human brain",
  author   = "Ding, Song-Lin and Royall, Joshua J and Sunkin, Susan M and Ng,
              Lydia and Facer, Benjamin A C and Lesnar, Phil and
              Guillozet-Bongaarts, Angie and McMurray, Bergen and Szafer, Aaron
              and Dolbeare, Tim A and Stevens, Allison and Tirrell, Lee and
              Benner, Thomas and Caldejon, Shiella and Dalley, Rachel A and
              Dee, Nick and Lau, Christopher and Nyhus, Julie and Reding,
              Melissa and Riley, Zackery L and Sandman, David and Shen, Elaine
              and van der Kouwe, Andre and Varjabedian, Ani and Wright,
              Michelle and Z{\"o}llei, Lilla and Dang, Chinh and Knowles, James
              A and Koch, Christof and Phillips, John W and Sestan, Nenad and
              Wohnoutka, Paul and Zielke, H Ronald and Hohmann, John G and
              Jones, Allan R and Bernard, Amy and Hawrylycz, Michael J and Hof,
              Patrick R and Fischl, Bruce and Lein, Ed S",
  abstract = "Detailed anatomical understanding of the human brain is essential
              for unraveling its functional architecture, yet current reference
              atlases have major limitations such as lack of whole-brain
              coverage, relatively low image resolution, and sparse structural
              annotation. We present the first digital human brain atlas to
              incorporate neuroimaging, high-resolution histology, and
              chemoarchitecture across a complete adult female brain,
              consisting of magnetic resonance imaging (MRI),
              diffusion-weighted imaging (DWI), and 1,356 large-format cellular
              resolution (1 µm/pixel) Nissl and immunohistochemistry anatomical
              plates. The atlas is comprehensively annotated for 862
              structures, including 117 white matter tracts and several novel
              cyto- and chemoarchitecturally defined structures, and these
              annotations were transferred onto the matching MRI dataset.
              Neocortical delineations were done for sulci, gyri, and modified
              Brodmann areas to link macroscopic anatomical and microscopic
              cytoarchitectural parcellations. Correlated neuroimaging and
              histological structural delineation allowed fine feature
              identification in MRI data and subsequent structural
              identification in MRI data from other brains. This interactive
              online digital atlas is integrated with existing Allen Institute
              for Brain Science gene expression atlases and is publicly
              accessible as a resource for the neuroscience community. J. Comp.
              Neurol. 524:3127-3481, 2016. \copyright{} 2016 The Authors The
              Journal of Comparative Neurology Published by Wiley Periodicals,
              Inc.",
  journal  = "J. Comp. Neurol.",
  volume   =  524,
  number   =  16,
  pages    = "3127--3481",
  month    =  nov,
  year     =  2016,
  keywords = "AB\_2314904; DWI; MRI; RRIDs: AB\_10000343; SCR\_014329;
              amygdala; brain atlas; brainstem; cerebellum; cerebral cortex;
              cytoarchitecture; hippocampal formation; hypothalamus;
              neurofilament protein; parvalbumin; thalamus",
  language = "en",
  issn     = "0021-9967, 1096-9861",
  pmid     = "27418273",
  doi      = "10.1002/cne.24080",
  pmc      = "PMC5054943"
}

@ARTICLE{Wang2020-ee,
  title    = "The Allen Mouse Brain Common Coordinate Framework: A {3D}
              Reference Atlas",
  author   = "Wang, Quanxin and Ding, Song-Lin and Li, Yang and Royall, Josh
              and Feng, David and Lesnar, Phil and Graddis, Nile and Naeemi,
              Maitham and Facer, Benjamin and Ho, Anh and Dolbeare, Tim and
              Blanchard, Brandon and Dee, Nick and Wakeman, Wayne and Hirokawa,
              Karla E and Szafer, Aaron and Sunkin, Susan M and Oh, Seung Wook
              and Bernard, Amy and Phillips, John W and Hawrylycz, Michael and
              Koch, Christof and Zeng, Hongkui and Harris, Julie A and Ng,
              Lydia",
  abstract = "Summary Recent large-scale collaborations are generating major
              surveys of cell types and connections in the mouse brain,
              collecting large amounts of data across modalities, spatial
              scales, and brain areas. Successful integration of these data
              requires a standard 3D reference atlas. Here, we present the
              Allen Mouse Brain Common Coordinate Framework (CCFv3) as such a
              resource. We constructed an average template brain at 10 $\mu$m
              voxel resolution by interpolating high resolution in-plane serial
              two-photon tomography images with 100 $\mu$m z-sampling from
              1,675 young adult C57BL/6J mice. Then, using multimodal reference
              data, we parcellated the entire brain directly in 3D, labeling
              every voxel with a brain structure spanning 43 isocortical areas
              and their layers, 329 subcortical gray matter structures, 81
              fiber tracts, and 8 ventricular structures. CCFv3 can be used to
              analyze, visualize, and integrate multimodal and multiscale
              datasets in 3D and is openly accessible
              (https://atlas.brain-map.org/).",
  journal  = "Cell",
  volume   =  181,
  number   =  4,
  pages    = "936--953.e20",
  month    =  may,
  year     =  2020,
  keywords = "average mouse brain; reference atlas; 3D brain atlas; brain
              parcellation; brain anatomy; mouse cortex; common coordinate
              framework; CCFv3; fiber tracts; transgenic mice",
  issn     = "0092-8674",
  doi      = "10.1016/j.cell.2020.04.007"
}

@MISC{Musy2019-vb,
  title  = "marcomusy/vtkplotter: vtkplotter",
  author = "Musy, Marco and Dalmasso, Giovanni and Sullivan, Bane",
  month  =  feb,
  year   =  2019,
  doi    = "10.5281/zenodo.2561402"
}

@UNPUBLISHED{Pachitariu2017-be,
  title    = "Suite2p: beyond 10,000 neurons with standard two-photon
              microscopy",
  author   = "Pachitariu, M and Stringer, C and Dipoppa, M and Schr{\"o}der, S
              and Rossi, L F and Dalgleish, H and Carandini, M and Harris, K D",
  abstract = "Two-photon microscopy of calcium-dependent sensors has enabled
              unprecedented recordings from vast populations of neurons. While
              the sensors and microscopes have matured over several generations
              of development, computational methods to process the resulting
              movies remain inefficient and can give results that are hard to
              interpret. Here we introduce Suite2p: a fast, accurate and
              complete pipeline that registers raw movies, detects active
              cells, extracts their calcium traces and infers their spike
              times. Suite2p runs on standard workstations, operates faster
              than real time, and recovers ~2 times more cells than the
              previous state-of-the-art method. Its low computational load
              allows routine detection of ~10,000 cells simultaneously with
              standard two-photon resonant-scanning microscopes. Recordings at
              this scale promise to reveal the fine structure of activity in
              large populations of neurons or large populations of subcellular
              structures such as synaptic boutons.",
  journal  = "bioRxiv",
  pages    = "30",
  month    =  jul,
  year     =  2017,
  language = "en",
  doi      = "10.1101/061507"
}

@ARTICLE{Mathis2018-cn,
  title     = "{DeepLabCut}: markerless pose estimation of user-defined body
               parts with deep learning",
  author    = "Mathis, Alexander and Mamidanna, Pranav and Cury, Kevin M and
               Abe, Taiga and Murthy, Venkatesh N and Mathis, Mackenzie
               Weygandt and Bethge, Matthias",
  abstract  = "Quantifying behavior is crucial for many applications in
               neuroscience. Videography provides easy methods for the
               observation and recording of animal behavior in diverse
               settings, yet extracting particular aspects of a behavior for
               further analysis can be highly time consuming. In motor control
               studies, humans or other animals are often marked with
               reflective markers to assist with computer-based tracking, but
               markers are intrusive, and the number and location of the
               markers must be determined a priori. Here we present an
               efficient method for markerless pose estimation based on
               transfer learning with deep neural networks that achieves
               excellent results with minimal training data. We demonstrate the
               versatility of this framework by tracking various body parts in
               multiple species across a broad collection of behaviors.
               Remarkably, even when only a small number of frames are labeled
               (~200), the algorithm achieves excellent tracking performance on
               test frames that is comparable to human accuracy.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  21,
  number    =  9,
  pages     = "1281--1289",
  month     =  sep,
  year      =  2018,
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "30127430",
  doi       = "10.1038/s41593-018-0209-y"
}

@ARTICLE{Genkin2020-jr,
  title    = "Moving beyond generalization to accurate interpretation of
              flexible models",
  author   = "Genkin, Mikhail and Engel, Tatiana A",
  abstract = "Machine learning optimizes flexible models to predict data. In
              scientific applications, there is a rising interest in
              interpreting these flexible models to derive hypotheses from
              data. However, it is unknown whether good data prediction
              guarantees the accurate interpretation of flexible models. Here,
              we test this connection using a flexible, yet intrinsically
              interpretable framework for modelling neural dynamics. We find
              that many models discovered during optimization predict data
              equally well, yet they fail to match the correct hypothesis. We
              develop an alternative approach that identifies models with
              correct interpretation by comparing model features across data
              samples to separate true features from noise. We illustrate our
              findings using recordings of spiking activity from the visual
              cortex of monkeys performing a fixation task. Our results reveal
              that good predictions cannot substitute for accurate
              interpretation of flexible models and offer a principled approach
              to identify models with correct interpretation.",
  journal  = "Nature Machine Intelligence",
  month    =  oct,
  year     =  2020,
  keywords = "RNN To read;RNN",
  issn     = "2522-5839",
  doi      = "10.1038/s42256-020-00242-6"
}

@ARTICLE{noauthor_undated-xx,
  title    = "{Carroll\_SG.pdf}",
  keywords = "To Read;BCI"
}

@UNPUBLISHED{Dahmen2020-so,
  title    = "Strong coupling and local control of dimensionality across brain
              areas",
  author   = "Dahmen, David and Recanatesi, Stefano and Ocker, Gabriel Koch and
              Jia, Xiaoxuan and Helias, Moritz and Shea-Brown, Eric",
  abstract = "The dimensionality of a network's collective activity is the
              number of modes into which it is organized. This quantity is of
              great interest in neural coding: small dimensionality suggests a
              compressed neural code and possibly high robustness and
              generalizability, while high dimensionality suggests expansion of
              input features to enable flexible downstream computation. Here,
              for recurrent neural circuits operating in the ubiquitous
              balanced regime, we show how dimensionality arises
              mechanistically via perhaps the most basic property of neural
              circuits: a single number characterizing the net strength of
              their connectivity. Our results combine novel theoretical
              approaches with new analyses of high-density neuropixels
              recordings and high-throughput synaptic physiology datasets. The
              analysis of electrophysiological recordings identifies bounds on
              the dimensionality of neural responses across brain regions,
              showing that it is on the order of hundreds -- striking a balance
              between high and low-dimensional codes. Furthermore, focusing on
              the visual stream, we show that dimensionality expands from
              primary to deeper visual areas and similarly within an area from
              layer 2/3 to layer 5. We interpret these results via a novel
              theoretical result which links dimensionality to a single measure
              of net connectivity strength. This requires calculations that
              extend beyond traditional mean-field approaches to neural
              networks. Our result suggests that areas across the brain operate
              in a strongly coupled regime where dimensionality is under
              sensitive control by net connectivity strength; moreover, we show
              how this net connectivity strength is regulated by local
              connectivity features, or synaptic motifs. This enables us to
              interpret changes in dimensionality in terms of changes in
              coupling among pairs and triplets of neurons. Analysis of
              large-scale synaptic physiology datasets from both mouse and
              human cortex then reveal the presence of synaptic coupling motifs
              capable of substantially regulating this dimensionality. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2020.11.02.365072",
  month    =  nov,
  year     =  2020,
  keywords = "RNN",
  language = "en",
  doi      = "10.1101/2020.11.02.365072"
}

@ARTICLE{Chang2019-bd,
  title         = "{AntisymmetricRNN}: A Dynamical System View on Recurrent
                   Neural Networks",
  author        = "Chang, Bo and Chen, Minmin and Haber, Eldad and Chi, Ed H",
  abstract      = "Recurrent neural networks have gained widespread use in
                   modeling sequential data. Learning long-term dependencies
                   using these models remains difficult though, due to
                   exploding or vanishing gradients. In this paper, we draw
                   connections between recurrent networks and ordinary
                   differential equations. A special form of recurrent networks
                   called the AntisymmetricRNN is proposed under this
                   theoretical framework, which is able to capture long-term
                   dependencies thanks to the stability property of its
                   underlying differential equation. Existing approaches to
                   improving RNN trainability often incur significant
                   computation overhead. In comparison, AntisymmetricRNN
                   achieves the same goal by design. We showcase the advantage
                   of this new architecture through extensive simulations and
                   experiments. AntisymmetricRNN exhibits much more predictable
                   dynamics. It outperforms regular LSTM models on tasks
                   requiring long-term memory and matches the performance on
                   tasks where short-term dependencies dominate despite being
                   much simpler.",
  month         =  feb,
  year          =  2019,
  keywords      = "RNN",
  archivePrefix = "arXiv",
  eprint        = "1902.09689",
  primaryClass  = "stat.ML",
  arxivid       = "1902.09689"
}

@ARTICLE{Maheswaranathan2019-ue,
  title     = "Reverse engineering recurrent networks for sentiment
               classification reveals line attractor dynamics",
  author    = "Maheswaranathan, Niru and Williams, Alex H and Golub, Matthew D
               and Ganguli, Surya and Sussillo, David",
  abstract  = "Recurrent neural networks (RNNs) are a widely used tool for
               modeling sequential data, yet they are often treated as
               inscrutable black boxes. Given a trained recurrent network, we
               would like to reverse engineer it-to obtain a quantitative,
               interpretable description of how it solves a particular task.
               Even for simple tasks, a detailed understanding of how recurrent
               networks work, or a prescription for how to develop such an
               understanding, remains elusive. In this work, we use tools from
               dynamical systems analysis to reverse engineer recurrent
               networks trained to perform sentiment classification, a
               foundational natural language processing task. Given a trained
               network, we find fixed points of the recurrent dynamics and
               linearize the nonlinear system around these fixed points.
               Despite their theoretical capacity to implement complex,
               high-dimensional computations, we find that trained networks
               converge to highly interpretable, low-dimensional
               representations. In particular, the topological structure of the
               fixed points and corresponding linearized dynamics reveal an
               approximate line attractor within the RNN, which we can use to
               quantitatively understand how the RNN solves the sentiment
               analysis task. Finally, we find this mechanism present across
               RNN architectures (including LSTMs, GRUs, and vanilla RNNs)
               trained on multiple datasets, suggesting that our findings are
               not unique to a particular architecture or dataset. Overall,
               these results demonstrate that surprisingly universal and human
               interpretable computations can arise across a range of recurrent
               networks.",
  journal   = "Adv. Neural Inf. Process. Syst.",
  publisher = "papers.nips.cc",
  volume    =  32,
  pages     = "15696--15705",
  month     =  dec,
  year      =  2019,
  keywords  = "RNN To read;RNN",
  language  = "en",
  issn      = "1049-5258",
  pmid      = "32782423",
  pmc       = "PMC7416638"
}

@ARTICLE{Maheswaranathan2019-ux,
  title    = "Universality and individuality in neural dynamics across large
              populations of recurrent networks",
  author   = "Maheswaranathan, Niru and Williams, Alex H and Golub, Matthew D
              and Ganguli, Surya and Sussillo, David",
  abstract = "Task-based modeling with recurrent neural networks (RNNs) has
              emerged as a popular way to infer the computational function of
              different brain regions. These models are quantitatively assessed
              by comparing the low-dimensional neural representations of the
              model with the brain, for example using canonical correlation
              analysis (CCA). However, the nature of the detailed
              neurobiological inferences one can draw from such efforts remains
              elusive. For example, to what extent does training neural
              networks to solve common tasks uniquely determine the network
              dynamics, independent of modeling architectural choices? Or
              alternatively, are the learned dynamics highly sensitive to
              different model choices? Knowing the answer to these questions
              has strong implications for whether and how we should use
              task-based RNN modeling to understand brain dynamics. To address
              these foundational questions, we study populations of thousands
              of networks, with commonly used RNN architectures, trained to
              solve neuroscientifically motivated tasks and characterize their
              nonlinear dynamics. We find the geometry of the RNN
              representations can be highly sensitive to different network
              architectures, yielding a cautionary tale for measures of
              similarity that rely on representational geometry, such as CCA.
              Moreover, we find that while the geometry of neural dynamics can
              vary greatly across architectures, the underlying computational
              scaffold-the topological structure of fixed points, transitions
              between them, limit cycles, and linearized dynamics-often appears
              universal across all architectures.",
  journal  = "Adv. Neural Inf. Process. Syst.",
  volume   =  2019,
  pages    = "15629--15641",
  month    =  dec,
  year     =  2019,
  keywords = "RNN",
  language = "en",
  issn     = "1049-5258",
  pmid     = "32782422",
  pmc      = "PMC7416639"
}

@ARTICLE{Vyas2020-pw,
  title    = "Computation Through Neural Population Dynamics",
  author   = "Vyas, Saurabh and Golub, Matthew D and Sussillo, David and
              Shenoy, Krishna V",
  abstract = "Significant experimental, computational, and theoretical work has
              identified rich structure within the coordinated activity of
              interconnected neural populations. An emerging challenge now is
              to uncover the nature of the associated computations, how they
              are implemented, and what role they play in driving behavior. We
              term this computation through neural population dynamics. If
              successful, this framework will reveal general motifs of neural
              population activity and quantitatively describe how neural
              population dynamics implement computations necessary for driving
              goal-directed behavior. Here, we start with a mathematical primer
              on dynamical systems theory and analytical tools necessary to
              apply this perspective to experimental data. Next, we highlight
              some recent discoveries resulting from successful application of
              dynamical systems. We focus on studies spanning motor control,
              timing, decision-making, and working memory. Finally, we briefly
              discuss promising recent lines of investigation and future
              directions for the computation through neural population dynamics
              framework.",
  journal  = "Annu. Rev. Neurosci.",
  volume   =  43,
  pages    = "249--275",
  month    =  jul,
  year     =  2020,
  keywords = "dynamical systems; neural computation; neural population
              dynamics; state spaces;RNN",
  language = "en",
  issn     = "0147-006X, 1545-4126",
  pmid     = "32640928",
  doi      = "10.1146/annurev-neuro-092619-094115",
  pmc      = "PMC7402639"
}

@ARTICLE{Sussillo2014-mo,
  title    = "Neural circuits as computational dynamical systems",
  author   = "Sussillo, David",
  abstract = "Many recent studies of neurons recorded from cortex reveal
              complex temporal dynamics. How such dynamics embody the
              computations that ultimately lead to behavior remains a mystery.
              Approaching this issue requires developing plausible hypotheses
              couched in terms of neural dynamics. A tool ideally suited to aid
              in this question is the recurrent neural network (RNN). RNNs
              straddle the fields of nonlinear dynamical systems and machine
              learning and have recently seen great advances in both theory and
              application. I summarize recent theoretical and technological
              advances and highlight an example of how RNNs helped to explain
              perplexing high-dimensional neurophysiological data in the
              prefrontal cortex.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  25,
  pages    = "156--163",
  month    =  apr,
  year     =  2014,
  keywords = "RNN To read;RNN",
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "24509098",
  doi      = "10.1016/j.conb.2014.01.008"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Schuessler2020-jm,
  title     = "Dynamics of random recurrent networks with correlated low-rank
               structure",
  author    = "Schuessler, F and Dubreuil, A and Mastrogiuseppe, F and {others}",
  abstract  = "A given neural network in the brain is involved in many
               different tasks. This implies that, when considering a specific
               task, the network's connectivity contains a component which is
               related to the task and another component which can be
               considered random. Understanding …",
  journal   = "Physical Review",
  publisher = "APS",
  year      =  2020,
  keywords  = "RNN"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Dubreuil2020-fk,
  title     = "Complementary roles of dimensionality and population structure
               in neural computations",
  author    = "Dubreuil, A and Valente, A and Beiran, M and Mastrogiuseppe, F
               and {others}",
  abstract  = "Neural computations are currently investigated using two
               competing approaches: sorting neurons into functional classes,
               or examining the low-dimensional dynamics of collective
               activity. Whether and how these two aspects interact to shape
               computations is currently …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2020,
  keywords  = "RNN"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Schuessler2020-ug,
  title     = "The interplay between randomness and structure during learning
               in {RNNs}",
  author    = "Schuessler, F and Mastrogiuseppe, F and Dubreuil, A and {others}",
  abstract  = "Training recurrent neural networks ( RNNs ) on low-dimensional
               tasks has been widely used to model functional biological
               networks. However, the solutions found by learning and the
               effect of initial connectivity are not well understood. Here, we
               examine RNNs trained using …",
  journal   = "Adv. Neural Inf. Process. Syst.",
  publisher = "papers.nips.cc",
  year      =  2020,
  keywords  = "RNN",
  issn      = "1049-5258"
}

@ARTICLE{Mastrogiuseppe2019-xu,
  title    = "A Geometrical Analysis of Global Stability in Trained Feedback
              Networks",
  author   = "Mastrogiuseppe, Francesca and Ostojic, Srdjan",
  abstract = "Recurrent neural networks have been extensively studied in the
              context of neuroscience and machine learning due to their ability
              to implement complex computations. While substantial progress in
              designing effective learning algorithms has been achieved, a full
              understanding of trained recurrent networks is still lacking.
              Specifically, the mechanisms that allow computations to emerge
              from the underlying recurrent dynamics are largely unknown. Here
              we focus on a simple yet underexplored computational setup: a
              feedback architecture trained to associate a stationary output to
              a stationary input. As a starting point, we derive an approximate
              analytical description of global dynamics in trained networks,
              which assumes uncorrelated connectivity weights in the feedback
              and in the random bulk. The resulting mean-field theory suggests
              that the task admits several classes of solutions, which imply
              different stability properties. Different classes are
              characterized in terms of the geometrical arrangement of the
              readout with respect to the input vectors, defined in the
              high-dimensional space spanned by the network population. We find
              that such an approximate theoretical approach can be used to
              understand how standard training techniques implement the
              input-output task in finite-size feedback networks. In
              particular, our simplified description captures the local and the
              global stability properties of the target solution, and thus
              predicts training performance.",
  journal  = "Neural Comput.",
  volume   =  31,
  number   =  6,
  pages    = "1139--1182",
  month    =  jun,
  year     =  2019,
  keywords = "RNN",
  language = "en",
  issn     = "0899-7667, 1530-888X",
  pmid     = "30979353",
  doi      = "10.1162/neco\_a\_01187"
}

@ARTICLE{Mastrogiuseppe2018-ss,
  title    = "Linking Connectivity, Dynamics, and Computations in {Low-Rank}
              Recurrent Neural Networks",
  author   = "Mastrogiuseppe, Francesca and Ostojic, Srdjan",
  abstract = "Large-scale neural recordings have established that the
              transformation of sensory stimuli into motor outputs relies on
              low-dimensional dynamics at the population level, while
              individual neurons exhibit complex selectivity. Understanding how
              low-dimensional computations on mixed, distributed
              representations emerge from the structure of the recurrent
              connectivity and inputs to cortical networks is a major
              challenge. Here, we study a class of recurrent network models in
              which the connectivity is a sum of a random part and a minimal,
              low-dimensional structure. We show that, in such networks, the
              dynamics are low dimensional and can be directly inferred from
              connectivity using a geometrical approach. We exploit this
              understanding to determine minimal connectivity required to
              implement specific computations and find that the dynamical range
              and computational capacity quickly increase with the
              dimensionality of the connectivity structure. This framework
              produces testable experimental predictions for the relationship
              between connectivity, low-dimensional dynamics, and computational
              features of recorded neurons.",
  journal  = "Neuron",
  volume   =  99,
  number   =  3,
  pages    = "609--623.e29",
  month    =  aug,
  year     =  2018,
  keywords = "low dimensional dynamics; mixed selectivity; neural computations;
              recurrent neural networks;RNN",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "30057201",
  doi      = "10.1016/j.neuron.2018.07.003"
}

@ARTICLE{Barak2017-uh,
  title    = "Recurrent neural networks as versatile tools of neuroscience
              research",
  author   = "Barak, Omri",
  abstract = "Recurrent neural networks (RNNs) are a class of computational
              models that are often used as a tool to explain neurobiological
              phenomena, considering anatomical, electrophysiological and
              computational constraints. RNNs can either be designed to
              implement a certain dynamical principle, or they can be trained
              by input-output examples. Recently, there has been large progress
              in utilizing trained RNNs both for computational tasks, and as
              explanations of neural phenomena. I will review how combining
              trained RNNs with reverse engineering can provide an alternative
              framework for modeling in neuroscience, potentially serving as a
              powerful hypothesis generation tool. Despite the recent progress
              and potential benefits, there are many fundamental gaps towards a
              theory of these networks. I will discuss these challenges and
              possible methods to attack them.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  46,
  pages    = "1--6",
  month    =  oct,
  year     =  2017,
  keywords = "RNN",
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "28668365",
  doi      = "10.1016/j.conb.2017.06.003"
}

@ARTICLE{Golub2018-il,
  title   = "{FixedPointFinder}: A Tensorflow toolbox for identifying and
             characterizing fixed points in recurrent neural networks",
  author  = "Golub, Matthew D and Sussillo, David",
  journal = "Journal of Open Source Software",
  volume  =  3,
  number  =  31,
  pages   = "1003",
  year    =  2018,
  doi     = "10.21105/joss.01003"
}

@ARTICLE{Chon2019-ka,
  title     = "Enhanced and unified anatomical labeling for a common mouse
               brain atlas",
  author    = "Chon, Uree and Vanselow, Daniel J and Cheng, Keith C and Kim,
               Yongsoo",
  abstract  = "Anatomical atlases in standard coordinates are necessary for the
               interpretation and integration of research findings in a common
               spatial context. However, the two most-used mouse brain atlases,
               the Franklin-Paxinos (FP) and the common coordinate framework
               (CCF) from the Allen Institute for Brain Science, have
               accumulated inconsistencies in anatomical delineations and
               nomenclature, creating confusion among neuroscientists. To
               overcome these issues, we adopt here the FP labels into the CCF
               to merge the labels in the single atlas framework. We use cell
               type-specific transgenic mice and an MRI atlas to adjust and
               further segment our labels. Moreover, detailed segmentations are
               added to the dorsal striatum using cortico-striatal connectivity
               data. Lastly, we digitize our anatomical labels based on the
               Allen ontology, create a web-interface for visualization, and
               provide tools for comprehensive comparisons between the CCF and
               FP labels. Our open-source labels signify a key step towards a
               unified mouse brain atlas.",
  journal   = "Nat. Commun.",
  publisher = "nature.com",
  volume    =  10,
  number    =  1,
  pages     = "5067",
  month     =  nov,
  year      =  2019,
  language  = "en",
  issn      = "2041-1723",
  pmid      = "31699990",
  doi       = "10.1038/s41467-019-13057-w",
  pmc       = "PMC6838086"
}

@ARTICLE{Saxe2020-mi,
  title    = "If deep learning is the answer, what is the question?",
  author   = "Saxe, Andrew and Nelli, Stephanie and Summerfield, Christopher",
  abstract = "Neuroscience research is undergoing a minor revolution. Recent
              advances in machine learning and artificial intelligence research
              have opened up new ways of thinking about neural computation.
              Many researchers are excited by the possibility that deep neural
              networks may offer theories of perception, cognition and action
              for biological brains. This approach has the potential to
              radically reshape our approach to understanding neural systems,
              because the computations performed by deep networks are learned
              from experience, and not endowed by the researcher. If so, how
              can neuroscientists use deep networks to model and understand
              biological brains? What is the outlook for neuroscientists who
              seek to characterize computations or neural codes, or who wish to
              understand perception, attention, memory and executive functions?
              In this Perspective, our goal is to offer a road map for systems
              neuroscience research in the age of deep learning. We discuss the
              conceptual and methodological challenges of comparing behaviour,
              learning dynamics and neural representations in artificial and
              biological systems, and we highlight new research questions that
              have emerged for neuroscience as a direct consequence of recent
              advances in machine learning.",
  journal  = "Nat. Rev. Neurosci.",
  month    =  nov,
  year     =  2020,
  keywords = "RNN",
  issn     = "1471-003X, 1471-0048",
  doi      = "10.1038/s41583-020-00395-8"
}

@ARTICLE{Sussillo2016-zn,
  title         = "{LFADS} - Latent Factor Analysis via Dynamical Systems",
  author        = "Sussillo, David and Jozefowicz, Rafal and Abbott, L F and
                   Pandarinath, Chethan",
  abstract      = "Neuroscience is experiencing a data revolution in which many
                   hundreds or thousands of neurons are recorded
                   simultaneously. Currently, there is little consensus on how
                   such data should be analyzed. Here we introduce LFADS
                   (Latent Factor Analysis via Dynamical Systems), a method to
                   infer latent dynamics from simultaneously recorded,
                   single-trial, high-dimensional neural spiking data. LFADS is
                   a sequential model based on a variational auto-encoder. By
                   making a dynamical systems hypothesis regarding the
                   generation of the observed data, LFADS reduces observed
                   spiking to a set of low-dimensional temporal factors,
                   per-trial initial conditions, and inferred inputs. We
                   compare LFADS to existing methods on synthetic data and show
                   that it significantly out-performs them in inferring neural
                   firing rates and latent dynamics.",
  month         =  aug,
  year          =  2016,
  keywords      = "To Read;BCI",
  archivePrefix = "arXiv",
  eprint        = "1608.06315",
  primaryClass  = "cs.LG",
  arxivid       = "1608.06315"
}

@ARTICLE{Rivkind2017-pf,
  title    = "Local Dynamics in Trained Recurrent Neural Networks",
  author   = "Rivkind, Alexander and Barak, Omri",
  abstract = "Learning a task induces connectivity changes in neural circuits,
              thereby changing their dynamics. To elucidate task-related neural
              dynamics, we study trained recurrent neural networks. We develop
              a mean field theory for reservoir computing networks trained to
              have multiple fixed point attractors. Our main result is that the
              dynamics of the network's output in the vicinity of attractors is
              governed by a low-order linear ordinary differential equation.
              The stability of the resulting equation can be assessed,
              predicting training success or failure. As a consequence,
              networks of rectified linear units and of sigmoidal
              nonlinearities are shown to have diametrically different
              properties when it comes to learning attractors. Furthermore, a
              characteristic time constant, which remains finite at the edge of
              chaos, offers an explanation of the network's output robustness
              in the presence of variability of the internal neural dynamics.
              Finally, the proposed theory predicts state-dependent frequency
              selectivity in the network response.",
  journal  = "Phys. Rev. Lett.",
  volume   =  118,
  number   =  25,
  pages    = "258101",
  month    =  jun,
  year     =  2017,
  keywords = "RNN;to\_read\_for\_review",
  language = "en",
  issn     = "0031-9007, 1079-7114",
  pmid     = "28696758",
  doi      = "10.1103/PhysRevLett.118.258101"
}

@ARTICLE{Elsayed2017-ru,
  title     = "Structure in neural population recordings: an expected byproduct
               of simpler phenomena?",
  author    = "Elsayed, Gamaleldin F and Cunningham, John P",
  abstract  = "Neuroscientists increasingly analyze the joint activity of
               multineuron recordings to identify population-level structures
               believed to be significant and scientifically novel. Claims of
               significant population structure support hypotheses in many
               brain areas. However, these claims require first investigating
               the possibility that the population structure in question is an
               expected byproduct of simpler features known to exist in data.
               Classically, this critical examination can be either intuited or
               addressed with conventional controls. However, these approaches
               fail when considering population data, raising concerns about
               the scientific merit of population-level studies. Here we
               develop a framework to test the novelty of population-level
               findings against simpler features such as correlations across
               times, neurons and conditions. We apply this framework to test
               two recent population findings in prefrontal and motor cortices,
               providing essential context to those studies. More broadly, the
               methodologies we introduce provide a general neural population
               control for many population-level hypotheses.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  20,
  number    =  9,
  pages     = "1310--1318",
  month     =  sep,
  year      =  2017,
  keywords  = "RNN To read;RNN",
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "28783140",
  doi       = "10.1038/nn.4617",
  pmc       = "PMC5577566"
}

@ARTICLE{Russo2018-me,
  title    = "Motor Cortex Embeds Muscle-like Commands in an Untangled
              Population Response",
  author   = "Russo, Abigail A and Bittner, Sean R and Perkins, Sean M and
              Seely, Jeffrey S and London, Brian M and Lara, Antonio H and
              Miri, Andrew and Marshall, Najja J and Kohn, Adam and Jessell,
              Thomas M and Abbott, Laurence F and Cunningham, John P and
              Churchland, Mark M",
  abstract = "Primate motor cortex projects to spinal interneurons and
              motoneurons, suggesting that motor cortex activity may be
              dominated by muscle-like commands. Observations during reaching
              lend support to this view, but evidence remains ambiguous and
              much debated. To provide a different perspective, we employed a
              novel behavioral paradigm that facilitates comparison between
              time-evolving neural and muscle activity. We found that single
              motor cortex neurons displayed many muscle-like properties, but
              the structure of population activity was not muscle-like. Unlike
              muscle activity, neural activity was structured to avoid
              ``tangling'': moments where similar activity patterns led to
              dissimilar future patterns. Avoidance of tangling was present
              across tasks and species. Network models revealed a potential
              reason for this consistent feature: low tangling confers noise
              robustness. Finally, we were able to predict motor cortex
              activity from muscle activity by leveraging the hypothesis that
              muscle-like commands are embedded in additional structure that
              yields low tangling.",
  journal  = "Neuron",
  volume   =  97,
  number   =  4,
  pages    = "953--966.e8",
  month    =  feb,
  year     =  2018,
  keywords = "motor control; motor cortex; movement generation; neural
              dynamics; neural network; pattern generation; rhythmic
              movement;RNN",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "29398358",
  doi      = "10.1016/j.neuron.2018.01.004",
  pmc      = "PMC5823788"
}

@ARTICLE{Machado2015-ig,
  title    = "A quantitative framework for whole-body coordination reveals
              specific deficits in freely walking ataxic mice",
  author   = "Machado, Ana S and Darmohray, Dana M and Fayad, Jo{\~a}o and
              Marques, Hugo G and Carey, Megan R",
  abstract = "The coordination of movement across the body is a fundamental,
              yet poorly understood aspect of motor control. Mutant mice with
              cerebellar circuit defects exhibit characteristic impairments in
              locomotor coordination; however, the fundamental features of this
              gait ataxia have not been effectively isolated. Here we describe
              a novel system (LocoMouse) for analyzing limb, head, and tail
              kinematics of freely walking mice. Analysis of visibly ataxic
              Purkinje cell degeneration (pcd) mice reveals that while
              differences in the forward motion of individual paws are fully
              accounted for by changes in walking speed and body size, more
              complex 3D trajectories and, especially, inter-limb and
              whole-body coordination are specifically impaired. Moreover, the
              coordination deficits in pcd are consistent with a failure to
              predict and compensate for the consequences of movement across
              the body. These results isolate specific impairments in
              whole-body coordination in mice and provide a quantitative
              framework for understanding cerebellar contributions to
              coordinated locomotion.",
  journal  = "Elife",
  volume   =  4,
  month    =  oct,
  year     =  2015,
  keywords = "Purkinje cell; ataxia; cerebellum; locomotion; mouse;
              neuroscience;Locomotion",
  language = "en",
  issn     = "2050-084X",
  pmid     = "26433022",
  doi      = "10.7554/eLife.07892",
  pmc      = "PMC4630674"
}

@UNPUBLISHED{Reis2020-bp,
  title    = "Dorsal Periaqueductal gray ensembles represent approach and
              avoidance states",
  author   = "Reis, Fernando Mcv and Lee, Johannes Y and Maesta-Pereira, Sandra
              and Schuette, Peter J and Chakerian, Meghmik and Liu, Jinhan and
              La-Vu, Mimi Q and Tobias, Brooke C and Canteras, Newton and Kao,
              Jonathan C and Adhikari, Avishek",
  abstract = "Animals must balance needs to approach threats for
              risk-assessment and to avoid danger. The dorsal periaqueductal
              gray (dPAG) controls defensive behaviors, but it is unknown how
              it represents states associated with threat approach and
              avoidance. We identified a dPAG threat-avoidance ensemble in mice
              that showed higher activity far from threats such as the open
              arms of the elevated plus maze and a live predator. These cells
              were also more active during threat-avoidance behaviors such as
              escape and freezing, even though these behaviors have
              antagonistic motor output. Conversely, the threat-approach
              ensemble was more active during risk-assessment behaviors and
              near threats. Furthermore, unsupervised methods showed
              approach/avoidance states were encoded with shared activity
              patterns across threats. Lastly, the relative number of cells in
              each ensemble predicted threat-avoidance across mice. Thus, dPAG
              ensembles dynamically encode threat approach and avoidance
              states, providing a flexible mechanism to balance risk-assessment
              and danger avoidance.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2020.11.19.389486",
  month    =  nov,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.11.19.389486"
}

@ARTICLE{Carlsson2020-lg,
  title     = "Topological methods for data modelling",
  author    = "Carlsson, Gunnar",
  abstract  = "The analysis of large and complex data sets is one of the most
               important problems facing the scientific community, and physics
               in particular. One response to this challenge has been the
               development of topological data analysis (TDA), which models
               data by graphs or networks rather than by linear algebraic
               (matrix) methods or cluster analysis. TDA represents the shape
               of the data (suitably defined) in a combinatorial fashion.
               Methods for measuring shape have been developed within
               mathematics, providing a toolkit referred to as homology. In
               working with data, one can use this kind of modelling to obtain
               an understanding of the overall structure of the data set. There
               is a suite of methods for constructing vector representations of
               various kinds of unstructured data. In this Review, we sketch
               the basics of TDA and provide examples where this kind of
               analysis has been carried out. The rapidly developing field of
               topological data analysis represents data via graphs rather than
               as solutions to equations or as decompositions into clusters.
               This Review discusses the methods and provides examples from
               physics and other sciences.",
  journal   = "Nature Reviews Physics",
  publisher = "Nature Publishing Group",
  pages     = "1--12",
  month     =  nov,
  year      =  2020,
  keywords  = "RNN",
  language  = "en",
  issn      = "2522-5820, 2522-5820",
  doi       = "10.1038/s42254-020-00249-3"
}

@UNPUBLISHED{Kalidindi2020-wd,
  title    = "Rotational dynamics in motor cortex are consistent with a
              feedback controller",
  author   = "Kalidindi, Hari Teja and Cross, Kevin P and Lillicrap, Timothy P
              and Omrani, Mohsen and Falotico, Egidio and Sabes, Philip N and
              Scott, Stephen H",
  abstract = "Recent studies hypothesize that motor cortical (MC) dynamics are
              generated largely through its recurrent connections based on
              observations that MC activity exhibits rotational structure.
              However, behavioural and neurophysiological studies suggest that
              MC behaves like a feedback controller where continuous sensory
              feedback and interactions with other brain areas contribute
              substantially to MC processing. We investigated these apparently
              conflicting theories by building recurrent neural networks that
              controlled a model arm and received sensory feedback about the
              limb. Networks were trained to counteract perturbations to the
              limb and to reach towards spatial targets. Network activities and
              sensory feedback signals to the network exhibited rotational
              structure even when the recurrent connections were removed.
              Furthermore, neural recordings in monkeys performing similar
              tasks also exhibited rotational structure not only in MC but also
              in somatosensory cortex. Our results argue that rotational
              structure may reflect dynamics throughout voluntary motor
              circuits involved in online control of motor actions. \#\#\#
              Competing Interest Statement SHS is co-founder and CSO of Kinarm
              which commercializes the robotic technology used in the present
              study.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2020.11.17.387043",
  month    =  nov,
  year     =  2020,
  keywords = "RNN",
  language = "en",
  doi      = "10.1101/2020.11.17.387043"
}

@ARTICLE{Renier2016-cx,
  title    = "Mapping of Brain Activity by Automated Volume Analysis of
              Immediate Early Genes",
  author   = "Renier, Nicolas and Adams, Eliza L and Kirst, Christoph and Wu,
              Zhuhao and Azevedo, Ricardo and Kohl, Johannes and Autry, Anita E
              and Kadiri, Lolahon and Umadevi Venkataraju, Kannan and Zhou, Yu
              and Wang, Victoria X and Tang, Cheuk Y and Olsen, Olav and Dulac,
              Catherine and Osten, Pavel and Tessier-Lavigne, Marc",
  abstract = "Understanding how neural information is processed in
              physiological and pathological states would benefit from precise
              detection, localization, and quantification of the activity of
              all neurons across the entire brain, which has not, to date, been
              achieved in the mammalian brain. We introduce a pipeline for
              high-speed acquisition of brain activity at cellular resolution
              through profiling immediate early gene expression using
              immunostaining and light-sheet fluorescence imaging, followed by
              automated mapping and analysis of activity by an open-source
              software program we term ClearMap. We validate the pipeline first
              by analysis of brain regions activated in response to
              haloperidol. Next, we report new cortical regions downstream of
              whisker-evoked sensory processing during active exploration.
              Last, we combine activity mapping with axon tracing to uncover
              new brain regions differentially activated during parenting
              behavior. This pipeline is widely applicable to different
              experimental paradigms, including animal species for which
              transgenic activity reporters are not readily available.",
  journal  = "Cell",
  volume   =  165,
  number   =  7,
  pages    = "1789--1802",
  month    =  jun,
  year     =  2016,
  language = "en",
  issn     = "0092-8674, 1097-4172",
  pmid     = "27238021",
  doi      = "10.1016/j.cell.2016.05.007",
  pmc      = "PMC4912438"
}

@ARTICLE{Goubran2019-je,
  title    = "Multimodal image registration and connectivity analysis for
              integration of connectomic data from microscopy to {MRI}",
  author   = "Goubran, Maged and Leuze, Christoph and Hsueh, Brian and Aswendt,
              Markus and Ye, Li and Tian, Qiyuan and Cheng, Michelle Y and
              Crow, Ailey and Steinberg, Gary K and McNab, Jennifer A and
              Deisseroth, Karl and Zeineh, Michael",
  abstract = "3D histology, slice-based connectivity atlases, and diffusion MRI
              are common techniques to map brain wiring. While there are many
              modality-specific tools to process these data, there is a lack of
              integration across modalities. We develop an automated resource
              that combines histologically cleared volumes with connectivity
              atlases and MRI, enabling the analysis of histological features
              across multiple fiber tracts and networks, and their correlation
              with in-vivo biomarkers. We apply our pipeline in a murine stroke
              model, demonstrating not only strong correspondence between MRI
              abnormalities and CLARITY-tissue staining, but also uncovering
              acute cellular effects in areas connected to the ischemic core.
              We provide improved maps of connectivity by quantifying
              projection terminals from CLARITY viral injections, and integrate
              diffusion MRI with CLARITY viral tracing to compare connectivity
              maps across scales. Finally, we demonstrate tract-level
              histological changes of stroke through this multimodal
              integration. This resource can propel investigations of network
              alterations underlying neurological disorders.",
  journal  = "Nat. Commun.",
  volume   =  10,
  number   =  1,
  pages    = "5504",
  month    =  dec,
  year     =  2019,
  language = "en",
  issn     = "2041-1723",
  pmid     = "31796741",
  doi      = "10.1038/s41467-019-13374-0",
  pmc      = "PMC6890789"
}

@UNPUBLISHED{Mano2020-dx,
  title    = "{CUBIC-Cloud}: An Integrative Computational Framework Towards
              Community-driven {Whole-Mouse-Brain} Mapping",
  author   = "Mano, Tomoyuki and Murata, Ken and Kon, Kazuhiro and Shimizu,
              Chika and Ono, Hiroaki and Shi, Shoi and Yamada, Rikuhiro G and
              Miyamichi, Kazunari and Susaki, Etsuo A and Touhara, Kazushige
              and Ueda, Hiroki R",
  abstract = "Recent advancements in tissue clearing technologies have offered
              unparalleled opportunities for researchers to explore the whole
              mouse brain at cellular resolution. With the expansion of this
              experimental technique, however, a scalable and easy-to-use
              computational tool is in demand to effectively analyze and
              integrate whole-brain mapping datasets. To that end, here we
              present CUBIC-Cloud, a cloud-based framework to quantify,
              visualize and integrate whole mouse brain data. CUBIC-Cloud is a
              fully automated system where users can upload their whole-brain
              data, run analysis and publish the results. We demonstrate the
              generality of CUBIC-Cloud by a variety of applications. First, we
              investigated brain-wide distribution of PV, Sst, ChAT, Th and
              Iba1 expressing cells. Second, A$\beta$ plaque deposition in AD
              model mouse brains were quantified. Third, we reconstructed
              neuronal activity profile under LPS-induced inflammation by c-Fos
              immunostaining. Last, we show brain-wide connectivity mapping by
              pseudo-typed Rabies virus. Together, CUBIC-Cloud provides an
              integrative platform to advance scalable and collaborative
              whole-brain mapping. \#\#\# Competing Interest Statement T.M. and
              H.R.U. filed a patent application regarding the CUBIC-Cloud
              software. CUBIC-Cloud web service is provided and maintained by
              CUBICStars Inc.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2020.08.28.271031",
  month    =  aug,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.08.28.271031"
}

@ARTICLE{Song2020-sg,
  title    = "Precise Mapping of Single Neurons by Calibrated {3D}
              Reconstruction of Brain Slices Reveals Topographic Projection in
              Mouse Visual Cortex",
  author   = "Song, Jun Ho and Choi, Woochul and Song, You-Hyang and Kim,
              Jae-Hyun and Jeong, Daun and Lee, Seung-Hee and Paik, Se-Bum",
  abstract = "Recent breakthroughs in neuroanatomical tracing methods have
              helped unravel complicated neural connectivity in whole-brain
              tissue at single-cell resolution. However, in most cases,
              analysis of brain images remains dependent on highly subjective
              and sample-specific manual processing, preventing precise
              comparison across sample animals. In the present study, we
              introduce AMaSiNe, software for automated mapping of single
              neurons in the standard mouse brain atlas with annotated regions.
              AMaSiNe automatically calibrates misaligned and deformed slice
              samples to locate labeled neuronal positions from multiple brain
              samples into the standardized 3D Allen Mouse Brain Reference
              Atlas. We exploit the high fidelity and reliability of AMaSiNe to
              investigate the topographic structures of feedforward projections
              from the lateral geniculate nucleus to the primary visual area by
              reconstructing rabies-virus-injected brain slices in 3D space.
              Our results demonstrate that distinct organization of neural
              projections can be precisely mapped using AMaSiNe.",
  journal  = "Cell Rep.",
  volume   =  31,
  number   =  8,
  pages    = "107682",
  month    =  may,
  year     =  2020,
  keywords = "Allen Mouse Brain Reference Atlas; automated brain mapping; brain
              image registration; brain slice calibration; mouse brain slice;
              retrograde tracing; single-neuron mapping; standard 3D brain
              atlas; topographic projection; visual cortex",
  language = "en",
  issn     = "2211-1247",
  pmid     = "32460016",
  doi      = "10.1016/j.celrep.2020.107682"
}

@UNPUBLISHED{Jin2019-xr,
  title    = "{SMART}: An open source extension of {WholeBrain} for {iDISCO+}
              {LSFM} intact mouse brain registration and segmentation",
  author   = "Jin, Michelle and Nguyen, Joseph D and Weber, Sophia J and
              Mejias-Aponte, Carlos A and Madangopal, Rajtarun and Golden, Sam
              A",
  abstract = "Abstract Mapping immediate early gene (IEG) expression across
              intact brains is becoming a popular approach for identifying the
              brain-wide activity patterns underlying behavior. Registering
              whole brains to an anatomical atlas presents a technical
              challenge that has predominantly been tackled using automated
              voxel-based registration methods; however, these methods may fail
              when brains are damaged or only partially imaged, can be
              challenging to correct, and require substantial computational
              power. Here we present an open source package in R called SMART
              (semi-manual alignment to reference templates) as an extension to
              the WholeBrain framework for automated segmentation and
              semi-automated registration of experimental images to vectorized
              atlas plates from the Allen Brain Institute Mouse Common
              Coordinate Framework (CCF).The SMART package was created with the
              novice programmer in mind and introduces a streamlined pipeline
              for aligning, registering, and segmenting large LSFM volumetric
              datasets with the CCF across the anterior-posterior axis, using a
              simple `choice game' and interactive user-friendly menus. SMART
              further provides the flexibility to register partial brains or
              discrete user-chosen experimental images across the CCF, making
              it compatible with analysis of traditionally sectioned coronal
              brain slices. In addition to SMART, we introduce a modified
              tissue clearing protocol based on the iDISCO+ procedure that is
              optimized for uniform Fos antibody labeling and tissue clearing
              across whole intact mouse brains. Here we demonstrate the utility
              of the SMART-WholeBrain pipeline, in conjunction with the
              modified iDISCO+ Fos procedure, by providing example datasets
              alongside a full user tutorial. Finally, we present a subset of
              these data online in an interactive web applet. The complete
              SMART package is available for download on GitHub.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "727529",
  month    =  aug,
  year     =  2019,
  language = "en",
  doi      = "10.1101/727529"
}

@ARTICLE{Young2020-du,
  title    = "{Whole-Brain} Image Analysis and Anatomical Atlas {3D} Generation
              Using {MagellanMapper}",
  author   = "Young, David M and Duhn, Clif and Gilson, Michael and Nojima, Mai
              and Yuruk, Deniz and Kumar, Aparna and Yu, Weimiao and Sanders,
              Stephan J",
  abstract = "MagellanMapper is a software suite designed for visual inspection
              and end-to-end automated processing of large-volume, 3D brain
              imaging datasets in a memory-efficient manner. The rapidly
              growing number of large-volume, high-resolution datasets
              necessitates visualization of raw data at both macro- and
              microscopic levels to assess the quality of data, as well as
              automated processing to quantify data in an unbiased manner for
              comparison across a large number of samples. To facilitate these
              analyses, MagellanMapper provides both a graphical user interface
              for manual inspection and a command-line interface for automated
              image processing. At the macroscopic level, the graphical
              interface allows researchers to view full volumetric images
              simultaneously in each dimension and to annotate anatomical label
              placements. At the microscopic level, researchers can inspect
              regions of interest at high resolution to build ground truth data
              of cellular locations such as nuclei positions. Using the
              command-line interface, researchers can automate cell detection
              across volumetric images, refine anatomical atlas labels to fit
              underlying histology, register these atlases to sample images,
              and perform statistical analyses by anatomical region.
              MagellanMapper leverages established open-source computer vision
              libraries and is itself open source and freely available for
              download and extension. \copyright{} 2020 Wiley Periodicals LLC.
              Basic Protocol 1: MagellanMapper installation Alternate Protocol:
              Alternative methods for MagellanMapper installation Basic
              Protocol 2: Import image files into MagellanMapper Basic Protocol
              3: Region of interest visualization and annotation Basic Protocol
              4: Explore an atlas along all three dimensions and register to a
              sample brain Basic Protocol 5: Automated 3D anatomical atlas
              construction Basic Protocol 6: Whole-tissue cell detection and
              quantification by anatomical label Support Protocol: Import a
              tiled microscopy image in proprietary format into MagellanMapper.",
  journal  = "Curr. Protoc. Neurosci.",
  volume   =  94,
  number   =  1,
  pages    = "e104",
  month    =  dec,
  year     =  2020,
  keywords = "3D atlas; graphical interface; image processing; microscopy
              images; tissue clearing",
  language = "en",
  issn     = "1934-8584, 1934-8576",
  pmid     = "32981139",
  doi      = "10.1002/cpns.104"
}

@ARTICLE{Sussillo2015-xp,
  title    = "A neural network that finds a naturalistic solution for the
              production of muscle activity",
  author   = "Sussillo, David and Churchland, Mark M and Kaufman, Matthew T and
              Shenoy, Krishna V",
  abstract = "It remains an open question how neural responses in motor cortex
              relate to movement. We explored the hypothesis that motor cortex
              reflects dynamics appropriate for generating temporally patterned
              outgoing commands. To formalize this hypothesis, we trained
              recurrent neural networks to reproduce the muscle activity of
              reaching monkeys. Models had to infer dynamics that could
              transform simple inputs into temporally and spatially complex
              patterns of muscle activity. Analysis of trained models revealed
              that the natural dynamical solution was a low-dimensional
              oscillator that generated the necessary multiphasic commands.
              This solution closely resembled, at both the single-neuron and
              population levels, what was observed in neural recordings from
              the same monkeys. Notably, data and simulations agreed only when
              models were optimized to find simple solutions. An appealing
              interpretation is that the empirically observed dynamics of motor
              cortex may reflect a simple solution to the problem of generating
              temporally patterned descending commands.",
  journal  = "Nat. Neurosci.",
  volume   =  18,
  number   =  7,
  pages    = "1025--1033",
  month    =  jul,
  year     =  2015,
  keywords = "RNN;RNN To read",
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "26075643",
  doi      = "10.1038/nn.4042",
  pmc      = "PMC5113297"
}

@ARTICLE{Humphries2020-nf,
  title         = "Strong and weak principles of neural dimension reduction",
  author        = "Humphries, Mark D",
  abstract      = "If spikes are the medium, what is the message? Answering
                   that question is driving the development of large-scale,
                   single neuron resolution recordings from behaving animals,
                   on the scale of thousands of neurons. But these data are
                   inherently high-dimensional, with as many dimensions as
                   neurons - so how do we make sense of them? For many the
                   answer is to reduce the number of dimensions. Here I argue
                   we can distinguish weak and strong principles of neural
                   dimension reduction. The weak principle is that dimension
                   reduction is a convenient tool for making sense of complex
                   neural data. The strong principle is that dimension
                   reduction shows us how neural circuits actually operate and
                   compute. Elucidating these principles is crucial, for which
                   we subscribe to provides radically different interpretations
                   of the same neural activity data. I show how we could make
                   either the weak or strong principles appear to be true based
                   on innocuous looking decisions about how we use dimension
                   reduction on our data. To counteract these confounds, I
                   outline the experimental evidence for the strong principle
                   that do not come from dimension reduction; but also show
                   there are a number of neural phenomena that the strong
                   principle fails to address. To reconcile these conflicting
                   data, I suggest that the brain has both principles at play.",
  month         =  nov,
  year          =  2020,
  archivePrefix = "arXiv",
  eprint        = "2011.08088",
  primaryClass  = "q-bio.NC",
  arxivid       = "2011.08088"
}

@UNPUBLISHED{Michaels2020-ut,
  title    = "A modular neural network model of grasp movement generation",
  author   = "Michaels, Jonathan A and Schaffelhofer, Stefan and Agudelo-Toro,
              Andres and Scherberger, Hansj{\"o}rg",
  abstract = "Summary One of the primary ways we interact with the world is
              using our hands. In macaques, the circuit spanning the anterior
              intraparietal area, the hand area of the ventral premotor cortex,
              and the primary motor cortex is necessary for transforming visual
              information into grasping movements. We hypothesized that a
              recurrent neural network mimicking the multi-area structure of
              the anatomical circuit and using visual features to generate the
              required muscle dynamics to grasp objects would explain the
              neural and computational basis of the grasping circuit. Modular
              networks with object feature input and sparse inter-module
              connectivity outperformed other models at explaining neural data
              and the inter-area relationships present in the biological
              circuit, despite the absence of neural data during network
              training. Network dynamics were governed by simple rules, and
              targeted lesioning of modules produced deficits similar to those
              observed in lesion studies, providing a potential explanation for
              how grasping movements are generated.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "742189",
  month    =  feb,
  year     =  2020,
  keywords = "RNN",
  language = "en",
  doi      = "10.1101/742189"
}

@UNPUBLISHED{Harris2020-im,
  title    = "Nonsense correlations in neuroscience",
  author   = "Harris, Kenneth D",
  abstract = "Most neurophysiological signals exhibit slow continuous trends
              over time. Because standard correlation analyses assume that all
              samples are independent, they can yield apparently significant
              ``nonsense correlations'' even for signals that are completely
              unrelated. Here we compare the performance of several methods for
              assessing correlations between timeseries, using simulated slowly
              drifting signals with and without genuine correlations. The best
              performance was obtained from a ``pseudosession method'', which
              relies on one of the signals being randomly generated by the
              experimenter, or a ``session perturbation'' method which requires
              multiple recordings under the same conditions. If neither of
              these is applicable, we find that a ``linear shift method can
              work well, but only when one of the signals is stationary.
              Methods based on cross-validation, circular shifting, phase
              randomization, or detrending gave up to 100\% false positive
              rates in our simulations. We conclude that analysis of neural
              timeseries is best performed when stationarity and randomization
              is built into the experimental design. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2020.11.29.402719",
  month    =  nov,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.11.29.402719"
}

@ARTICLE{Yamawaki2016-fp,
  title    = "A Corticocortical Circuit Directly Links Retrosplenial Cortex to
              {M2} in the Mouse",
  author   = "Yamawaki, Naoki and Radulovic, Jelena and Shepherd, Gordon M G",
  abstract = "UNLABELLED: Retrosplenial cortex (RSC) is a dorsomedial parietal
              area involved in a range of cognitive functions, including
              episodic memory, navigation, and spatial memory. Anatomically,
              the RSC receives inputs from dorsal hippocampal networks and in
              turn projects to medial neocortical areas. A particularly
              prominent projection extends rostrally to the posterior secondary
              motor cortex (M2), suggesting a functional corticocortical link
              from the RSC to M2 and thus a bridge between hippocampal and
              neocortical networks involved in mnemonic and sensorimotor
              aspects of navigation. We investigated the cellular connectivity
              in this RSC$\rightarrow$M2 projection in the mouse using
              optogenetic photostimulation, retrograde labeling, and
              electrophysiology. Axons from RSC formed monosynaptic excitatory
              connections onto M2 pyramidal neurons across layers and
              projection classes, including corticocortical/intratelencephalic
              neurons (reciprocally and callosally projecting) in layers 2-6,
              pyramidal tract neurons (corticocollicular, corticopontine) in
              layer 5B, and, to a lesser extent, corticothalamic neurons in
              layer 6. In addition to these direct connections, disynaptic
              connections were made via posterior parietal cortex
              (RSC$\rightarrow$PPC$\rightarrow$M2) and anteromedial thalamus
              (RSC$\rightarrow$AM$\rightarrow$M2). In the reverse direction,
              axons from M2 monosynaptically excited M2-projecting
              corticocortical neurons in the RSC, especially in the superficial
              layers of the dysgranular region. These findings establish an
              excitatory RSC$\rightarrow$M2 corticocortical circuit that
              engages diverse types of excitatory projection neurons in the
              downstream area, suggesting a basis for direct communication from
              dorsal hippocampal networks involved in spatial memory and
              navigation to neocortical networks involved in diverse aspects of
              sensorimotor integration and motor control. SIGNIFICANCE
              STATEMENT: Corticocortical pathways interconnect cortical areas
              extensively, but the cellular connectivity in these pathways
              remains largely uncharacterized. Here, we show that a posterior
              part of secondary motor cortex receives corticocortical axons
              from the rostral retrosplenial cortex (RSC) and these form
              monosynaptic excitatory connections onto a wide spectrum of
              excitatory projection neurons in this area. Our results define a
              cellular basis for direct communication from RSC to this medial
              frontal area, suggesting a direct link from dorsal hippocampal
              networks involved in spatial cognition and navigation (the
              ``map'') to sensorimotor networks involved the control of
              movement (the ``motor'').",
  journal  = "J. Neurosci.",
  volume   =  36,
  number   =  36,
  pages    = "9365--9374",
  month    =  sep,
  year     =  2016,
  keywords = "circuit; motor; neocortex; optogenetic; retrosplenial",
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "27605612",
  doi      = "10.1523/JNEUROSCI.1099-16.2016",
  pmc      = "PMC5013186"
}

@UNPUBLISHED{Schaeffer2020-qv,
  title    = "Reverse-engineering Recurrent Neural Network solutions to a
              hierarchical inference task for mice",
  author   = "Schaeffer, Rylan and Khona, Mikail and Meshulam, Leenoy and
              {International Brain Laboratory} and Fiete, Ila Rani",
  abstract = "We study how recurrent neural networks (RNNs) solve a
              hierarchical inference task involving two latent variables and
              disparate timescales separated by 1-2 orders of magnitude. The
              task is of interest to the International Brain Laboratory, a
              global collaboration of experimental and theoretical
              neuroscientists studying how the mammalian brain generates
              behavior. We make four discoveries. First, RNNs learn behavior
              that is quantitatively similar to ideal Bayesian baselines.
              Second, RNNs perform inference by learning a two-dimensional
              subspace defining beliefs about the latent variables. Third, the
              geometry of RNN dynamics reflects an induced coupling between the
              two separate inference processes necessary to solve the task.
              Fourth, we perform model compression through a novel form of
              knowledge distillation on hidden representations --
              Representations and Dynamics Distillation (RADD)-- to reduce the
              RNN dynamics to a low-dimensional, highly interpretable model.
              This technique promises a useful tool for interpretability of
              high dimensional nonlinear dynamical systems. Altogether, this
              work yields predictions to guide exploration and analysis of
              mouse neural data and circuity. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2020.06.09.142745",
  month    =  jun,
  year     =  2020,
  keywords = "RNN",
  language = "en",
  doi      = "10.1101/2020.06.09.142745"
}

@INPROCEEDINGS{Fukayama2012-uk,
  title     = "{RatCar}: A whole-body neuromuscular locomotion prosthetic
               device with exoskeletal robotic limbs for a rat",
  booktitle = "The 6th International Conference on Soft Computing and
               Intelligent Systems, and The 13th International Symposium on
               Advanced Intelligence Systems",
  author    = "Fukayama, O and Nakanishi, R and Otsuka, H and Suzuki, T and
               Mabuchi, K",
  abstract  = "RatCar; a vehicular BMI device for a rat has been developed to
               substitute natural limbs of the rat. The device aims for a
               future wheelchair controlled by motor commands acquired directly
               from human nervous system. It also contributes to the
               neuroscience through observing the brain functionality and its
               plastic changes in the presence of external inputs and outputs.
               A basic idea of the system is to estimate locomotion state
               according to the neural signals either in the brain or in the
               peripheral nerve fibers. In the first design, a linear
               correlation model estimated locomotion velocity and directional
               changes according to neural spikes in the motor cortex. The
               results were applied to control the vehicular device which mount
               a rat on its body. Then, the extended model in a state space
               representation form achieved an adaptive estimation. Currently,
               our system further branched to include a micro-electrical
               stimulator for correlation induction, and exoskeletal robotic
               limbs. This paper overviews the structure of the system, and
               describes a draft methodology of correlation induction and
               controlling robotic limbs.",
  publisher = "ieeexplore.ieee.org",
  pages     = "1158--1161",
  month     =  nov,
  year      =  2012,
  keywords  = "brain-computer interfaces;mobile
               robots;neurophysiology;prosthetics;wheelchairs;RatCar;whole-body
               neuromuscular locomotion prosthetic device;exoskeletal robotic
               limbs;rat;vehicular BMI device;wheelchair;motor commands;human
               nervous system;neuroscience;locomotion state estimation;neural
               signals;peripheral nerve fibers;linear correlation model;neural
               spikes;motor cortex;micro-electrical stimulator;Locomotion",
  doi       = "10.1109/SCIS-ISIS.2012.6505404"
}

@ARTICLE{Madhav2020-qs,
  title     = "The Synergy Between Neuroscience and Control Theory: The Nervous
               System as Inspiration for Hard Control Challenges",
  author    = "Madhav, Manu S and Cowan, Noah J",
  abstract  = "Here, we review the role of control theory in modeling neural
               control systems through a top-down analysis approach.
               Specifically, we examine the role of the brain and central
               nervous system as the controller in the organism, connected to
               but isolated from the rest of the animal through insulated
               interfaces. Though biological and engineering control systems
               operate on similar principles, they differ in several critical
               features, which makes drawing inspiration from biology for
               engineering controllers challenging but worthwhile. We also
               outline a procedure that the control theorist can use to draw
               inspiration from the biological controller: starting from the
               intact, behaving animal; designing experiments to deconstruct
               and model hierarchies of feedback; modifying feedback
               topologies; perturbing inputs and plant dynamics; using the
               resultant outputs to perform system identification; and tuning
               and validating the resultant control-theoretic model using
               specially engineered robophysical models.",
  journal   = "Annu. Rev. Control Robot. Auton. Syst.",
  publisher = "Annual Reviews",
  volume    =  3,
  number    =  1,
  pages     = "243--267",
  month     =  may,
  year      =  2020,
  issn      = "2573-5144",
  doi       = "10.1146/annurev-control-060117-104856"
}

@UNPUBLISHED{Kao2020-dl,
  title    = "Optimal anticipatory control as a theory of motor preparation: a
              thalamo-cortical circuit model",
  author   = "Kao, Ta-Chu and Sadabadi, Mahdieh S and Hennequin, Guillaume",
  abstract = "Summary Across a range of motor and cognitive tasks, cortical
              activity can be accurately described by low-dimensional dynamics
              unfolding from specific initial conditions on every trial. These
              ``preparatory states'' largely determine the subsequent evolution
              of both neural activity and behaviour, and their importance
              raises questions regarding how they are --- or ought to be ---
              set. Here, we formulate motor preparation as optimal prospective
              control of future movements. The solution is a form of internal
              control of cortical circuit dynamics, which can be implemented as
              a thalamo-cortical loop gated by the basal ganglia. Critically,
              optimal control predicts selective quenching of variability in
              components of preparatory population activity that have future
              motor consequences, but not in others. This is consistent with
              recent perturbation experiments performed in mice, and with our
              novel analysis of monkey motor cortex activity during reaching.
              Together, these results suggest optimal anticipatory control of
              movement.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2020.02.02.931246",
  month    =  feb,
  year     =  2020,
  keywords = "control",
  language = "en",
  doi      = "10.1101/2020.02.02.931246"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INCOLLECTION{Velagic2008-nb,
  title     = "Nonlinear motion control of mobile robot dynamic model",
  booktitle = "Motion planning",
  author    = "Velagic, Jasmin and Lacevic, Bakir and Osmic, Nedim",
  abstract  = "The problem of motion planning and control of mobile robots has
               attracted the interest of researchers in view of its theoretical
               challenges because of their obvious relevance in applications.
               From a control viewpoint, the peculiar nature of nonholonomic
               kinematics and dynamic complexity of the mobile robot makes that
               feedback stabilization at a given posture cannot be achieved via
               smooth time-invariant control (Oriolo et al., 2002). This
               indicates that the problem is truly nonlinear; linear control is
               ineffective, and innovative design techniques …",
  publisher = "IntechOpen",
  year      =  2008,
  keywords  = "control"
}

@ARTICLE{Marshall2020-rp,
  title    = "Continuous {Whole-Body} {3D} Kinematic Recordings across the
              Rodent Behavioral Repertoire",
  author   = "Marshall, Jesse D and Aldarondo, Diego E and Dunn, Timothy W and
              Wang, William L and Berman, Gordon J and {\"O}lveczky, Bence P",
  abstract = "In mammalian animal models, high-resolution kinematic tracking is
              restricted to brief sessions in constrained environments,
              limiting our ability to probe naturalistic behaviors and their
              neural underpinnings. To address this, we developed CAPTURE
              (Continuous Appendicular and Postural Tracking Using
              Retroreflector Embedding), a behavioral monitoring system that
              combines motion capture and deep learning to continuously track
              the 3D kinematics of a rat's head, trunk, and limbs for week-long
              timescales in freely behaving animals. CAPTURE realizes 10- to
              100-fold gains in precision and robustness compared with existing
              convolutional network approaches to behavioral tracking. We
              demonstrate CAPTURE's ability to comprehensively profile the
              kinematics and sequential organization of natural rodent
              behavior, its variation across individuals, and its perturbation
              by drugs and disease, including identifying perseverative
              grooming states in a rat model of fragile X syndrome. CAPTURE
              significantly expands the range of behaviors and contexts that
              can be quantitatively investigated, opening the door to a new
              understanding of natural behavior and its neural basis.",
  journal  = "Neuron",
  month    =  dec,
  year     =  2020,
  keywords = "animal tracking; autism; behavior; computational ethology;
              grooming; individuality; motion capture; phenotyping",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "33340448",
  doi      = "10.1016/j.neuron.2020.11.016"
}

@ARTICLE{Maheswaranathan2020-fy,
  title         = "How recurrent networks implement contextual processing in
                   sentiment analysis",
  author        = "Maheswaranathan, Niru and Sussillo, David",
  abstract      = "Neural networks have a remarkable capacity for contextual
                   processing--using recent or nearby inputs to modify
                   processing of current input. For example, in natural
                   language, contextual processing is necessary to correctly
                   interpret negation (e.g. phrases such as ``not bad'').
                   However, our ability to understand how networks process
                   context is limited. Here, we propose general methods for
                   reverse engineering recurrent neural networks (RNNs) to
                   identify and elucidate contextual processing. We apply these
                   methods to understand RNNs trained on sentiment
                   classification. This analysis reveals inputs that induce
                   contextual effects, quantifies the strength and timescale of
                   these effects, and identifies sets of these inputs with
                   similar properties. Additionally, we analyze contextual
                   effects related to differential processing of the beginning
                   and end of documents. Using the insights learned from the
                   RNNs we improve baseline Bag-of-Words models with simple
                   extensions that incorporate contextual modification,
                   recovering greater than 90\% of the RNN's performance
                   increase over the baseline. This work yields a new
                   understanding of how RNNs process contextual information,
                   and provides tools that should provide similar insight more
                   broadly.",
  month         =  apr,
  year          =  2020,
  keywords      = "RNN;RNN To read",
  archivePrefix = "arXiv",
  eprint        = "2004.08013",
  primaryClass  = "cs.CL",
  arxivid       = "2004.08013"
}

@ARTICLE{Hahn2020-rj,
  title     = "An open access mouse brain flatmap and upgraded rat and human
               brain flatmaps based on current reference atlases",
  author    = "Hahn, Joel D and Swanson, Larry W and Bowman, Ian and Foster,
               Nicholas N and Zingg, Brian and Bienkowski, Michael S and
               Hintiryan, Houri and Dong, Hong-Wei",
  abstract  = "Here we present a flatmap of the mouse central nervous system
               (CNS) (brain) and substantially enhanced flatmaps of the rat and
               human brain. Also included are enhanced representations of
               nervous system white matter tracts, ganglia, and nerves, and an
               enhanced series of 10 flatmaps showing different stages of rat
               brain development. The adult mouse and rat brain flatmaps
               provide layered diagrammatic representation of CNS divisions,
               according to their arrangement in corresponding reference
               atlases: Brain Maps 4.0 (BM4, rat) (Swanson, The Journal of
               Comparative Neurology, 2018, 526, 935-943), and the first
               version of the Allen Reference Atlas (mouse) (Dong, The Allen
               reference atlas, (book + CD-ROM): A digital color brain atlas of
               the C57BL/6J male mouse, 2007). To facilitate comparative
               analysis, both flatmaps are scaled equally, and the divisional
               hierarchy of gray matter follows a topographic arrangement used
               in BM4. Also included with the mouse and rat brain flatmaps are
               cerebral cortex atlas level contours based on the reference
               atlases, and direct graphical and tabular comparison of regional
               parcellation. To encourage use of the brain flatmaps, they were
               designed and organized, with supporting reference tables, for
               ease-of-use and to be amenable to computational applications. We
               demonstrate how they can be adapted to represent novel
               parcellations resulting from experimental data, and we provide a
               proof-of-concept for how they could form the basis of a
               web-based graphical data viewer and analysis platform. The
               mouse, rat, and human brain flatmap vector graphics files (Adobe
               Reader/Acrobat viewable and Adobe Illustrator editable) and
               supporting tables are provided open access; they constitute a
               broadly applicable neuroscience toolbox resource for researchers
               seeking to map and perform comparative analysis of brain data.",
  journal   = "J. Comp. Neurol.",
  publisher = "Wiley",
  number    = "cne.24966",
  month     =  jun,
  year      =  2020,
  keywords  = "brain atlases; brain flatmap; brain mapping; computer graphics;
               human; mouse; rat",
  copyright = "http://onlinelibrary.wiley.com/termsAndConditions\#vor",
  language  = "en",
  issn      = "0021-9967, 1096-9861",
  pmid      = "32511750",
  doi       = "10.1002/cne.24966",
  pmc       = "PMC7721992"
}

@ARTICLE{Simmons2009-ax,
  title     = "Comparing histological data from different brains: sources of
               error and strategies for minimizing them",
  author    = "Simmons, Donna M and Swanson, Larry W",
  abstract  = "The recent development of brain atlases with computer graphics
               templates, and of huge databases of neurohistochemical data on
               the internet, has forced a systematic re-examination of errors
               associated with comparing histological features between adjacent
               sections of the same brain, between brains treated in the same
               way, and between brains from groups treated in different ways.
               The long-term goal is to compare as accurately as possible a
               broad array of data from experimental brains within the
               framework of reference atlases. Main sources of error, each of
               which ideally should be measured and minimized, include
               intrinsic biological variation, linear and nonlinear distortion
               of histological sections, plane of section differences between
               each brain, section alignment problems, and sampling errors.
               These variables are discussed, along with approaches to error
               estimation and minimization in terms of a specific example-the
               distribution of neuroendocrine neurons in the rat
               paraventricular nucleus. Based on the strategy developed here,
               the main conclusion is that the best long-term solution is a
               high-resolution 3D computer graphics model of the brain that can
               be sliced in any plane and used as the framework for
               quantitative neuroanatomy, databases, knowledge management
               systems, and structure-function modeling. However, any approach
               to the automatic annotation of neuroanatomical data-relating its
               spatial distribution to a reference atlas-should deal
               systematically with these sources of error, which reduce
               localization reliability.",
  journal   = "Brain Res. Rev.",
  publisher = "Elsevier",
  volume    =  60,
  number    =  2,
  pages     = "349--367",
  month     =  may,
  year      =  2009,
  language  = "en",
  issn      = "0165-0173",
  pmid      = "19248810",
  doi       = "10.1016/j.brainresrev.2009.02.002",
  pmc       = "PMC2680454"
}

@ARTICLE{Taylor1982-pi,
  title     = "Energetics and mechanics of terrestrial locomotion. I. Metabolic
               energy consumption as a function of speed and body size in birds
               and mammals",
  author    = "Taylor, C R and Heglund, N C and Maloiy, G M",
  abstract  = "This series of four papers investigates the link between the
               energetics and the mechanics of terrestrial locomotion. Two
               experimental variables are used throughout the study: speed and
               body size. Mass-specific metabolic rates of running animals can
               be varied by about tenfold using either variable. This first
               paper considers metabolic energy consumed during terrestrial
               locomotion. New data relating rate of oxygen consumption and
               speed are reported for: eight species of wild and domestic
               artiodactyls; seven species of carnivores; four species of
               primates; and one species of rodent. These are combined with
               previously published data to formulate a new allometric equation
               relating mass-specific rates of oxygen consumed (VO2/Mb) during
               locomotion at a constant speed to speed and body mass (based on
               data from 62 avian and mammalian species): VO2/Mb = 0.533
               Mb-0.316.vg + 0.300 Mb-0.303 where VO2/Mb has the units ml O2
               s-1 kg-1; Mb is in kg; and vg is in m s-1. This equation can be
               expressed in terms of mass-specific rates of energy consumption
               (Emetab/Mb) using the energetic equivalent of 1 ml O2 = 20.1 J
               because the contribution of anaerobic glycolysis was negligible:
               Emetab/Mb = 10.7 Mb-0.316.vg + 6.03 Mb-0.303 where Emetab/Mb has
               the units watts/kg. This new relationship applies equally well
               to bipeds and quadrupeds and differs little from the allometric
               equation reported 12 years ago by Taylor, Schmid-Nielsen \& Raab
               (1970). Ninety per cent of the values calculated from this
               genera equation for the diverse assortment of avian and
               mammalian species included in this regression fall within 25\%
               of the observed values at the middle of the speed range where
               measurements were made. This agreement is impressive when one
               considers that mass-specific rates of oxygen consumption
               differed by more than 1400\% over this size range of animals.",
  journal   = "J. Exp. Biol.",
  publisher = "jeb.biologists.org",
  volume    =  97,
  pages     = "1--21",
  month     =  apr,
  year      =  1982,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "0022-0949",
  pmid      = "7086334"
}

@ARTICLE{Usseglio2020-nl,
  title    = "Control of Orienting Movements and Locomotion by
              {Projection-Defined} Subsets of Brainstem V2a Neurons",
  author   = "Usseglio, Giovanni and Gatier, Edwin and Heuz{\'e}, Aur{\'e}lie
              and H{\'e}rent, Coralie and Bouvier, Julien",
  abstract = "Spatial orientation requires the execution of lateralized
              movements and a change in the animal's heading in response to
              multiple sensory modalities. While much research has focused on
              the circuits for sensory integration, chiefly to the midbrain
              superior colliculus (SC), the downstream cells and circuits that
              engage adequate motor actions have remained elusive. Furthermore,
              the mechanisms supporting trajectory changes are still
              speculative. Here, using transneuronal viral tracings in mice, we
              show that brainstem V2a neurons, a genetically defined subtype of
              glutamatergic neurons of the reticular formation, receive
              putative synaptic inputs from the contralateral SC. This makes
              them a candidate relay of lateralized orienting commands. We next
              show that unilateral optogenetic activations of brainstem V2a
              neurons in vivo evoked ipsilateral orienting-like responses of
              the head and the nose tip on stationary mice. When animals are
              walking, similar stimulations impose a transient locomotor arrest
              followed by a change of trajectory. Third, we reveal that these
              distinct motor actions are controlled by dedicated V2a subsets
              each projecting to a specific spinal cord segment, with at least
              (1) a lumbar-projecting subset whose unilateral activation
              specifically controls locomotor speed but neither impacts
              trajectory nor evokes orienting movements, and (2) a
              cervical-projecting subset dedicated to head orientation, but not
              to locomotor speed. Activating the latter subset suffices to
              steer the animals' directional heading, placing the head
              orientation as the prime driver of locomotor trajectory. V2a
              neurons and their modular organization may therefore underlie the
              orchestration of multiple motor actions during multi-faceted
              orienting behaviors.",
  journal  = "Curr. Biol.",
  volume   =  30,
  number   =  23,
  pages    = "4665--4681.e6",
  month    =  dec,
  year     =  2020,
  keywords = "V2a neurons; brainstem; circuit tracings; locomotion; motor
              control; mouse; optogenetics; orientation; reticulospinal
              neurons; spinal cord;Locomotion",
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "33007251",
  doi      = "10.1016/j.cub.2020.09.014"
}

@ARTICLE{Caggiano2018-td,
  title    = "Midbrain circuits that set locomotor speed and gait selection",
  author   = "Caggiano, V and Leiras, R and Go{\~n}i-Erro, H and Masini, D and
              Bellardita, C and Bouvier, J and Caldeira, V and Fisone, G and
              Kiehn, O",
  abstract = "Locomotion is a fundamental motor function common to the animal
              kingdom. It is implemented episodically and adapted to
              behavioural needs, including exploration, which requires slow
              locomotion, and escape behaviour, which necessitates faster
              speeds. The control of these functions originates in brainstem
              structures, although the neuronal substrate(s) that support them
              have not yet been elucidated. Here we show in mice that speed and
              gait selection are controlled by glutamatergic excitatory neurons
              (GlutNs) segregated in two distinct midbrain nuclei: the
              cuneiform nucleus (CnF) and the pedunculopontine nucleus (PPN).
              GlutNs in both of these regions contribute to the control of
              slower, alternating-gait locomotion, whereas only GlutNs in the
              CnF are able to elicit high-speed, synchronous-gait locomotion.
              Additionally, both the activation dynamics and the input and
              output connectivity matrices of GlutNs in the PPN and the CnF
              support explorative and escape locomotion, respectively. Our
              results identify two regions in the midbrain that act in
              conjunction to select context-dependent locomotor behaviours.",
  journal  = "Nature",
  volume   =  553,
  number   =  7689,
  pages    = "455--460",
  month    =  jan,
  year     =  2018,
  keywords = "Locomotion",
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "29342142",
  doi      = "10.1038/nature25448",
  pmc      = "PMC5937258"
}

@ARTICLE{Bouvier2015-nm,
  title    = "Descending Command Neurons in the Brainstem that Halt Locomotion",
  author   = "Bouvier, Julien and Caggiano, Vittorio and Leiras, Roberto and
              Caldeira, Vanessa and Bellardita, Carmelo and Balueva, Kira and
              Fuchs, Andrea and Kiehn, Ole",
  abstract = "The episodic nature of locomotion is thought to be controlled by
              descending inputs from the brainstem. Most studies have largely
              attributed this control to initiating excitatory signals, but
              little is known about putative commands that may specifically
              determine locomotor offset. To link identifiable brainstem
              populations to a potential locomotor stop signal, we used
              developmental genetics and considered a discrete neuronal
              population in the reticular formation: the V2a neurons. We find
              that those neurons constitute a major excitatory pathway to
              locomotor areas of the ventral spinal cord. Selective activation
              of V2a neurons of the rostral medulla stops ongoing locomotor
              activity, owing to an inhibition of premotor locomotor networks
              in the spinal cord. Moreover, inactivation of such neurons
              decreases spontaneous stopping in vivo. Therefore, the V2a ``stop
              neurons'' represent a glutamatergic descending pathway that
              favors immobility and may thus help control the episodic nature
              of locomotion.",
  journal  = "Cell",
  volume   =  163,
  number   =  5,
  pages    = "1191--1203",
  month    =  nov,
  year     =  2015,
  keywords = "Locomotion",
  language = "en",
  issn     = "0092-8674, 1097-4172",
  pmid     = "26590422",
  doi      = "10.1016/j.cell.2015.10.074",
  pmc      = "PMC4899047"
}

@INCOLLECTION{Matsuyama2004-fv,
  title     = "Locomotor role of the corticoreticular--reticulospinal--spinal
               interneuronal system",
  booktitle = "Progress in Brain Research",
  author    = "Matsuyama, Kiyoji and Mori, Futoshi and Nakajima, Katsumi and
               Drew, Trevor and Aoki, Mamoru and Mori, Shigemi",
  abstract  = "In vertebrates, the descending reticulospinal pathway is the
               primary means of conveying locomotor command signals from higher
               motor centers to spinal interneuronal circuits, the latter
               including the central pattern generators for locomotion. The
               pathway is morphologically heterogeneous, being composed of
               various types of in-parallel-descending axons, which terminate
               with different arborization patterns in the spinal cord. Such
               morphology suggests that this pathway and its target spinal
               interneurons comprise varying types of functional subunits,
               which have a wide variety of functional roles, as dictated by
               command signals from the higher motor centers. Corticoreticular
               fibers are one of the major output pathways from the motor
               cortex to the brainstem. They project widely and diffusely
               within the pontomedullary reticular formation. Such a diffuse
               projection pattern seems well suited to combining and
               integrating the function of the various types of reticulospinal
               neurons, which are widely scattered throughout the
               pontomedullary reticular formation. The
               corticoreticular--reticulospinal--spinal interneuronal
               connections appear to operate as a cohesive, yet flexible,
               control system for the elaboration of a wide variety of
               movements, including those that combine goal-directed locomotion
               with other motor actions.",
  publisher = "Elsevier",
  volume    =  143,
  pages     = "239--249",
  month     =  jan,
  year      =  2004,
  keywords  = "Locomotion",
  doi       = "10.1016/S0079-6123(03)43024-0"
}

@ARTICLE{Karadimas2020-ub,
  title     = "Sensory cortical control of movement",
  author    = "Karadimas, Spyridon K and Satkunendrarajah, Kajana and
               Laliberte, Alex M and Ringuette, Dene and Weisspapir, Iliya and
               Li, Lijun and Gosgnach, Simon and Fehlings, Michael G",
  abstract  = "Walking in our complex environment requires continual higher
               order integrated spatiotemporal information. This information is
               processed in the somatosensory cortex, and it has long been
               presumed that it influences movement via descending tracts
               originating from the motor cortex. Here we show that neuronal
               activity in the primary somatosensory cortex tightly correlates
               with the onset and speed of locomotion in freely moving mice.
               Using optogenetics and pharmacogenetics in combination with in
               vivo and in vitro electrophysiology, we provide evidence for a
               direct corticospinal pathway from the primary somatosensory
               cortex that synapses with cervical excitatory neurons and
               modulates the lumbar locomotor network independently of the
               motor cortex and other supraspinal locomotor centers.
               Stimulation of this pathway enhances speed of locomotion, while
               inhibition decreases locomotor speed and ultimately terminates
               stepping. Our findings reveal a novel pathway for neural control
               of movement whereby the somatosensory cortex directly influences
               motor behavior, possibly in response to environmental cues.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  23,
  number    =  1,
  pages     = "75--84",
  month     =  jan,
  year      =  2020,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "31740813",
  doi       = "10.1038/s41593-019-0536-7"
}

@ARTICLE{Lemieux2019-yc,
  title     = "Glutamatergic neurons of the gigantocellular reticular nucleus
               shape locomotor pattern and rhythm in the freely behaving mouse",
  author    = "Lemieux, Maxime and Bretzner, Frederic",
  abstract  = "Because of their intermediate position between supraspinal
               locomotor centers and spinal circuits, gigantocellular reticular
               nucleus (GRN) neurons play a key role in motor command. However,
               the functional contribution of glutamatergic GRN neurons in
               initiating, maintaining, and stopping locomotion is still
               unclear. Combining electromyographic recordings with optogenetic
               manipulations in freely behaving mice, we investigate the
               functional contribution of glutamatergic brainstem neurons of
               the GRN to motor and locomotor activity. Short-pulse
               photostimulation of one side of the glutamatergic GRN did not
               elicit locomotion but evoked distinct motor responses in flexor
               and extensor muscles at rest and during locomotion.
               Glutamatergic GRN outputs to the spinal cord appear to be gated
               according to the spinal locomotor network state. Increasing the
               duration of photostimulation increased motor and postural tone
               at rest and reset locomotor rhythm during ongoing locomotion. In
               contrast, photoinhibition impaired locomotor pattern and rhythm.
               We conclude that unilateral activation of glutamatergic GRN
               neurons triggered motor activity and modified ongoing locomotor
               pattern and rhythm.",
  journal   = "PLoS Biol.",
  publisher = "journals.plos.org",
  volume    =  17,
  number    =  4,
  pages     = "e2003880",
  month     =  apr,
  year      =  2019,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "1544-9173, 1545-7885",
  pmid      = "31017885",
  doi       = "10.1371/journal.pbio.2003880",
  pmc       = "PMC6502437"
}

@ARTICLE{Schwenkgrub2020-yl,
  title     = "Deep imaging in the brainstem reveals functional heterogeneity
               in V2a neurons controlling locomotion",
  author    = "Schwenkgrub, Joanna and Harrell, Evan R and Bathellier, Brice
               and Bouvier, Julien",
  abstract  = "V2a neurons are a genetically defined cell class that forms a
               major excitatory descending pathway from the brainstem reticular
               formation to the spinal cord. Their activation has been linked
               to the termination of locomotor activity based on broad
               optogenetic manipulations. However, because of the difficulties
               involved in accessing brainstem structures for in vivo cell
               type-specific recordings, V2a neuron function has never been
               directly observed during natural behaviors. Here, we imaged the
               activity of V2a neurons using micro-endoscopy in freely moving
               mice. We find that as many as half of the V2a neurons are
               excited at locomotion arrest and with low reliability. Other V2a
               neurons are inhibited at locomotor arrests and/or activated
               during other behaviors such as locomotion initiation or
               stationary grooming. Our results establish that V2a neurons not
               only drive stops as suggested by bulk optogenetics but also are
               stratified into subpopulations that likely contribute to diverse
               motor patterns.",
  journal   = "Sci Adv",
  publisher = "advances.sciencemag.org",
  volume    =  6,
  number    =  49,
  month     =  dec,
  year      =  2020,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "2375-2548",
  pmid      = "33277252",
  doi       = "10.1126/sciadv.abc6309"
}

@ARTICLE{Ueno2011-tt,
  title     = "Kinematic analyses reveal impaired locomotion following injury
               of the motor cortex in mice",
  author    = "Ueno, Masaki and Yamashita, Toshihide",
  abstract  = "Brain injury in the motor cortex can result in deleterious
               functional deficits of skilled and fine motor functions.
               However, in contrast to humans, the destruction of cortex and
               its descending fibers has been thought not to cause remarkable
               deficits in simple locomotion in quadropedal animals. In the
               present study, we aimed to investigate in detail how lesion of
               the sensorimotor cortex affected locomotion ability in mice
               using the KinemaTracer system, a novel video-based kinematic
               analyzer. We found that traumatic injury to the left
               sensorimotor cortex induced several apparent deficits in the
               movement of contralesional right limbs during treadmill
               locomotion. The step length of right limbs decreased, and the
               speed in the forward direction was abrogated in the swing phase.
               The coordinates and angle of each joint were also changed after
               the injury. Some of the abnormal values in these parameters
               gradually recovered near the control level. The number of
               cFos-expressing neurons following locomotion significantly
               decreased in the right side of the spinal cord in injured mice,
               suggesting a role for cortex and descending fibers in
               locomotion. In contrast, interlimb coordination did not change
               remarkably even after the injury, supporting the notion that the
               basic locomotor pattern was determined by intraspinal neural
               circuits. These results indicate that the motor cortex and its
               descending fibers regulate several aspects of fine limb movement
               during locomotion. Our findings provide practical parameters to
               assess motor deficits and recovery following cortical injury in
               mice.",
  journal   = "Exp. Neurol.",
  publisher = "Elsevier",
  volume    =  230,
  number    =  2,
  pages     = "280--290",
  month     =  aug,
  year      =  2011,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "0014-4886, 1090-2430",
  pmid      = "21619878",
  doi       = "10.1016/j.expneurol.2011.05.006"
}

@ARTICLE{Drew2015-sv,
  title     = "Taking the next step: cortical contributions to the control of
               locomotion",
  author    = "Drew, Trevor and Marigold, Daniel S",
  abstract  = "The planning and execution of both discrete voluntary movements
               and visually guided locomotion depends on the contribution of
               multiple cortical areas. In this review, we discuss recent
               experiments that address the contribution of the posterior
               parietal cortex (PPC) and the motor cortex to the control of
               locomotion. The results from these experiments show that the PPC
               contributes to the planning of locomotion by providing an
               estimate of the position of an animal with respect to objects in
               its path. In contrast, the motor cortex contributes primarily to
               the execution of gait modifications by modulating the activity
               of groups of synergistic muscles active at different times
               during the gait cycle.",
  journal   = "Curr. Opin. Neurobiol.",
  publisher = "Elsevier",
  volume    =  33,
  pages     = "25--33",
  month     =  aug,
  year      =  2015,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "0959-4388, 1873-6882",
  pmid      = "25643847",
  doi       = "10.1016/j.conb.2015.01.011"
}

@ARTICLE{Ruder2016-iv,
  title     = "{Long-Distance} Descending Spinal Neurons Ensure Quadrupedal
               Locomotor Stability",
  author    = "Ruder, Ludwig and Takeoka, Aya and Arber, Silvia",
  abstract  = "Locomotion is an essential animal behavior used for
               translocation. The spinal cord acts as key executing center, but
               how it coordinates many body parts located across distance
               remains poorly understood. Here we employed mouse genetic and
               viral approaches to reveal organizational principles of
               long-projecting spinal circuits and their role in quadrupedal
               locomotion. Using neurotransmitter identity, developmental
               origin, and projection patterns as criteria, we uncover that
               spinal segments controlling forelimbs and hindlimbs are
               bidirectionally connected by symmetrically organized direct
               synaptic pathways that encompass multiple genetically tractable
               neuronal subpopulations. We demonstrate that selective ablation
               of descending spinal neurons linking cervical to lumbar segments
               impairs coherent locomotion, by reducing postural stability and
               speed during exploratory locomotion, as well as perturbing
               interlimb coordination during reinforced high-speed stepping.
               Together, our results implicate a highly organized long-distance
               projection system of spinal origin in the control of postural
               body stabilization and reliability during quadrupedal
               locomotion.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  92,
  number    =  5,
  pages     = "1063--1078",
  month     =  dec,
  year      =  2016,
  keywords  = "genetic identity; interlimb coordination; locomotion; motor
               control; posture; spinal cord;Locomotion",
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "27866798",
  doi       = "10.1016/j.neuron.2016.10.032"
}

@UNPUBLISHED{Dautan2020-lv,
  title    = "Modulation of motor behavior by the mesencephalic locomotor
              region",
  author   = "Dautan, Daniel and Kov{\'a}cs, Adrienn and Bayasgalan,
              Tsogbadrakh and Diaz-Acevedo, Miguel A and Pal, Balazs and
              Mena-Segovia, Juan",
  abstract = "The mesencephalic locomotor region (MLR) serves as an interface
              between higher-order motor systems and lower motor neurons. The
              excitatory module of the MLR is composed of the pedunculopontine
              nucleus (PPN) and the cuneiform nucleus (CnF), and their
              activation has been proposed to elicit different modalities of
              movement, but how the differences in connectivity and
              physiological properties explain their contributions to motor
              activity is not known. Here we report that CnF glutamatergic
              neurons are electrophysiologically homogeneous and have
              short-range axonal projections, whereas PPN glutamatergic neurons
              are heterogeneous and maintain long-range connections, most
              notably with the basal ganglia. Optogenetic activation of CnF
              neurons produced fast-onset, involuntary motor activity mediated
              by short-lasting muscle activation. In contrast, activation of
              PPN neurons produced long-lasting increases in muscle tone that
              reduced motor activity and disrupted gait. Our results thus
              reveal a differential contribution to motor behavior by the
              structures that compose the MLR. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2020.06.25.172296",
  month    =  jun,
  year     =  2020,
  keywords = "Locomotion",
  language = "en",
  doi      = "10.1101/2020.06.25.172296"
}

@ARTICLE{Carvalho2020-pw,
  title    = "A Brainstem Locomotor Circuit Drives the Activity of Speed Cells
              in the Medial Entorhinal Cortex",
  author   = "Carvalho, Miguel M and Tanke, Nouk and Kropff, Emilio and Witter,
              Menno P and Moser, May-Britt and Moser, Edvard I",
  abstract = "Locomotion activates an array of sensory inputs that may help
              build the self-position map of the medial entorhinal cortex
              (MEC). In this map, speed-coding neurons are thought to
              dynamically update representations of the animal's position. A
              possible origin for the entorhinal speed signal is the
              mesencephalic locomotor region (MLR), which is critically
              involved in the activation of locomotor programs. Here, we
              describe, in rats, a circuit connecting the pedunculopontine
              tegmental nucleus (PPN) of the MLR to the MEC via the horizontal
              limb of the diagonal band of Broca (HDB). At each level of this
              pathway, locomotion speed is linearly encoded in neuronal firing
              rates. Optogenetic activation of PPN cells drives locomotion and
              modulates activity of speed-modulated neurons in HDB and MEC. Our
              results provide evidence for a pathway by which brainstem speed
              signals can reach cortical structures implicated in navigation
              and higher-order dynamic representations of space.",
  journal  = "Cell Rep.",
  volume   =  32,
  number   =  10,
  pages    = "108123",
  month    =  sep,
  year     =  2020,
  keywords = "diagonal band of Broca; medial entorhinal cortex; mesencephalic
              locomotor region; pedunculopontine tegmental nucleus; speed
              cells;Locomotion",
  language = "en",
  issn     = "2211-1247",
  pmid     = "32905779",
  doi      = "10.1016/j.celrep.2020.108123",
  pmc      = "PMC7487772"
}

@UNPUBLISHED{Roseberry2019-iz,
  title    = "Locomotor suppression by a monosynaptic amygdala to brainstem
              circuit",
  author   = "Roseberry, Thomas K and Lalive, Arnaud L and Margolin, Benjamin D
              and Kreitzer, Anatol C",
  abstract = "Abstract The control of locomotion is fundamental to vertebrate
              animal survival. Defensive situations require an animal to
              rapidly decide whether to run away or suppress locomotor activity
              to avoid detection. While much of the neural circuitry involved
              in defensive action selection has been elucidated, top-down
              modulation of brainstem locomotor circuitry remains unclear. Here
              we provide evidence for the existence and functionality of a
              monosynaptic connection from the central amygdala (CeA) to the
              mesencephalic locomotor region (MLR) that inhibits locomotion in
              unconditioned and conditioned defensive behavior in mice. We show
              that locomotion stimulated by airpuff coincides with increased
              activity of MLR glutamatergic neurons. Using retrograde tracing
              and ex vivo electrophysiology, we find that the CeA makes a
              monosynaptic connection with the MLR. In the open field, in vivo
              stimulation of this projection suppressed spontaneous locomotion,
              whereas inhibition of this projection had no effect. However,
              inhibiting CeA terminals within the MLR increased both neural
              activity and locomotor responses to airpuff. Finally, using a
              conditioned avoidance paradigm known to activate CeA neurons, we
              find that inhibition of the CeA projection increased successful
              escape, whereas activating the projection reduced escape.
              Together these results provide evidence for a new circuit
              substrate influencing locomotion and defensive behaviors.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "724252",
  month    =  aug,
  year     =  2019,
  keywords = "Locomotion",
  language = "en",
  doi      = "10.1101/724252"
}

@ARTICLE{Inagaki_undated-th,
  title  = "A midbrain - thalamus - cortex circuit reorganizes cortical
            dynamics to initiate planned movement",
  author = "Inagaki, Hidehiko K and Chen, Susu and Ridder, Margreet C and Sah,
            Pankaj and Li, Nuo and Yang, Zidan and Hasanbegovic, Hana and Gao,
            Zhenyu and Gerfen, Charles R and Svoboda, Karel",
  doi    = "10.1101/2020.12.16.423127"
}

@ARTICLE{Fukuoka2015-ks,
  title    = "A simple rule for quadrupedal gait generation determined by leg
              loading feedback: a modeling study",
  author   = "Fukuoka, Yasuhiro and Habu, Yasushi and Fukui, Takahiro",
  abstract = "We discovered a specific rule for generating typical quadrupedal
              gaits (the order of the movement of four legs) through a
              simulated quadrupedal locomotion, in which unprogrammed gaits
              (diagonal/lateral sequence walks, left/right-lead canters, and
              left/right-lead transverse gallops) spontaneously emerged because
              of leg loading feedbacks to the CPGs hard-wired to produce a
              default trot. Additionally, all gaits transitioned according to
              speed, as seen in animals. We have therefore hypothesized that
              various gaits derive from a trot because of posture control
              through leg loading feedback. The body tilt on the two support
              legs of each diagonal pair during trotting was classified into
              three types (level, tilted up, or tilted down) according to
              speed. The load difference between the two legs led to the phase
              difference between their CPGs via the loading feedbacks,
              resulting in nine gaits (3(2): three tilts to the power of two
              diagonal pairs) including the aforementioned.",
  journal  = "Sci. Rep.",
  volume   =  5,
  pages    = "8169",
  month    =  feb,
  year     =  2015,
  keywords = "Locomotion",
  language = "en",
  issn     = "2045-2322",
  pmid     = "25639661",
  doi      = "10.1038/srep08169",
  pmc      = "PMC4313093"
}

@ARTICLE{McNaughton1994-hv,
  title    = "Cortical representation of motion during unrestrained spatial
              navigation in the rat",
  author   = "McNaughton, B L and Mizumori, S J and Barnes, C A and Leonard, B
              J and Marquis, M and Green, E J",
  abstract = "Neural activity related to unrestrained movement through space
              was studied in rat sensorimotor and posterior parietal cortices
              during performance of an eight-arm, radial maze task. Nearly half
              of the cells exhibited movement-related activity that
              discriminated among three basic modes of locomotion: left turns,
              right turns, and forward motion. Correlates ranged from strong
              excitation (relative to the still condition) to strong
              inhibition, and were distributed among the movement modes in a
              variety of different ways. For example, cells that discriminated
              between clockwise and counterclockwise turns did so with either
              antagonistic responses or simple excitation or inhibition. Others
              showed either excitation or inhibition relative to both turning
              and the still condition, and hence were selective for forward
              motion. Many cells exhibited somatosensory responsiveness;
              however, in agreement with findings of others, motion correlates
              could rarely be sensibly explained by the somatosensory response.
              Moreover, movement correlates sometimes varied considerably with
              spatial context. Some cells exhibited more complex motion
              correlates, such as an apparent dependence on the nature of the
              preceding movement. Irrespective of the specific sensory or motor
              determinants of cell activity, which varied considerably among
              cells, the posterior neocortex of the rat appears to generate a
              robust and redundant internal representation of body motion
              through space. Such a representation could be useful in
              constructing ``cognitive maps'' of the environment.",
  journal  = "Cereb. Cortex",
  volume   =  4,
  number   =  1,
  pages    = "27--39",
  month    =  jan,
  year     =  1994,
  keywords = "navigation",
  language = "en",
  issn     = "1047-3211",
  pmid     = "8180489",
  doi      = "10.1093/cercor/4.1.27"
}

@ARTICLE{Li2015-tj,
  title    = "A motor cortex circuit for motor planning and movement",
  author   = "Li, Nuo and Chen, Tsai-Wen and Guo, Zengcai V and Gerfen, Charles
              R and Svoboda, Karel",
  abstract = "Activity in motor cortex predicts specific movements seconds
              before they occur, but how this preparatory activity relates to
              upcoming movements is obscure. We dissected the conversion of
              preparatory activity to movement within a structured motor cortex
              circuit. An anterior lateral region of the mouse cortex (a
              possible homologue of premotor cortex in primates) contains equal
              proportions of intermingled neurons predicting ipsi- or
              contralateral movements, yet unilateral inactivation of this
              cortical region during movement planning disrupts contralateral
              movements. Using cell-type-specific electrophysiology, cellular
              imaging and optogenetic perturbation, we show that layer 5
              neurons projecting within the cortex have unbiased laterality.
              Activity with a contralateral population bias arises specifically
              in layer 5 neurons projecting to the brainstem, and only late
              during movement planning. These results reveal the transformation
              of distributed preparatory activity into movement commands within
              hierarchically organized cortical circuits.",
  journal  = "Nature",
  volume   =  519,
  number   =  7541,
  pages    = "51--56",
  month    =  mar,
  year     =  2015,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "25731172",
  doi      = "10.1038/nature14178"
}

@ARTICLE{Holmes2006-fn,
  title     = "The Dynamics of Legged Locomotion: Models, Analyses, and
               Challenges",
  author    = "Holmes, Philip and Full, Robert J and Koditschek, Dan and
               Guckenheimer, John",
  abstract  = "Cheetahs and beetles run, dolphins and salmon swim, and bees and
               birds fly with grace and economy surpassing our technology.
               Evolution has shaped the breathtaking abilities of animals,
               leaving us the challenge of reconstructing their targets of
               control and mechanisms of dexterity. In this review we explore a
               corner of this fascinating world. We describe mathematical
               models for legged animal locomotion, focusing on rapidly running
               insects and highlighting past achievements and challenges that
               remain. Newtonian body--limb dynamics are most naturally
               formulated as piecewise-holonomic rigid body mechanical systems,
               whose constraints change as legs touch down or lift off. Central
               pattern generators and proprioceptive sensing require models of
               spiking neurons and simplified phase oscillator descriptions of
               ensembles of them. A full neuromechanical model of a running
               animal requires integration of these elements, along with
               proprioceptive feedback and models of goal-oriented sensing,
               planning, and learning. We outline relevant background material
               from biomechanics and neurobiology, explain key properties of
               the hybrid dynamical systems that underlie legged locomotion
               models, and provide numerous examples of such models, from the
               simplest, completely soluble ``peg-leg walker'' to complex
               neuromuscular subsystems that are yet to be assembled into
               models of behaving animals. This final integration in a
               tractable and illuminating model is an outstanding challenge.",
  journal   = "SIAM Rev.",
  publisher = "Society for Industrial and Applied Mathematics",
  volume    =  48,
  number    =  2,
  pages     = "207--304",
  month     =  jan,
  year      =  2006,
  keywords  = "Locomotion",
  issn      = "0036-1445",
  doi       = "10.1137/S0036144504445133"
}

@ARTICLE{Cho2001-nw,
  title     = "Head direction, place, and movement correlates for cells in the
               rat retrosplenial cortex",
  author    = "Cho, J and Sharp, P E",
  abstract  = "The retrosplenial cortex is strongly connected with brain
               regions involved in spatial signaling. To test whether it also
               codes space, single cells were recorded while rats navigated in
               an open field. As in earlier work (L. L. Chen, L. H. Lin, C. A.
               Barnes, \& B. L. McNaughton, 1994; L. L. Chen, L. H. Lin, E. J.
               Green, C. A. Barnes, \& B. L. McNaughton, 1994), the authors
               found head direction cells with properties similar to those in
               other areas. These cells were slightly anticipatory. Another
               cell type fired to particular combinations of location,
               direction, and movement, which suggested that they may fire
               whenever the rat approaches a particular location, using a
               particular locomotor behavior. The remaining cells could not be
               clearly categorized but also showed a significant correlation
               with one or more of the spatial-movement variables examined. The
               fact that the retrosplenial cortex contains spatial and
               movement-related signals and is connected with the motor cortex
               suggests that it may play a role in path integration or
               navigational motor planning.",
  journal   = "Behav. Neurosci.",
  publisher = "psycnet.apa.org",
  volume    =  115,
  number    =  1,
  pages     = "3--25",
  month     =  feb,
  year      =  2001,
  keywords  = "navigation",
  language  = "en",
  issn      = "0735-7044",
  pmid      = "11256450",
  doi       = "10.1037/0735-7044.115.1.3"
}

@ARTICLE{Calton2009-hj,
  title    = "Where am {I} and how will {I} get there from here? A role for
              posterior parietal cortex in the integration of spatial
              information and route planning",
  author   = "Calton, Jeffrey L and Taube, Jeffrey S",
  abstract = "The ability of an organism to accurately navigate from one place
              to another requires integration of multiple spatial constructs,
              including the determination of one's position and direction in
              space relative to allocentric landmarks, movement velocity, and
              the perceived location of the goal of the movement. In this
              review, we propose that while limbic areas are important for the
              sense of spatial orientation, the posterior parietal cortex is
              responsible for relating this sense with the location of a
              navigational goal and in formulating a plan to attain it. Hence,
              the posterior parietal cortex is important for the computation of
              the correct trajectory or route to be followed while navigating.
              Prefrontal and motor areas are subsequently responsible for
              executing the planned movement. Using this theory, we are able to
              bridge the gap between the rodent and primate literatures by
              suggesting that the allocentric role of the rodent PPC is largely
              analogous to the egocentric role typically emphasized in
              primates, that is, the integration of spatial orientation with
              potential goals in the planning of goal-directed movements.",
  journal  = "Neurobiol. Learn. Mem.",
  volume   =  91,
  number   =  2,
  pages    = "186--196",
  month    =  feb,
  year     =  2009,
  keywords = "navigation",
  language = "en",
  issn     = "1074-7427, 1095-9564",
  pmid     = "18929674",
  doi      = "10.1016/j.nlm.2008.09.015",
  pmc      = "PMC2666283"
}

@ARTICLE{Ebbesen2017-cm,
  title    = "Motor cortex - to act or not to act?",
  author   = "Ebbesen, Christian Laut and Brecht, Michael",
  abstract = "The motor cortex is a large frontal structure in the cerebral
              cortex of eutherian mammals. A vast array of evidence implicates
              the motor cortex in the volitional control of motor output, but
              how does the motor cortex exert this 'control'? Historically,
              ideas regarding motor cortex function have been shaped by the
              discovery of cortical 'motor maps' - that is, ordered
              representations of stimulation-evoked movements in anaesthetized
              animals. Volitional control, however, entails the initiation of
              movements and the ability to suppress undesired movements. In
              this article, we highlight classic and recent findings that
              emphasize that motor cortex neurons have a role in both
              processes.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  18,
  number   =  11,
  pages    = "694--705",
  month    =  oct,
  year     =  2017,
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "29042690",
  doi      = "10.1038/nrn.2017.119"
}

@ARTICLE{Schiemann2015-th,
  title     = "Cellular mechanisms underlying behavioral state-dependent
               bidirectional modulation of motor cortex output",
  author    = "Schiemann, Julia and Puggioni, Paolo and Dacre, Joshua and
               Pelko, Miha and Domanski, Aleksander and van Rossum, Mark C W
               and Duguid, Ian",
  abstract  = "Neuronal activity in primary motor cortex (M1) correlates with
               behavioral state, but the cellular mechanisms underpinning
               behavioral state-dependent modulation of M1 output remain
               largely unresolved. Here, we performed in vivo patch-clamp
               recordings from layer 5B (L5B) pyramidal neurons in awake mice
               during quiet wakefulness and self-paced, voluntary movement. We
               show that L5B output neurons display bidirectional (i.e.,
               enhanced or suppressed) firing rate changes during movement,
               mediated via two opposing subthreshold mechanisms: (1) a global
               decrease in membrane potential variability that reduced L5B
               firing rates (L5Bsuppressed neurons), and (2) a coincident
               noradrenaline-mediated increase in excitatory drive to a
               subpopulation of L5B neurons (L5Benhanced neurons) that elevated
               firing rates. Blocking noradrenergic receptors in forelimb M1
               abolished the bidirectional modulation of M1 output during
               movement and selectively impaired contralateral forelimb motor
               coordination. Together, our results provide a mechanism for how
               noradrenergic neuromodulation and network-driven input changes
               bidirectionally modulate M1 output during motor behavior.",
  journal   = "Cell Rep.",
  publisher = "Elsevier",
  volume    =  11,
  number    =  8,
  pages     = "1319--1330",
  month     =  may,
  year      =  2015,
  language  = "en",
  issn      = "2211-1247",
  pmid      = "25981037",
  doi       = "10.1016/j.celrep.2015.04.042",
  pmc       = "PMC4451462"
}

@ARTICLE{Magno2019-qz,
  title    = "Optogenetic Stimulation of the {M2} Cortex Reverts Motor
              Dysfunction in a Mouse Model of Parkinson's Disease",
  author   = "Magno, Luiz Alexandre Viana and Tenza-Ferrer, Helia and
              Collodetti, M{\'e}lcar and Aguiar, Matheus Felipe Guimar{\~a}es
              and Rodrigues, Ana Paula Carneiro and da Silva, Rodrigo Souza and
              Silva, Joice do Prado and Nicolau, Nycolle Ferreira and Rosa,
              Daniela Valad{\~a}o Freitas and Birbrair, Alexander and Miranda,
              D{\'e}bora Marques and Romano-Silva, Marco Aur{\'e}lio",
  abstract = "Neuromodulation of deep brain structures (deep brain stimulation)
              is the current surgical procedure for treatment of Parkinson's
              disease (PD). Less studied is the stimulation of cortical motor
              areas to treat PD symptoms, although also known to alleviate
              motor disturbances in PD. We were able to show that optogenetic
              activation of secondary (M2) motor cortex improves motor
              functions in dopamine-depleted male mice. The stimulated M2
              cortex harbors glutamatergic pyramidal neurons that project to
              subcortical structures, critically involved in motor control, and
              makes synaptic contacts with dopaminergic neurons. Strikingly,
              optogenetic activation of M2 neurons or axons into the
              dorsomedial striatum increases striatal levels of dopamine and
              evokes locomotor activity. We found that dopamine
              neurotransmission sensitizes the locomotor behavior elicited by
              activation of M2 neurons. Furthermore, combination of intranigral
              infusion of glutamatergic antagonists and circuit specific
              optogenetic stimulation revealed that behavioral response
              depended on the activity of M2 neurons projecting to SNc.
              Interestingly, repeated M2 stimulation combined with l-DOPA
              treatment produced an unanticipated improvement in working memory
              performance, which was absent in control mice under l-DOPA
              treatment only. Therefore, the M2-basal ganglia circuit is
              critical for the assembly of the motor and cognitive function,
              and this study demonstrates a therapeutic mechanism for cortical
              stimulation in PD that involves recruitment of long-range
              glutamatergic projection neurons.SIGNIFICANCE STATEMENT Some
              patients with Parkinson's disease are offered treatment through
              surgery, which consists of delivering electrical current to
              regions deep within the brain. This study shows that stimulation
              of an area located on the brain surface, known as the secondary
              motor cortex, can also reverse movement disorders in mice.
              Authors have used a brain stimulation technique called
              optogenetics, which allowed targeting a specific type of surface
              neuron that communicates with the deep part of the brain involved
              in movement control. The study also shows that a combination of
              this stimulation with drug treatment might be useful to treat
              memory impairment, a kind of cognitive problem in Parkinson's
              disease.",
  journal  = "J. Neurosci.",
  volume   =  39,
  number   =  17,
  pages    = "3234--3248",
  month    =  apr,
  year     =  2019,
  keywords = "Parkinson's disorder; brain stimulation; cognition; movement;
              optogenetics; prefrontal cortex;Locomotion",
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "30782975",
  doi      = "10.1523/JNEUROSCI.2277-18.2019",
  pmc      = "PMC6788829"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Gradinaru2007-qv,
  title     = "Targeting and readout strategies for fast optical neural control
               in vitro and in vivo",
  author    = "Gradinaru, Viviana and Thompson, Kimberly R and Zhang, Feng and
               Mogri, Murtaza and Kay, Kenneth and Schneider, M Bret and
               Deisseroth, Karl",
  abstract  = "Major obstacles faced by neuroscientists in attempting to
               unravel the complexity of brain function include both the
               heterogeneity of brain tissue (with a multitude of cell types
               present in vivo) and the high speed of brain information
               processing (with behaviorally relevant millisecondscale
               electrical activity patterns). To address different aspects of
               these technical constraints, genetically targetable neural
               modulation tools have been developed by a number of groups
               (Zemelman et al., 2002; Banghart et al., 2004; Karpova et al.,
               2005; Lima …",
  journal   = "J. Neurosci.",
  publisher = "Soc Neuroscience",
  volume    =  27,
  number    =  52,
  pages     = "14231--14238",
  month     =  dec,
  year      =  2007,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "0270-6474, 1529-2401",
  pmid      = "18160630",
  doi       = "10.1523/JNEUROSCI.3578-07.2007",
  pmc       = "PMC6673457"
}

@ARTICLE{Jeong2016-dq,
  title    = "Comparative three-dimensional connectome map of motor cortical
              projections in the mouse brain",
  author   = "Jeong, Minju and Kim, Yongsoo and Kim, Jeongjin and Ferrante,
              Daniel D and Mitra, Partha P and Osten, Pavel and Kim, Daesoo",
  abstract = "The motor cortex orchestrates simple to complex motor behaviors
              through its output projections to target areas. The primary (MOp)
              and secondary (MOs) motor cortices are known to produce specific
              output projections that are targeted to both similar and
              different target areas. These projections are further divided
              into layer 5 and 6 neuronal outputs, thereby producing four
              cortical outputs that may target other areas in a combinatorial
              manner. However, the precise network structure that integrates
              these four projections remains poorly understood. Here, we
              constructed a whole-brain, three-dimensional (3D) map showing the
              tract pathways and targeting locations of these four motor
              cortical outputs in mice. Remarkably, these motor cortical
              projections showed unique and separate tract pathways despite
              targeting similar areas. Within target areas, various
              combinations of these four projections were defined based on
              specific 3D spatial patterns, reflecting anterior-posterior,
              dorsal-ventral, and core-capsular relationships. This 3D
              topographic map ultimately provides evidence for the relevance of
              comparative connectomics: motor cortical projections known to be
              convergent are actually segregated in many target areas with
              unique targeting patterns, a finding that has anatomical value
              for revealing functional subdomains that have not been classified
              by conventional methods.",
  journal  = "Sci. Rep.",
  volume   =  6,
  pages    = "20072",
  month    =  feb,
  year     =  2016,
  language = "en",
  issn     = "2045-2322",
  pmid     = "26830143",
  doi      = "10.1038/srep20072",
  pmc      = "PMC4735720"
}

@ARTICLE{Erlich2011-rn,
  title     = "A cortical substrate for memory-guided orienting in the rat",
  author    = "Erlich, Jeffrey C and Bialek, Max and Brody, Carlos D",
  abstract  = "Anatomical, stimulation, and lesion data have suggested a
               homology between the rat frontal orienting fields (FOF)
               (centered at +2 AP, $\pm$1.3 ML mm from Bregma) and primate
               frontal cortices such as the frontal or supplementary eye
               fields. We investigated the functional role of the FOF using
               rats trained to perform a memory-guided orienting task, in which
               there was a delay period between the end of a sensory stimulus
               instructing orienting direction and the time of the allowed
               motor response. Unilateral inactivation of the FOF resulted in
               impaired contralateral responses. Extracellular recordings of
               single units revealed that 37\% of FOF neurons had delay period
               firing rates that predicted the direction of the rats' later
               orienting motion. Our data provide the first
               electrophysiological and pharmacological evidence supporting the
               existence in the rat, as in the primate, of a frontal cortical
               area involved in the preparation and/or planning of orienting
               responses.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  72,
  number    =  2,
  pages     = "330--343",
  month     =  oct,
  year      =  2011,
  keywords  = "navigation",
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "22017991",
  doi       = "10.1016/j.neuron.2011.07.010",
  pmc       = "PMC3212026"
}

@ARTICLE{Gremel2013-im,
  title     = "Premotor cortex is critical for goal-directed actions",
  author    = "Gremel, Christina M and Costa, Rui M",
  abstract  = "Shifting between motor plans is often necessary for adaptive
               behavior. When faced with changing consequences of one's
               actions, it is often imperative to switch from automatic actions
               to deliberative and controlled actions. The pre-supplementary
               motor area (pre-SMA) in primates, akin to the premotor cortex
               (M2) in mice, has been implicated in motor learning and
               planning, and action switching. We hypothesized that M2 would be
               differentially involved in goal-directed actions, which are
               controlled by their consequences vs. habits, which are more
               dependent on their past reinforcement history and less on their
               consequences. To investigate this, we performed M2 lesions in
               mice and then concurrently trained them to press the same lever
               for the same food reward using two different schedules of
               reinforcement that differentially bias towards the use of
               goal-directed versus habitual action strategies. We then probed
               whether actions were dependent on their expected consequence
               through outcome revaluation testing. We uncovered that M2
               lesions did not affect the acquisition of lever-pressing.
               However, in mice with M2 lesions, lever-pressing was insensitive
               to changes in expected outcome value following goal-directed
               training. However, habitual actions were intact. We confirmed a
               role for M2 in goal-directed but not habitual actions in
               separate groups of mice trained on the individual schedules
               biasing towards goal-directed versus habitual actions. These
               data indicate that M2 is critical for actions to be updated
               based on their consequences, and suggest that habitual action
               strategies may not require processing by M2 and the updating of
               motor plans.",
  journal   = "Front. Comput. Neurosci.",
  publisher = "frontiersin.org",
  volume    =  7,
  pages     = "110",
  month     =  aug,
  year      =  2013,
  keywords  = "action selection; goal-directed actions; habitual actions;
               premotor cortex; value-based decision making",
  language  = "en",
  issn      = "1662-5188",
  pmid      = "23964233",
  doi       = "10.3389/fncom.2013.00110",
  pmc       = "PMC3740264"
}

@ARTICLE{Murakami2014-lh,
  title     = "Neural antecedents of self-initiated actions in secondary motor
               cortex",
  author    = "Murakami, Masayoshi and Vicente, M In{\^e}s and Costa, Gil M and
               Mainen, Zachary F",
  abstract  = "The neural origins of spontaneous or self-initiated actions are
               not well understood and their interpretation is controversial.
               To address these issues, we used a task in which rats decide
               when to abort waiting for a delayed tone. We recorded neurons in
               the secondary motor cortex (M2) and interpreted our findings in
               light of an integration-to-bound decision model. A first
               population of M2 neurons ramped to a constant threshold at rates
               proportional to waiting time, strongly resembling integrator
               output. A second population, which we propose provide input to
               the integrator, fired in sequences and showed trial-to-trial
               rate fluctuations correlated with waiting times. An integration
               model fit to these data also quantitatively predicted the
               observed inter-neuronal correlations. Together, these results
               reinforce the generality of the integration-to-bound model of
               decision-making. These models identify the initial intention to
               act as the moment of threshold crossing while explaining how
               antecedent subthreshold neural activity can influence an action
               without implying a decision.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  17,
  number    =  11,
  pages     = "1574--1582",
  month     =  nov,
  year      =  2014,
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "25262496",
  doi       = "10.1038/nn.3826"
}

@UNPUBLISHED{Okazawa2021-qd,
  title    = "The geometry of the representation of decision variable and
              stimulus difficulty in the parietal cortex",
  author   = "Okazawa, Gouki and Hatch, Christina E and Mancoo, Allan and
              Machens, Christian K and Kiani, Roozbeh",
  abstract = "Lateral intraparietal (LIP) neurons represent formation of
              perceptual decisions involving eye movements. In circuit models
              for these decisions, neural ensembles that encode actions compete
              to form decisions. Consequently, decision variables (DVs) are
              represented as partially potentiated action plans, where
              ensembles increase their average responses for stronger evidence
              supporting their preferred actions. As another consequence, DV
              representation and readout are implemented similarly for
              decisions with identical competing actions, irrespective of input
              and task context differences. Here, we challenge those core
              principles using a novel face-discrimination task, where LIP
              firing rates decrease with supporting evidence, contrary to
              conventional motion-discrimination tasks. These opposite response
              patterns arise from similar mechanisms in which decisions form
              along curved population-response manifolds misaligned with action
              representations. These manifolds rotate in state space based on
              task context, necessitating distinct readouts. We show similar
              manifolds in lateral and medial prefrontal cortices, suggesting a
              ubiquitous representational geometry across decision-making
              circuits. \#\#\# Competing Interest Statement The authors have
              declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.01.04.425244",
  month    =  jan,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.01.04.425244"
}

@ARTICLE{Melzer2017-ek,
  title     = "Distinct Corticostriatal {GABAergic} Neurons Modulate Striatal
               Output Neurons and Motor Activity",
  author    = "Melzer, Sarah and Gil, Mariana and Koser, David E and Michael,
               Magdalena and Huang, Kee Wui and Monyer, Hannah",
  abstract  = "The motor cortico-basal ganglion loop is critical for motor
               planning, execution, and learning. Balanced excitation and
               inhibition in this loop is crucial for proper motor output.
               Excitatory neurons have been thought to be the only source of
               motor cortical input to the striatum. Here, we identify
               long-range projecting GABAergic neurons in the primary (M1) and
               secondary (M2) motor cortex that target the dorsal striatum.
               This population of projecting GABAergic neurons comprises both
               somatostatin-positive (SOM+) and parvalbumin-positive (PV+)
               neurons that target direct and indirect pathway striatal output
               neurons as well as cholinergic interneurons differentially.
               Notably, optogenetic stimulation of M1 PV+ and M2 SOM+
               projecting neurons reduced locomotion, whereas stimulation of M1
               SOM+ projecting neurons enhanced locomotion. Thus,
               corticostriatal GABAergic projections modulate striatal output
               and motor activity.",
  journal   = "Cell Rep.",
  publisher = "Elsevier",
  volume    =  19,
  number    =  5,
  pages     = "1045--1055",
  month     =  may,
  year      =  2017,
  keywords  = "GABA; locomotion; long-range; motor cortex; optogenetics;
               parvalbumin; somatostatin; striatum;Locomotion",
  language  = "en",
  issn      = "2211-1247",
  pmid      = "28467898",
  doi       = "10.1016/j.celrep.2017.04.024",
  pmc       = "PMC5437725"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Mizumori2005-mq,
  title     = "Head direction codes in hippocampal afferent and efferent
               systems: what functions do they serve",
  author    = "Mizumori, Sheri J Y and Puryear, Corey B and Gill, Kathryn M and
               Guazzelli, Alex",
  abstract  = "The discovery of head direction cells in many limbic and
               limbic-afferent structures could lead one to suggest that the
               limbic system is specialized for spatial analysis, and in
               particular the processing of directional orientation.
               Considering this hypothesis, it becomes important to know
               whether head direction codes are unique to the limbic system.
               Previous chapters provide convincing evidence that the mechanism
               for the generation of head direction signals involves sequential
               processing through the tegmentum, mammillary nucleus, anterior
               dorsal …",
  journal   = "Head direction cells and the neural mechanisms of spatial
               orientation",
  publisher = "books.google.com",
  pages     = "203--220",
  year      =  2005
}

@ARTICLE{Bi2020-vh,
  title    = "Understanding the computation of time using neural network models",
  author   = "Bi, Zedong and Zhou, Changsong",
  abstract = "To maximize future rewards in this ever-changing world, animals
              must be able to discover the temporal structure of stimuli and
              then anticipate or act correctly at the right time. How do
              animals perceive, maintain, and use time intervals ranging from
              hundreds of milliseconds to multiseconds in working memory? How
              is temporal information processed concurrently with spatial
              information and decision making? Why are there strong neuronal
              temporal signals in tasks in which temporal information is not
              required? A systematic understanding of the underlying neural
              mechanisms is still lacking. Here, we addressed these problems
              using supervised training of recurrent neural network models. We
              revealed that neural networks perceive elapsed time through state
              evolution along stereotypical trajectory, maintain time intervals
              in working memory in the monotonic increase or decrease of the
              firing rates of interval-tuned neurons, and compare or produce
              time intervals by scaling state evolution speed. Temporal and
              nontemporal information is coded in subspaces orthogonal with
              each other, and the state trajectories with time at different
              nontemporal information are quasiparallel and isomorphic. Such
              coding geometry facilitates the decoding generalizability of
              temporal and nontemporal information across each other. The
              network structure exhibits multiple feedforward sequences that
              mutually excite or inhibit depending on whether their preferences
              of nontemporal information are similar or not. We identified four
              factors that facilitate strong temporal signals in nontiming
              tasks, including the anticipation of coming events. Our work
              discloses fundamental computational principles of temporal
              processing, and it is supported by and gives predictions to a
              number of experimental phenomena.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  117,
  number   =  19,
  pages    = "10530--10540",
  month    =  may,
  year     =  2020,
  keywords = "interval timing; neural network model; population coding;RNN",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "32341153",
  doi      = "10.1073/pnas.1921609117",
  pmc      = "PMC7229760"
}

@UNPUBLISHED{Weissenberger2019-jl,
  title    = "Decoding mouse behavior to explain single-trial decisions and
              their relationship with neural activity",
  author   = "Weissenberger, Yves and King, Andrew J and Dahmen, Johannes C",
  abstract = "Abstract Models of behavior typically focus on sparse
              measurements of motor output over long timescales, limiting their
              ability to explain momentary decisions or neural activity. We
              developed data-driven models relating experimental variables to
              videos of behavior. Applied to mouse operant behavior, they
              revealed behavioral encoding of cognitive variables. Model-based
              decoding of videos yielded an accurate account of single-trial
              behavior in terms of the relationship between cognition, motor
              output and cortical activity.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "567479",
  month    =  mar,
  year     =  2019,
  language = "en",
  doi      = "10.1101/567479"
}

@ARTICLE{Hok2005-sy,
  title    = "Coding for spatial goals in the prelimbic/infralimbic area of the
              rat frontal cortex",
  author   = "Hok, V and Save, E and Lenck-Santini, P P and Poucet, B",
  abstract = "Finding one's way in space requires a distributed neural network
              to support accurate spatial navigation. In the rat, this network
              likely includes the hippocampus and its place cells. Although
              such cells allow the organism to locate itself in the
              environment, an additional mechanism is required to specify the
              animal's goal. Here, we show that firing activity of neurons in
              medial prefrontal cortex (mPFC) reflects the motivational
              salience of places. We recorded mPFC neurons from rats performing
              a place navigation task, and found that a substantial proportion
              of cells in the prelimbic/infralimbic area had place fields. A
              much smaller proportion of cells with such properties was found
              in the dorsal anterior cingulate area. Furthermore, the
              distribution of place fields in prelimbic/infralimbic cells was
              not homogeneous: goal locations were overrepresented. Because
              such locations were spatially dissociated from rewards, we
              suggest that mPFC neurons might be responsible for encoding the
              rat's goals, a process necessary for path planning.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  102,
  number   =  12,
  pages    = "4602--4607",
  month    =  mar,
  year     =  2005,
  keywords = "navigation",
  language = "en",
  issn     = "0027-8424",
  pmid     = "15761059",
  doi      = "10.1073/pnas.0407332102",
  pmc      = "PMC555486"
}

@ARTICLE{Deliagina2019-nj,
  title    = "Nervous mechanisms of locomotion in different directions",
  author   = "Deliagina, Tatiana G and Musienko, Pavel E and Zelenin, Pavel V",
  abstract = "Locomotion, that is active propulsive movement of the body in
              space, is a vital motor function. Intensive studies of the main,
              for the majority of living beings, form of locomotion, forward
              locomotion, have revealed essential features of the organization
              and operation of underlying neural mechanisms. However, animals
              and humans are capable to locomote not only forward but also in
              other directions in relation to the body axis, e.g. backward,
              sideways, etc. Single steps in different directions are also used
              for postural corrections during locomotion and during standing.
              Recent studies of mechanisms underlying control of locomotion in
              different directions have greatly expanded our knowledge about
              locomotor system and can contribute to improvement of
              rehabilitation strategies aimed at restoration of locomotion and
              balance control in patients. This review outlines recent advances
              in the studies of locomotion in different directions in lower and
              higher vertebrates, with special attention given to the neuronal
              locomotor mechanisms.",
  journal  = "Curr Opin Physiol",
  volume   =  8,
  pages    = "7--13",
  month    =  apr,
  year     =  2019,
  keywords = "backward; reflexes; spinal networks; supraspinal control;
              swimming; walking;Locomotion",
  language = "en",
  issn     = "2468-8673",
  pmid     = "31468024",
  doi      = "10.1016/j.cophys.2018.11.010",
  pmc      = "PMC6715308"
}

@ARTICLE{Saitoh2007-yr,
  title    = "Tectal control of locomotion, steering, and eye movements in
              lamprey",
  author   = "Saitoh, Kazuya and M{\'e}nard, Ariane and Grillner, Sten",
  abstract = "The intrinsic function of the brain stem-spinal cord networks
              eliciting the locomotor synergy is well described in the
              lamprey-a vertebrate model system. This study addresses the role
              of tectum in integrating eye, body orientation, and locomotor
              movements as in steering and goal-directed behavior. Electrical
              stimuli were applied to different areas within the optic tectum
              in head-restrained semi-intact lampreys (n = 40). Motions of the
              eyes and body were recorded simultaneously (videotaped). Brief
              pulse trains (0.5 s) lateral bending movements of the body
              (orientation movements) were added, and with even longer stimuli
              locomotor movements were initiated. Depending on the tectal area
              stimulated, four characteristic response patterns were observed.
              In a lateral area conjugate horizontal eye movements combined
              with lateral bending movements of the body and locomotor
              movements were elicited, depending on stimulus duration. The
              amplitude of the eye movement and bending movements was site
              specific within this region. In a rostromedial area, bilateral
              downward vertical eye movements occurred. In a caudomedial tectal
              area, large-amplitude undulatory body movements akin to
              struggling behavior were elicited, combined with large-amplitude
              eye movements that were antiphasic to the body movements. The
              alternating eye movements were not dependent on vestibuloocular
              reflexes. Finally, in a caudolateral area locomotor movements
              without eye or bending movements could be elicited. These results
              show that tectum can provide integrated motor responses of eye,
              body orientation, and locomotion of the type that would be
              required in goal-directed locomotion.",
  journal  = "J. Neurophysiol.",
  volume   =  97,
  number   =  4,
  pages    = "3093--3108",
  month    =  apr,
  year     =  2007,
  keywords = "Locomotion",
  language = "en",
  issn     = "0022-3077",
  pmid     = "17303814",
  doi      = "10.1152/jn.00639.2006"
}

@ARTICLE{Goddard2018-or,
  title    = "Interpreting the dimensions of neural feature representations
              revealed by dimensionality reduction",
  author   = "Goddard, Erin and Klein, Colin and Solomon, Samuel G and
              Hogendoorn, Hinze and Carlson, Thomas A",
  abstract = "Recent progress in understanding the structure of neural
              representations in the cerebral cortex has centred around the
              application of multivariate classification analyses to
              measurements of brain activity. These analyses have proved a
              sensitive test of whether given brain regions provide information
              about specific perceptual or cognitive processes. An exciting
              extension of this approach is to infer the structure of this
              information, thereby drawing conclusions about the underlying
              neural representational space. These approaches rely on
              exploratory data-driven dimensionality reduction to extract the
              natural dimensions of neural spaces, including natural visual
              object and scene representations, semantic and conceptual
              knowledge, and working memory. However, the efficacy of these
              exploratory methods is unknown, because they have only been
              applied to representations in brain areas for which we have
              little or no secondary knowledge. One of the best-understood
              areas of the cerebral cortex is area MT of primate visual cortex,
              which is known to be important in motion analysis. To assess the
              effectiveness of dimensionality reduction for recovering neural
              representational space we applied several dimensionality
              reduction methods to multielectrode measurements of spiking
              activity obtained from area MT of marmoset monkeys, made while
              systematically varying the motion direction and speed of moving
              stimuli. Despite robust tuning at individual electrodes, and high
              classifier performance, dimensionality reduction rarely revealed
              dimensions for direction and speed. We use this example to
              illustrate important limitations of these analyses, and suggest a
              framework for how to best apply such methods to data where the
              structure of the neural representation is unknown.",
  journal  = "Neuroimage",
  volume   =  180,
  number   = "Pt A",
  pages    = "41--67",
  month    =  oct,
  year     =  2018,
  keywords = "Exploratory analysis; Multi-dimensional scaling (MDS);
              Multivariate pattern analysis; Principal component analysis (PCA)",
  language = "en",
  issn     = "1053-8119, 1095-9572",
  pmid     = "28663068",
  doi      = "10.1016/j.neuroimage.2017.06.068"
}

@ARTICLE{Green2019-kn,
  title     = "A neural heading estimate is compared with an internal goal to
               guide oriented navigation",
  author    = "Green, Jonathan and Vijayan, Vikram and Mussells Pires, Peter
               and Adachi, Atsuko and Maimon, Gaby",
  abstract  = "Goal-directed navigation is thought to rely on the activity of
               head-direction cells, but how this activity guides
               moment-to-moment actions remains poorly understood. Here we
               characterize how heading neurons in the Drosophila central
               complex guide moment-to-moment navigational behavior. We
               establish an innate, heading-neuron-dependent, tethered
               navigational behavior where walking flies maintain a straight
               trajectory along a specific angular bearing for hundreds of body
               lengths. While flies perform this task, we use chemogenetics to
               transiently rotate their neural heading estimate and observe
               that the flies slow down and turn in a direction that aims to
               return the heading estimate to the angle it occupied before
               stimulation. These results support a working model in which the
               fly brain quantitatively compares an internal estimate of
               current heading with an internal goal heading and uses the sign
               and magnitude of the difference to determine which way to turn,
               how hard to turn and how fast to walk forward.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  22,
  number    =  9,
  pages     = "1460--1468",
  month     =  sep,
  year      =  2019,
  keywords  = "navigation",
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "31332373",
  doi       = "10.1038/s41593-019-0444-x",
  pmc       = "PMC7688015"
}

@UNPUBLISHED{Keshavarzi2021-jl,
  title    = "The retrosplenial cortex combines internal and external cues to
              encode head velocity during navigation",
  author   = "Keshavarzi, Sepiedeh and Bracey, Edward F and Faville, Richard A
              and Campagner, Dario and Tyson, Adam L and Lenzi, Stephen C and
              Branco, Tiago and Margrie, Troy W",
  abstract = "The extent to which we successfully navigate the environment
              depends on our ability to continuously track our heading
              direction and speed. Cells that encode angular velocity of the
              head (AHV) are fundamental in this process, but the sensory
              computations underlying their activity remains unknown. By
              performing chronic single-unit recordings in the retrosplenial
              cortex (RSP) of the mouse and tracking the activity of individual
              AHV neurons between freely moving and head-restrained conditions,
              we find that vestibular inputs dominate AHV signalling. In
              addition, we discover that self-generated optic flow input onto
              these neurons increases the gain and signal-to-noise ratio of
              angular velocity coding during navigation. Psychophysical
              experiments and neural decoding further reveal that
              vestibular-visual integration increases the perceptual accuracy
              of egocentric angular velocity and the fidelity of its
              representation by RSP ensembles. We propose that while AHV coding
              is dependent on vestibular cues, it also utilises vision to
              maximise navigation accuracy in nocturnal and diurnal
              environments. \#\#\# Competing Interest Statement The authors
              have declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.01.22.427789",
  month    =  jan,
  year     =  2021,
  keywords = "navigation",
  language = "en",
  doi      = "10.1101/2021.01.22.427789"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Petrov2010-bl,
  title       = "Modeling and adaptive path control of a differential drive
                 mobile robot",
  booktitle   = "Proceedings of the 12th {WSEAS} international conference on
                 Automatic control, modelling \& simulation",
  author      = "Petrov, Plamen",
  abstract    = "… 5], Lyapunov-based techniques [6, 7, 8, 9]. The most common
                 way to build a … In Section 3, the path following problem in
                 error coordinates expressed in a moving … Proceedings of the
                 12th WSEAS International Conference on AUTOMATIC CONTROL ,
                 MODELLING \& SIMULATION …",
  publisher   = "researchgate.net",
  volume      =  6,
  pages       = "403--408",
  institution = "World Scientific and Engineering Academy and Society (WSEAS)",
  year        =  2010,
  keywords    = "control"
}

@ARTICLE{Garcia-Campmany2010-nk,
  title    = "From circuits to behaviour: motor networks in vertebrates",
  author   = "Garcia-Campmany, Lidia and Stam, Floor J and Goulding, Martyn",
  abstract = "Neural networks in the hindbrain and spinal cord generate the
              simple patterns of motor activity that are necessary for
              breathing and locomotion. These networks function autonomously,
              producing simple yet flexible rhythmic motor behaviours that are
              highly responsive to sensory inputs and central control. This
              review outlines recent advances in our understanding of the
              genetic programmes controlling the assembly and functioning of
              circuits in the hindbrain and spinal cord that are responsible
              for respiration and locomotion. In addition, we highlight the
              influence that target-derived retrograde signaling and
              experience-dependent mechanisms have on establishing
              connectivity, particularly with respect to sensory afferent
              innervation of the spinal cord.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  20,
  number   =  1,
  pages    = "116--125",
  month    =  feb,
  year     =  2010,
  keywords = "Locomotion",
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "20138753",
  doi      = "10.1016/j.conb.2010.01.002",
  pmc      = "PMC2847443"
}

@INCOLLECTION{Roussel2020-ou,
  title     = "Chapter 12 - Using mouse genetics to investigate supraspinal
               pathways of the brain important to locomotion",
  booktitle = "The Neural Control of Movement",
  author    = "Roussel, Marie and Lemieux, Maxime and Bretzner, Frederic",
  editor    = "Whelan, Patrick J and Sharples, Simon A",
  abstract  = "Mouse genetics and in vitro studies using developing spinal
               cords have played important roles in improving our understanding
               of the spinal locomotor circuit. However, less is known about
               brain circuits. Recent advances in our ability to investigate
               descending supraspinal pathways and brain locomotor centers have
               emerged over the last decade, with the development of new mouse
               genetics targeting specific neuronal populations of the brain
               and better tools to monitor locomotion using freely behaving
               mice. In this chapter, we first describe the development of
               experimental models from in vitro isolated studies to in vivo
               techniques allowing researchers to assess locomotion through
               adulthood. We then present the new genetic tools available in
               the mouse to probe and dissect brain motor circuits. We then
               give an overview of supraspinal descending pathways and brain
               centers pertaining to basic and voluntary locomotion. In our
               companion chapter (Chapter 11), we focus on spinal locomotor
               circuits using in vitro techniques and spinal cord preparations
               isolated from neonatal rodents.",
  publisher = "Academic Press",
  pages     = "269--313",
  month     =  jan,
  year      =  2020,
  keywords  = "Locomotion; Rat; Mouse genetics; Neurophysiology; Kinematic;
               Experimental model; Neonatal; Adult; Descending supraspinal
               pathways; Supraspinal locomotor centers;Locomotion",
  isbn      = "9780128164778",
  doi       = "10.1016/B978-0-12-816477-8.00012-0"
}

@ARTICLE{Yttri2016-ny,
  title     = "Opponent and bidirectional control of movement velocity in the
               basal ganglia",
  author    = "Yttri, Eric A and Dudman, Joshua T",
  abstract  = "For goal-directed behaviour it is critical that we can both
               select the appropriate action and learn to modify the underlying
               movements (for example, the pitch of a note or velocity of a
               reach) to improve outcomes. The basal ganglia are a critical
               nexus where circuits necessary for the production of behaviour,
               such as the neocortex and thalamus, are integrated with reward
               signalling to reinforce successful, purposive actions. The
               dorsal striatum, a major input structure of basal ganglia, is
               composed of two opponent pathways, direct and indirect, thought
               to select actions that elicit positive outcomes and suppress
               actions that do not, respectively. Activity-dependent plasticity
               modulated by reward is thought to be sufficient for selecting
               actions in the striatum. Although perturbations of basal ganglia
               function produce profound changes in movement, it remains
               unknown whether activity-dependent plasticity is sufficient to
               produce learned changes in movement kinematics, such as
               velocity. Here we use cell-type-specific stimulation in mice
               delivered in closed loop during movement to demonstrate that
               activity in either the direct or indirect pathway is sufficient
               to produce specific and sustained increases or decreases in
               velocity, without affecting action selection or motivation.
               These behavioural changes were a form of learning that
               accumulated over trials, persisted after the cessation of
               stimulation, and were abolished in the presence of dopamine
               antagonists. Our results reveal that the direct and indirect
               pathways can each bidirectionally control movement velocity,
               demonstrating unprecedented specificity and flexibility in the
               control of volition by the basal ganglia.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  533,
  number    =  7603,
  pages     = "402--406",
  month     =  may,
  year      =  2016,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "27135927",
  doi       = "10.1038/nature17639",
  pmc       = "PMC4873380"
}

@ARTICLE{Witts2019-xk,
  title     = "Vestibulospinal contributions to mammalian locomotion",
  author    = "Witts, Emily C and Murray, Andrew J",
  abstract  = "The basic mammalian locomotor pattern is generated by spinal
               circuits which must maintain enough output flexibility to
               sustain locomotion in an ever-changing environment. Lateral
               vestibulospinal tract (LVST) neurons receive multimodal sensory
               feedback regarding ongoing movement, as well as input from the
               forebrain and cerebellum, and send dense projections to multiple
               areas of the spinal cord. Traditionally, LVST-neurons have been
               implicated in the generation of reflexes that maintain upright
               posture, but they may also have an underappreciated role in the
               generation of normal locomotor movements. Here, we review
               anatomical data regarding the inputs, projection pathways and
               spinal targets of LVST-neurons and discuss evidence from both
               animal and human studies around their potential role in the
               modification of locomotor patterns in mammals.",
  journal   = "Current Opinion in Physiology",
  publisher = "Elsevier",
  volume    =  8,
  pages     = "56--62",
  month     =  apr,
  year      =  2019,
  keywords  = "Locomotion",
  issn      = "2468-8673",
  doi       = "10.1016/j.cophys.2018.12.010"
}

@PHDTHESIS{Yen_Na_Lau2020-er,
  title     = "Supraspinal activity patterns underpinning locomotor diversity
               in larval zebrafish",
  author    = "Yen Na Lau, Joanna",
  editor    = "Bianco, I",
  abstract  = "How do supraspinal circuits produce the diversity of locomotor
               outputs needed for an animal's survival? To answer this
               question, I study the reticulospinal (RS) system of larval
               zebrafish, as these cells provide the main source of descending
               motor control. I combine two-photon calcium imaging of RS
               neurons with high-speed behavioural tracking to study RS
               activity across a range of kinematically distinct swim types.
               Examination of reticulospinal recruitment across different swim
               types has revealed unique, but partially overlapping activity
               patterns, suggesting that some cells encode kinematics common to
               multiple swim types, while others encode kinematics which are
               characteristic of a specific swim type. By developing
               regression-based encoding models which describe a cell's
               activity using low-level tail kinematics, we identify
               ``kinematic modules''. These modules contain cells with similar
               kinematic encoding and thus represent the core combinations of
               kinematic features encoded by RS activity. I find that laser
               ablation of cells within a module produce specific kinematic
               deficits without affecting shared elements of locomotion. This
               data suggest a circuit architecture where kinematic modules can
               be differentially combined to produce locomotor diversity
               through the context-specific recruitment of particular groups of
               RS neurons. I also describe a novel preparation for the imaging
               of fluorescent activity indicators in larval zebrafish using an
               acousto-optic lens microscope. This methodology allows for rapid
               3D point scanning of the entire reticulospinal complex during
               visual stimulus presentation and behavioural tracking. The
               improved temporal resolution and sampling across the whole
               population provides an opportunity to examine the relative
               timing of activity between reticulospinal neurons.",
  publisher = "UCL (University College London)",
  month     =  mar,
  year      =  2020,
  school    = "UCL (University College London)",
  keywords  = "Locomotion",
  language  = "en"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Opris2019-vm,
  title     = "Activation of brainstem neurons during mesencephalic locomotor
               region-evoked locomotion in the cat",
  author    = "Opris, Ioan and Dai, Xiaohong and Johnson, Dawn M G and Sanchez,
               Francisco J and Villamil, Luz M and Xie, Songtao and Lee-Hauser,
               Cecelia R and Chang, Stephano and Jordan, Larry M and Noga,
               Brian R",
  abstract  = "The distribution of locomotor-activated neurons in the brainstem
               of the cat was studied by c- Fos immunohistochemistry in
               combination with antibody-based cellular phenotyping following
               electrical stimulation of the mesencephalic locomotor region
               (MLR)--the anatomical constituents of which remain debated
               today, primarily between the cuneiform (CnF) and the
               pedunculopontine tegmental nuclei (PPT). Effective MLR sites
               were co- extensive with the CnF nucleus. Animals subject to the
               locomotor task showed abundant Fos …",
  journal   = "Front. Syst. Neurosci.",
  publisher = "Frontiers Media SA",
  volume    =  13,
  year      =  2019,
  keywords  = "Locomotion",
  pmc       = "pmc6868058"
}

@ARTICLE{Cote2018-xl,
  title     = "Spinal Control of Locomotion: Individual Neurons, Their Circuits
               and Functions",
  author    = "C{\^o}t{\'e}, Marie-Pascale and Murray, Lynda M and Knikou,
               Maria",
  abstract  = "Systematic research on the physiological and anatomical
               characteristics of spinal cord interneurons along with their
               functional output has evolved for more than one century. Despite
               significant progress in our understanding of these networks and
               their role in generating and modulating movement, it has
               remained a challenge to elucidate the properties of the
               locomotor rhythm across species. Neurophysiological experimental
               evidence indicates similarities in the function of interneurons
               mediating afferent information regarding muscle stretch and
               loading, being affected by motor axon collaterals and those
               mediating presynaptic inhibition in animals and humans when
               their function is assessed at rest. However, significantly
               different muscle activation profiles are observed during
               locomotion across species. This difference may potentially be
               driven by a modified distribution of muscle afferents at
               multiple segmental levels in humans, resulting in an altered
               interaction between different classes of spinal interneurons.
               Further, different classes of spinal interneurons are likely
               activated or silent to some extent simultaneously in all
               species. Regardless of these limitations, continuous efforts on
               the function of spinal interneuronal circuits during mammalian
               locomotion will assist in delineating the neural mechanisms
               underlying locomotor control, and help develop novel targeted
               rehabilitation strategies in cases of impaired bipedal gait in
               humans. These rehabilitation strategies will include
               activity-based therapies and targeted neuromodulation of spinal
               interneuronal circuits via repetitive stimulation delivered to
               the brain and/or spinal cord.",
  journal   = "Front. Physiol.",
  publisher = "frontiersin.org",
  volume    =  9,
  pages     = "784",
  month     =  jun,
  year      =  2018,
  keywords  = "interneurons; locomotion; motoneurons; spinal neural circuits;
               spinal reflexes;Locomotion",
  language  = "en",
  issn      = "1664-042X",
  pmid      = "29988534",
  doi       = "10.3389/fphys.2018.00784",
  pmc       = "PMC6026662"
}

@ARTICLE{Chen2018-qm,
  title     = "Imaging neural activity in the ventral nerve cord of behaving
               adult Drosophila",
  author    = "Chen, Chin-Lin and Hermans, Laura and Viswanathan, Meera C and
               Fortun, Denis and Aymanns, Florian and Unser, Michael and
               Cammarato, Anthony and Dickinson, Michael H and Ramdya, Pavan",
  abstract  = "To understand neural circuits that control limbs, one must
               measure their activity during behavior. Until now this goal has
               been challenging, because limb premotor and motor circuits have
               been largely inaccessible for large-scale recordings in intact,
               moving animals-a constraint that is true for both vertebrate and
               invertebrate models. Here, we introduce a method for 2-photon
               functional imaging from the ventral nerve cord (VNC) of behaving
               adult Drosophila melanogaster. We use this method to reveal
               patterns of activity across nerve cord populations during
               grooming and walking and to uncover the functional encoding of
               moonwalker ascending neurons (MANs), moonwalker descending
               neurons (MDNs), and a previously uncharacterized class of
               locomotion-associated A1 descending neurons. Finally, we develop
               a genetic reagent to destroy the indirect flight muscles and to
               facilitate experimental access to the VNC. Taken together, these
               approaches enable the direct investigation of circuits
               associated with complex limb movements.",
  journal   = "Nat. Commun.",
  publisher = "nature.com",
  volume    =  9,
  number    =  1,
  pages     = "4390",
  month     =  oct,
  year      =  2018,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "2041-1723",
  pmid      = "30348941",
  doi       = "10.1038/s41467-018-06857-z",
  pmc       = "PMC6197219"
}

@ARTICLE{Lahr2020-cu,
  title     = "Navigation: How Spatial Cognition Is Transformed into Action",
  author    = "Lahr, Maria and Donato, Flavio",
  abstract  = "Navigation relies on the brain's ability to build a cognitive
               map of the environment, and to use such a map to guide the
               animal's movements to goals. A new study proposes that the
               secondary motor cortex might convert the map into action.",
  journal   = "Curr. Biol.",
  publisher = "Elsevier",
  volume    =  30,
  number    =  10,
  pages     = "R430--R432",
  month     =  may,
  year      =  2020,
  keywords  = "navigation",
  language  = "en",
  issn      = "0960-9822, 1879-0445",
  pmid      = "32428470",
  doi       = "10.1016/j.cub.2020.03.069"
}

@ARTICLE{Shalit2012-du,
  title    = "Descending systems translate transient cortical commands into a
              sustained muscle activation signal",
  author   = "Shalit, Uri and Zinger, Nofya and Joshua, Mati and Prut, Yifat",
  abstract = "Controlling motor actions requires online adjustments of
              time-varying parameters. Although numerous studies have attempted
              to identify the parameters coded in different motor sites, the
              relationships between the temporal profile of neuronal responses
              and the dynamics of motor behavior remain poorly understood in
              particular because motor parameters such as force and movement
              direction often change over time. We studied time-dependent
              coding of cortical and spinal neurons in primates performing an
              isometric wrist task with an active hold period, which made it
              possible to segregate motor behavior into its phasic and
              sustained components. Here, we show that cortical neurons
              transiently code motor-related parameters when actively acquiring
              a goal, whereas spinal interneurons provide persistent
              information regarding maintained torque level and posture.
              Moreover, motor cortical neurons differed substantially from
              spinal neurons with regard to the evolvement of
              parameter-specific coding over the course of a trial. These
              results suggest that the motor cortex and spinal cord use
              different control policies: Cortical neurons produce transient
              motor commands governing ensuing actions, whereas spinal neurons
              exhibit sustained coding of ongoing motor states. Hence, motor
              structures downstream to M1 need to integrate cortical commands
              to produce state-dependent spinal firing.",
  journal  = "Cereb. Cortex",
  volume   =  22,
  number   =  8,
  pages    = "1904--1914",
  month    =  aug,
  year     =  2012,
  language = "en",
  issn     = "1047-3211, 1460-2199",
  pmid     = "21965441",
  doi      = "10.1093/cercor/bhr267"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Eriksson2020-mp,
  title     = "Cortical activity at different time scales: high-pass filtering
               separates motor planning and execution",
  author    = "Eriksson, David and Heiland, Mona and Schneider, Artur and
               Diester, Ilka",
  abstract  = "David Eriksson*, Mona Heiland, Artur Schneider, and Ilka
               Diester* 4 … Department of Physiology and Medical Physics 19 …
               The copyright holder for this preprint (which was this version
               posted June 6, 2020. . https://doi.org/10.1101/857300 doi:
               bioRxiv preprint … The copyright holder for this preprint (which
               was this version posted June 6, 2020. .
               https://doi.org/10.1101/857300 doi: bioRxiv preprint … The
               smooth conduction of movements requires simultaneous motor
               planning and execution according 43 … Here, we introduced two
               novel tasks in which motor planning …",
  journal   = "bioRxiv",
  publisher = "Cold Spring Harbor Laboratory",
  pages     = "857300",
  year      =  2020
}

@ARTICLE{Warren2021-wk,
  title    = "A rapid whisker-based decision underlying skilled locomotion in
              mice",
  author   = "Warren, Richard A and Zhang, Qianyun and Hoffman, Judah R and Li,
              Edward Y and Hong, Y Kate and Bruno, Randy M and Sawtell,
              Nathaniel B",
  abstract = "Skilled motor behavior requires rapidly integrating external
              sensory input with information about internal state to decide
              which movements to make next. Using machine learning approaches
              for high-resolution kinematic analysis, we uncover the logic of a
              rapid decision underlying sensory-guided locomotion in mice.
              After detecting obstacles with their whiskers mice select
              distinct kinematic strategies depending on a whisker-derived
              estimate of obstacle location together with the position and
              velocity of their body. Although mice rely on whiskers for
              obstacle avoidance, lesions of primary whisker sensory cortex had
              minimal impact. While motor cortex manipulations affected the
              execution of the chosen strategy, the decision-making process
              remained largely intact. These results highlight the potential of
              machine learning for reductionist analysis of naturalistic
              behaviors and provide a case in which subcortical brain
              structures appear sufficient for mediating a relatively
              sophisticated sensorimotor decision.",
  journal  = "Elife",
  volume   =  10,
  month    =  jan,
  year     =  2021,
  keywords = "barrel cortex; decision-making; locomotion; motor cortex; mouse;
              neuroscience; whiskers",
  language = "en",
  issn     = "2050-084X",
  pmid     = "33428566",
  doi      = "10.7554/eLife.63596",
  pmc      = "PMC7800376"
}

@UNPUBLISHED{Rosenberg2021-pa,
  title    = "Mice in a labyrinth: Rapid learning, sudden insight, and
              efficient exploration",
  author   = "Rosenberg, Matthew and Zhang, Tony and Perona, Pietro and
              Meister, Markus",
  abstract = "Animals learn certain complex tasks remarkably fast, sometimes
              after a single experience. What behavioral algorithms support
              this efficiency? Many contemporary studies based on
              two-alternative-forced-choice (2AFC) tasks observe only slow or
              incomplete learning. As an alternative, we study the
              unconstrained behavior of mice in a complex labyrinth and measure
              the dynamics of learning and the behaviors that enable it. A
              mouse in the labyrinth makes ~2000 navigation decisions per hour.
              The animal quickly discovers the location of a reward in the maze
              and executes correct 10-bit choices after only 10 reward
              experiences -- a learning rate 1000-fold higher than in 2AFC
              experiments. Many mice improve discontinuously from one minute to
              the next, suggesting moments of sudden insight about the
              structure of the labyrinth. The underlying search algorithm does
              not require a global memory of places visited and is largely
              explained by purely local turning rules. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.01.14.426746",
  month    =  jan,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.01.14.426746"
}

@UNPUBLISHED{Keshtkaran2021-xk,
  title    = "A large-scale neural network training framework for generalized
              estimation of single-trial population dynamics",
  author   = "Keshtkaran, Mohammad Reza and Sedler, Andrew R and Chowdhury,
              Raeed H and Tandon, Raghav and Basrai, Diya and Nguyen, Sarah L
              and Sohn, Hansem and Jazayeri, Mehrdad and Miller, Lee E and
              Pandarinath, Chethan",
  abstract = "Large-scale recordings of neural activity are providing new
              opportunities to study network-level dynamics. However, the sheer
              volume of data and its dynamical complexity are critical barriers
              to uncovering and interpreting these dynamics. Deep learning
              methods are a promising approach due to their ability to uncover
              meaningful relationships from large, complex, and noisy datasets.
              When applied to high-D spiking data from motor cortex (M1) during
              stereotyped behaviors, they offer improvements in the ability to
              uncover dynamics and their relation to subjects' behaviors on a
              millisecond timescale. However, applying such methods to
              less-structured behaviors, or in brain areas that are not
              well-modeled by autonomous dynamics, is far more challenging,
              because deep learning methods often require careful hand-tuning
              of complex model hyperparameters (HPs). Here we demonstrate
              AutoLFADS, a large-scale, automated model-tuning framework that
              can characterize dynamics in diverse brain areas without regard
              to behavior. AutoLFADS uses distributed computing to train dozens
              of models simultaneously while using evolutionary algorithms to
              tune HPs in a completely unsupervised way. This enables accurate
              inference of dynamics out-of-the-box on a variety of datasets,
              including data from M1 during stereotyped and free-paced
              reaching, somatosensory cortex during reaching with
              perturbations, and frontal cortex during cognitive timing tasks.
              We present a cloud software package and comprehensive tutorials
              that enable new users to apply the method without needing
              dedicated computing resources. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.01.13.426570",
  month    =  jan,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.01.13.426570"
}

@UNPUBLISHED{Chopek2021-mg,
  title    = "Local brainstem circuits contribute to reticulospinal output in
              the mouse",
  author   = "Chopek, Jeremy W and Zhang, Ying and Brownstone, Robert M",
  abstract = "Glutamatergic reticulospinal neurons in the gigantocellular
              reticular nucleus (GRN) of the medullary reticular formation can
              function as command neurons, transmitting motor commands to
              spinal cord circuits. Recent advances in our understanding of
              this neuron-dense region have been facilitated by the discovery
              of expression of the transcriptional regulator, Chx10, in
              excitatory reticulospinal neurons. Here, we address the capacity
              of local circuitry in the GRN to contribute to reticulospinal
              output. We define two sub-populations of Chx10-expressing neurons
              in this region, based on distinct electrophysiological properties
              and somata size (small and large), and show that these correspond
              to local interneurons and reticulospinal neurons, respectively.
              Using focal release of caged-glutamate combined with patch clamp
              recordings, we demonstrated that Chx10 neurons form microcircuits
              in which the Chx10 interneurons project to and facilitate the
              firing of Chx10 reticulospinal neurons. We discuss the
              implications of these microcircuits in terms of movement
              selection. SIGNIFICANCE STATEMENT Reticulospinal neurons in the
              medullary reticular formation play a key role in movement. The
              transcriptional regulator Chx10 defines a population of
              glutamatergic neurons in this region, a proportion of which have
              been shown to be involved in stopping, steering, and modulating
              locomotion. While it has been shown that these neurons integrate
              descending inputs, we asked whether local processing also
              ultimately contributes to reticulospinal outputs. Here, we define
              Chx10-expressing medullary reticular formation interneurons and
              reticulospinal neurons, and demonstrate how the former modulate
              the output of the latter. The results shed light on the internal
              organization and microcircuit formation of reticular formation
              neurons. \#\#\# Competing Interest Statement The authors have
              declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.01.11.426243",
  month    =  jan,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.01.11.426243"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@UNPUBLISHED{Kao2021-pq,
  title    = "Optimal anticipatory control as a theory of motor preparation: a
              thalamo-cortical circuit model",
  author   = "Kao, Ta-Chu and Sadabadi, Mahdieh S and Hennequin, Guillaume",
  abstract = "Across a range of motor and cognitive tasks, cortical activity
              can be accurately described by low-dimensional dynamics unfolding
              from specific initial conditions on every trial. These
              ``preparatory states'' largely determine the subsequent evolution
              of both neural activity and behaviour, and their importance
              raises questions regarding how they are ─ or ought to be ─ set.
              Here, we formulate motor preparation as optimal anticipatory
              control of future movements, and show that the solution requires
              a form of internal feedback control of cortical circuit dynamics.
              In contrast to a simple feedforward strategy, feedback control
              enables fast movement preparation and orthogonality between
              preparatory and movement activity, a distinctive feature of
              peri-movement activity in reaching monkeys. We propose a circuit
              model in which optimal preparatory control is implemented as a
              thalamo-cortical loop gated by the basal ganglia. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2020.02.02.931246",
  month    =  jan,
  year     =  2021,
  keywords = "control",
  language = "en",
  doi      = "10.1101/2020.02.02.931246"
}

@ARTICLE{Erdem2015-sf,
  title    = "A hierarchical model of goal directed navigation selects
              trajectories in a visual environment",
  author   = "Erdem, U{\u g}ur M and Milford, Michael J and Hasselmo, Michael E",
  abstract = "We have developed a Hierarchical Look-Ahead Trajectory Model
              (HiLAM) that incorporates the firing pattern of medial entorhinal
              grid cells in a planning circuit that includes interactions with
              hippocampus and prefrontal cortex. We show the model's
              flexibility in representing large real world environments using
              odometry information obtained from challenging video sequences.
              We acquire the visual data from a camera mounted on a small
              tele-operated vehicle. The camera has a panoramic field of view
              with its focal point approximately 5 cm above the ground level,
              similar to what would be expected from a rat's point of view.
              Using established algorithms for calculating perceptual speed
              from the apparent rate of visual change over time, we generate
              raw dead reckoning information which loses spatial fidelity over
              time due to error accumulation. We rectify the loss of fidelity
              by exploiting the loop-closure detection ability of a
              biologically inspired, robot navigation model termed RatSLAM. The
              rectified motion information serves as a velocity input to the
              HiLAM to encode the environment in the form of grid cell and
              place cell maps. Finally, we show goal directed path planning
              results of HiLAM in two different environments, an indoor square
              maze used in rodent experiments and an outdoor arena more than
              two orders of magnitude larger than the indoor maze. Together
              these results bridge for the first time the gap between higher
              fidelity bio-inspired navigation models (HiLAM) and more
              abstracted but highly functional bio-inspired robotic mapping
              systems (RatSLAM), and move from simulated environments into
              real-world studies in rodent-sized arenas and beyond.",
  journal  = "Neurobiol. Learn. Mem.",
  volume   =  117,
  pages    = "109--121",
  month    =  jan,
  year     =  2015,
  keywords = "Grid cell; Hippocampus; Navigation; Path planning; Place cell;
              RatSLAM; SLAM",
  language = "en",
  issn     = "1074-7427, 1095-9564",
  pmid     = "25079451",
  doi      = "10.1016/j.nlm.2014.07.003"
}

@ARTICLE{Zhou2019-jm,
  title    = "Towards {Goal-Directed} Navigation Through Combining Learning
              Based Global and Local Planners",
  author   = "Zhou, Xiaomao and Gao, Yanbin and Guan, Lianwu",
  abstract = "Robot navigation is a fundamental problem in robotics and various
              approaches have been developed to cope with this problem. Despite
              the great success of previous approaches, learning-based methods
              are receiving growing interest in the research community. They
              have shown great efficiency in solving navigation tasks and offer
              considerable promise to build intelligent navigation systems.
              This paper presents a goal-directed robot navigation system that
              integrates global planning based on goal-directed end-to-end
              learning and local planning based on reinforcement learning (RL).
              The proposed system aims to navigate the robot to desired goal
              positions while also being adaptive to changes in the
              environment. The global planner is trained to imitate an expert's
              navigation between different positions by goal-directed
              end-to-end learning, where both the goal representations and
              local observations are incorporated to generate actions. However,
              it is trained in a supervised fashion and is weak in dealing with
              changes in the environment. To solve this problem, a local
              planner based on deep reinforcement learning (DRL) is designed.
              The local planner is first implemented in a simulator and then
              transferred to the real world. It works complementarily to deal
              with situations that have not been met during training the global
              planner and is able to generalize over different situations. The
              experimental results on a robot platform demonstrate the
              effectiveness of the proposed navigation system.",
  journal  = "Sensors",
  volume   =  19,
  number   =  1,
  month    =  jan,
  year     =  2019,
  keywords = "end-to-end learning; global planning; local planning;
              reinforcement learning; robot navigation",
  language = "en",
  issn     = "1424-8220",
  pmid     = "30621314",
  doi      = "10.3390/s19010176",
  pmc      = "PMC6339171"
}

@ARTICLE{Tan2002-pk,
  title     = "Using voting technique in mobile robot behavior coordination for
               goal-directed navigation",
  author    = "Tan, Chee Kwong and M. Amin, Shamsudin H and Mamat, Rosbi",
  journal   = "J. Teknol.",
  publisher = "Penerbit UTM Press",
  volume    =  36,
  number    =  1,
  month     =  jun,
  year      =  2002,
  issn      = "0127-9696, 2180-3722",
  doi       = "10.11113/jt.v36.575"
}

@ARTICLE{Goldschmidt2017-bt,
  title    = "A Neurocomputational Model of {Goal-Directed} Navigation in
              {Insect-Inspired} Artificial Agents",
  author   = "Goldschmidt, Dennis and Manoonpong, Poramate and Dasgupta,
              Sakyasingha",
  abstract = "Despite their small size, insect brains are able to produce
              robust and efficient navigation in complex environments.
              Specifically in social insects, such as ants and bees, these
              navigational capabilities are guided by orientation directing
              vectors generated by a process called path integration. During
              this process, they integrate compass and odometric cues to
              estimate their current location as a vector, called the home
              vector for guiding them back home on a straight path. They
              further acquire and retrieve path integration-based vector
              memories globally to the nest or based on visual landmarks.
              Although existing computational models reproduced similar
              behaviors, a neurocomputational model of vector navigation
              including the acquisition of vector representations has not been
              described before. Here we present a model of neural mechanisms in
              a modular closed-loop control-enabling vector navigation in
              artificial agents. The model consists of a path integration
              mechanism, reward-modulated global learning, random search, and
              action selection. The path integration mechanism integrates
              compass and odometric cues to compute a vectorial representation
              of the agent's current location as neural activity patterns in
              circular arrays. A reward-modulated learning rule enables the
              acquisition of vector memories by associating the local food
              reward with the path integration state. A motor output is
              computed based on the combination of vector memories and random
              exploration. In simulation, we show that the neural mechanisms
              enable robust homing and localization, even in the presence of
              external sensory noise. The proposed learning rules lead to
              goal-directed navigation and route formation performed under
              realistic conditions. Consequently, we provide a novel approach
              for vector learning and navigation in a simulated, situated agent
              linking behavioral observations to their possible underlying
              neural substrates.",
  journal  = "Front. Neurorobot.",
  volume   =  11,
  pages    = "20",
  month    =  apr,
  year     =  2017,
  keywords = "artificial intelligence; insect navigation; neural networks; path
              integration; reward-based learning",
  language = "en",
  issn     = "1662-5218",
  pmid     = "28446872",
  doi      = "10.3389/fnbot.2017.00020",
  pmc      = "PMC5388780"
}

@ARTICLE{Verschure2014-nq,
  title    = "The why, what, where, when and how of goal-directed choice:
              neuronal and computational principles",
  author   = "Verschure, Paul F M J and Pennartz, Cyriel M A and Pezzulo,
              Giovanni",
  abstract = "The central problems that goal-directed animals must solve are:
              'What do I need and Why, Where and When can this be obtained, and
              How do I get it?' or the H4W problem. Here, we elucidate the
              principles underlying the neuronal solutions to H4W using a
              combination of neurobiological and neurorobotic approaches.
              First, we analyse H4W from a system-level perspective by mapping
              its objectives onto the Distributed Adaptive Control embodied
              cognitive architecture which sees the generation of adaptive
              action in the real world as the primary task of the brain rather
              than optimally solving abstract problems. We next map this
              functional decomposition to the architecture of the rodent brain
              to test its consistency. Following this approach, we propose that
              the mammalian brain solves the H4W problem on the basis of
              multiple kinds of outcome predictions, integrating central
              representations of needs and drives (e.g. hypothalamus), valence
              (e.g. amygdala), world, self and task state spaces (e.g.
              neocortex, hippocampus and prefrontal cortex, respectively)
              combined with multi-modal selection (e.g. basal ganglia). In our
              analysis, goal-directed behaviour results from a well-structured
              architecture in which goals are bootstrapped on the basis of
              predefined needs, valence and multiple learning, memory and
              planning mechanisms rather than being generated by a singular
              computation.",
  journal  = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  volume   =  369,
  number   =  1655,
  month    =  nov,
  year     =  2014,
  keywords = "computational modelling; decision-making; distributed adaptive
              control; embodied cognition; goal-directed behaviour; reward",
  language = "en",
  issn     = "0962-8436, 1471-2970",
  pmid     = "25267825",
  doi      = "10.1098/rstb.2013.0483",
  pmc      = "PMC4186236"
}

@ARTICLE{Tzschentke2000-oz,
  title     = "Functional relationship among medial prefrontal cortex, nucleus
               accumbens, and ventral tegmental area in locomotion and reward",
  author    = "Tzschentke, T M and Schmidt, W J",
  abstract  = "Prominent projections of the medial prefrontal cortex (mPFC) to
               the nucleus accumbens (NAS) and the ventral tegmental area (VTA)
               exist, but it has been difficult to assign a clear functional
               role to either of these projections. With some exceptions to be
               discussed in some detail, only a few neurochemical and
               behavioral effects of manipulating the mPFC can be explained by
               invoking the mPFC-NAS projection, while most effects are
               compatible with an involvement of the mPFC-VTA-NAS or
               mPFC-pedunculopontine tegmental nucleus (PPTg)-VTA-NAS circuits.
               What is known about the organization and function of these loops
               is generally consistent with the results obtained by stimulating
               or lesioning or injecting drugs into the mPFC, yet these
               findings are largely inconsistent with the functional
               organization of the mPFC-NAS projection. This review briefly
               summarizes some of the most important aspects of what is known
               about the functional interactions of the mPFC. NAS, VTA, and
               associated areas, and focuses on functional differences between
               the mesocortical and the mesoaccumbal dopaminergic projections,
               and between the corticomesencephalic and the corticoaccumbal
               glutamatergic projections.",
  journal   = "Crit. Rev. Neurobiol.",
  publisher = "dl.begellhouse.com",
  volume    =  14,
  number    =  2,
  pages     = "131--142",
  year      =  2000,
  language  = "en",
  issn      = "0892-0915",
  pmid      = "11513242"
}

@ARTICLE{Drew2002-sn,
  title     = "Contributions of the motor cortex to the control of the
               hindlimbs during locomotion in the cat",
  author    = "Drew, Trevor and Jiang, Wan and Widajewicz, Witold",
  abstract  = "Although the corticospinal tract is not essential for the
               production of the basic locomotor rhythm in cats, it does
               contribute to the regulation of locomotion, particularly in
               situations in which there is a requirement for precise control
               over paw placement or limb trajectory. Lesions of the
               dorsolateral funiculi at the low thoracic level (T13) that
               completely interrupted both the cortico- and rubrospinal
               pathways produced long-term deficits in locomotion on a level
               surface. These deficits included a paw-drag that was probably
               caused both by a loss of cortico- and rubrospinal input to
               motoneurones controlling distal muscles as well as by a change
               in the relative timing of muscles acting around the hip and
               knee. Smaller lesions produced similar deficits from which the
               cats recovered relatively quickly. Cats with the largest lesions
               of the dorsolateral funiculi were unable to modify their gait
               sufficiently to step over obstacles attached to the treadmill
               belt even 3--5 months postlesion. These results imply that the
               medial pathways, the reticulo- and vestibulospinal pathways, are
               unable to fully compensate for damage to the lateral pathways.
               Single unit recordings from identified pyramidal tract neurones
               (PTNs) within the hindlimb representation of the primary motor
               cortex (area 4) showed that a substantial proportion of neurones
               (67\%) significantly increased their discharge frequency when
               the cats modified their gait to step over obstacles attached to
               the treadmill belt. Of those PTNs that showed increased activity
               during the swing phase, populations of neurones were activated
               at different times. A large proportion of PTNS discharged early
               in swing, in phase with knee flexors such as the semitendinosus.
               Others discharged slightly later, in phase with the activity of
               ankle flexors, such as tibialis anterior, while still others
               discharged at the end of swing, in phase with digit
               dorsiflexors, such as the extensor digitorum brevis. We suggest
               that different populations of cortical neurones may specifically
               modify the activity of selected groups of close synergistic
               muscles during different parts of the swing phase. We further
               suggest that these modifications are mediated, in part, by
               groups of interneurones that are involved in determining the
               base locomotor rhythm. This provides a means by which the
               changes specified by the descending signal from the motor cortex
               may be smoothly, and appropriately, incorporated into the
               locomotor cycle.",
  journal   = "Brain Res. Rev.",
  publisher = "Elsevier",
  volume    =  40,
  number    =  1,
  pages     = "178--191",
  month     =  oct,
  year      =  2002,
  keywords  = "Motor cortex; Locomotion; Corticospinal; Gait modification",
  issn      = "0165-0173",
  doi       = "10.1016/S0165-0173(02)00200-X"
}

@INCOLLECTION{Beloozerova1988-dx,
  title     = "Role of Motor Cortex in Control of Locomotion",
  booktitle = "Stance and Motion: Facts and Concepts",
  author    = "Beloozerova, I N and Sirota, M G",
  editor    = "Gurfinkel, V S and Ioffe, M E and Massion, J and Roll, J P",
  abstract  = "1.The activity of 252 motor cortex (MC) neurons (including 70
               pyramidal tract neurons) was recorded extracellularly in the cat
               by means of a mobile electrode during free locomotion in a
               box.2.The activity of 89\% MC neurons was modulated during
               locomotion. The modulation was related to the stepping
               movements, since it increased in one stepping phase and
               decreased in the next.3.MC neurons were also studied while the
               animal moved up a flat inclined surface, walking at different
               speeds, with a load of 85g attached to each forelimb, when the
               cat had to perform snakelike movements (turns) or walk on the
               flat surface placed in a horizontal plane. The pattern of MC
               neuron activity changed little under these conditions in
               comparison with uncomplicated locomotion.4.The activity of 68
               neurons was recorded in experiments with barriers and involving
               locomotion on a horizontal ladder which restricted the possible
               paw positions along the direction of locomotion. These tasks
               greatly affected the MC activity.5.Neither bilateral MC lesion
               nor tetrodotoxin inactivation hampered uphill locomotion,
               walking along a moving floor, or locomotion involving turns and
               loaded forelimbs. On the contrary, it proved to be necessary for
               the MC to be intact for locomotion with space linked stepping
               limb movements (i.e. with barriers, on a ladder) to be
               possible.6.Bilateral destruction of the ventrolateral nucleus of
               the thalamus (VL) resulted in a decrease in the rhythmical
               modulation of MC neurons during locomotion. After VL lesion the
               cat could walk quite well on the horizontal surface and uphill,
               at various speeds, with the forelimbs loaded; it could perform
               turns and could walk on the moving floor. The cat proved to be
               incapable, however, of walking with barriers and on the ladder.",
  publisher = "Springer US",
  pages     = "163--176",
  year      =  1988,
  address   = "Boston, MA",
  isbn      = "9781489908216",
  doi       = "10.1007/978-1-4899-0821-6\_15"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Gentile1978-sr,
  title     = "Disruption and recovery of locomotor and manipulatory behavior
               following cortical lesions in rats",
  author    = "Gentile, A M and Green, S and Nieburgs, A and Schmelzer, W and
               Stein, D G",
  abstract  = "The first experiment demonstrated that removals of frontal
               cortex disrupted manipulation (latch opening) but not locomotion
               ; damage of medial parietal cortex (sensorimotor cortex )
               produced the reverse effects. In the second study, serial
               lesions of medial parietal cortex …",
  journal   = "Behav. Biol.",
  publisher = "Elsevier",
  volume    =  22,
  number    =  4,
  pages     = "417--455",
  month     =  apr,
  year      =  1978,
  language  = "en",
  issn      = "0091-6773",
  pmid      = "697680",
  doi       = "10.1016/s0091-6773(78)92547-6"
}

@ARTICLE{Goodale1975-wg,
  title     = "The effects of lesions of the superior colliculus on locomotor
               orientation and the orienting reflex in the rat",
  author    = "Goodale, M A and Murison, R C",
  abstract  = "The effects of bilateral removal of the superior colliculus or
               visual cortex on visually guided locomotor movements in rats
               performing a brightness discrimination task were investigated
               directly with the use of cine film. Rats with collicular lesions
               showed patterns of locomotion comparable to or more efficient
               than those of normal animals when approaching one of 5 small
               doors located at one end of a large open area. In contrast,
               animals with large but incomplete lesions of visual cortex were
               distinctly impaired in their visual control of approach
               responses to the same stimuli. On the other hand, rats with
               collicular damage showed no orienting reflex or evidence of
               distraction in the same task when novel visual or auditory
               stimuli were presented. However, both normal and
               visual-decorticate rats showed various components of the
               orienting reflex and disturbance in task performance when the
               same novel stimuli were presented. These results suggest that
               although the superior colliculus does not appear to be essential
               to the visual control of locomotor orientation, this midbrain
               structure might participate in the mediation of shifts in visual
               fixation and attention. Visual cortex, while contributing to
               visuospatial guidance of locomotor movements, might not play a
               significant role in the control and integration of the orienting
               reflex.",
  journal   = "Brain Res.",
  publisher = "Elsevier",
  volume    =  88,
  number    =  2,
  pages     = "243--261",
  month     =  may,
  year      =  1975,
  language  = "en",
  issn      = "0006-8993",
  pmid      = "1148825",
  doi       = "10.1016/0006-8993(75)90388-1"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Sandbrink2020-qc,
  title     = "Task-driven hierarchical deep neural network models of the
               proprioceptive pathway",
  author    = "Sandbrink, K J and Mamidanna, P and Michaelis, C and Mathis, M W
               and {others}",
  abstract  = "Biological motor control is versatile and efficient. Muscles are
               flexible and undergo continuous changes requiring distributed
               adaptive control mechanisms. How proprioception solves this
               problem in the brain is unknown. Here we pursue a task-driven
               modeling …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2020
}

@ARTICLE{Mathis2017-dt,
  title    = "Somatosensory Cortex Plays an Essential Role in Forelimb Motor
              Adaptation in Mice",
  author   = "Mathis, Mackenzie Weygandt and Mathis, Alexander and Uchida,
              Naoshige",
  abstract = "Our motor outputs are constantly re-calibrated to adapt to
              systematic perturbations. This motor adaptation is thought to
              depend on the ability to form a memory of a systematic
              perturbation, often called an internal model. However, the
              mechanisms underlying the formation, storage, and expression of
              such models remain unknown. Here, we developed a mouse model to
              study forelimb adaptation to force field perturbations. We found
              that temporally precise photoinhibition of somatosensory cortex
              (S1) applied concurrently with the force field abolished the
              ability to update subsequent motor commands needed to reduce
              motor errors. This S1 photoinhibition did not impair basic motor
              patterns, post-perturbation completion of the action, or their
              performance in a reward-based learning task. Moreover, S1
              photoinhibition after partial adaptation blocked further
              adaptation, but did not affect the expression of already-adapted
              motor commands. Thus, S1 is critically involved in updating the
              memory about the perturbation that is essential for forelimb
              motor adaptation.",
  journal  = "Neuron",
  volume   =  93,
  number   =  6,
  pages    = "1493--1503.e6",
  month    =  mar,
  year     =  2017,
  keywords = "force field adaptation; motor adaptation; mouse; optogenetics;
              primary somatosensory cortex; sensorimotor learning; sensory
              prediction error",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "28334611",
  doi      = "10.1016/j.neuron.2017.02.049",
  pmc      = "PMC5491974"
}

@UNPUBLISHED{Goulas2021-bz,
  title    = "Bio-instantiated recurrent neural networks",
  author   = "Goulas, Alexandros and Damicelli, Fabrizio and Hilgetag, Claus C",
  abstract = "Biological neuronal networks (BNNs) constitute a niche for
              inspiration and analogy making for researchers that focus on
              artificial neuronal networks (ANNs). Moreover, neuroscientists
              increasingly use ANNs as a model for the brain. However, apart
              from certain similarities and analogies that can be drawn between
              ANNs and BNNs, such networks exhibit marked differences,
              specifically with respect to their network topology. Here, we
              investigate to what extent network topology found in nature can
              lead to beneficial aspects in recurrent neural networks (RNNs):
              i) the prediction performance itself, that is, the capacity of
              the network to minimize the desired function at hand in test data
              and ii) speed of training, that is, how fast during training the
              network reaches its optimal performance. To this end, we examine
              different ways to construct RNNs that instantiate the network
              topology of brains of different species. We refer to such RNNs as
              bio-instantiated. We examine the bio-instantiated RNNs in the
              context of a key cognitive capacity, that is, working memory,
              defined as the ability to track task-relevant information as a
              sequence of events unfolds in time. We highlight what strategies
              can be used to construct RNNs with the network topology found in
              nature, without sacrificing prediction capacity and speed of
              training. Despite that we observe no enhancement of performance
              when compared to randomly wired RNNs, our approach demonstrates
              how empirical neural network data can be used for constructing
              RNNs, thus, facilitating further experimentation with
              biologically realistic networks topology. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.01.22.427744",
  month    =  jan,
  year     =  2021,
  keywords = "RNN",
  language = "en",
  doi      = "10.1101/2021.01.22.427744"
}

@ARTICLE{Shenoy2013-wt,
  title     = "Cortical control of arm movements: a dynamical systems
               perspective",
  author    = "Shenoy, Krishna V and Sahani, Maneesh and Churchland, Mark M",
  abstract  = "Our ability to move is central to everyday life. Investigating
               the neural control of movement in general, and the cortical
               control of volitional arm movements in particular, has been a
               major research focus in recent decades. Studies have involved
               primarily either attempts to account for single-neuron responses
               in terms of tuning for movement parameters or attempts to decode
               movement parameters from populations of tuned neurons. Even
               though this focus on encoding and decoding has led to many
               seminal advances, it has not produced an agreed-upon conceptual
               framework. Interest in understanding the underlying neural
               dynamics has recently increased, leading to questions such as
               how does the current population response determine the future
               population response, and to what purpose? We review how a
               dynamical systems perspective may help us understand why neural
               activity evolves the way it does, how neural activity relates to
               movement parameters, and how a unified conceptual framework may
               result.",
  journal   = "Annu. Rev. Neurosci.",
  publisher = "annualreviews.org",
  volume    =  36,
  pages     = "337--359",
  month     =  jul,
  year      =  2013,
  language  = "en",
  issn      = "0147-006X, 1545-4126",
  pmid      = "23725001",
  doi       = "10.1146/annurev-neuro-062111-150509"
}

@UNPUBLISHED{Barter2021-wc,
  title    = "Achieving natural behavior in a robot using neurally inspired
              hierarchical control",
  author   = "Barter, Joseph W and Yin, Henry H",
  abstract = "Terrestrial locomotion presents tremendous computational
              challenges on account of the enormous degrees of freedom in
              legged animals, and the complex and unpredictable properties of
              the natural environment and the effectors. Yet the nervous system
              can achieve locomotion with ease. Here we introduce a quadrupedal
              robot capable of goal-directed posture control and locomotion
              over rough terrain. The underlying control architecture is a
              hierarchical network of simple negative feedback control systems
              inspired by the organization of the vertebrate nervous system.
              Without using an internal model or feedforward planning, and
              without any training, our robot shows robust posture control and
              locomotor behavior in novel environments containing unpredictable
              disturbances. \#\#\# Competing Interest Statement The authors
              have declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.01.22.427862",
  month    =  jan,
  year     =  2021,
  keywords = "control",
  language = "en",
  doi      = "10.1101/2021.01.22.427862"
}

@ARTICLE{Elsayed2016-rx,
  title     = "Reorganization between preparatory and movement population
               responses in motor cortex",
  author    = "Elsayed, Gamaleldin F and Lara, Antonio H and Kaufman, Matthew T
               and Churchland, Mark M and Cunningham, John P",
  abstract  = "Neural populations can change the computation they perform on
               very short timescales. Although such flexibility is common, the
               underlying computational strategies at the population level
               remain unknown. To address this gap, we examined population
               responses in motor cortex during reach preparation and movement.
               We found that there exist exclusive and orthogonal
               population-level subspaces dedicated to preparatory and movement
               computations. This orthogonality yielded a reorganization in
               response correlations: the set of neurons with shared response
               properties changed completely between preparation and movement.
               Thus, the same neural population acts, at different times, as
               two separate circuits with very different properties. This
               finding is not predicted by existing motor cortical models,
               which predict overlapping preparation-related and
               movement-related subspaces. Despite orthogonality, responses in
               the preparatory subspace were lawfully related to subsequent
               responses in the movement subspace. These results reveal a
               population-level strategy for performing separate but linked
               computations.",
  journal   = "Nat. Commun.",
  publisher = "nature.com",
  volume    =  7,
  pages     = "13239",
  month     =  oct,
  year      =  2016,
  language  = "en",
  issn      = "2041-1723",
  pmid      = "27807345",
  doi       = "10.1038/ncomms13239",
  pmc       = "PMC5095296"
}

@UNPUBLISHED{De2022-th,
  title    = "Common population codes produce extremely nonlinear neural
              manifolds",
  author   = "De, Anandita and Chaudhuri, Rishidev",
  abstract = "Populations of neurons represent sensory, motor and cognitive
              variables via patterns of activity distributed across the
              population. The size of the population used to encode a variable
              is typically much greater than the dimension of the variable
              itself, and thus the corresponding neural population activity
              occupies lower-dimensional subsets of the full set of possible
              activity states. Given population activity data with such
              lower-dimensional structure, a fundamental question asks how
              close the low-dimensional data lies to a linear subspace. The
              linearity or non-linearity of the low-dimensional structure
              reflects important computational features of the encoding, such
              as robustness and generalizability. Moreover, identifying such
              linear structure underlies common data analysis methods such as
              Principal Component Analysis. Here we show that for data drawn
              from many common population codes the resulting point clouds and
              manifolds are exceedingly nonlinear, with the dimension of the
              best-fitting linear subspace growing at least exponentially with
              the true dimension of the data. Consequently, linear methods like
              Principal Component Analysis fail dramatically at identifying the
              true underlying structure, even in the limit of arbitrarily many
              data points and no noise. \#\#\# Competing Interest Statement The
              authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.09.27.509823",
  month    =  sep,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.09.27.509823"
}

@ARTICLE{Harnie2020-ec,
  title    = "The spinal control of backward locomotion",
  author   = "Harnie, Jonathan and Audet, Johannie and Klishko, Alexander N and
              Doelman, Adam and Prilutsky, Boris I and Frigon, Alain",
  abstract = "Animal locomotion requires changing direction, from forward to
              backward. Here, we tested the hypothesis that sensorimotor
              circuits within the spinal cord generate backward locomotion and
              adjust it to task demands. We collected kinematic and
              electromyography data during forward and backward locomotion at
              different treadmill speeds before and after complete spinal
              transection in six adult cats (3 males and 3 females). After
              spinal transection, 5/6 cats performed backward locomotion, which
              required tonic somatosensory input in the form of perineal
              stimulation. One spinal cat performed forward locomotion but not
              backward locomotion while two others stepped backward but not
              forward. Spatiotemporal adjustments to increasing speed were
              similar in intact and spinal cats during backward locomotion and
              strategies were similar to forward locomotion, with shorter cycle
              and stance durations and longer stride lengths. Patterns of
              muscle activations, including muscle synergies, were similar for
              forward and backward locomotion in spinal cats. Indeed, we
              identified five muscle synergies that were similar during forward
              and backward locomotion. Lastly, spinal cats also stepped
              backward on a split-belt treadmill, with the left and right
              hindlimbs stepping at different speeds. Therefore, our results
              show that spinal sensorimotor circuits generate backward
              locomotion but require additional excitability compared to
              forward locomotion. Similar strategies for speed modulation and
              similar patterns of muscle activations and muscle synergies
              during forward and backward locomotion are consistent with a
              shared spinal locomotor network, with sensory feedback from the
              limbs controlling the direction.SIGNIFICANCE STATEMENTAnimal
              locomotion requires changing direction, including forward,
              sideways and backward. This paper shows that the center
              controlling locomotion within the spinal cord can produce a
              backward pattern when instructed by sensory signals from the
              limbs. However, the spinal locomotor network requires greater
              excitability to produce backward locomotion compared to forward
              locomotion. The paper also shows that the spinal network
              controlling locomotion in the forward direction also controls
              locomotion in the backward direction.",
  journal  = "J. Neurosci.",
  month    =  nov,
  year     =  2020,
  keywords = "Locomotion",
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "33239399",
  doi      = "10.1523/JNEUROSCI.0816-20.2020"
}

@ARTICLE{Miri2017-ag,
  title    = "Behaviorally Selective Engagement of {Short-Latency} Effector
              Pathways by Motor Cortex",
  author   = "Miri, Andrew and Warriner, Claire L and Seely, Jeffrey S and
              Elsayed, Gamaleldin F and Cunningham, John P and Churchland, Mark
              M and Jessell, Thomas M",
  abstract = "Blocking motor cortical output with lesions or pharmacological
              inactivation has identified movements that require motor cortex.
              Yet, when and how motor cortex influences muscle activity during
              movement execution remains unresolved. We addressed this
              ambiguity using measurement and perturbation of motor cortical
              activity together with electromyography in mice during two
              forelimb movements that differ in their requirement for cortical
              involvement. Rapid optogenetic silencing and electrical
              stimulation indicated that short-latency pathways linking motor
              cortex with spinal motor neurons are selectively activated during
              one behavior. Analysis of motor cortical activity revealed a
              dramatic change between behaviors in the coordination of firing
              patterns across neurons that could account for this differential
              influence. Thus, our results suggest that changes in motor
              cortical output patterns enable a behaviorally selective
              engagement of short-latency effector pathways. The model of motor
              cortical influence implied by our findings helps reconcile
              previous observations on the function of motor cortex.",
  journal  = "Neuron",
  volume   =  95,
  number   =  3,
  pages    = "683--696.e11",
  month    =  aug,
  year     =  2017,
  keywords = "channelrhodopsin; motor cortex; mouse; neural dynamics; neural
              recording",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "28735748",
  doi      = "10.1016/j.neuron.2017.06.042",
  pmc      = "PMC5593145"
}

@ARTICLE{Russo2020-ix,
  title     = "Neural Trajectories in the Supplementary Motor Area and Motor
               Cortex Exhibit Distinct Geometries, Compatible with Different
               Classes of Computation",
  author    = "Russo, Abigail A and Khajeh, Ramin and Bittner, Sean R and
               Perkins, Sean M and Cunningham, John P and Abbott, L F and
               Churchland, Mark M",
  abstract  = "The supplementary motor area (SMA) is believed to contribute to
               higher order aspects of motor control. We considered a key
               higher order role: tracking progress throughout an action. We
               propose that doing so requires population activity to display
               low ``trajectory divergence'': situations with different future
               motor outputs should be distinct, even when present motor output
               is identical. We examined neural activity in SMA and primary
               motor cortex (M1) as monkeys cycled various distances through a
               virtual environment. SMA exhibited multiple response features
               that were absent in M1. At the single-neuron level, these
               included ramping firing rates and cycle-specific responses. At
               the population level, they included a helical
               population-trajectory geometry with shifts in the occupied
               subspace as movement unfolded. These diverse features all served
               to reduce trajectory divergence, which was much lower in SMA
               versus M1. Analogous population-trajectory geometry, also with
               low divergence, naturally arose in networks trained to
               internally guide multi-cycle movement.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  107,
  number    =  4,
  pages     = "745--758.e6",
  month     =  aug,
  year      =  2020,
  keywords  = "motor control; motor cortex; neural computation; neural
               dynamics; population coding; population geometry; recurrent
               neural network; supplementary motor area;RNN",
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "32516573",
  doi       = "10.1016/j.neuron.2020.05.020"
}

@ARTICLE{Gupta2021-mn,
  title         = "Embodied Intelligence via Learning and Evolution",
  author        = "Gupta, Agrim and Savarese, Silvio and Ganguli, Surya and
                   Fei-Fei, Li",
  abstract      = "The intertwined processes of learning and evolution in
                   complex environmental niches have resulted in a remarkable
                   diversity of morphological forms. Moreover, many aspects of
                   animal intelligence are deeply embodied in these evolved
                   morphologies. However, the principles governing relations
                   between environmental complexity, evolved morphology, and
                   the learnability of intelligent control, remain elusive,
                   partially due to the substantial challenge of performing
                   large-scale in silico experiments on evolution and learning.
                   We introduce Deep Evolutionary Reinforcement Learning
                   (DERL): a novel computational framework which can evolve
                   diverse agent morphologies to learn challenging locomotion
                   and manipulation tasks in complex environments using only
                   low level egocentric sensory information. Leveraging DERL we
                   demonstrate several relations between environmental
                   complexity, morphological intelligence and the learnability
                   of control. First, environmental complexity fosters the
                   evolution of morphological intelligence as quantified by the
                   ability of a morphology to facilitate the learning of novel
                   tasks. Second, evolution rapidly selects morphologies that
                   learn faster, thereby enabling behaviors learned late in the
                   lifetime of early ancestors to be expressed early in the
                   lifetime of their descendants. In agents that learn and
                   evolve in complex environments, this result constitutes the
                   first demonstration of a long-conjectured morphological
                   Baldwin effect. Third, our experiments suggest a mechanistic
                   basis for both the Baldwin effect and the emergence of
                   morphological intelligence through the evolution of
                   morphologies that are more physically stable and energy
                   efficient, and can therefore facilitate learning and
                   control.",
  month         =  feb,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2102.02202",
  primaryClass  = "cs.LG",
  arxivid       = "2102.02202"
}

@ARTICLE{Remington2018-im,
  title     = "Flexible Sensorimotor Computations through Rapid Reconfiguration
               of Cortical Dynamics",
  author    = "Remington, E D and Narain, D and Hosseini, E A and Jazayeri, M",
  abstract  = "Neural mechanisms that support flexible sensorimotor
               computations are not well understood. In a dynamical system
               whose state is determined by interactions among neurons,
               computations can be rapidly reconfigured by controlling the
               system's inputs and initial conditions. To investigate whether
               the brain employs such control mechanisms, we recorded from the
               dorsomedial frontal cortex of monkeys trained to measure and
               produce time intervals in two sensorimotor contexts. The
               geometry of neural trajectories during the production epoch was
               consistent with a mechanism wherein the measured interval and
               sensorimotor context exerted control over cortical dynamics by
               adjusting the system's initial condition and input,
               respectively. These adjustments, in turn, set the speed at which
               activity evolved in the production epoch, allowing the animal to
               flexibly produce different time intervals. These results provide
               evidence that the language of dynamical systems can be used to
               parsimoniously link brain activity to sensorimotor computations.
               Remington et al. employ a dynamical systems perspective to
               understand how the brain flexibly controls timed movements.
               Results suggest that neurons in the frontal cortex form a
               recurrent network whose behavior is flexibly controlled by
               inputs and initial conditions. \copyright{} 2018 Elsevier Inc.",
  journal   = "Neuron",
  publisher = "Cell Press",
  volume    =  98,
  number    =  5,
  pages     = "1005--1019.e5",
  year      =  2018,
  keywords  = "cognitive flexibility; Dynamical Systems; electrophysiology;
               frontal cortex; motor planning; population coding; recurrent
               neural networks; sensorimotor coordination; timing; Article;
               cognition; computational fluid dynamics; controlled study;
               cortical dynamics; dorsomedial prefrontal cortex; Haplorhini;
               medial frontal cortex; mental task; nerve cell network;
               nonhuman; priority journal; sensorimotor function; task
               performance; animal; artificial neural network; brain cortex;
               cognition; electroencephalography; female; frontal lobe; male;
               nerve cell; physiology; rhesus monkey; sensorimotor cortex;
               system analysis; time factor; Animals; Cerebral Cortex;
               Cognition; Electroencephalography; Female; Frontal Lobe; Macaca
               mulatta; Male; Neural Networks (Computer); Neurons; Sensorimotor
               Cortex; Systems Analysis; Task Performance and Analysis; Time
               Factors",
  issn      = "0896-6273",
  doi       = "10.1016/j.neuron.2018.05.020",
  pmc       = "29879384"
}

@INPROCEEDINGS{Sarkar1993-ju,
  title     = "Dynamic path following: a new control algorithm for mobile
               robots",
  booktitle = "Proceedings of 32nd {IEEE} Conference on Decision and Control",
  author    = "Sarkar, N and {Xiaoping Yun} and Kumar, V",
  abstract  = "A new algorithm for the control of wheeled mobile robots called
               dynamic path following is presented. This algorithm regulates
               the motion of the mobile robots to desired geometric paths as
               opposed to desired trajectories which are given as time
               histories in conventional trajectory tracking algorithms. The
               desired trajectory for the dynamic path following algorithm is
               parameterized by a convenient geometrical parameter (e.g., arc
               length of the path). The algorithm is designed by using a
               nonlinear feedback for input-output linearization and
               decoupling. The performance of this new algorithm is compared
               with that of the trajectory tracking algorithm and is evaluated
               under different initial conditions as well as in the presence of
               various uncertainties using computer simulations.",
  publisher = "ieeexplore.ieee.org",
  pages     = "2670--2675 vol.3",
  month     =  dec,
  year      =  1993,
  keywords  = "mobile robots;path planning;feedback;position control;nonlinear
               control systems;linearisation techniques;tracking;dynamic path
               following;wheeled mobile robots;geometric paths;nonlinear
               feedback;input-output linearization;decoupling;initial
               conditions;Mobile robots;Vehicle
               dynamics;Trajectory;Equations;History;Algorithm design and
               analysis;Computer simulation;Control systems;Feedback
               control;Wheels",
  doi       = "10.1109/CDC.1993.325681"
}

@ARTICLE{Shojaei2011-cv,
  title     = "Adaptive trajectory tracking control of a differential drive
               wheeled mobile robot",
  author    = "Shojaei, Khoshnam and Shahri, Alireza Mohammad and Tarakameh,
               Ahmadreza and Tabibian, Behzad",
  abstract  = "SUMMARYThis paper presents an adaptive trajectory tracking
               controller for a non-holonomic wheeled mobile robot (WMR) in the
               presence of parametric uncertainty in the kinematic and dynamic
               models of the WMR and actuator dynamics. The adaptive non-linear
               control law is designed based on input--output feedback
               linearization technique to get asymptotically exact cancellation
               for the uncertainty in the given system parameters. In order to
               evaluate the performance of the proposed controller, a
               non-adaptive controller is compared with the adaptive controller
               via computer simulation results. The results show satisfactory
               trajectory tracking performance by virtue of SPR-Lyapunov design
               approach. In order to verify the simulation results, a set of
               experiments have been carried out on a commercial mobile robot.
               The experimental results also show the effectiveness of the
               proposed controller.",
  journal   = "Robotica",
  publisher = "Cambridge University Press (CUP)",
  volume    =  29,
  number    =  3,
  pages     = "391--402",
  month     =  may,
  year      =  2011,
  keywords  = "control",
  language  = "en",
  issn      = "0263-5747, 1469-8668",
  doi       = "10.1017/s0263574710000202"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Park2007-br,
  title     = "Performance and Lyapunov Stability of a Nonlinear Path Following
               Guidance Method",
  author    = "Park, Sanghyuk and Deyst, John and How, Jonathan P",
  abstract  = "… 5, No. 2/3. Indoor low-cost localization system for
               controlling aerial robots. Control Engineering Practice, Vol …
               3D Path - Following Algorithms for Unmanned Aerial Vehicles
               Adjusted with Genetic Algorithm . 12 July 2017. Introduction.
               Experimental Test of Unmanned …",
  journal   = "J. Guid. Control Dyn.",
  publisher = "American Institute of Aeronautics and Astronautics",
  volume    =  30,
  number    =  6,
  pages     = "1718--1728",
  month     =  nov,
  year      =  2007,
  issn      = "0731-5090",
  doi       = "10.2514/1.28957"
}

@ARTICLE{Zingg2014-se,
  title    = "Neural networks of the mouse neocortex",
  author   = "Zingg, Brian and Hintiryan, Houri and Gou, Lin and Song, Monica Y
              and Bay, Maxwell and Bienkowski, Michael S and Foster, Nicholas N
              and Yamashita, Seita and Bowman, Ian and Toga, Arthur W and Dong,
              Hong-Wei",
  abstract = "Numerous studies have examined the neuronal inputs and outputs of
              many areas within the mammalian cerebral cortex, but how these
              areas are organized into neural networks that communicate across
              the entire cortex is unclear. Over 600 labeled neuronal pathways
              acquired from tracer injections placed across the entire mouse
              neocortex enabled us to generate a cortical connectivity atlas. A
              total of 240 intracortical connections were manually
              reconstructed within a common neuroanatomic framework, forming a
              cortico-cortical connectivity map that facilitates comparison of
              connections from different cortical targets. Connectivity
              matrices were generated to provide an overview of all
              intracortical connections and subnetwork clusterings. The
              connectivity matrices and cortical map revealed that the entire
              cortex is organized into four somatic sensorimotor, two medial,
              and two lateral subnetworks that display unique topologies and
              can interact through select cortical areas. Together, these data
              provide a resource that can be used to further investigate
              cortical networks and their corresponding functions.",
  journal  = "Cell",
  volume   =  156,
  number   =  5,
  pages    = "1096--1111",
  month    =  feb,
  year     =  2014,
  language = "en",
  issn     = "0092-8674, 1097-4172",
  pmid     = "24581503",
  doi      = "10.1016/j.cell.2014.02.023",
  pmc      = "PMC4169118"
}

@ARTICLE{Raposo2014-xz,
  title     = "A category-free neural population supports evolving demands
               during decision-making",
  author    = "Raposo, David and Kaufman, Matthew T and Churchland, Anne K",
  abstract  = "The posterior parietal cortex (PPC) receives diverse inputs and
               is involved in a dizzying array of behaviors. These many
               behaviors could rely on distinct categories of neurons
               specialized to represent particular variables or could rely on a
               single population of PPC neurons that is leveraged in different
               ways. To distinguish these possibilities, we evaluated rat PPC
               neurons recorded during multisensory decisions. Newly designed
               tests revealed that task parameters and temporal response
               features were distributed randomly across neurons, without
               evidence of categories. This suggests that PPC neurons
               constitute a dynamic network that is decoded according to the
               animal's present needs. To test for an additional signature of a
               dynamic network, we compared moments when behavioral demands
               differed: decision and movement. Our new state-space analysis
               revealed that the network explored different dimensions during
               decision and movement. These observations suggest that a single
               network of neurons can support the evolving behavioral demands
               of decision-making.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  17,
  number    =  12,
  pages     = "1784--1792",
  month     =  dec,
  year      =  2014,
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "25383902",
  doi       = "10.1038/nn.3865",
  pmc       = "PMC4294797"
}

@UNPUBLISHED{Ehrlich2021-hh,
  title    = "Geometry of neural computation unifies working memory and
              planning",
  author   = "Ehrlich, Daniel B and Murray, John D",
  abstract = "Real-world tasks require coordination of working memory, decision
              making, and planning, yet these cognitive functions have
              disproportionately been studied as independent modular processes
              in the brain. Here we propose that contingency representations,
              defined as mappings for how future behaviors depend on upcoming
              events, can unify working memory and planning computations. We
              designed a task capable of disambiguating distinct types of
              representations. Our experiments revealed that human behavior is
              consistent with contingency representations, and not with
              traditional sensory models of working memory. In task-optimized
              recurrent neural networks we investigated possible circuit
              mechanisms for contingency representations and found that these
              representations can explain neurophysiological observations from
              prefrontal cortex during working memory tasks. Finally, we
              generated falsifiable predictions for neural data to identify
              contingency representations in neural data and to dissociate
              different models of working memory. Our findings characterize a
              neural representational strategy that can unify working memory,
              planning, and context-dependent decision making. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.02.01.429156",
  month    =  feb,
  year     =  2021,
  keywords = "RNN",
  language = "en",
  doi      = "10.1101/2021.02.01.429156"
}

@UNPUBLISHED{Saxena2021-tj,
  title    = "Motor cortex activity across movement speeds is predicted by
              network-level strategies for generating muscle activity",
  author   = "Saxena, Shreya and Russo, Abigail and Cunningham, John and
              Churchland, Mark M",
  abstract = "Learned movements can be skillfully performed at different paces.
              What neural strategies produce this flexibility? Can they be
              predicted and understood by network modeling? We trained monkeys
              to perform a cycling task at different speeds, and trained
              artificial recurrent networks to generate the empirical
              muscle-activity patterns. Network solutions reflected the
              principle that smooth well-behaved dynamics require low
              trajectory tangling, and yielded quantitative and qualitative
              predictions. To evaluate predictions, we recorded motor cortex
              population activity during the same task. Responses supported the
              hypothesis that the dominant neural signals reflect not muscle
              activity, but network-level strategies for generating muscle
              activity. Single-neuron responses were better accounted for by
              network activity than by muscle activity. Similarly, neural
              population trajectories shared their organization not with muscle
              trajectories, but with network solutions. Thus, cortical activity
              could be understood based on the need to generate muscle activity
              via dynamics that allow smooth, robust control over movement
              speed. \#\#\# Competing Interest Statement The authors have
              declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.02.01.429168",
  month    =  feb,
  year     =  2021,
  keywords = "RNN",
  language = "en",
  doi      = "10.1101/2021.02.01.429168"
}

@UNPUBLISHED{Olson2021-dh,
  title    = "Complementary Maps for Location and Environmental Structure in
              {CA1} and Subiculum",
  author   = "Olson, Jacob M and Johnson, Alexander B and Chang, Lillian and
              Tao, Emily L and Wang, Xuefei and Nitz, Douglas A",
  abstract = "The dorsal subiculum lies among a network of interconnected brain
              regions that collectively map multiple spatial and orientational
              relationships between an organism and the boundaries and pathways
              composing its environment. A unique role of the subiculum in
              spatial information processing has yet to be defined despite
              reports of small neuron subpopulations that encode relationships
              to specific boundaries, axes of travel, or locations. We examined
              the activity patterns among populations of subiculum neurons
              during performance of a spatial working memory task performed
              within a complex network of interconnected pathways. Compared to
              neurons in hippocampal sub-region CA1, a major source of its
              afferents, subiculum neurons were far more likely to exhibit
              multiple firing fields at locations that were analogous with
              respect to path structure and function. Subiculum neuron
              populations were also found to exhibit a greater dynamic range in
              scale of spatial representation and for persistent patterns of
              spiking activity to be aligned to transitions between maze
              segments. Together, the findings indicate that the subiculum
              plays a unique role in spatial mapping, one that complements the
              location-specific firing of CA1 neurons with the encoding of
              emergent and recurring structural features of a complex path
              network. \#\#\# Competing Interest Statement The authors have
              declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.02.01.428537",
  month    =  feb,
  year     =  2021,
  keywords = "navigation",
  language = "en",
  doi      = "10.1101/2021.02.01.428537"
}

@ARTICLE{Wong2006-os,
  title    = "A recurrent network mechanism of time integration in perceptual
              decisions",
  author   = "Wong, Kong-Fatt and Wang, Xiao-Jing",
  abstract = "Recent physiological studies using behaving monkeys revealed
              that, in a two-alternative forced-choice visual motion
              discrimination task, reaction time was correlated with ramping of
              spike activity of lateral intraparietal cortical neurons. The
              ramping activity appears to reflect temporal accumulation, on a
              timescale of hundreds of milliseconds, of sensory evidence before
              a decision is reached. To elucidate the cellular and circuit
              basis of such integration times, we developed and investigated a
              simplified two-variable version of a biophysically realistic
              cortical network model of decision making. In this model, slow
              time integration can be achieved robustly if excitatory
              reverberation is primarily mediated by NMDA receptors; our model
              with only fast AMPA receptors at recurrent synapses produces
              decision times that are not comparable with experimental
              observations. Moreover, we found two distinct modes of network
              behavior, in which decision computation by winner-take-all
              competition is instantiated with or without attractor states for
              working memory. Decision process is closely linked to the local
              dynamics, in the ``decision space'' of the system, in the
              vicinity of an unstable saddle steady state that separates the
              basins of attraction for the two alternative choices. This
              picture provides a rigorous and quantitative explanation for the
              dependence of performance and response time on the degree of task
              difficulty, and the reason for which reaction times are longer in
              error trials than in correct trials as observed in the monkey
              experiment. Our reduced two-variable neural model offers a simple
              yet biophysically plausible framework for studying perceptual
              decision making in general.",
  journal  = "J. Neurosci.",
  volume   =  26,
  number   =  4,
  pages    = "1314--1328",
  month    =  jan,
  year     =  2006,
  keywords = "RNN",
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "16436619",
  doi      = "10.1523/JNEUROSCI.3733-05.2006",
  pmc      = "PMC6674568"
}

@ARTICLE{Hennequin2014-vj,
  title    = "Optimal control of transient dynamics in balanced networks
              supports generation of complex movements",
  author   = "Hennequin, Guillaume and Vogels, Tim P and Gerstner, Wulfram",
  abstract = "Populations of neurons in motor cortex engage in complex
              transient dynamics of large amplitude during the execution of
              limb movements. Traditional network models with stochastically
              assigned synapses cannot reproduce this behavior. Here we
              introduce a class of cortical architectures with strong and
              random excitatory recurrence that is stabilized by intricate,
              fine-tuned inhibition, optimized from a control theory
              perspective. Such networks transiently amplify specific activity
              states and can be used to reliably execute multidimensional
              movement patterns. Similar to the experimental observations,
              these transients must be preceded by a steady-state
              initialization phase from which the network relaxes back into the
              background state by way of complex internal dynamics. In our
              networks, excitation and inhibition are as tightly balanced as
              recently reported in experiments across several brain areas,
              suggesting inhibitory control of complex excitatory recurrence as
              a generic organizational principle in cortex.",
  journal  = "Neuron",
  volume   =  82,
  number   =  6,
  pages    = "1394--1406",
  month    =  jun,
  year     =  2014,
  keywords = "RNN",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "24945778",
  doi      = "10.1016/j.neuron.2014.04.045",
  pmc      = "PMC6364799"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Shenoy2021-nh,
  title     = "Measurement, manipulation and modeling of brain-wide neural
               population dynamics",
  author    = "Shenoy, Krishna V and Kao, Jonathan C",
  abstract  = "… Neural recording technologies increasingly enable simultaneous
               measurement of neural activity from multiple brain areas … We
               discuss two opportunities towards this end: the manipulation and
               modeling of neural population dynamics … Manipulating neural
               dynamics …",
  journal   = "Nat. Commun.",
  publisher = "nature.com",
  volume    =  12,
  number    =  1,
  pages     = "633",
  month     =  jan,
  year      =  2021,
  language  = "en",
  issn      = "2041-1723",
  pmid      = "33504773",
  doi       = "10.1038/s41467-020-20371-1",
  pmc       = "PMC7840924"
}

@ARTICLE{Scholle2005-vz,
  title     = "A surface {EMG} multi-electrode technique for characterizing
               muscle activation patterns in mice during treadmill locomotion",
  author    = "Scholle, Hans Christoph and Biedermann, Frank and Arnold, Dirk
               and Jinnah, Hyder Azad and Grassme, Roland and Schumann,
               Nikolaus Peter",
  abstract  = "In mice a new method for 2x4-channel surface electromyography
               (EMG) recordings of the vastus lateralis and biceps femoris
               muscles during locomotion on a treadmill with varying speed is
               presented. The approach involves high-speed-videography
               (sampling interval 2.5 ms) in concert with the application of
               chronically implanted surface EMG multi-electrodes (EMG sampling
               rate 4000 Hz, frequency range 10-700 Hz). The recordings are
               started 2 days after surgery and finished 2 weeks after surgery.
               During the whole investigation period EMG recordings of both
               muscles have been possible. The monopolar EMG activities
               recorded by the electrode-arrays and the bipolar EMG signals
               derived from the monopolar activities permit an evaluation of
               the extent of myo-electrical activation in larger regions of
               both muscles and co-ordination between the flexor and extensor
               muscles. Bipolar EMG signals indicate propagation of activities
               along the muscle fibers and a slight effect of non-propagating
               signal components. Thus, the cross talk between these muscles is
               small and does not influence the evaluation of the EMG results.
               The resolution of the simultaneously recorded synchronized data
               allows a precise temporal correlation of kinematic and EMG
               parameters.",
  journal   = "J. Neurosci. Methods",
  publisher = "Elsevier",
  volume    =  146,
  number    =  2,
  pages     = "174--182",
  month     =  aug,
  year      =  2005,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "0165-0270",
  pmid      = "16054507",
  doi       = "10.1016/j.jneumeth.2005.02.006"
}

@ARTICLE{Foster2014-hn,
  title     = "A freely-moving monkey treadmill model",
  author    = "Foster, Justin D and Nuyujukian, Paul and Freifeld, Oren and
               Gao, Hua and Walker, Ross and I Ryu, Stephen and H Meng, Teresa
               and Murmann, Boris and J Black, Michael and Shenoy, Krishna V",
  abstract  = "OBJECTIVE: Motor neuroscience and brain-machine interface (BMI)
               design is based on examining how the brain controls voluntary
               movement, typically by recording neural activity and behavior
               from animal models. Recording technologies used with these
               animal models have traditionally limited the range of behaviors
               that can be studied, and thus the generality of science and
               engineering research. We aim to design a freely-moving animal
               model using neural and behavioral recording technologies that do
               not constrain movement. APPROACH: We have established a
               freely-moving rhesus monkey model employing technology that
               transmits neural activity from an intracortical array using a
               head-mounted device and records behavior through computer vision
               using markerless motion capture. We demonstrate the flexibility
               and utility of this new monkey model, including the first
               recordings from motor cortex while rhesus monkeys walk
               quadrupedally on a treadmill. MAIN RESULTS: Using this monkey
               model, we show that multi-unit threshold-crossing neural
               activity encodes the phase of walking and that the average
               firing rate of the threshold crossings covaries with the speed
               of individual steps. On a population level, we find that neural
               state-space trajectories of walking at different speeds have
               similar rotational dynamics in some dimensions that evolve at
               the step rate of walking, yet robustly separate by speed in
               other state-space dimensions. SIGNIFICANCE: Freely-moving animal
               models may allow neuroscientists to examine a wider range of
               behaviors and can provide a flexible experimental paradigm for
               examining the neural mechanisms that underlie movement
               generation across behaviors and environments. For BMIs,
               freely-moving animal models have the potential to aid prosthetic
               design by examining how neural encoding changes with posture,
               environment and other real-world context changes. Understanding
               this new realm of behavior in more naturalistic settings is
               essential for overall progress of basic motor neuroscience and
               for the successful translation of BMIs to people with paralysis.",
  journal   = "J. Neural Eng.",
  publisher = "iopscience.iop.org",
  volume    =  11,
  number    =  4,
  pages     = "046020",
  month     =  aug,
  year      =  2014,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "1741-2560, 1741-2552",
  pmid      = "24995476",
  doi       = "10.1088/1741-2560/11/4/046020"
}

@ARTICLE{Rigosa2015-bj,
  title    = "Decoding bipedal locomotion from the rat sensorimotor cortex",
  author   = "Rigosa, J and Panarese, A and Dominici, N and Friedli, L and van
              den Brand, R and Carpaneto, J and DiGiovanna, J and Courtine, G
              and Micera, S",
  abstract = "OBJECTIVE: Decoding forelimb movements from the firing activity
              of cortical neurons has been interfaced with robotic and
              prosthetic systems to replace lost upper limb functions in
              humans. Despite the potential of this approach to improve
              locomotion and facilitate gait rehabilitation, decoding lower
              limb movement from the motor cortex has received comparatively
              little attention. Here, we performed experiments to identify the
              type and amount of information that can be decoded from neuronal
              ensemble activity in the hindlimb area of the rat motor cortex
              during bipedal locomotor tasks. APPROACH: Rats were trained to
              stand, step on a treadmill, walk overground and climb staircases
              in a bipedal posture. To impose this gait, the rats were secured
              in a robotic interface that provided support against the
              direction of gravity and in the mediolateral direction, but
              behaved transparently in the forward direction. After completion
              of training, rats were chronically implanted with a micro-wire
              array spanning the left hindlimb motor cortex to record single
              and multi-unit activity, and bipolar electrodes into 10 muscles
              of the right hindlimb to monitor electromyographic signals.
              Whole-body kinematics, muscle activity, and neural signals were
              simultaneously recorded during execution of the trained tasks
              over multiple days of testing. Hindlimb kinematics, muscle
              activity, gait phases, and locomotor tasks were decoded using
              offline classification algorithms. MAIN RESULTS: We found that
              the stance and swing phases of gait and the locomotor tasks were
              detected with accuracies as robust as 90\% in all rats. Decoded
              hindlimb kinematics and muscle activity exhibited a larger
              variability across rats and tasks. SIGNIFICANCE: Our study shows
              that the rodent motor cortex contains useful information for
              lower limb neuroprosthetic development. However, brain-machine
              interfaces estimating gait phases or locomotor behaviors, instead
              of continuous variables such as limb joint positions or speeds,
              are likely to provide more robust control strategies for the
              design of such neuroprostheses.",
  journal  = "J. Neural Eng.",
  volume   =  12,
  number   =  5,
  pages    = "056014",
  month    =  oct,
  year     =  2015,
  keywords = "Locomotion",
  language = "en",
  issn     = "1741-2560, 1741-2552",
  pmid     = "26331532",
  doi      = "10.1088/1741-2560/12/5/056014"
}

@ARTICLE{Charles2018-ed,
  title     = "A Dynamic Simulation of Musculoskeletal Function in the Mouse
               Hindlimb During Trotting Locomotion",
  author    = "Charles, James P and Cappellari, Ornella and Hutchinson, John R",
  abstract  = "Mice are often used as animal models of various human
               neuromuscular diseases, and analysis of these models often
               requires detailed gait analysis. However, little is known of the
               dynamics of the mouse musculoskeletal system during locomotion.
               In this study, we used computer optimization procedures to
               create a simulation of trotting in a mouse, using a previously
               developed mouse hindlimb musculoskeletal model in conjunction
               with new experimental data, allowing muscle forces, activation
               patterns, and levels of mechanical work to be estimated.
               Analyzing musculotendon unit (MTU) mechanical work throughout
               the stride allowed a deeper understanding of their respective
               functions, with the rectus femoris MTU dominating the generation
               of positive and negative mechanical work during the swing and
               stance phases. This analysis also tested previous functional
               inferences of the mouse hindlimb made from anatomical data
               alone, such as the existence of a proximo-distal gradient of
               muscle function, thought to reflect adaptations for
               energy-efficient locomotion. The results do not strongly support
               the presence of this gradient within the mouse musculoskeletal
               system, particularly given relatively high negative net work
               output from the ankle plantarflexor MTUs, although more detailed
               simulations could test this further. This modeling analysis lays
               a foundation for future studies of the control of vertebrate
               movement through the development of neuromechanical simulations.",
  journal   = "Front Bioeng Biotechnol",
  publisher = "frontiersin.org",
  volume    =  6,
  pages     = "61",
  month     =  may,
  year      =  2018,
  keywords  = "biomechanics; kinematics; muscle function; muscle work;
               rodent;Locomotion",
  language  = "en",
  issn      = "2296-4185",
  pmid      = "29868576",
  doi       = "10.3389/fbioe.2018.00061",
  pmc       = "PMC5964171"
}

@INPROCEEDINGS{Jensen2020-oj,
  title     = "Adaptive control for hindlimb locomotion in a simulated mouse
               through temporal cerebellar learning",
  booktitle = "Proceedings of the Neuro-inspired Computational Elements
               Workshop",
  author    = "Jensen, T P and Tata, S and Ijspeert, A J and Tolu, S",
  abstract  = "Human beings and other vertebrates show remarkable performance
               and efficiency in locomotion, but the functioning of their
               biological control systems for locomotion is still only
               partially understood. The basic patterns and timing for
               locomotion are provided by a central pattern generator (CPG) in
               the spinal cord. The cerebellum is known to play an important
               role in adaptive locomotion. Recent studies have given insights
               into the error signals responsible for driving the cerebellar
               adaptation in locomotion. However, the question of how the
               cerebellar output influences the gait remains unanswered. We
               hypothesize that the cerebellar correction is applied to the
               pattern formation part of the CPG.Here, a bio-inspired control
               system for adaptive locomotion of the musculoskeletal system of
               the mouse is presented, where a cerebellar-like module adapts
               the step time by using the double support interlimb asymmetry as
               a temporal teaching signal. The control system is tested on a
               simulated mouse in a split-belt treadmill setup similar to those
               used in experiments with real mice.The results show adaptive
               locomotion behavior in the interlimb parameters similar to that
               seen in humans and mice. The control system adaptively decreases
               the double support asymmetry that occurs due to environmental
               perturbations in the split-belt protocol.",
  publisher = "Association for Computing Machinery",
  number    = "Article 5",
  pages     = "1--8",
  series    = "NICE '20",
  month     =  mar,
  year      =  2020,
  address   = "New York, NY, USA",
  keywords  = "Bio control, adaptive locomotion, motor control, learning
               algorithms, brain models;Locomotion",
  location  = "Heidelberg, Germany",
  isbn      = "9781450377188",
  doi       = "10.1145/3381755.3381761"
}

@ARTICLE{Manfredi2013-de,
  title    = "A bioinspired autonomous swimming robot as a tool for studying
              goal-directed locomotion",
  author   = "Manfredi, L and Assaf, T and Mintchev, S and Marrazza, S and
              Capantini, L and Orofino, S and Ascari, L and Grillner, S and
              Wall{\'e}n, P and Ekeberg, O and Stefanini, C and Dario, P",
  abstract = "The bioinspired approach has been key in combining the
              disciplines of robotics with neuroscience in an effective and
              promising fashion. Indeed, certain aspects in the field of
              neuroscience, such as goal-directed locomotion and behaviour
              selection, can be validated through robotic artefacts. In
              particular, swimming is a functionally important behaviour where
              neuromuscular structures, neural control architecture and
              operation can be replicated artificially following models from
              biology and neuroscience. In this article, we present a
              biomimetic system inspired by the lamprey, an early vertebrate
              that locomotes using anguilliform swimming. The artefact
              possesses extra- and proprioceptive sensory receptors,
              muscle-like actuation, distributed embedded control and a vision
              system. Experiments on optimised swimming and on goal-directed
              locomotion are reported, as well as the assessment of the
              performance of the system, which shows high energy efficiency and
              adaptive behaviour. While the focus is on providing a robotic
              platform for testing biological models, the reported system can
              also be of major relevance for the development of engineering
              system applications.",
  journal  = "Biol. Cybern.",
  volume   =  107,
  number   =  5,
  pages    = "513--527",
  month    =  oct,
  year     =  2013,
  language = "en",
  issn     = "0340-1200, 1432-0770",
  pmid     = "24030051",
  doi      = "10.1007/s00422-013-0566-2"
}

@ARTICLE{Yu2007-bq,
  title    = "Mixture of trajectory models for neural decoding of goal-directed
              movements",
  author   = "Yu, Byron M and Kemere, Caleb and Santhanam, Gopal and Afshar,
              Afsheen and Ryu, Stephen I and Meng, Teresa H and Sahani, Maneesh
              and Shenoy, Krishna V",
  abstract = "Probabilistic decoding techniques have been used successfully to
              infer time-evolving physical state, such as arm trajectory or the
              path of a foraging rat, from neural data. A vital element of such
              decoders is the trajectory model, expressing knowledge about the
              statistical regularities of the movements. Unfortunately,
              trajectory models that both 1) accurately describe the movement
              statistics and 2) admit decoders with relatively low
              computational demands can be hard to construct. Simple models are
              computationally inexpensive, but often inaccurate. More complex
              models may gain accuracy, but at the expense of higher
              computational cost, hindering their use for real-time decoding.
              Here, we present a new general approach to defining trajectory
              models that simultaneously meets both requirements. The core idea
              is to combine simple trajectory models, each accurate within a
              limited regime of movement, in a probabilistic mixture of
              trajectory models (MTM). We demonstrate the utility of the
              approach by using an MTM decoder to infer goal-directed reaching
              movements to multiple discrete goals from multi-electrode neural
              data recorded in monkey motor and premotor cortex. Compared with
              decoders using simpler trajectory models, the MTM decoder reduced
              the decoding error by 38 (48) percent in two monkeys using 98
              (99) units, without a necessary increase in running time. When
              available, prior information about the identity of the upcoming
              reach goal can be incorporated in a principled way, further
              reducing the decoding error by 20 (11) percent. Taken together,
              these advances should allow prosthetic cursors or limbs to be
              moved more accurately toward intended reach goals.",
  journal  = "J. Neurophysiol.",
  volume   =  97,
  number   =  5,
  pages    = "3763--3780",
  month    =  may,
  year     =  2007,
  language = "en",
  issn     = "0022-3077",
  pmid     = "17329627",
  doi      = "10.1152/jn.00482.2006"
}

@INPROCEEDINGS{Kuffner1998-nd,
  title     = "{Goal-Directed} Navigation for Animated Characters Using
               {Real-Time} Path Planning and Control",
  booktitle = "Modelling and Motion Capture Techniques for Virtual Environments",
  author    = "Kuffner, James J",
  abstract  = "This paper presents a new technique for computing collision-free
               navigation motions from task-level commands for animated human
               characters in interactive virtual environments. The algorithm
               implementation utilizes the hardware rendering pipeline commonly
               found on graphics accelerator cards to perform fast 2D motion
               planning. Given a 3D geometric description of an animated
               character and a level-terrain environment, collision-free
               navigation paths can be computed between initial and goal
               locations at interactive rates. Speed is gained by leveraging
               the graphics hardware to quickly project the obstacle geometry
               into a 2D bitmap for planning. The bitmap may be searched by any
               number of standard dynamic programming techniques to produce a
               final path. Cyclic motion capture data is used along with a
               simple proportional derivative controller to animate the
               character as it follows the computed path. The technique has
               been implemented on an SGI Indigo2 workstation and runs at
               interactive rates. It allows for real-time modification of the
               goal locations and obstacle positions for multiple characters in
               complex environments composed of more than 15,000 triangles.",
  publisher = "Springer Berlin Heidelberg",
  pages     = "171--186",
  year      =  1998,
  keywords  = "navigation",
  doi       = "10.1007/3-540-49384-0\_14"
}

@ARTICLE{Santos2012-oz,
  title    = "{CPG} modulation for navigation and omnidirectional quadruped
              locomotion",
  author   = "Santos, Cristina P and Matos, V{\'\i}tor",
  abstract = "Navigation in biological mechanisms represents a set of skills
              needed for the survival of individuals, including target
              acquisition and obstacle avoidance. In this article, we focus on
              the development of a quadruped locomotion controller able to
              generate omnidirectional locomotion and a path planning
              controller for heading direction. The heading direction
              controller is able to adapt to sensory-motor visual feedback, and
              online adapt its trajectory according to visual information that
              modifies the control parameters. This allows for integration of
              sensory-motor feedback and closed-loop control. This issue is
              crucial for autonomous and adaptive control, and has received
              little attention so far. This modeling is based on the concept of
              dynamical systems. We present experiments performed on a real
              AIBO platform. The obtained results demonstrate both the adequacy
              of the proposed locomotor controller to generate the required
              trajectories and to generate the desired movement in terms of the
              walking velocity, orientation and angular velocity. Further, the
              controller is demonstrated on a simulated quadruped robot which
              walks towards a visually acquired target while avoiding
              online-visually detected obstacles in its path.",
  journal  = "Rob. Auton. Syst.",
  volume   =  60,
  number   =  6,
  pages    = "912--927",
  month    =  jun,
  year     =  2012,
  keywords = "CPGs; Autonomous robots; Quadruped locomotion; Omnidirectional
              locomotion; Architecture bio-inspired",
  issn     = "0921-8890",
  doi      = "10.1016/j.robot.2012.01.004"
}

@INCOLLECTION{Grillner2007-iq,
  title     = "Modeling a vertebrate motor system: pattern generation, steering
               and control of body orientation",
  booktitle = "Progress in Brain Research",
  author    = "Grillner, Sten and Kozlov, Alexander and Dario, Paolo and
               Stefanini, Cesare and Menciassi, Arianna and Lansner, Anders and
               Hellgren Kotaleski, Jeanette",
  editor    = "Cisek, Paul and Drew, Trevor and Kalaska, John F",
  abstract  = "The lamprey is one of the few vertebrates in which the neural
               control system for goal-directed locomotion including steering
               and control of body orientation is well described at a cellular
               level. In this report we review the modeling of the central
               pattern-generating network, which has been carried out based on
               detailed experimentation. In the same way the modeling of the
               control system for steering and control of body orientation is
               reviewed, including neuromechanical simulations and robotic
               devices.",
  publisher = "Elsevier",
  volume    =  165,
  pages     = "221--234",
  month     =  jan,
  year      =  2007,
  keywords  = "locomotor network; lamprey; spinal cord; modeling; steering;
               robot",
  doi       = "10.1016/S0079-6123(06)65014-0"
}

@ARTICLE{Happee1994-rq,
  title    = "Inverse dynamic optimization including muscular dynamics, a new
              simulation method applied to goal directed movements",
  author   = "Happee, R",
  abstract = "This paper presents a new method for estimating muscular force
              and activation from experimental kinematic data. The method
              combines conventional inverse dynamics with optimization
              utilizing a dynamic muscle model. The method uses only very
              limited computational power, which makes it a useful tool
              especially for complex systems like the shoulder or the locomotor
              system. The net torques/forces are calculated by using
              conventional inverse dynamics. A solution of the load sharing
              problem is determined by minimization of the weighted sum of
              squared muscle forces. The load sharing problem is solved with a
              dynamic constraint reflecting physiological muscle properties.
              This constraint takes into account the nonlinear dynamics of the
              contractile element (CE) and the series elastic element (SE),
              active state dynamics and neural excitation dynamics. This
              physiological constraint is determined with an inverse muscle
              model. With this model, muscular states and neural inputs are
              also estimated. The method of inverse dynamics requires position,
              velocity and acceleration signals as input. A method to prepare
              such signals from noisy measured data is presented.",
  journal  = "J. Biomech.",
  volume   =  27,
  number   =  7,
  pages    = "953--960",
  month    =  jul,
  year     =  1994,
  keywords = "Locomotion",
  language = "en",
  issn     = "0021-9290",
  pmid     = "8063845",
  doi      = "10.1016/0021-9290(94)90267-4"
}

@UNPUBLISHED{Ali2021-wu,
  title    = "Predictive coding is a consequence of energy efficiency in
              recurrent neural networks",
  author   = "Ali, Abdullahi and Ahmad, Nasir and de Groot, Elgar and van
              Gerven, Marcel A J and Kietzmann, Tim C",
  abstract = "Predictive coding represents a promising framework for
              understanding brain function. It postulates that the brain
              continuously inhibits predictable sensory input, ensuring a
              preferential processing of surprising elements. A central aspect
              of this view is its hierarchical connectivity, involving
              recurrent message passing between excitatory bottom-up signals
              and inhibitory top-down feedback. Here we use computational
              modelling to demonstrate that such architectural hard-wiring is
              not necessary. Rather, predictive coding is shown to emerge as a
              consequence of energy efficiency. When training recurrent neural
              networks to minimise their energy consumption while operating in
              predictive environments, the networks self-organise into
              prediction and error units with appropriate inhibitory and
              excitatory interconnections, and learn to inhibit predictable
              sensory input. Moving beyond the view of purely top-down driven
              predictions, we demonstrate via virtual lesioning experiments
              that networks perform predictions on two timescales: fast lateral
              predictions among sensory units, and slower prediction cycles
              that integrate evidence over time. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.02.16.430904",
  month    =  feb,
  year     =  2021,
  keywords = "RNN",
  language = "en",
  doi      = "10.1101/2021.02.16.430904"
}

@ARTICLE{Darmohray2019-co,
  title     = "Spatial and Temporal Locomotor Learning in Mouse Cerebellum",
  author    = "Darmohray, Dana M and Jacobs, Jovin R and Marques, Hugo G and
               Carey, Megan R",
  abstract  = "Stable and efficient locomotion requires the precise
               coordination of movement across the limbs and body. Learned
               changes in interlimb coordination can be induced by exposure to
               a split-belt treadmill that imposes different speeds under each
               side of the body. Here, we demonstrate locomotor learning on a
               split-belt treadmill in mice. Mouse locomotor adaptation is
               specific to measures of interlimb coordination, has spatial and
               temporal components that adapt at different rates, and is
               context specific. The many similarities between human and mouse
               locomotor adaptation suggest that this form of locomotor
               learning is highly conserved across vertebrates. Using a variety
               of approaches, we demonstrate that split-belt adaptation in mice
               specifically depends on the intermediate cerebellum but is
               insensitive to large lesions of the cerebral cortex. Finally,
               cell-type-specific chemogenetics combined with quantitative
               behavioral analysis reveals that spatial and temporal components
               of locomotor adaptation are dissociable on the circuit level.
               VIDEO ABSTRACT.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  102,
  number    =  1,
  pages     = "217--231.e4",
  month     =  apr,
  year      =  2019,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "30795901",
  doi       = "10.1016/j.neuron.2019.01.038"
}

@ARTICLE{Hagglund2010-rq,
  title    = "Activation of groups of excitatory neurons in the mammalian
              spinal cord or hindbrain evokes locomotion",
  author   = "H{\"a}gglund, Martin and Borgius, Lotta and Dougherty, Kimberly J
              and Kiehn, Ole",
  abstract = "Central pattern generators (CPGs) are spinal neuronal networks
              required for locomotion. Glutamatergic neurons have been
              implicated as being important for intrinsic rhythm generation in
              the CPG and for the command signal for initiating locomotion,
              although this has not been demonstrated directly. We used a newly
              generated vesicular glutamate transporter
              2-channelrhodopsin2-yellow fluorescent protein (Vglut2-ChR2-YFP)
              mouse to directly examine the functional role of glutamatergic
              neurons in rhythm generation and initiation of locomotion. This
              mouse line expressed ChR2-YFP in the spinal cord and hindbrain.
              ChR2-YFP was reliably expressed in Vglut2-positive cells and
              YFP-expressing cells could be activated by light.
              Photo-stimulation of either the lumbar spinal cord or the caudal
              hindbrain was sufficient to both initiate and maintain
              locomotor-like activity. Our results indicate that glutamatergic
              neurons in the spinal cord are critical for initiating or
              maintaining the rhythm and that activation of hindbrain areas
              containing the locomotor command regions is sufficient to
              directly activate the spinal locomotor network.",
  journal  = "Nat. Neurosci.",
  volume   =  13,
  number   =  2,
  pages    = "246--252",
  month    =  feb,
  year     =  2010,
  keywords = "Locomotion",
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "20081850",
  doi      = "10.1038/nn.2482"
}

@ARTICLE{McLean2015-xv,
  title    = "Peeling back the layers of locomotor control in the spinal cord",
  author   = "McLean, David L and Dougherty, Kimberly J",
  abstract = "Vertebrate locomotion is executed by networks of neurons within
              the spinal cord. Here, we describe recent advances in our
              understanding of spinal locomotor control provided by work using
              optical and genetic approaches in mice and zebrafish. In
              particular, we highlight common observations that demonstrate
              simplification of limb and axial motor pool coordination by
              spinal network modularity, differences in the deployment of
              spinal modules at increasing speeds of locomotion, and functional
              hierarchies in the regulation of locomotor rhythm and pattern. We
              also discuss the promise of intersectional genetic strategies for
              better resolution of network components and connectivity, which
              should help us continue to close the gap between theory and
              function.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  33,
  pages    = "63--70",
  month    =  aug,
  year     =  2015,
  keywords = "Locomotion",
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "25820136",
  doi      = "10.1016/j.conb.2015.03.001",
  pmc      = "PMC4523447"
}

@ARTICLE{Todorov2002-xo,
  title     = "Optimal feedback control as a theory of motor coordination",
  author    = "Todorov, Emanuel and Jordan, Michael I",
  abstract  = "A central problem in motor control is understanding how the many
               biomechanical degrees of freedom are coordinated to achieve a
               common goal. An especially puzzling aspect of coordination is
               that behavioral goals are achieved reliably and repeatedly with
               movements rarely reproducible in their detail. Existing
               theoretical frameworks emphasize either goal achievement or the
               richness of motor variability, but fail to reconcile the two.
               Here we propose an alternative theory based on stochastic
               optimal feedback control. We show that the optimal strategy in
               the face of uncertainty is to allow variability in redundant
               (task-irrelevant) dimensions. This strategy does not enforce a
               desired trajectory, but uses feedback more intelligently,
               correcting only those deviations that interfere with task goals.
               From this framework, task-constrained variability, goal-directed
               corrections, motor synergies, controlled parameters, simplifying
               rules and discrete coordination modes emerge naturally. We
               present experimental results from a range of motor tasks to
               support this theory.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  5,
  number    =  11,
  pages     = "1226--1235",
  month     =  nov,
  year      =  2002,
  language  = "en",
  issn      = "1097-6256",
  pmid      = "12404008",
  doi       = "10.1038/nn963"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Arechavaleta2008-ne,
  title    = "On the nonholonomic nature of human locomotion",
  author   = "Arechavaleta, Gustavo and Laumond, Jean-Paul and Hicheur, Halim
              and Berthoz, Alain",
  abstract = "In the kinematic realm, wheeled robot's determining
              characteristic lies in its nonholonomic constraint. Indeed, the
              wheels of the robot unequivocally force the robot vehicle to move
              tangentially to its main axis. Here we test the hypothesis that
              human locomotion can also be partly described by such a
              nonholonomic system. This hypothesis is inspired by the trivial
              observation that humans do not walk sideways: some constraints of
              different natures (anatomical, mechanical…) may restrict the way
              humans generate locomotor trajectories. To model these
              constraints, we propose a simple differential system satisfying
              the so called rolling without sliding constraint. We validated
              the proposed model by comparing simulated trajectories with
              actual (recorded) trajectories obtained from goal-oriented
              locomotion of human subjects. These subjects had to start from a
              pre-defined position and direction in space and cross over to a
              distant porch so that both initial and final positions and
              directions were controlled. A comparative analysis was
              successfully undertaken by making use of numerical methods to
              compute the control inputs from actual trajectories. To achieve
              this, three body segments were used as local reference frames:
              head, pelvis and torso. The best simulations were obtained using
              the last body segment. We therefore suggest an analogy between
              the steering wheels and the torso segment, meaning that for the
              control of locomotion, the trunk behavior is constrained in a
              nonholonomic manner. Our approach allowed us to successfully
              predict 87 percent of trajectories recorded in seven subjects and
              might be particularly relevant for future pluridisciplinary
              research programs dealing with modeling of biological locomotor
              behaviors.",
  journal  = "Auton. Robots",
  volume   =  25,
  number   =  1,
  pages    = "25--35",
  month    =  aug,
  year     =  2008,
  keywords = "Locomotion",
  issn     = "0929-5593, 1573-7527",
  doi      = "10.1007/s10514-007-9075-2"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Uno1989-kq,
  title     = "Formation and control of optimal trajectory in human multijoint
               arm movement",
  author    = "Uno, Yoji and Kawato, Mitsuo and Suzuki, Rika",
  abstract  = "In this paper, we study trajectory planning and control in
               voluntary, human arm movements. When a hand is moved to a
               target, the central nervous system must select one specific
               trajectory among an infinite number of possible trajectories
               that lead to the target position …",
  journal   = "Biol. Cybern.",
  publisher = "Springer",
  volume    =  61,
  number    =  2,
  pages     = "89--101",
  year      =  1989,
  issn      = "0340-1200"
}

@ARTICLE{Ye_undated-lh,
  title  = "Representation learning for neural population activity with Neural
            Data Transformers",
  author = "Ye, Joel and Pandarinath, Chethan",
  doi    = "10.1101/2021.01.16.426955"
}

@ARTICLE{Ruder2021-fo,
  title    = "A functional map for diverse forelimb actions within brainstem
              circuitry",
  author   = "Ruder, Ludwig and Schina, Riccardo and Kanodia, Harsh and
              Valencia-Garcia, Sara and Pivetta, Chiara and Arber, Silvia",
  abstract = "The brainstem is a key centre in the control of body movements.
              Although the precise nature of brainstem cell types and circuits
              that are central to full-body locomotion are becoming known1-5,
              efforts to understand the neuronal underpinnings of skilled
              forelimb movements have focused predominantly on supra-brainstem
              centres and the spinal cord6-12. Here we define the logic of a
              functional map for skilled forelimb movements within the lateral
              rostral medulla (latRM) of the brainstem. Using in vivo
              electrophysiology in freely moving mice, we reveal a neuronal
              code with tuning of latRM populations to distinct forelimb
              actions. These include reaching and food handling, both of which
              are impaired by perturbation of excitatory latRM neurons. Through
              the combinatorial use of genetics and viral tracing, we
              demonstrate that excitatory latRM neurons segregate into distinct
              populations by axonal target, and act through the differential
              recruitment of intra-brainstem and spinal circuits. Investigating
              the behavioural potential of projection-stratified latRM
              populations, we find that the optogenetic stimulation of these
              populations can elicit diverse forelimb movements, with each
              behaviour stably expressed by individual mice. In summary,
              projection-stratified brainstem populations encode action phases
              and together serve as putative building blocks for regulating key
              features of complex forelimb movements, identifying substrates of
              the brainstem for skilled forelimb behaviours.",
  journal  = "Nature",
  month    =  jan,
  year     =  2021,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "33408409",
  doi      = "10.1038/s41586-020-03080-z"
}

@UNPUBLISHED{Centeno2021-uf,
  title    = "A hands-on tutorial on network and topological neuroscience",
  author   = "Centeno, Eduarda Gervini Zampieri and Moreni, Giulia and Vriend,
              Chris and Douw, Linda and Santos, Fernando A N",
  abstract = "The brain is an extraordinarily complex system that facilitates
              the efficient integration of information from different regions
              to execute its functions. With the recent advances in technology,
              researchers can now collect enormous amounts of data from the
              brain using neuroimaging at different scales and from numerous
              modalities. With that comes the need for sophisticated tools for
              analysis. The field of network neuroscience has been trying to
              tackle these challenges, and graph theory has been one of its
              essential branches through the investigation of brain networks.
              Recently, topological data analysis has gained more attention as
              an alternative framework by providing a set of metrics that go
              beyond pair-wise connections and offer improved robustness
              against noise. In this hands-on tutorial, our goal is to provide
              the computational tools to explore neuroimaging data using these
              frameworks and to facilitate their accessibility, data
              visualisation, and comprehension for newcomers to the field. We
              will start by giving a concise (and by no means complete)
              overview of the field to introduce the two frameworks, and then
              explain how to compute both well-established and newer metrics on
              resting-state functional magnetic resonance imaging. We use an
              open-source language (Python) and provide an accompanying
              publicly available Jupyter Notebook that uses data from the 1000
              Functional Connectomes Project. Moreover, we would like to
              highlight one part of our notebook that is solely dedicated to
              realistic visualisation of high order interactions in brain
              networks. This pipeline provides three-dimensional (3-D) plots of
              pair-wise and higher-order interactions projected in a brain
              atlas, a new feature tailor-made for network neuroscience. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.02.15.431255",
  month    =  feb,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.02.15.431255"
}

@UNPUBLISHED{Harland2021-mp,
  title    = "Dorsal {CA1} Hippocampal Place Cells Form a {Multi-Scale}
              Representation of Megaspace",
  author   = "Harland, Bruce and Contreras, Marco and Souder, Madeline and
              Fellous, Jean-Marc",
  abstract = "Spatially firing 'place cells' within the hippocampal CA1 region
              form internal maps of the environment necessary for navigation
              and memory. In rodents, these neurons have been almost
              exclusively studied in small environments (<4 m2 8 ). It remains
              unclear how place cells encode a very large open 2D environment,
              which is more analogous to the natural environments experienced
              by rodents and other mammals. Such an ethologically realistic
              environment would require a more complex spatial representation,
              capable of simultaneously representing space at overlapping
              multiple fine to coarse informational scales. Here we show that
              in a 'megaspace' (18.6 m2), the majority of dorsal CA1 place
              cells exhibited multiple place subfields of different sizes, akin
              to those observed along the septo temporal axis. Furthermore, the
              total area covered by the subfields of each cell was not
              correlated with the number of subfields, and this total area
              increased with the scale of the environment. The multiple
              different-sized subfields exhibited by place cells in the
              megaspace suggest that the ensemble population of subfields form
              a multi-scale representation of space within the dorsal
              hippocampus. Our findings point to a new dorsal hippocampus
              ensemble coding scheme that simultaneously supports navigational
              processes at both fine- and coarse grained resolutions. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.02.15.431172",
  month    =  feb,
  year     =  2021,
  keywords = "navigation",
  language = "en",
  doi      = "10.1101/2021.02.15.431172"
}

@ARTICLE{Gianelli2018-ka,
  title    = "A new rat-compatible robotic framework for spatial navigation
              behavioral experiments",
  author   = "Gianelli, Sam and Harland, Bruce and Fellous, Jean-Marc",
  abstract = "BACKGROUND: Understanding the neural substrate of information
              encoding and processing requires a precise control of the
              animal's behavior. Most of what has been learned from the rodent
              navigational system results from relatively simple tasks in which
              the movements of the animal is controlled by corridors or
              walkways, passive movements, treadmills or virtual reality
              environments. While a lot has been and continues to be learned
              from these types of experiments, recent evidence has shown that
              such artificial constraints may have significant consequences on
              the functioning of the neural circuits of spatial navigation. NEW
              METHODS: We present a novel and alternative approach for
              effectively controlling the precise direction and speed of
              movement of the animal in an ethologically realistic environment,
              using a small robot (Sphero). RESULTS: We describe the robotic
              framework and demonstrate its use in replicating pre-programmed
              or rat-recorded paths. We show that the robot can control the
              movement of a rat in order to produce specific trajectories and
              speeds. We demonstrate that the robot can be used to aid the rat
              in learning a spatial memory task in a large and complex
              environment. We show that dorsal hippocampal CA1 place cells do
              not remap when the rat is following the robot. Comparison with
              existing method(s): Our framework only involves positive
              motivation and has been tested together with wireless
              electrophysiology in large and complex environments. CONCLUSIONS:
              Our robotic framework can be used to design novel tasks and
              experiments in which electrophysiological recordings would be
              largely devoid of maze or task-dependent artifacts.",
  journal  = "J. Neurosci. Methods",
  volume   =  294,
  pages    = "40--50",
  month    =  jan,
  year     =  2018,
  keywords = "Hippocampus; Place-cell; Robot; Spatial navigation; Sphero",
  language = "en",
  issn     = "0165-0270, 1872-678X",
  pmid     = "29113794",
  doi      = "10.1016/j.jneumeth.2017.10.021"
}

@ARTICLE{Klibaite_undated-nr,
  title  = "{DEEP} {BEHAVIORAL} {PHENOTYPING} {OF} {MOUSE} {AUTISM} {MODELS}
            {USING} {OPEN-FIELD} {BEHAVIOR}",
  author = "Klibaite, Ugne",
  doi    = "10.1101/2021.02.16.431500"
}

@ARTICLE{Rueden2017-ih,
  title    = "{ImageJ2}: {ImageJ} for the next generation of scientific image
              data",
  author   = "Rueden, Curtis T and Schindelin, Johannes and Hiner, Mark C and
              DeZonia, Barry E and Walter, Alison E and Arena, Ellen T and
              Eliceiri, Kevin W",
  abstract = "BACKGROUND: ImageJ is an image analysis program extensively used
              in the biological sciences and beyond. Due to its ease of use,
              recordable macro language, and extensible plug-in architecture,
              ImageJ enjoys contributions from non-programmers, amateur
              programmers, and professional developers alike. Enabling such a
              diversity of contributors has resulted in a large community that
              spans the biological and physical sciences. However, a rapidly
              growing user base, diverging plugin suites, and technical
              limitations have revealed a clear need for a concerted software
              engineering effort to support emerging imaging paradigms, to
              ensure the software's ability to handle the requirements of
              modern science. RESULTS: We rewrote the entire ImageJ codebase,
              engineering a redesigned plugin mechanism intended to facilitate
              extensibility at every level, with the goal of creating a more
              powerful tool that continues to serve the existing community
              while addressing a wider range of scientific requirements. This
              next-generation ImageJ, called ``ImageJ2'' in places where the
              distinction matters, provides a host of new functionality. It
              separates concerns, fully decoupling the data model from the user
              interface. It emphasizes integration with external applications
              to maximize interoperability. Its robust new plugin framework
              allows everything from image formats, to scripting languages, to
              visualization to be extended by the community. The redesigned
              data model supports arbitrarily large, N-dimensional datasets,
              which are increasingly common in modern image acquisition.
              Despite the scope of these changes, backwards compatibility is
              maintained such that this new functionality can be seamlessly
              integrated with the classic ImageJ interface, allowing users and
              developers to migrate to these new methods at their own pace.
              CONCLUSIONS: Scientific imaging benefits from open-source
              programs that advance new method development and deployment to a
              diverse audience. ImageJ has continuously evolved with this idea
              in mind; however, new and emerging scientific requirements have
              posed corresponding challenges for ImageJ's development. The
              described improvements provide a framework engineered for
              flexibility, intended to support these requirements as well as
              accommodate future needs. Future efforts will focus on
              implementing new algorithms in this framework and expanding
              collaborations with other popular scientific software suites.",
  journal  = "BMC Bioinformatics",
  volume   =  18,
  number   =  1,
  pages    = "529",
  month    =  nov,
  year     =  2017,
  keywords = "Extensibility; Image processing; ImageJ; ImageJ2;
              Interoperability; N-dimensional; Open development; Open source;
              Reproducibility",
  language = "en",
  issn     = "1471-2105",
  pmid     = "29187165",
  doi      = "10.1186/s12859-017-1934-z",
  pmc      = "PMC5708080"
}

@ARTICLE{Zimnik2021-ub,
  title    = "Independent generation of sequence elements by motor cortex",
  author   = "Zimnik, Andrew J and Churchland, Mark M",
  abstract = "Rapid execution of motor sequences is believed to depend on
              fusing movement elements into cohesive units that are executed
              holistically. We sought to determine the contribution of primary
              motor and dorsal premotor cortex to this ability. Monkeys
              performed highly practiced two-reach sequences, interleaved with
              matched reaches performed alone or separated by a delay. We
              partitioned neural population activity into components pertaining
              to preparation, initiation and execution. The hypothesis that
              movement elements fuse makes specific predictions regarding all
              three forms of activity. We observed none of these predicted
              effects. Rapid two-reach sequences involved the same set of
              neural events as individual reaches but with preparation for the
              second reach occurring as the first was in flight. Thus, at the
              level of dorsal premotor and primary motor cortex, skillfully
              executing a rapid sequence depends not on fusing elements, but on
              the ability to perform two key processes at the same time.",
  journal  = "Nat. Neurosci.",
  month    =  feb,
  year     =  2021,
  issn     = "1097-6256, 1546-1726",
  doi      = "10.1038/s41593-021-00798-5"
}

@ARTICLE{Wortsman2021-dc,
  title         = "Learning Neural Network Subspaces",
  author        = "Wortsman, Mitchell and Horton, Maxwell and Guestrin, Carlos
                   and Farhadi, Ali and Rastegari, Mohammad",
  abstract      = "Recent observations have advanced our understanding of the
                   neural network optimization landscape, revealing the
                   existence of (1) paths of high accuracy containing diverse
                   solutions and (2) wider minima offering improved
                   performance. Previous methods observing diverse paths
                   require multiple training runs. In contrast we aim to
                   leverage both property (1) and (2) with a single method and
                   in a single training run. With a similar computational cost
                   as training one model, we learn lines, curves, and simplexes
                   of high-accuracy neural networks. These neural network
                   subspaces contain diverse solutions that can be ensembled,
                   approaching the ensemble performance of independently
                   trained networks without the training cost. Moreover, using
                   the subspace midpoint boosts accuracy, calibration, and
                   robustness to label noise, outperforming Stochastic Weight
                   Averaging.",
  month         =  feb,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2102.10472",
  primaryClass  = "cs.LG",
  arxivid       = "2102.10472"
}

@UNPUBLISHED{Whiteway2021-kn,
  title    = "Partitioning variability in animal behavioral videos using
              semi-supervised variational autoencoders",
  author   = "Whiteway, Matthew R and Biderman, Dan and Friedman, Yoni and
              Dipoppa, Mario and Kelly Buchanan, E and Wu, Anqi and Zhou, John
              and Noel, Jean-Paul R and {The International Brain Lab} and
              Cunningham, John P and Paninski, Liam",
  abstract = "Recent neuroscience studies in awake and behaving animals
              demonstrate that a deeper understanding of brain function
              requires a deeper understanding of behavior. Detailed behavioral
              measurements are now often collected using video cameras,
              resulting in an increased need for computer vision algorithms
              that extract useful information from this video data. In this
              work we introduce a new semi-supervised framework that combines
              the output of supervised pose estimation algorithms (e.g.
              DeepLabCut) with unsupervised dimensionality reduction methods to
              produce interpretable, low-dimensional representations of
              behavioral videos that extract more information than pose
              estimates alone. We demonstrate this method, the Partitioned
              Subspace Variational Autoencoder (PS-VAE), on head-fixed mouse
              behavioral videos. In a close up video of a mouse face, where we
              track pupil location and size, our method extracts unsupervised
              outputs that correspond to the eyelid and whisker pad positions,
              with no additional user annotations required. We use this
              resulting interpretable behavioral representation to construct
              saccade and whisking detectors, and quantify the accuracy with
              which these signals can be decoded from neural activity in visual
              cortex. In a two-camera mouse video we show how our method
              separates movements of experimental equipment from animal
              behavior, and extracts unsupervised features like chest position,
              again with no additional user annotation needed. This allows us
              to construct paw and body movement detectors, and decode
              individual features of behavior from widefield calcium imaging
              data. Our results demonstrate how the interpretable partitioning
              of behavioral videos provided by the PS-VAE can facilitate
              downstream behavioral and neural analyses. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.02.22.432309",
  month    =  feb,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.02.22.432309"
}

@ARTICLE{Ehrlich2021-vs,
  title     = "{PsychRNN}: An accessible and flexible Python package for
               training recurrent neural network models on cognitive tasks",
  author    = "Ehrlich, Daniel B and Stone, Jasmine T and Brandfonbrener, David
               and Atanasov, Alexander and Murray, John D",
  abstract  = "Task-trained artificial recurrent neural networks (RNNs) provide
               a computational modeling framework of increasing interest and
               application in computational, systems, and cognitive
               neuroscience. RNNs can be trained, using deep-learning methods,
               to perform cognitive tasks used in animal and human experiments
               and can be studied to investigate potential neural
               representations and circuit mechanisms underlying cognitive
               computations and behavior. Widespread application of these
               approaches within neuroscience has been limited by technical
               barriers in use of deep-learning software packages to train
               network models. Here, we introduce PsychRNN, an accessible,
               flexible, and extensible Python package for training RNNs on
               cognitive tasks. Our package is designed for accessibility, for
               researchers to define tasks and train RNN models using only
               Python and NumPy, without requiring knowledge of deep-learning
               software. The training backend is based on TensorFlow and is
               readily extensible for researchers with TensorFlow knowledge to
               develop projects with additional customization. PsychRNN
               implements a number of specialized features to support
               applications in systems and cognitive neuroscience. Users can
               impose neurobiologically relevant constraints on synaptic
               connectivity patterns. Furthermore, specification of cognitive
               tasks has a modular structure, which facilitates parametric
               variation of task demands to examine their impact on model
               solutions. PsychRNN also enables task shaping during training,
               or curriculum learning, in which tasks are adjusted in
               closed-loop based on performance. Shaping is ubiquitous in
               training of animals in cognitive tasks, and PsychRNN allows
               investigation of how shaping trajectories impact learning and
               model solutions. Overall, the PsychRNN framework facilitates
               application of trained RNNs in neuroscience research.",
  journal   = "eNeuro",
  publisher = "Society for Neuroscience",
  volume    =  8,
  number    =  1,
  pages     = "ENEURO.0427--20.2020",
  month     =  jan,
  year      =  2021,
  keywords  = "cognitive task; computational model; deep learning; recurrent
               neural network; training;RNN",
  language  = "en",
  issn      = "2373-2822",
  pmid      = "33328247",
  doi       = "10.1523/ENEURO.0427-20.2020",
  pmc       = "PMC7814477"
}

@ARTICLE{Chen2018-ht,
  title         = "Neural Ordinary Differential Equations",
  author        = "Chen, Ricky T Q and Rubanova, Yulia and Bettencourt, Jesse
                   and Duvenaud, David",
  abstract      = "We introduce a new family of deep neural network models.
                   Instead of specifying a discrete sequence of hidden layers,
                   we parameterize the derivative of the hidden state using a
                   neural network. The output of the network is computed using
                   a black-box differential equation solver. These
                   continuous-depth models have constant memory cost, adapt
                   their evaluation strategy to each input, and can explicitly
                   trade numerical precision for speed. We demonstrate these
                   properties in continuous-depth residual networks and
                   continuous-time latent variable models. We also construct
                   continuous normalizing flows, a generative model that can
                   train by maximum likelihood, without partitioning or
                   ordering the data dimensions. For training, we show how to
                   scalably backpropagate through any ODE solver, without
                   access to its internal operations. This allows end-to-end
                   training of ODEs within larger models.",
  month         =  jun,
  year          =  2018,
  keywords      = "RNN",
  archivePrefix = "arXiv",
  eprint        = "1806.07366",
  primaryClass  = "cs.LG",
  arxivid       = "1806.07366"
}

@INPROCEEDINGS{Foerster2017-ca,
  title     = "Input Switched Affine Networks: An {RNN} Architecture Designed
               for Interpretability",
  booktitle = "Proceedings of the 34th International Conference on Machine
               Learning",
  author    = "Foerster, Jakob N and Gilmer, Justin and Sohl-Dickstein, Jascha
               and Chorowski, Jan and Sussillo, David",
  editor    = "Precup, Doina and Teh, Yee Whye",
  abstract  = "There exist many problem domains where the interpretability of
               neural network models is essential for deployment. Here we
               introduce a recurrent architecture composed of input-switched
               affine transformations -- in other words an RNN without any
               explicit nonlinearities, but with input-dependent recurrent
               weights. This simple form allows the RNN to be analyzed via
               straightforward linear methods: we can exactly characterize the
               linear contribution of each input to the model predictions; we
               can use a change-of-basis to disentangle input, output, and
               computational hidden unit subspaces; we can fully
               reverse-engineer the architecture's solution to a simple task.
               Despite this ease of interpretation, the input switched affine
               network achieves reasonable performance on a text modeling
               tasks, and allows greater computational efficiency than networks
               with standard nonlinearities.",
  publisher = "PMLR",
  volume    =  70,
  pages     = "1136--1145",
  series    = "Proceedings of Machine Learning Research",
  year      =  2017,
  address   = "International Convention Centre, Sydney, Australia"
}

@UNPUBLISHED{Kang2020-rn,
  title    = "State space discovery in spatial representation circuits with
              persistent cohomology",
  author   = "Kang, Louis and Xu, Boyan and Morozov, Dmitriy",
  abstract = "Persistent cohomology is a powerful technique for discovering
              topological structure in data. Strategies for its use in
              neuroscience are still undergoing development. We explore the
              application of persistent cohomology to the brain's spatial
              representation system. We simulate populations of grid cells,
              head direction cells, and conjunctive cells, each of which span
              low-dimensional topological structures embedded in
              high-dimensional neural activity space. We evaluate the ability
              for persistent cohomology to discover these structures and
              demonstrate its robustness to various forms of noise. We identify
              regimes under which mixtures of populations form product
              topologies can be detected. Our results suggest guidelines for
              applying persistent cohomology, as well as persistent homology,
              to experimental neural recordings. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2020.10.06.328773",
  month    =  oct,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.10.06.328773"
}

@UNPUBLISHED{Orlandi2021-ak,
  title    = "Distributed context-dependent choice information in mouse
              dorsal-parietal cortex",
  author   = "Orlandi, Javier G and Abdolrahmani, Mohammad and Aoki, Ryo and
              Lyamzin, Dmitry R and Benucci, Andrea",
  abstract = "Choice information appears in the brain as distributed signals
              with top-down and bottom-up components that together support
              decision-making computations. In sensory and associative cortical
              regions, the presence of choice signals, their strength, and area
              specificity are known to be elusive and changeable, limiting a
              cohesive understanding of their computational significance. In
              this study, examining the mesoscale activity in mouse posterior
              cortex during a complex visual discrimination task, we found that
              broadly distributed choice signals defined a decision variable in
              a low-dimensional embedding space of multi-area activations,
              particularly along the ventral visual stream. The subspace they
              defined was near-orthogonal to concurrently represented sensory
              and motor-related activations, and it was modulated by task
              difficulty and contextually by the attention state of the
              animals. To mechanistically relate choice representations to
              decision-making computations, we trained recurrent neural
              networks with the choices of the animals and found an equivalent
              decision variable whose context-dependent dynamics agreed with
              that of the neural data. In conclusion, our results demonstrated
              an independent decision variable broadly represented in the
              posterior cortex, controlled by task features and cognitive
              demands. Its dynamics reflected decision computations, possibly
              linked to context-dependent feedback signals used for
              probabilistic-inference computations in variable
              animal-environment interactions. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.03.02.433657",
  month    =  mar,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.03.02.433657"
}

@ARTICLE{Liu_undated-db,
  title    = "Drop, Swap, and Generate: A {Self-Supervised} Approach for
              Generating Neural Activity",
  author   = "Liu, Ran and Azabou, Mehdi and Dabagia, Max and Lin, Chi-Heng",
  keywords = "To Read;BCI",
  doi      = "10.1101/2021.07.21.453285"
}

@UNPUBLISHED{Melbaum2021-yo,
  title    = "Conserved structures of neural activity in sensorimotor cortex of
              freely moving rats allow cross-subject decoding",
  author   = "Melbaum, Svenja and Eriksson, David and Brox, Thomas and Diester,
              Ilka",
  abstract = "Our knowledge about neuronal activity in the sensorimotor cortex
              relies primarily on stereotyped movements which are strictly
              controlled via the experimental settings. It remains unclear how
              results can be carried over to less constrained behavior, i.e.
              freely moving subjects. Towards this goal, we developed a
              self-paced behavioral paradigm which encouraged rats to conduct
              different types of movements. Via bilateral electrophysiological
              recordings across the entire sensorimotor cortex and simultaneous
              paw tracking, we identified behavioral coupling of neurons with
              lateralization and an anterior-posterior gradient from premotor
              to primary sensory cortex. The structure of population activity
              patterns was conserved across animals, in spite of severe
              undersampling of the total number of neurons and variations of
              electrode positions across individuals. Via alignments of
              low-dimensional neural manifolds, we demonstrate cross-subject
              and cross-session generalization in a decoding task arguing for a
              conserved neuronal code. \#\#\# Competing Interest Statement The
              authors have declared no competing interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.03.04.433869",
  month    =  mar,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.03.04.433869"
}

@UNPUBLISHED{Prince2021-up,
  title    = "Parallel inference of hierarchical latent dynamics in two-photon
              calcium imaging of neuronal populations",
  author   = "Prince, Luke Yuri and Bakhtiari, Shahab and Gillon, Colleen J and
              Richards, Blake A",
  abstract = "Dynamic latent variable modelling has provided a powerful tool
              for understanding how populations of neurons compute. For spiking
              data, such latent variable modelling can treat the data as a set
              of point-processes, due to the fact that spiking dynamics occur
              on a much faster timescale than the computational dynamics being
              inferred. In contrast, for other experimental techniques, the
              slow dynamics governing the observed data are similar in
              timescale to the computational dynamics that researchers want to
              infer. An example of this is in calcium imaging data, where
              calcium dynamics can have timescales on the order of hundreds of
              milliseconds. As such, the successful application of dynamic
              latent variable modelling to modalities like calcium imaging data
              will rest on the ability to disentangle the deeper- and
              shallower-level dynamical systems' contributions to the data. To
              date, no techniques have been developed to directly achieve this.
              Here we solve this problem by extending recent advances using
              sequential variational autoencoders for dynamic latent variable
              modelling of neural data. Our system VaLPACa (Variational Ladders
              for Parallel Autoencoding of Calcium imaging data) solves the
              problem of disentangling deeper- and shallower-level dynamics by
              incorporating a ladder architecture that can infer a hierarchy of
              dynamical systems. Using some built-in inductive biases for
              calcium dynamics, we show that we can disentangle calcium flux
              from the underlying dynamics of neural computation. First, we
              demonstrate with synthetic calcium data that we can correctly
              disentangle an underlying Lorenz attractor from calcium dynamics.
              Next, we show that we can infer appropriate rotational dynamics
              in spiking data from macaque motor cortex after it has been
              converted into calcium fluorescence data via a calcium dynamics
              model. Finally, we show that our method applied to real calcium
              imaging data from primary visual cortex in mice allows us to
              infer latent factors that carry salient sensory information about
              unexpected stimuli. These results demonstrate that variational
              ladder autoencoders are a promising approach for inferring
              hierarchical dynamics in experimental settings where the measured
              variable has its own slow dynamics, such as calcium imaging data.
              Our new, open-source tool thereby provides the neuroscience
              community with the ability to apply dynamic latent variable
              modelling to a wider array of data modalities. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest.",
  journal  = "Cold Spring Harbor Laboratory",
  pages    = "2021.03.05.434105",
  month    =  mar,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.03.05.434105"
}

@ARTICLE{Wei2021-qc,
  title     = "Neural circuits of social behaviors: innate yet flexible",
  author    = "Wei, Dongyu and Talwar, Vaishali and Lin, Dayu",
  abstract  = "SummarySocial behaviors, such as mating, fighting, and
               parenting, are fundamental for survival of any vertebrate
               species. All members of a species express social behaviors in a
               stereotypical and species-specific way without training because
               of developmentally hardwired neural circuits dedicated to these
               behaviors. Despite being innate, social behaviors are flexible.
               The readiness to interact with a social target or engage in
               specific social acts can vary widely based on reproductive
               state, social experience, and many other internal and external
               factors. Such high flexibility gives vertebrates the ability to
               release the relevant behavior at the right moment and toward the
               right target. This maximizes reproductive success while
               minimizing the cost and risk associated with behavioral
               expression. Decades of research have revealed the basic neural
               circuits underlying each innate social behavior. The neural
               mechanisms that support behavioral plasticity have also started
               to emerge. Here we provide an overview of these social behaviors
               and their underlying neural circuits and then discuss in detail
               recent findings regarding the neural processes that support the
               flexibility of innate social behaviors.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  0,
  number    =  0,
  month     =  mar,
  year      =  2021,
  language  = "en",
  issn      = "0896-6273",
  doi       = "10.1016/j.neuron.2021.02.012"
}

@ARTICLE{Perich_undated-wb,
  title    = "Inferring brain-wide interactions using data-constrained
              recurrent neural network models",
  author   = "Perich, Matthew G and Arlt, Charlotte and Soares, Sofia and
              Young, Megan E and Mosher, Clayton P and Minxha, Juri and Carter,
              Eugene and Rutishauser, Ueli and Rudebeck, Peter H and Harvey,
              Christopher D and Rajan, Kanaka",
  keywords = "RNN",
  doi      = "10.1101/2020.12.18.423348"
}

@ARTICLE{Laumond1998-ko,
  title  = "Robot Motion Planning and Control",
  author = "{Laumond}",
  year   =  1998
}

@MISC{David_Redishyx1996-xq,
  title        = "A coupled attractor model of the rodent head direction system",
  author       = "David Redishyx, A and Elgazk, Adam N and Touretzkyy{, David S",
  year         =  1996,
  howpublished = "\url{https://www.princeton.edu/~adame/papers/coupled-attractor/coupled-attractor.pdf}",
  note         = "Accessed: 2021-6-28"
}

@ARTICLE{Hausmann2021-pz,
  title         = "Measuring and modeling the motor system with machine
                   learning",
  author        = "Hausmann, S{\'e}bastien B and Vargas, Alessandro Marin and
                   Mathis, Alexander and Mathis, Mackenzie W",
  abstract      = "The utility of machine learning in understanding the motor
                   system is promising a revolution in how to collect, measure,
                   and analyze data. The field of movement science already
                   elegantly incorporates theory and engineering principles to
                   guide experimental work, and in this review we discuss the
                   growing use of machine learning: from pose estimation,
                   kinematic analyses, dimensionality reduction, and
                   closed-loop feedback, to its use in understanding neural
                   correlates and untangling sensorimotor systems. We also give
                   our perspective on new avenues where markerless motion
                   capture combined with biomechanical modeling and neural
                   networks could be a new platform for hypothesis-driven
                   research.",
  month         =  mar,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2103.11775",
  primaryClass  = "q-bio.QM",
  arxivid       = "2103.11775"
}

@ARTICLE{Sharma2019-bw,
  title         = "{Dynamics-Aware} Unsupervised Discovery of Skills",
  author        = "Sharma, Archit and Gu, Shixiang and Levine, Sergey and
                   Kumar, Vikash and Hausman, Karol",
  abstract      = "Conventionally, model-based reinforcement learning (MBRL)
                   aims to learn a global model for the dynamics of the
                   environment. A good model can potentially enable planning
                   algorithms to generate a large variety of behaviors and
                   solve diverse tasks. However, learning an accurate model for
                   complex dynamical systems is difficult, and even then, the
                   model might not generalize well outside the distribution of
                   states on which it was trained. In this work, we combine
                   model-based learning with model-free learning of primitives
                   that make model-based planning easy. To that end, we aim to
                   answer the question: how can we discover skills whose
                   outcomes are easy to predict? We propose an unsupervised
                   learning algorithm, Dynamics-Aware Discovery of Skills
                   (DADS), which simultaneously discovers predictable behaviors
                   and learns their dynamics. Our method can leverage
                   continuous skill spaces, theoretically, allowing us to learn
                   infinitely many behaviors even for high-dimensional
                   state-spaces. We demonstrate that zero-shot planning in the
                   learned latent space significantly outperforms standard MBRL
                   and model-free goal-conditioned RL, can handle sparse-reward
                   tasks, and substantially improves over prior hierarchical RL
                   methods for unsupervised skill discovery.",
  month         =  jul,
  year          =  2019,
  archivePrefix = "arXiv",
  eprint        = "1907.01657",
  primaryClass  = "cs.LG",
  arxivid       = "1907.01657"
}

@ARTICLE{Botvinick2014-vq,
  title    = "Model-based hierarchical reinforcement learning and human action
              control",
  author   = "Botvinick, Matthew and Weinstein, Ari",
  abstract = "Recent work has reawakened interest in goal-directed or
              'model-based' choice, where decisions are based on prospective
              evaluation of potential action outcomes. Concurrently, there has
              been growing attention to the role of hierarchy in
              decision-making and action control. We focus here on the
              intersection between these two areas of interest, considering the
              topic of hierarchical model-based control. To characterize this
              form of action control, we draw on the computational framework of
              hierarchical reinforcement learning, using this to interpret
              recent empirical findings. The resulting picture reveals how
              hierarchical model-based mechanisms might play a special and
              pivotal role in human decision-making, dramatically extending the
              scope and complexity of human behaviour.",
  journal  = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  volume   =  369,
  number   =  1655,
  month    =  nov,
  year     =  2014,
  keywords = "goal-directed behaviour; hierarchy; reinforcement learning",
  language = "en",
  issn     = "0962-8436, 1471-2970",
  pmid     = "25267822",
  doi      = "10.1098/rstb.2013.0480",
  pmc      = "PMC4186233"
}

@ARTICLE{Zhang2020-op,
  title         = "Generating {Adjacency-Constrained} Subgoals in Hierarchical
                   Reinforcement Learning",
  author        = "Zhang, Tianren and Guo, Shangqi and Tan, Tian and Hu,
                   Xiaolin and Chen, Feng",
  abstract      = "Goal-conditioned hierarchical reinforcement learning (HRL)
                   is a promising approach for scaling up reinforcement
                   learning (RL) techniques. However, it often suffers from
                   training inefficiency as the action space of the high-level,
                   i.e., the goal space, is often large. Searching in a large
                   goal space poses difficulties for both high-level subgoal
                   generation and low-level policy learning. In this paper, we
                   show that this problem can be effectively alleviated by
                   restricting the high-level action space from the whole goal
                   space to a $k$-step adjacent region of the current state
                   using an adjacency constraint. We theoretically prove that
                   the proposed adjacency constraint preserves the optimal
                   hierarchical policy in deterministic MDPs, and show that
                   this constraint can be practically implemented by training
                   an adjacency network that can discriminate between adjacent
                   and non-adjacent subgoals. Experimental results on discrete
                   and continuous control tasks show that incorporating the
                   adjacency constraint improves the performance of
                   state-of-the-art HRL approaches in both deterministic and
                   stochastic environments.",
  month         =  jun,
  year          =  2020,
  archivePrefix = "arXiv",
  eprint        = "2006.11485",
  primaryClass  = "cs.LG",
  arxivid       = "2006.11485"
}

@ARTICLE{Ramesh2019-gy,
  title         = "Successor Options: An Option Discovery Framework for
                   Reinforcement Learning",
  author        = "Ramesh, Rahul and Tomar, Manan and Ravindran, Balaraman",
  abstract      = "The options framework in reinforcement learning models the
                   notion of a skill or a temporally extended sequence of
                   actions. The discovery of a reusable set of skills has
                   typically entailed building options, that navigate to
                   bottleneck states. This work adopts a complementary
                   approach, where we attempt to discover options that navigate
                   to landmark states. These states are prototypical
                   representatives of well-connected regions and can hence
                   access the associated region with relative ease. In this
                   work, we propose Successor Options, which leverages
                   Successor Representations to build a model of the state
                   space. The intra-option policies are learnt using a novel
                   pseudo-reward and the model scales to high-dimensional
                   spaces easily. Additionally, we also propose an Incremental
                   Successor Options model that iterates between constructing
                   Successor Representations and building options, which is
                   useful when robust Successor Representations cannot be built
                   solely from primitive actions. We demonstrate the efficacy
                   of our approach on a collection of grid-worlds, and on the
                   high-dimensional robotic control environment of Fetch.",
  month         =  may,
  year          =  2019,
  archivePrefix = "arXiv",
  eprint        = "1905.05731",
  primaryClass  = "cs.LG",
  arxivid       = "1905.05731"
}

@ARTICLE{Sutton1999-ja,
  title    = "Between {MDPs} and {semi-MDPs}: A framework for temporal
              abstraction in reinforcement learning",
  author   = "Sutton, Richard S and Precup, Doina and Singh, Satinder",
  abstract = "Learning, planning, and representing knowledge at multiple levels
              of temporal abstraction are key, longstanding challenges for AI.
              In this paper we consider how these challenges can be addressed
              within the mathematical framework of reinforcement learning and
              Markov decision processes (MDPs). We extend the usual notion of
              action in this framework to include options---closed-loop
              policies for taking action over a period of time. Examples of
              options include picking up an object, going to lunch, and
              traveling to a distant city, as well as primitive actions such as
              muscle twitches and joint torques. Overall, we show that options
              enable temporally abstract knowledge and action to be included in
              the reinforcement learning framework in a natural and general
              way. In particular, we show that options may be used
              interchangeably with primitive actions in planning methods such
              as dynamic programming and in learning methods such as
              Q-learning. Formally, a set of options defined over an MDP
              constitutes a semi-Markov decision process (SMDP), and the theory
              of SMDPs provides the foundation for the theory of options.
              However, the most interesting issues concern the interplay
              between the underlying MDP and the SMDP and are thus beyond SMDP
              theory. We present results for three such cases: (1) we show that
              the results of planning with options can be used during execution
              to interrupt options and thereby perform even better than
              planned, (2) we introduce new intra-option methods that are able
              to learn about an option from fragments of its execution, and (3)
              we propose a notion of subgoal that can be used to improve the
              options themselves. All of these results have precursors in the
              existing literature; the contribution of this paper is to
              establish them in a simpler and more general setting with fewer
              changes to the existing reinforcement learning framework. In
              particular, we show that these results can be obtained without
              committing to (or ruling out) any particular approach to state
              abstraction, hierarchy, function approximation, or the
              macro-utility problem.",
  journal  = "Artif. Intell.",
  volume   =  112,
  number   =  1,
  pages    = "181--211",
  month    =  aug,
  year     =  1999,
  keywords = "Temporal abstraction; Reinforcement learning; Markov decision
              processes; Options; Macros; Macroactions; Subgoals; Intra-option
              learning; Hierarchical planning; Semi-Markov decision processes",
  issn     = "0004-3702",
  doi      = "10.1016/S0004-3702(99)00052-1"
}

@MISC{Jong_undated-si,
  title        = "Hierarchical model-based reinforcement learning: {R-MAX} +
                  {MAXQ}",
  author       = "Jong, Nicholas K",
  howpublished = "\url{https://www.cs.utexas.edu/~pstone/Papers/bib2html-links/ICML08-jong.pdf}",
  note         = "Accessed: 2021-3-29"
}

@ARTICLE{Blackmore2021-vx,
  title    = "Widening spinal injury research to consider all supraspinal cell
              types: Why we must and how we can",
  author   = "Blackmore, Murray and Batsel, Elizabeth and Tsoulfas, Pantelis",
  abstract = "The supraspinal connectome consists of dozens of neuronal
              populations that project axons from the brain to the spinal cord
              to influence a wide range of motor, autonomic, and sensory
              functions. The complexity and wide distribution of supraspinal
              neurons present significant technical challenges, leading most
              spinal cord injury research to focus on a handful of major
              pathways such as the corticospinal, rubrospinal, and raphespinal.
              Much less is known about many additional populations that carry
              information to modulate or compensate for these main pathways, or
              which carry pre-autonomic and other information of high value to
              individuals with spinal injury. A confluence of technical
              developments, however, now enables a whole-connectome study of
              spinal cord injury. Improved viral labeling, tissue clearing, and
              automated registration to 3D atlases can quantify supraspinal
              neurons throughout the murine brain, offering a practical means
              to track responses to injury and treatment on an unprecedented
              scale. Here we discuss the need for expanded connectome-wide
              analyses in spinal injury research, illustrate the potential by
              discussing a new web-based resource for brain-wide study of
              supraspinal neurons, and highlight future prospects for
              connectome analyses.",
  journal  = "Exp. Neurol.",
  pages    = "113862",
  month    =  sep,
  year     =  2021,
  keywords = "AAV; BrainGlobe; Connectome; Fluorescent protein; Light-sheet
              microscopy; Propriospinal; Regeneration; Retrograde;
              Transcriptome;Locomotion",
  language = "en",
  issn     = "0014-4886, 1090-2430",
  pmid     = "34520726",
  doi      = "10.1016/j.expneurol.2021.113862"
}

@ARTICLE{MendonCa2019-fp,
  title     = "{Graph-Based} Skill Acquisition For Reinforcement Learning",
  author    = "Mendon{\c C}a, Matheus R F and Ziviani, Artur and Barreto,
               Andr{\'e} M S",
  abstract  = "In machine learning, Reinforcement Learning (RL) is an important
               tool for creating intelligent agents that learn solely through
               experience. One particular subarea within the RL domain that has
               received great attention is how to define macro-actions, which
               are temporal abstractions composed of a sequence of primitive
               actions. This subarea, loosely called skill acquisition, has
               been under development for several years and has led to better
               results in a diversity of RL problems. Among the many skill
               acquisition approaches, graph-based methods have received
               considerable attention. This survey presents an overview of
               graph-based skill acquisition methods for RL. We cover a
               diversity of these approaches and discuss how they evolved
               throughout the years. Finally, we also discuss the current
               challenges and open issues in the area of graph-based skill
               acquisition for RL.",
  journal   = "ACM Comput. Surv.",
  publisher = "Association for Computing Machinery",
  volume    =  52,
  number    =  1,
  pages     = "1--26",
  month     =  feb,
  year      =  2019,
  address   = "New York, NY, USA",
  keywords  = "Skill acquisition, graph analytics, reinforcement learning,
               clustering, centrality",
  issn      = "0360-0300",
  doi       = "10.1145/3291045"
}

@ARTICLE{Waradpande2020-jx,
  title         = "Graph-based State Representation for Deep Reinforcement
                   Learning",
  author        = "Waradpande, Vikram and Kudenko, Daniel and Khosla, Megha",
  abstract      = "Deep RL approaches build much of their success on the
                   ability of the deep neural network to generate useful
                   internal representations. Nevertheless, they suffer from a
                   high sample-complexity and starting with a good input
                   representation can have a significant impact on the
                   performance. In this paper, we exploit the fact that the
                   underlying Markov decision process (MDP) represents a graph,
                   which enables us to incorporate the topological information
                   for effective state representation learning. Motivated by
                   the recent success of node representations for several graph
                   analytical tasks we specifically investigate the capability
                   of node representation learning methods to effectively
                   encode the topology of the underlying MDP in Deep RL. To
                   this end we perform a comparative analysis of several models
                   chosen from 4 different classes of representation learning
                   algorithms for policy learning in grid-world navigation
                   tasks, which are representative of a large class of RL
                   problems. We find that all embedding methods outperform the
                   commonly used matrix representation of grid-world
                   environments in all of the studied cases. Moreoever, graph
                   convolution based methods are outperformed by simpler random
                   walk based methods and graph linear autoencoders.",
  month         =  apr,
  year          =  2020,
  archivePrefix = "arXiv",
  eprint        = "2004.13965",
  primaryClass  = "cs.LG",
  arxivid       = "2004.13965"
}

@ARTICLE{Madjiheurem2019-dx,
  title         = "Representation learning on graphs: A reinforcement learning
                   application",
  author        = "Madjiheurem, Sephora and Toni, Laura",
  abstract      = "In this work, we study value function approximation in
                   reinforcement learning (RL) problems with high dimensional
                   state or action spaces via a generalized version of
                   representation policy iteration (RPI). We consider the
                   limitations of proto-value functions (PVFs) at accurately
                   approximating the value function in low dimensions and we
                   highlight the importance of features learning for an
                   improved low-dimensional value function approximation. Then,
                   we adopt different representation learning algorithm on
                   graphs to learn the basis functions that best represent the
                   value function. We empirically show that node2vec, an
                   algorithm for scalable feature learning in networks, and the
                   Variational Graph Auto-Encoder constantly outperform the
                   commonly used smooth proto-value functions in
                   low-dimensional feature space.",
  month         =  jan,
  year          =  2019,
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  eprint        = "1901.05351",
  primaryClass  = "cs.LG",
  arxivid       = "1901.05351"
}

@INPROCEEDINGS{Diuk2006-la,
  title     = "A hierarchical approach to efficient reinforcement learning in
               deterministic domains",
  booktitle = "Proceedings of the fifth international joint conference on
               Autonomous agents and multiagent systems",
  author    = "Diuk, Carlos and Strehl, Alexander L and Littman, Michael L",
  abstract  = "Factored representations, model-based learning, and hierarchies
               are well-studied techniques for improving the learning
               efficiency of reinforcement-learning algorithms in large-scale
               state spaces. We bring these three ideas together in a new
               algorithm. Our algorithm tackles two open problems from the
               reinforcement-learning literature, and provides a solution to
               those problems in deterministic domains. First, it shows how
               models can improve learning speed in the hierarchy-based MaxQ
               framework without disrupting opportunities for state
               abstraction. Second, we show how hierarchies can augment
               existing factored exploration algorithms to achieve not only low
               sample complexity for learning, but provably efficient planning
               as well. We illustrate the resulting performance gains in
               example domains. We prove polynomial bounds on the computational
               effort needed to attain near optimal performance within the
               hierarchy.",
  publisher = "Association for Computing Machinery",
  pages     = "313--319",
  series    = "AAMAS '06",
  month     =  may,
  year      =  2006,
  address   = "New York, NY, USA",
  keywords  = "factored representations, sample complexity, hierarchical
               reinforcement learning, reinforcement learning",
  location  = "Hakodate, Japan",
  isbn      = "9781595933034",
  doi       = "10.1145/1160633.1160686"
}

@UNPUBLISHED{Kleinman2020-ts,
  title    = "Recurrent neural network models of multi-area computation
              underlying decision-making",
  author   = "Kleinman, Michael and Chandrasekaran, Chandramouli and Kao,
              Jonathan C",
  abstract = "Cognition emerges from coordinated computations across multiple
              brain areas. However, elucidating these computations within and
              across brain regions is challenging because intra- and inter-area
              connectivity are typically unknown. To study coordinated
              computation, we trained multi-area recurrent neural networks
              (RNNs) to discriminate the dominant color of a checker-board and
              output decision variables reflecting a direction decision, a task
              previously used to investigate decision-related dynamics in
              dorsal premotor cortex (PMd) of monkeys. We found that multi-area
              RNNs, trained with neurophysiological connectivity constraints
              and Dale's law, recapitulated decision-related dynamics observed
              in PMd. The RNN solved this task by a dynamical mechanism where
              the direction decision was computed and outputted, via precisely
              oriented dynamics, on an axis that was nearly orthogonal to
              checkerboard color inputs. This orthogonal direction information
              was preferentially propagated through alignment with inter-area
              connections; in contrast, color information was filtered. These
              results suggest that cortex uses modular computation to generate
              minimal sufficient representations of task information. Finally,
              we used multi-area RNNs to produce experimentally testable
              hypotheses for computations that occur within and across multiple
              brain areas, enabling new insights into distributed computation
              in neural systems. \#\#\# Competing Interest Statement The
              authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "798553",
  month    =  nov,
  year     =  2020,
  keywords = "RNN",
  language = "en",
  doi      = "10.1101/798553"
}

@ARTICLE{Dietterich2000-ga,
  title     = "Hierarchical Reinforcement Learning with the {MAXQ} Value
               Function Decomposition",
  author    = "Dietterich, T G",
  abstract  = "This paper presents a new approach to hierarchical reinforcement
               learning based on decomposing the target Markov decision process
               (MDP) into a hierarchy of smaller MDPs and decomposing the value
               function of the target MDP into an additive combination of the
               value functions of the smaller MDPs. The decomposition, known as
               the MAXQ decomposition, has both a procedural semantics---as a
               subroutine hierarchy---and a declarative semantics---as a
               representation of the value function of a hierarchical policy.
               MAXQ unifies and extends previous work on hierarchical
               reinforcement learning by Singh, Kaelbling, and Dayan and
               Hinton. It is based on the assumption that the programmer can
               identify useful subgoals and define subtasks that achieve these
               subgoals. By defining such subgoals, the programmer constrains
               the set of policies that need to be considered during
               reinforcement learning. The MAXQ value function decomposition
               can represent the value function of any policy that is
               consistent with the given hierarchy. The decomposition also
               creates opportunities to exploit state abstractions, so that
               individual MDPs within the hierarchy can ignore large parts of
               the state space. This is important for the practical application
               of the method. This paper defines the MAXQ hierarchy, proves
               formal results on its representational power, and establishes
               five conditions for the safe use of state abstractions. The
               paper presents an online model-free learning algorithm, MAXQ-Q,
               and proves that it converges with probability 1 to a kind of
               locally-optimal policy known as a recursively optimal policy,
               even in the presence of the five kinds of state abstraction. The
               paper evaluates the MAXQ representation and MAXQ-Q through a
               series of experiments in three domains and shows experimentally
               that MAXQ-Q (with state abstractions) converges to a recursively
               optimal policy much faster than flat Q learning. The fact that
               MAXQ learns a representation of the value function has an
               important benefit: it makes it possible to compute and execute
               an improved, non-hierarchical policy via a procedure similar to
               the policy improvement step of policy iteration. The paper
               demonstrates the effectiveness of this non-hierarchical
               execution experimentally. Finally, the paper concludes with a
               comparison to related work and a discussion of the design
               tradeoffs in hierarchical reinforcement learning.",
  journal   = "J. Artif. Intell. Res.",
  publisher = "jair.org",
  volume    =  13,
  pages     = "227--303",
  month     =  nov,
  year      =  2000,
  language  = "en",
  issn      = "1076-9757",
  doi       = "10.1613/jair.639"
}

@ARTICLE{Braga2006-vb,
  title     = "Influence zones: A strategy to enhance reinforcement learning",
  author    = "Braga, Arthur Pl{\'\i}nio de S and Ara{\'u}jo, Alu{\'\i}zio F R",
  abstract  = "Reinforcement Learning (RL) aims to learn through direct
               experimentation how to solve decision-making problems. RL
               algorithms often have their practical applications restricted to
               small or medium size problems---mainly because of their
               strategies for value function estimation demanding very high
               number of interactions. To overcome this difficulty, we propose
               to enhance RL performance by updating several state (or
               state--action) values at each interaction. Therefore, the
               influence zone algorithm, an improvement over the topological RL
               agent (TRLA) strategy, allows to reduce the number of requested
               interactions. Such a reduction is based on the
               topological-preserving characteristic of the mapping between
               states (or state--action pairs) and value estimates. The
               comparison of the influence zone approach with seven other RL
               algorithms suggests that the proposed algorithm is among the
               fastest to estimate the value function and that it takes less
               value function updatings to perform such an estimation. The
               influence zone algorithm also presents a remarkable flexibility
               in adapting its policy to changes of the input space topology.",
  journal   = "Neurocomputing",
  publisher = "Elsevier",
  volume    =  70,
  number    =  1,
  pages     = "21--34",
  month     =  dec,
  year      =  2006,
  keywords  = "Reinforcement learning; Self-organizing map; Instantaneous
               topological map; Learning acceleration",
  issn      = "0925-2312",
  doi       = "10.1016/j.neucom.2006.07.010"
}

@MISC{Lane_undated-hb,
  title        = "Toward a topological theory of relational reinforcement
                  learning for navigation tasks",
  author       = "Lane, Terran and Wilson, Andrew",
  howpublished = "\url{https://www.aaai.org/Papers/FLAIRS/2005/Flairs05-076.pdf}",
  note         = "Accessed: 2021-4-5"
}

@ARTICLE{Braga2003-tn,
  title    = "A topological reinforcement learning agent for navigation",
  author   = "Braga, Arthur P S and Ara{\'u}jo, Alu{\'\i}zio F R",
  abstract = "This article proposes a reinforcement learning procedure for
              mobile robot navigation using a latent-like learning schema.
              Latent learning refers to learning that occurs in the absence of
              reinforcement signals and is not apparent until reinforcement is
              introduced. This concept considers that part of a task can be
              learned before the agent receives any indication of how to
              perform such a task. In the proposed topological reinforcement
              learning agent (TRLA), a topological map is used to perform the
              latent learning. The propagation of the reinforcement signal
              throughout the topological neighborhoods of the map permits the
              estimation of a value function which takes in average less trials
              and with less updatings per trial than six of the main temporal
              difference reinforcement learning algorithms: Q-learning, SARSA,
              Q($\lambda$)-learning, SARSA($\lambda$), Dyna-Q and fast
              Q($\lambda$)-learning. The RL agents were tested in four
              different environments designed to consider a growing level of
              complexity in accomplishing navigation tasks. The tests suggested
              that the TRLA chooses shorter trajectories (in the number of
              steps) and/or requires less value function updatings in each
              trial than the other six reinforcement learning (RL) algorithms.",
  journal  = "Neural Comput. Appl.",
  volume   =  12,
  number   =  3,
  pages    = "220--236",
  month    =  dec,
  year     =  2003,
  issn     = "0941-0643, 1433-3058",
  doi      = "10.1007/s00521-003-0385-9"
}

@ARTICLE{Yin2020-sz,
  title         = "{TOMA}: Topological Map Abstraction for Reinforcement
                   Learning",
  author        = "Yin, Zhao-Heng and Li, Wu-Jun",
  abstract      = "Animals are able to discover the topological map (graph) of
                   surrounding environment, which will be used for navigation.
                   Inspired by this biological phenomenon, researchers have
                   recently proposed to generate graph representation for
                   Markov decision process (MDP) and use such graphs for
                   planning in reinforcement learning (RL). However, existing
                   graph generation methods suffer from many drawbacks. One
                   drawback is that existing methods do not learn an
                   abstraction for graphs, which results in high memory and
                   computation cost. This drawback also makes generated graph
                   non-robust, which degrades the planning performance. Another
                   drawback is that existing methods cannot be used for
                   facilitating exploration which is important in RL. In this
                   paper, we propose a new method, called topological map
                   abstraction (TOMA), for graph generation. TOMA can generate
                   an abstract graph representation for MDP, which costs much
                   less memory and computation cost than existing methods.
                   Furthermore, TOMA can be used for facilitating exploration.
                   In particular, we propose planning to explore, in which TOMA
                   is used to accelerate exploration by guiding the agent
                   towards unexplored states. A novel experience replay module
                   called vertex memory is also proposed to improve exploration
                   performance. Experimental results show that TOMA can
                   outperform existing methods to achieve the state-of-the-art
                   performance.",
  month         =  may,
  year          =  2020,
  archivePrefix = "arXiv",
  eprint        = "2005.06061",
  primaryClass  = "cs.LG",
  arxivid       = "2005.06061"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Wiering1998-wr,
  title     = "Fast online {Q} ($\lambda$)",
  author    = "Wiering, Marco and Schmidhuber, J{\"u}rgen",
  abstract  = "Q ($\lambda$)-learning uses TD ($\lambda$)-methods to accelerate
               Q-learning. The update complexity of previous online Q
               ($\lambda$) implementations based on lookup tables is bounded by
               the size of the state/action space. Our faster algorithm's
               update complexity is bounded by the number of …",
  journal   = "Mach. Learn.",
  publisher = "Springer",
  volume    =  33,
  number    =  1,
  pages     = "105--115",
  year      =  1998,
  issn      = "0885-6125"
}

@INPROCEEDINGS{Jockusch1999-gm,
  title     = "An instantaneous topological mapping model for correlated
               stimuli",
  booktitle = "{IJCNN'99}. International Joint Conference on Neural Networks.
               Proceedings (Cat. {No.99CH36339})",
  author    = "Jockusch, J and Ritter, H",
  abstract  = "Topology-representing networks, such as the SOM and the growing
               neural gas (GNG) are powerful tools for the adaptive formation
               of maps of feature and state spaces for a broad range of
               applications. However, these algorithms suffer severe
               difficulties when their training inputs are strongly correlated.
               This makes them unsuitable for the online formation of maps of
               state spaces whose exploration occurs most naturally along
               trajectories, which is typical in many applications in the
               fields of robotics and process control. Based on investigations
               of the SOM and the GNG for these cases, we devise a new network
               model, the ``instantaneous topological map'' (ITM) that is able
               to overcome these difficulties and form maps from strongly
               correlated stimulus sequences in a fast and robust manner. This
               makes the ITM highly suitable for mapping of state spaces in
               control tasks in general and especially in robotics, where
               workspace limitations are complex and probably more easily
               explored than analyzed and coded by hand.",
  volume    =  1,
  pages     = "529--534 vol.1",
  month     =  jul,
  year      =  1999,
  keywords  = "State-space methods;Orbital
               robotics;Trajectory;Topology;Algorithm design and
               analysis;Training data;Process control;Robust
               control;Entropy;Interpolation",
  issn      = "1098-7576",
  doi       = "10.1109/IJCNN.1999.831553"
}

@ARTICLE{McNamee2021-sg,
  title     = "Flexible modulation of sequence generation in the
               entorhinal--hippocampal system",
  author    = "McNamee, Daniel C and Stachenfeld, Kimberly L and Botvinick,
               Matthew M and Gershman, Samuel J",
  abstract  = "Exploration, consolidation and planning depend on the generation
               of sequential state representations. However, these algorithms
               require disparate forms of sampling dynamics for optimal
               performance. We theorize how the brain should adapt internally
               generated sequences for particular cognitive functions and
               propose a neural mechanism by which this may be accomplished
               within the entorhinal--hippocampal circuit. Specifically, we
               demonstrate that the systematic modulation along the medial
               entorhinal cortex dorsoventral axis of grid population input
               into the hippocampus facilitates a flexible generative process
               that can interpolate between qualitatively distinct regimes of
               sequential hippocampal reactivations. By relating the emergent
               hippocampal activity patterns drawn from our model to empirical
               data, we explain and reconcile a diversity of recently observed,
               but apparently unrelated, phenomena such as generative cycling,
               diffusive hippocampal reactivations and jumping trajectory
               events. McNamee et al. develop a theory of
               entorhinal--hippocampal processing. Distributed entorhinal input
               drives hippocampal activity between distinct statistical and
               dynamical regimes of activity, thereby unifying several
               empirical observations.",
  journal   = "Nat. Neurosci.",
  publisher = "Nature Publishing Group",
  pages     = "1--12",
  month     =  apr,
  year      =  2021,
  keywords  = "navigation",
  language  = "en",
  issn      = "1097-6256",
  doi       = "10.1038/s41593-021-00831-7"
}

@ARTICLE{Kobak2016-yg,
  title    = "Demixed principal component analysis of neural population data",
  author   = "Kobak, Dmitry and Brendel, Wieland and Constantinidis, Christos
              and Feierstein, Claudia E and Kepecs, Adam and Mainen, Zachary F
              and Qi, Xue-Lian and Romo, Ranulfo and Uchida, Naoshige and
              Machens, Christian K",
  abstract = "Neurons in higher cortical areas, such as the prefrontal cortex,
              are often tuned to a variety of sensory and motor variables, and
              are therefore said to display mixed selectivity. This complexity
              of single neuron responses can obscure what information these
              areas represent and how it is represented. Here we demonstrate
              the advantages of a new dimensionality reduction technique,
              demixed principal component analysis (dPCA), that decomposes
              population activity into a few components. In addition to
              systematically capturing the majority of the variance of the
              data, dPCA also exposes the dependence of the neural
              representation on task parameters such as stimuli, decisions, or
              rewards. To illustrate our method we reanalyze population data
              from four datasets comprising different species, different
              cortical areas and different experimental tasks. In each case,
              dPCA provides a concise way of visualizing the data that
              summarizes the task-dependent features of the population response
              in a single figure.",
  journal  = "Elife",
  volume   =  5,
  month    =  apr,
  year     =  2016,
  keywords = "dimensionality reduction; neuroscience; population activity;
              prefrontal cortex; principal component analysis; rat; rhesus
              macaque",
  language = "en",
  issn     = "2050-084X",
  pmid     = "27067378",
  doi      = "10.7554/eLife.10989",
  pmc      = "PMC4887222"
}

@UNPUBLISHED{Wang2021-ba,
  title    = "Evolving the Olfactory System with Machine Learning",
  author   = "Wang, Peter Y and Sun, Yi and Axel, Richard and Abbott, L F and
              Yang, Guangyu Robert",
  abstract = "The convergent evolution of the fly and mouse olfactory system
              led us to ask whether the anatomic connectivity and functional
              logic in vivo would evolve in artificial neural networks
              constructed to perform olfactory tasks. Artificial networks
              trained to classify odor identity recapitulate the connectivity
              inherent in the olfactory system. Input units are driven by a
              single receptor type, and units driven by the same receptor
              converge to form a glomerulus. Glomeruli exhibit sparse,
              unstructured connectivity to a larger, expansion layer. When
              trained to both classify odor and impart innate valence on odors,
              the network develops independent pathways for innate output and
              odor classification. Thus, artificial networks evolve even
              without the biological mechanisms necessary to build these
              systems in vivo, providing a rationale for the convergent
              evolution of olfactory circuits. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.04.15.439917",
  month    =  apr,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.04.15.439917"
}

@ARTICLE{Branco2020-ez,
  title    = "The Neural Basis of Escape Behavior in Vertebrates",
  author   = "Branco, Tiago and Redgrave, Peter",
  abstract = "Escape is one of the most studied animal behaviors, and there is
              a rich normative theory that links threat properties to evasive
              actions and their timing. The behavioral principles of escape are
              evolutionarily conserved and rely on elementary computational
              steps such as classifying sensory stimuli and executing
              appropriate movements. These are common building blocks of
              general adaptive behaviors. Here we consider the computational
              challenges required for escape behaviors to be implemented,
              discuss possible algorithmic solutions, and review some of the
              underlying neural circuits and mechanisms. We outline shared
              neural principles that can be implemented by evolutionarily
              ancient neural systems to generate escape behavior, to which
              cortical encephalization has been added to allow for increased
              sophistication and flexibility in responding to threat.",
  journal  = "Annu. Rev. Neurosci.",
  volume   =  43,
  pages    = "417--439",
  month    =  jul,
  year     =  2020,
  keywords = "action selection; attention; defense; escape; loom; threat",
  language = "en",
  issn     = "0147-006X, 1545-4126",
  pmid     = "32259462",
  doi      = "10.1146/annurev-neuro-100219-122527"
}

@ARTICLE{Kim2021-ir,
  title     = "Teaching recurrent neural networks to infer global temporal
               structure from local examples",
  author    = "Kim, Jason Z and Lu, Zhixin and Nozari, Erfan and Pappas, George
               J and Bassett, Danielle S",
  abstract  = "The ability to store and manipulate information is a hallmark of
               computational systems. Whereas computers are carefully
               engineered to represent and perform mathematical operations on
               structured data, neurobiological systems adapt to perform
               analogous functions without needing to be explicitly engineered.
               Recent efforts have made progress in modelling the
               representation and recall of information in neural systems.
               However, precisely how neural systems learn to modify these
               representations remains far from understood. Here, we
               demonstrate that a recurrent neural network (RNN) can learn to
               modify its representation of complex information using only
               examples, and we explain the associated learning mechanism with
               new theory. Specifically, we drive an RNN with examples of
               translated, linearly transformed or pre-bifurcated time series
               from a chaotic Lorenz system, alongside an additional control
               signal that changes value for each example. By training the
               network to replicate the Lorenz inputs, it learns to
               autonomously evolve about a Lorenz-shaped manifold.
               Additionally, it learns to continuously interpolate and
               extrapolate the translation, transformation and bifurcation of
               this representation far beyond the training data by changing the
               control signal. Furthermore, we demonstrate that RNNs can infer
               the bifurcation structure of normal forms and period doubling
               routes to chaos, and extrapolate non-dynamical, kinematic
               trajectories. Finally, we provide a mechanism for how these
               computations are learned, and replicate our main results using a
               Wilson--Cowan reservoir. Together, our results provide a simple
               but powerful mechanism by which an RNN can learn to manipulate
               internal representations of complex information, enabling the
               principled study and precise design of RNNs. Recurrent neural
               networks (RNNs) can learn to process temporal information, such
               as speech or movement. New work makes such approaches more
               powerful and flexible by describing theory and experiments
               demonstrating that RNNs can learn from a few examples to
               generalize and predict complex dynamics including chaotic
               behaviour.",
  journal   = "Nature Machine Intelligence",
  publisher = "Nature Publishing Group",
  pages     = "1--8",
  month     =  apr,
  year      =  2021,
  language  = "en",
  issn      = "2522-5839, 2522-5839",
  doi       = "10.1038/s42256-021-00321-2"
}

@ARTICLE{Finkelstein2021-gb,
  title     = "Attractor dynamics gate cortical information flow during
               decision-making",
  author    = "Finkelstein, Arseny and Fontolan, Lorenzo and Economo, Michael N
               and Li, Nuo and Romani, Sandro and Svoboda, Karel",
  abstract  = "Decisions are held in memory until enacted, which makes them
               potentially vulnerable to distracting sensory input. Gating of
               information flow from sensory to motor areas could protect
               memory from interference during decision-making, but the
               underlying network mechanisms are not understood. Here, we
               trained mice to detect optogenetic stimulation of the
               somatosensory cortex, with a delay separating sensation and
               action. During the delay, distracting stimuli lost influence on
               behavior over time, even though distractor-evoked neural
               activity percolated through the cortex without attenuation.
               Instead, choice-encoding activity in the motor cortex became
               progressively less sensitive to the impact of distractors.
               Reverse engineering of neural networks trained to reproduce
               motor cortex activity revealed that the reduction in sensitivity
               to distractors was caused by a growing separation in the neural
               activity space between attractors that encode alternative
               decisions. Our results show that communication between brain
               regions can be gated via attractor dynamics, which control the
               degree of commitment to an action. The flow of information in
               the brain is regulated over space and time. The authors show
               that mice can adaptively filter stimuli originating in the
               sensory cortex. The stimuli are gated by attractor dynamics in
               the frontal cortex, revealing a mechanism of gating of neural
               information.",
  journal   = "Nat. Neurosci.",
  publisher = "Nature Publishing Group",
  pages     = "1--8",
  month     =  apr,
  year      =  2021,
  language  = "en",
  issn      = "1097-6256",
  doi       = "10.1038/s41593-021-00840-6"
}

@UNPUBLISHED{The_International_Brain_Laboratory2020-ob,
  title    = "Standardized and reproducible measurement of decision-making in
              mice",
  author   = "{The International Brain Laboratory} and Aguillon-Rodriguez,
              Valeria and Angelaki, Dora E and Bayer, Hannah M and Bonacchi,
              Niccol{\`o} and Carandini, Matteo and Cazettes, Fanny and
              Chapuis, Gaelle A and Churchland, Anne K and Dan, Yang and
              Dewitt, Eric E J and Faulkner, Mayo and Forrest, Hamish and
              Haetzel, Laura M and Hausser, Michael and Hofer, Sonja B and Hu,
              Fei and Khanal, Anup and Krasniak, Christopher S and Laranjeira,
              In{\^e}s and Mainen, Zachary F and Meijer, Guido T and Miska,
              Nathaniel J and Mrsic-Flogel, Thomas D and Murakami, Masayoshi
              and Noel, Jean-Paul and Pan-Vazquez, Alejandro and Rossant,
              Cyrille and Sanders, Joshua I and Socha, Karolina Z and Terry,
              Rebecca and Urai, Anne E and Vergara, Hernando M and Wells, Miles
              J and Wilson, Christian J and Witten, Ilana B and Wool, Lauren E
              and Zador, Anthony",
  abstract = "Progress in science requires standardized assays whose results
              can be readily shared, compared, and reproduced across
              laboratories. Reproducibility, however, has been a concern in
              neuroscience, particularly for measurements of mouse behavior.
              Here we show that a standardized task to probe decision-making in
              mice produces reproducible results across multiple laboratories.
              We designed a task for head-fixed mice that combines established
              assays of perceptual and value-based decision making, and we
              standardized training protocol and experimental hardware,
              software, and procedures. We trained 140 mice across seven
              laboratories in three countries, and we collected 5 million mouse
              choices into a publicly available database. Learning speed was
              variable across mice and laboratories, but once training was
              complete there were no significant differences in behavior across
              laboratories. Mice in different laboratories adopted similar
              reliance on visual stimuli, on past successes and failures, and
              on estimates of stimulus prior probability to guide their
              choices. These results reveal that a complex mouse behavior can
              be successfully reproduced across multiple laboratories. They
              establish a standard for reproducible rodent behavior, and
              provide an unprecedented dataset and open-access tools to study
              decision-making in mice. More generally, they indicate a path
              towards achieving reproducibility in neuroscience through
              collaborative open-science approaches. \#\#\# Competing Interest
              Statement J.I.S. is the owner of Sanworks LLC which provides
              hardware and consulting for the experimental set-up described in
              this work.",
  journal  = "bioRxiv",
  pages    = "2020.01.17.909838",
  month    =  oct,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.01.17.909838"
}

@INPROCEEDINGS{Sun2018-ad,
  title     = "An Analysis of a Ring Attractor Model for Cue Integration",
  booktitle = "Biomimetic and Biohybrid Systems",
  author    = "Sun, Xuelong and Mangan, Michael and Yue, Shigang",
  abstract  = "Animals and robots must constantly combine multiple streams of
               noisy information from their senses to guide their actions.
               Recently, it has been proposed that animals may combine cues
               optimally using a ring attractor neural network architecture
               inspired by the head direction system of rats augmented with a
               dynamic re-weighting mechanism. In this work we report that an
               older and simpler ring attractor network architecture, requiring
               no re-weighting property combines cues according to their
               certainty for moderate cue conflicts but converges on the most
               certain cue for larger conflicts. These results are consistent
               with observations in animal experiments that show sub-optimal
               cue integration and switching from cue integration to cue
               selection strategies. This work therefore demonstrates an
               alternative architecture for those seeking neural correlates of
               sensory integration in animals. In addition, performance is
               shown robust to noise and miniaturization and thus provides an
               efficient solution for artificial systems.",
  publisher = "Springer International Publishing",
  pages     = "459--470",
  year      =  2018,
  doi       = "10.1007/978-3-319-95972-6\_49"
}

@MISC{Belkin2013-nu,
  title        = "Distance preserving embeddings for general n-dimensional
                  manifolds",
  author       = "Belkin, Editor: Mikhail",
  year         =  2013,
  howpublished = "\url{https://jmlr.org/papers/volume14/verma13a/verma13a.pdf}",
  note         = "Accessed: 2021-5-22"
}

@UNPUBLISHED{Yang2021-ct,
  title    = "Next-generation of recurrent neural network models for cognition",
  author   = "Yang, Guangyu R and Molano-Mazon, Manuel",
  abstract = "Recurrent Neural Networks (RNNs) trained with machine learning
              techniques on cognitive tasks have become a widely accepted tool
              for neuroscientists. In this short opinion piece, we discuss
              fundamental challenges faced by early work of this approach, and
              recent steps to overcome such challenges and build
              next-generation RNN models for cognition. We propose several
              essential questions that practitioners of this approach should
              address to continue building future generations of RNN models.",
  month    =  apr,
  year     =  2021,
  keywords = "cognition; decision making; machine learning; neuroscience;
              Recurrent Neural Networks;RNN",
  doi      = "10.31234/osf.io/w34n2"
}

@ARTICLE{Pascanu2012-hw,
  title         = "On the difficulty of training Recurrent Neural Networks",
  author        = "Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua",
  abstract      = "There are two widely known issues with properly training
                   Recurrent Neural Networks, the vanishing and the exploding
                   gradient problems detailed in Bengio et al. (1994). In this
                   paper we attempt to improve the understanding of the
                   underlying issues by exploring these problems from an
                   analytical, a geometric and a dynamical systems perspective.
                   Our analysis is used to justify a simple yet effective
                   solution. We propose a gradient norm clipping strategy to
                   deal with exploding gradients and a soft constraint for the
                   vanishing gradients problem. We validate empirically our
                   hypothesis and proposed solutions in the experimental
                   section.",
  month         =  nov,
  year          =  2012,
  archivePrefix = "arXiv",
  eprint        = "1211.5063",
  primaryClass  = "cs.LG",
  arxivid       = "1211.5063"
}

@ARTICLE{Santuz_undated-yp,
  title  = "Differential role of spinal and supraspinal processing of
            proprioceptive information in mouse locomotion",
  author = "Santuz, Alessandro and Laflamme, Olivier and Akay, Turgay",
  doi    = "10.1101/2021.04.28.441796"
}

@ARTICLE{Piray_undated-ci,
  title  = "Linear reinforcement learning: Flexible reuse of computation in
            planning, grid fields, and cognitive control",
  author = "Piray, Payam and Daw, Nathaniel D",
  doi    = "10.1101/856849"
}

@ARTICLE{Pollock2020-hb,
  title     = "Engineering recurrent neural networks from task-relevant
               manifolds and dynamics",
  author    = "Pollock, Eli and Jazayeri, Mehrdad",
  abstract  = "Many cognitive processes involve transformations of distributed
               representations in neural populations, creating a need for
               population-level models. Recurrent neural network models fulfill
               this need, but there are many open questions about how their
               connectivity gives rise to dynamics that solve a task. Here, we
               present a method for finding the connectivity of networks for
               which the dynamics are specified to solve a task in an
               interpretable way. We apply our method to a working memory task
               by synthesizing a network that implements a drift-diffusion
               process over a ring-shaped manifold. We also use our method to
               demonstrate how inputs can be used to control network dynamics
               for cognitive flexibility and explore the relationship between
               representation geometry and network capacity. Our work fits
               within the broader context of understanding neural computations
               as dynamics over relatively low-dimensional manifolds formed by
               correlated patterns of neurons.",
  journal   = "PLoS Comput. Biol.",
  publisher = "journals.plos.org",
  volume    =  16,
  number    =  8,
  pages     = "e1008128",
  month     =  aug,
  year      =  2020,
  keywords  = "RNN",
  language  = "en",
  issn      = "1553-734X, 1553-7358",
  pmid      = "32785228",
  doi       = "10.1371/journal.pcbi.1008128",
  pmc       = "PMC7446915"
}

@UNPUBLISHED{Marshall2021-cs,
  title    = "Flexible neural control of motor units",
  author   = "Marshall, Najja J and Glaser, Joshua I and Trautmann, Eric M and
              Amematsro, Elom A and Perkins, Sean M and Shadlen, Michael N and
              Abbott, L F and Cunningham, John P and Churchland, Mark M",
  abstract = "Voluntary movement requires communication from cortex to the
              spinal cord, where a dedicated pool of motor units (MUs)
              activates each muscle. The canonical description of MU function,
              established decades ago, rests upon two foundational tenets.
              First, cortex cannot control MUs independently but supplies each
              pool with a common drive that specifies force amplitude. Second,
              as force rises, MUs are recruited in a consistent order typically
              described by Henneman's size principle. While this paradigm has
              considerable empirical support, a direct test requires
              simultaneous observations of many MUs over a range of behaviors.
              We developed an isometric task that allowed stable MU recordings
              during rapidly changing force production. MU responses were
              surprisingly flexible and behavior-dependent. MU activity could
              not be accurately described as reflecting common drive, even when
              fit with highly expressive latent factor models. Neuropixels
              probe recordings revealed that, consistent with the requirements
              of fully flexible control, the cortical population response
              displays a surprisingly large number of degrees of freedom.
              Furthermore, MUs were differentially recruited by
              microstimulation at neighboring cortical sites. Thus, MU
              activities are flexibly controlled to meet task demands, and
              cortex has the capacity to contribute to that ability. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.05.05.442653",
  month    =  may,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.05.05.442653"
}

@ARTICLE{Moskovitz_undated-ut,
  title  = "A {First-Occupancy} Representation for Reinforcement Learning",
  author = "Moskovitz, Ted and Wilson, Spencer R"
}

@ARTICLE{Duan2021-qb,
  title     = "A cortico-collicular pathway for motor planning in a
               memory-dependent perceptual decision task",
  author    = "Duan, Chunyu A and Pan, Yuxin and Ma, Guofen and Zhou, Taotao
               and Zhang, Siyu and Xu, Ning-Long",
  abstract  = "Survival in a dynamic environment requires animals to plan
               future actions based on past sensory evidence, known as motor
               planning. However, the neuronal circuits underlying this crucial
               brain function remain elusive. Here, we employ
               projection-specific imaging and perturbation methods to
               investigate the direct pathway linking two key nodes in the
               motor planning network, the secondary motor cortex (M2) and the
               midbrain superior colliculus (SC), in mice performing a
               memory-dependent perceptual decision task. We find dynamic
               coding of choice information in SC-projecting M2 neurons during
               motor planning and execution, and disruption of this information
               by inhibiting M2 terminals in SC selectively impaired decision
               maintenance. Furthermore, we show that while both excitatory and
               inhibitory SC neurons receive synaptic inputs from M2, these SC
               subpopulations display differential temporal patterns in choice
               coding during behavior. Our results reveal the dynamic
               recruitment of the premotor-collicular pathway as a circuit
               mechanism for motor planning. Duan, Pan et al. find that the
               premotor cortex cooperates with the midbrain superior colliculus
               via direct projections to implement decision maintenance. These
               results reveal mechanisms of cortico-collicular interaction
               during cognition and action in a pathway- and cell-type-specific
               manner.",
  journal   = "Nat. Commun.",
  publisher = "Nature Publishing Group",
  volume    =  12,
  number    =  1,
  pages     = "1--16",
  month     =  may,
  year      =  2021,
  language  = "en",
  issn      = "2041-1723, 2041-1723",
  doi       = "10.1038/s41467-021-22547-9"
}

@ARTICLE{Sans-Dublanc2021-tu,
  title    = "Optogenetic {fUSI} for brain-wide mapping of neural activity
              mediating collicular-dependent behaviors",
  author   = "Sans-Dublanc, Arnau and Chrzanowska, Anna and Reinhard, Katja and
              Lemmon, Dani and Nuttin, Bram and Lambert, Th{\'e}o and Montaldo,
              Gabriel and Urban, Alan and Farrow, Karl",
  abstract = "Neuronal cell types are arranged in brain-wide circuits that
              guide behavior. In mice, the superior colliculus innervates a set
              of targets that direct orienting and defensive actions. We
              combined functional ultrasound imaging (fUSI) with optogenetics
              to reveal the network of brain regions functionally activated by
              four collicular cell types. Stimulating each neuronal group
              triggered different behaviors and activated distinct sets of
              brain nuclei. This included regions not previously thought to
              mediate defensive behaviors, for example, the posterior
              paralaminar nuclei of the thalamus (PPnT), which we show to play
              a role in suppressing habituation. Neuronal recordings with
              Neuropixels probes show that (1) patterns of spiking activity and
              fUSI signals correlate well in space and (2) neurons in
              downstream nuclei preferentially respond to innately threatening
              visual stimuli. This work provides insight into the functional
              organization of the networks governing innate behaviors and
              demonstrates an experimental approach to explore the whole-brain
              neuronal activity downstream of targeted cell types.",
  journal  = "Neuron",
  month    =  apr,
  year     =  2021,
  keywords = "defensive behaviors; functional ultrasound imaging; innate
              behaviors; mouse; optogenetics; superior colliculus",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "33930307",
  doi      = "10.1016/j.neuron.2021.04.008"
}

@INPROCEEDINGS{Seabold2010-jq,
  title      = "Statsmodels: Econometric and statistical modeling with python",
  booktitle  = "Proceedings of the 9th Python in Science Conference",
  author     = "Seabold, Skipper and Perktold, Josef",
  publisher  = "SciPy",
  year       =  2010,
  conference = "Python in Science Conference",
  location   = "Austin, Texas",
  doi        = "10.25080/majora-92bf1922-011"
}

@ARTICLE{Perraul-Joncas2013-be,
  title         = "Non-linear dimensionality reduction: Riemannian metric
                   estimation and the problem of geometric discovery",
  author        = "Perraul-Joncas, Dominique and Meila, Marina",
  abstract      = "In recent years, manifold learning has become increasingly
                   popular as a tool for performing non-linear dimensionality
                   reduction. This has led to the development of numerous
                   algorithms of varying degrees of complexity that aim to
                   recover man ifold geometry using either local or global
                   features of the data. Building on the Laplacian Eigenmap and
                   Diffusionmaps framework, we propose a new paradigm that
                   offers a guarantee, under reasonable assumptions, that any
                   manifo ld learning algorithm will preserve the geometry of a
                   data set. Our approach is based on augmenting the output of
                   embedding algorithms with geometric informatio n embodied in
                   the Riemannian metric of the manifold. We provide an
                   algorithm for estimating the Riemannian metric from data and
                   demonstrate possible application s of our approach in a
                   variety of examples.",
  month         =  may,
  year          =  2013,
  archivePrefix = "arXiv",
  eprint        = "1305.7255",
  primaryClass  = "stat.ML",
  arxivid       = "1305.7255"
}

@UNPUBLISHED{Harpaz2021-mu,
  title    = "Precise visuomotor transformations underlying collective behavior
              in larval zebrafish",
  author   = "Harpaz, Roy and Nguyen, Minh Nguyet and Bahl, Armin and Engert,
              Florian",
  abstract = "Complex schooling behaviors result from local interactions among
              individuals. Yet, how sensory signals from neighbors are analyzed
              in the visuomotor stream of animals is poorly understood. Here,
              we studied aggregation behavior in larval zebrafish and found
              that over development larvae transition from overdispersed groups
              to tight shoals. Using a virtual reality assay, we characterized
              the algorithms fish use to transform visual inputs from neighbors
              into movement decisions. We found that young larvae turn away
              from retinal ``clutter'' by integrating and averaging retina-wide
              visual inputs within each eye, and by using a winner-take-all
              strategy for binocular integration. As fish mature, their
              responses expand to include attraction to low retinal clutter,
              that is based on similar algorithms of visual integration. Using
              model simulations, we show that the observed algorithms
              accurately predict group structure over development. These
              findings allow us to make testable predictions regarding the
              neuronal circuits underlying collective behavior in zebrafish.
              \#\#\# Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.05.24.445521",
  month    =  may,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.05.24.445521"
}

@UNPUBLISHED{Failor2021-wn,
  title    = "Learning orthogonalizes visual cortical population codes",
  author   = "Failor, Samuel W and Carandini, Matteo and Harris, Kenneth D",
  abstract = "The response of a neuronal population to a stimulus can be
              summarized by a vector in a high-dimensional space. Learning
              theory suggests that the brain should be most able to produce
              distinct behavioral responses to two stimuli when the rate
              vectors they evoke are close to orthogonal. To investigate how
              learning modifies population codes, we measured the orientation
              tuning of 4,000-neuron populations in visual cortex before and
              after training on a visual discrimination task. Learning
              suppressed responses to the task-informative stimuli, most
              strongly amongst weakly-tuned neurons. This suppression reflected
              a simple change at the population level: sparsening of population
              responses to relevant stimuli, resulting in orthogonalization of
              their rate vectors. A model of F-I curve modulation, requiring no
              synaptic plasticity, quantitatively predicted the learning
              effect. \#\#\# Competing Interest Statement The authors have
              declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.05.23.445338",
  month    =  may,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.05.23.445338"
}

@UNPUBLISHED{Sridhar2021-ov,
  title    = "The geometry of decision-making",
  author   = "Sridhar, Vivek Hari and Li, Liang and Gorbonos, Dan and Nagy,
              Mate and Schell, Bianca R and Sorochkin, Timothy and Gov, Nir S
              and Couzin, Iain D",
  abstract = "Choosing among spatially-distributed options is a central
              challenge for animals, from deciding among alternative potential
              food sources or refuges, to choosing with whom to associate.
              Using an integrated theoretical and experimental approach
              (employing immersive virtual reality), we consider the interplay
              between movement and vectorial integration during decision-making
              regarding two, or more, options in space. In computational models
              of this process we reveal the occurrence of spontaneous and
              abrupt ``critical'' transitions (associated with specific
              geometrical relationships) whereby organisms spontaneously switch
              from averaging vectorial information among, to suddenly excluding
              one, among the remaining options. This bifurcation process
              repeats until only one option\textbackslash---|the one ultimately
              selected\textbackslash---|remains. Thus we predict that the brain
              repeatedly breaks multi-choice decisions into a series of binary
              decisions in space-time. Experiments with fruit flies, desert
              locusts, and larval zebrafish reveal that they exhibit these same
              bifurcations, demonstrating that across taxa and ecological
              context, we show that there exist fundamental geometric
              principles that are essential to explain how, and why, animals
              move the way they do. \#\#\# Competing Interest Statement The
              authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.05.26.445795",
  month    =  may,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.05.26.445795"
}

@ARTICLE{Chung2021-hm,
  title         = "Neural population geometry: An approach for understanding
                   biological and artificial neural networks",
  author        = "Chung, Sueyeon and Abbott, L F",
  abstract      = "Advances in experimental neuroscience have transformed our
                   ability to explore the structure and function of neural
                   circuits. At the same time, advances in machine learning
                   have unleashed the remarkable computational power of
                   artificial neural networks (ANNs). While these two fields
                   have different tools and applications, they present a
                   similar challenge: namely, understanding how information is
                   embedded and processed through high-dimensional
                   representations to solve complex tasks. One approach to
                   addressing this challenge is to utilize mathematical and
                   computational tools to analyze the geometry of these
                   high-dimensional representations, i.e., neural population
                   geometry. We review examples of geometrical approaches
                   providing insight into the function of biological and
                   artificial neural networks: representation untangling in
                   perception, a geometric theory of classification capacity,
                   disentanglement and abstraction in cognitive systems,
                   topological representations underlying cognitive maps,
                   dynamic untangling in motor systems, and a dynamical
                   approach to cognition. Together, these findings illustrate
                   an exciting trend at the intersection of machine learning,
                   neuroscience, and geometry, in which neural population
                   geometry provides a useful population-level mechanistic
                   descriptor underlying task implementation. Importantly,
                   geometric descriptions are applicable across sensory
                   modalities, brain regions, network architectures and
                   timescales. Thus, neural population geometry has the
                   potential to unify our understanding of structure and
                   function in biological and artificial neural networks,
                   bridging the gap between single neurons, populations and
                   behavior.",
  month         =  apr,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2104.07059",
  primaryClass  = "q-bio.NC",
  arxivid       = "2104.07059"
}

@ARTICLE{Biswas2020-gi,
  title         = "A geometric framework to predict structure from function in
                   neural networks",
  author        = "Biswas, Tirthabir and Fitzgerald, James E",
  abstract      = "Neural computation in biological and artificial networks
                   relies on nonlinear synaptic integration. The structural
                   connectivity matrix of synaptic weights between neurons is a
                   critical determinant of overall network function, but
                   quantitative links between neural network structure and
                   function are complex and subtle. For example, many networks
                   can give rise to similar functional responses, and the same
                   network can function differently depending on context.
                   Whether certain patterns of synaptic connectivity are
                   required to generate specific network-level computations is
                   largely unknown. Here we introduce a geometric framework for
                   identifying synaptic connections required by steady-state
                   responses in recurrent networks of rectified-linear neurons.
                   Assuming that the number of specified response patterns does
                   not exceed the number of input synapses, we analytically
                   calculate the solution space of all feedforward and
                   recurrent connectivity matrices that can generate the
                   specified responses from the network inputs. A
                   generalization accounting for noise further reveals that the
                   solution space geometry can undergo topological transitions
                   as the allowed error increases, which could provide insight
                   into both neuroscience and machine learning. We ultimately
                   use this geometric characterization to derive certainty
                   conditions guaranteeing a non-zero synapse between neurons.
                   Our theoretical framework could thus be applied to neural
                   activity data to make rigorous anatomical predictions that
                   follow generally from the model architecture.",
  month         =  oct,
  year          =  2020,
  archivePrefix = "arXiv",
  eprint        = "2010.09660",
  primaryClass  = "q-bio.NC",
  arxivid       = "2010.09660"
}

@ARTICLE{Lyu_undated-dx,
  title  = "A neuronal circuit for vector computation direction signal in the
            Drosophila",
  author = "Lyu, Cheng and Abbott, L F",
  doi    = "10.1101/2020.12.22.423967"
}

@UNPUBLISHED{Darshan2021-dv,
  title    = "Learning to represent continuous variables in heterogeneous
              neural networks",
  author   = "Darshan, Ran and Rivkind, Alexander",
  abstract = "Manifold attractors are a key framework for understanding how
              continuous variables, such as position or head direction, are
              encoded in the brain. In this framework, the variable is
              represented along a continuum of persistent neuronal states which
              forms a manifold attactor. Neural networks with symmetric
              synaptic connectivity that can implement manifold attractors have
              become the dominant model in this framework. In addition to a
              symmetric connectome, these networks imply homogeneity of
              individual-neuron tuning curves and symmetry of the
              representational space; these features are largely inconsistent
              with neurobiological data. Here, we developed a theory for
              computations based on manifold attractors in trained neural
              networks and show how these manifolds can cope with diverse
              neuronal responses, imperfections in the geometry of the manifold
              and a high level of synaptic heterogeneity. In such heterogeneous
              trained networks, a continuous representational space emerges
              from a small set of stimuli used for training. Furthermore, we
              find that the network response to external inputs depends on the
              geometry of the representation and on the level of synaptic
              heterogeneity in an analytically tractable and interpretable way.
              Finally, we show that a too complex geometry of the neuronal
              representation impairs the attractiveness of the manifold and may
              lead to its destabilization. Our framework reveals that
              continuous features can be represented in the recurrent dynamics
              of heterogeneous networks without assuming unrealistic symmetry.
              It suggests that the representational space of putative manifold
              attractors in the brain dictates the dynamics in their vicinity.
              \#\#\# Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.06.01.446635",
  month    =  jun,
  year     =  2021,
  keywords = "RNN",
  language = "en",
  doi      = "10.1101/2021.06.01.446635"
}

@ARTICLE{Hunter2007-zc,
  title    = "Matplotlib: A {2D} Graphics Environment",
  author   = "Hunter, John D",
  abstract = "Matplotlib is a 2D graphics package used for Python for
              application development, interactive scripting,and
              publication-quality image generation across user interfaces and
              operating systems",
  journal  = "Computing in Science Engineering",
  volume   =  9,
  number   =  3,
  pages    = "90--95",
  month    =  may,
  year     =  2007,
  keywords = "Graphics;Interpolation;Equations;Graphical user
              interfaces;Packaging;Image generation;User interfaces;Operating
              systems;Computer languages;Programming
              profession;Python;scripting languages;application
              development;scientific programming",
  issn     = "1558-366X",
  doi      = "10.1109/MCSE.2007.55"
}

@ARTICLE{Turner-Evans2020-iw,
  title    = "The Neuroanatomical Ultrastructure and Function of a Biological
              Ring Attractor",
  author   = "Turner-Evans, Daniel B and Jensen, Kristopher T and Ali, Saba and
              Paterson, Tyler and Sheridan, Arlo and Ray, Robert P and Wolff,
              Tanya and Lauritzen, J Scott and Rubin, Gerald M and Bock, Davi D
              and Jayaraman, Vivek",
  abstract = "Neural representations of head direction (HD) have been
              discovered in many species. Theoretical work has proposed that
              the dynamics associated with these representations are generated,
              maintained, and updated by recurrent network structures called
              ring attractors. We evaluated this theorized structure-function
              relationship by performing electron-microscopy-based circuit
              reconstruction and RNA profiling of identified cell types in the
              HD system of Drosophila melanogaster. We identified motifs that
              have been hypothesized to maintain the HD representation in
              darkness, update it when the animal turns, and tether it to
              visual cues. Functional studies provided support for the proposed
              roles of individual excitatory or inhibitory circuit elements in
              shaping activity. We also discovered recurrent connections
              between neuronal arbors with mixed pre- and postsynaptic
              specializations. Our results confirm that the Drosophila HD
              network contains the core components of a ring attractor while
              also revealing unpredicted structural features that might enhance
              the network's computational power.",
  journal  = "Neuron",
  volume   =  108,
  number   =  1,
  pages    = "145--163.e10",
  month    =  oct,
  year     =  2020,
  keywords = "Drosophila; RNA-seq; behavior; central complex; electron
              microscopy; head direction; navigation; network dynamics; neural
              circuit; two-photon calcium imaging",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "32916090",
  doi      = "10.1016/j.neuron.2020.08.006"
}

@ARTICLE{Lu_undated-of,
  title  = "Transforming representations of movement from body- to
            world-centric space",
  author = "Lu, Jenny and Westeinde, Elena A and Hamburg, Lydia and Dawson,
            Paul M and Lyu, Cheng and Maimon, Gaby and Druckmann, Shaul and
            Wilson, Rachel I",
  doi    = "10.1101/2020.12.22.424001"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Hubel1965-ac,
  title     = "{RECEPTIVE} {FIELDS} {AND} {FUNCTIONAL} {ARCHITECTURE} {IN}
               {TWO} {NONSTRIATE} {VISUAL} {AREAS} (18 {AND} 19) {OF} {THE}
               {CAT}",
  author    = "Hubel, D H and Wiesel, T N",
  abstract  = "METHODS Seventeen cats were used. Procedures for preparing the
               animal, including anesthesia, immobilization of eyes, correction
               of refractive errors, and mapping of area centralis and optic
               discs on the projection screen, have all been described
               elsewhere(10, 11, 13). The retinas were stimulated by shining
               spots or patterns of light from a tungsten filament projector
               onto a wide movable tangent screen at 1.5 m. distance.
               Recordings were made in the light-adapted state. Background
               illumination was about 1.0 cd/m2, and stimuli …",
  journal   = "J. Neurophysiol.",
  publisher = "journals.physiology.org",
  volume    =  28,
  pages     = "229--289",
  month     =  mar,
  year      =  1965,
  keywords  = "AXONS; BRAIN ELECTROPHYSIOLOGY; BRAIN MAPPING; CATS;
               EXPERIMENTAL LAB STUDY; GENICULATE BODIES; MICROSCOPY; OCCIPITAL
               LOBE; RECEPTORS, NEURAL; RETINA; STAINS AND STAINING; VISION;
               VISUAL FIELDS",
  language  = "en",
  issn      = "0022-3077",
  pmid      = "14283058",
  doi       = "10.1152/jn.1965.28.2.229"
}

@ARTICLE{OKeefe1971-pr,
  title    = "The hippocampus as a spatial map. Preliminary evidence from unit
              activity in the freely-moving rat",
  author   = "O'Keefe, J and Dostrovsky, J",
  journal  = "Brain Res.",
  volume   =  34,
  number   =  1,
  pages    = "171--175",
  month    =  nov,
  year     =  1971,
  language = "en",
  issn     = "0006-8993",
  pmid     = "5124915",
  doi      = "10.1016/0006-8993(71)90358-1"
}

@ARTICLE{Zhang1996-zd,
  title     = "Representation of spatial orientation by the intrinsic dynamics
               of the head-direction cell ensemble: a theory",
  author    = "Zhang, K",
  abstract  = "The head-direction (HD) cells found in the limbic system in
               freely mov ing rats represent the instantaneous head direction
               of the animal in the horizontal plane regardless of the location
               of the animal. The internal direction represented by these cells
               uses both self-motion information for inertially based updating
               and familiar visual landmarks for calibration. Here, a model of
               the dynamics of the HD cell ensemble is presented. The stability
               of a localized static activity profile in the network and a
               dynamic shift mechanism are explained naturally by synaptic
               weight distribution components with even and odd symmetry,
               respectively. Under symmetric weights or symmetric reciprocal
               connections, a stable activity profile close to the known
               directional tuning curves will emerge. By adding a slight
               asymmetry to the weights, the activity profile will shift
               continuously without disturbances to its shape, and the shift
               speed can be controlled accurately by the strength of the
               odd-weight component. The generic formulation of the shift
               mechanism is determined uniquely within the current theoretical
               framework. The attractor dynamics of the system ensures
               modality-independence of the internal representation and
               facilitates the correction for cumulative error by the putative
               local-view detectors. The model offers a specific
               one-dimensional example of a computational mechanism in which a
               truly world-centered representation can be derived from
               observer-centered sensory inputs by integrating self-motion
               information.",
  journal   = "J. Neurosci.",
  publisher = "Soc Neuroscience",
  volume    =  16,
  number    =  6,
  pages     = "2112--2126",
  month     =  mar,
  year      =  1996,
  language  = "en",
  issn      = "0270-6474",
  pmid      = "8604055",
  pmc       = "PMC6578512"
}

@ARTICLE{Azencot2021-tk,
  title         = "A Differential Geometry Perspective on Orthogonal Recurrent
                   Models",
  author        = "Azencot, Omri and Benjamin Erichson, N and Ben-Chen, Mirela
                   and Mahoney, Michael W",
  abstract      = "Recently, orthogonal recurrent neural networks (RNNs) have
                   emerged as state-of-the-art models for learning long-term
                   dependencies. This class of models mitigates the exploding
                   and vanishing gradients problem by design. In this work, we
                   employ tools and insights from differential geometry to
                   offer a novel perspective on orthogonal RNNs. We show that
                   orthogonal RNNs may be viewed as optimizing in the space of
                   divergence-free vector fields. Specifically, based on a
                   well-known result in differential geometry that relates
                   vector fields and linear operators, we prove that every
                   divergence-free vector field is related to a skew-symmetric
                   matrix. Motivated by this observation, we study a new
                   recurrent model, which spans the entire space of vector
                   fields. Our method parameterizes vector fields via the
                   directional derivatives of scalar functions. This requires
                   the construction of latent inner product, gradient, and
                   divergence operators. In comparison to state-of-the-art
                   orthogonal RNNs, our approach achieves comparable or better
                   results on a variety of benchmark tasks.",
  month         =  feb,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2102.09589",
  primaryClass  = "cs.LG",
  arxivid       = "2102.09589"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Battista2020-kr,
  title    = "{Capacity-Resolution} {Trade-Off} in the Optimal Learning of
              Multiple {Low-Dimensional} Manifolds by Attractor Neural Networks",
  author   = "Battista, Aldo and Monasson, R{\'e}mi",
  abstract = "Recurrent neural networks (RNN) are powerful tools to explain how
              attractors may emerge from noisy, high-dimensional dynamics. We
              study here how to learn the ∼N^\{2\} pairwise interactions in a
              RNN with N neurons to embed L manifolds of dimension D≪N. We show
              that the capacity, i.e., the maximal ratio L/N, decreases as
              |log$\epsilon$|^\{-D\}, where $\epsilon$ is the error on the
              position encoded by the neural activity along each manifold.
              Hence, RNN are flexible memory devices capable of storing a large
              number of manifolds at high spatial resolution. Our results rely
              on a combination of analytical tools from statistical mechanics
              and random matrix theory, extending Gardner's classical theory of
              learning to the case of patterns with strong spatial
              correlations.",
  journal  = "Phys. Rev. Lett.",
  volume   =  124,
  number   =  4,
  pages    = "048302",
  month    =  jan,
  year     =  2020,
  keywords = "to\_read\_for\_review",
  language = "en",
  issn     = "0031-9007, 1079-7114",
  pmid     = "32058781",
  doi      = "10.1103/PhysRevLett.124.048302"
}

@ARTICLE{Brody2003-pl,
  title     = "Basic mechanisms for graded persistent activity: discrete
               attractors, continuous attractors, and dynamic representations",
  author    = "Brody, Carlos D and Romo, Ranulfo and Kepecs, Adam",
  abstract  = "Persistent neural activity is observed in many systems, and is
               thought to be a neural substrate for holding memories over time
               delays of a few seconds. Recent work has addressed two issues.
               First, how can networks of neurons robustly hold such an active
               memory? Computer systems obtain significant robustness to noise
               by approximating analogue quantities with discrete digital
               representations. In a similar manner, theoretical models of
               persistent activity in spiking neurons have shown that the most
               robust and stable way to store the short-term memory of a
               continuous parameter is to approximate it with a discrete
               representation. This general idea applies very broadly to
               mechanisms that range from biochemical networks to single cells
               and to large circuits of neurons. Second, why is it commonly
               observed that persistent activity in the cortex can be strongly
               time-varying? This observation is almost ubiquitous, and
               therefore must be taken into account in our models and our
               understanding of how short-term memories are held in the cortex.",
  journal   = "Curr. Opin. Neurobiol.",
  publisher = "Elsevier",
  volume    =  13,
  number    =  2,
  pages     = "204--211",
  month     =  apr,
  year      =  2003,
  language  = "en",
  issn      = "0959-4388",
  pmid      = "12744975",
  doi       = "10.1016/s0959-4388(03)00050-3"
}

@ARTICLE{Burak2009-rk,
  title     = "Accurate path integration in continuous attractor network models
               of grid cells",
  author    = "Burak, Yoram and Fiete, Ila R",
  abstract  = "Grid cells in the rat entorhinal cortex display strikingly
               regular firing responses to the animal's position in 2-D space
               and have been hypothesized to form the neural substrate for
               dead-reckoning. However, errors accumulate rapidly when velocity
               inputs are integrated in existing models of grid cell activity.
               To produce grid-cell-like responses, these models would require
               frequent resets triggered by external sensory cues. Such
               inadequacies, shared by various models, cast doubt on the
               dead-reckoning potential of the grid cell system. Here we focus
               on the question of accurate path integration, specifically in
               continuous attractor models of grid cell activity. We show, in
               contrast to previous models, that continuous attractor models
               can generate regular triangular grid responses, based on inputs
               that encode only the rat's velocity and heading direction. We
               consider the role of the network boundary in the integration
               performance of the network and show that both periodic and
               aperiodic networks are capable of accurate path integration,
               despite important differences in their attractor manifolds. We
               quantify the rate at which errors in the velocity integration
               accumulate as a function of network size and intrinsic noise
               within the network. With a plausible range of parameters and the
               inclusion of spike variability, our model networks can
               accurately integrate velocity inputs over a maximum of
               approximately 10-100 meters and approximately 1-10 minutes.
               These findings form a proof-of-concept that continuous attractor
               dynamics may underlie velocity integration in the dorsolateral
               medial entorhinal cortex. The simulations also generate
               pertinent upper bounds on the accuracy of integration that may
               be achieved by continuous attractor dynamics in the grid cell
               network. We suggest experiments to test the continuous attractor
               model and differentiate it from models in which single cells
               establish their responses independently of each other.",
  journal   = "PLoS Comput. Biol.",
  publisher = "journals.plos.org",
  volume    =  5,
  number    =  2,
  pages     = "e1000291",
  month     =  feb,
  year      =  2009,
  language  = "en",
  issn      = "1553-734X, 1553-7358",
  pmid      = "19229307",
  doi       = "10.1371/journal.pcbi.1000291",
  pmc       = "PMC2632741"
}

@MISC{Kim_undated-wm,
  title        = "Inferring latent dynamics underlying neural population
                  activity via neural differential equations",
  author       = "Kim, Timothy Doyeon and Luo, Thomas Zhihao",
  howpublished = "\url{https://pillowlab.princeton.edu/pubs/Kim_ICML2021_PLNDE.pdf}",
  note         = "Accessed: 2021-6-17",
  keywords     = "RNN"
}

@ARTICLE{Gallego2022-mf,
  title    = "Going beyond primary motor cortex to improve brain--computer
              interfaces",
  author   = "Gallego, Juan A and Makin, Tamar R and McDougle, Samuel D",
  abstract = "Brain--computer interfaces (BCIs) for movement restoration
              typically decode the user's intent from neural activity in their
              primary motor cortex (M1) and use this information to enable
              `mental control' of an external device. Here, we argue that
              activity in M1 has both too little and too much information for
              optimal decoding: too little, in that many regions beyond it
              contribute unique motor outputs and have movement-related
              information that is absent or otherwise difficult to resolve from
              M1 activity; and too much, in that motor commands are tangled up
              with nonmotor processes such as attention and feedback
              processing, potentially hindering decoding. Both challenges might
              be circumvented, we argue, by integrating additional information
              from multiple brain regions to develop BCIs that will better
              interpret the user's intent.",
  journal  = "Trends Neurosci.",
  month    =  jan,
  year     =  2022,
  keywords = "neuroprosthetics; motor learning; neural populations; decoding;
              neural networks; planning",
  issn     = "0166-2236",
  doi      = "10.1016/j.tins.2021.12.006"
}

@UNPUBLISHED{Ormond2021-vn,
  title    = "Hippocampal place cells use vector computations to navigate",
  author   = "Ormond, Jake and O'Keefe, John",
  abstract = "One function of the Hippocampal Cognitive Map is to provide
              information about salient locations in familiar environments such
              as those containing reward or danger, and to support navigation
              towards or away from those locations[1][1]. Although much is
              known about how the hippocampus encodes location in world-centred
              coordinates, how it supports flexible navigation is less well
              understood. We recorded from CA1 place cells while rats navigated
              to a goal or freely foraged on the honeycomb maze[2][2]. The maze
              tests the animal's ability to navigate using indirect as well as
              direct paths to the goal and allows the directionality of place
              cells to be assessed at each choice point during traversal to the
              goal. Place fields showed strong directional polarization in the
              navigation task, and to a lesser extent during random foraging.
              This polarization was characterized by vector fields which
              converged to sinks distributed throughout the environment. The
              distribution of these convergence sinks was centred near the goal
              location, and the population vector field converged on the goal,
              providing a strong navigational signal. Changing the goal
              location led to the movement of ConSinks and vector fields
              towards the new goal and within-days, the ConSink distance to the
              goal decreased with continued training. The honeycomb maze allows
              the independent assessment of spatial representation and spatial
              action in place cell activity and shows how the latter depends on
              the former. The results suggest a vector-based model of how the
              hippocampus supports flexible navigation, allowing animals to
              select optimal paths to destinations from any location in the
              environment. \#\#\# Competing Interest Statement The authors have
              declared no competing interest. [1]: \#ref-1 [2]: \#ref-2",
  journal  = "bioRxiv",
  pages    = "2021.06.23.449621",
  month    =  jun,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.06.23.449621"
}

@ARTICLE{Boucheny2005-hl,
  title    = "A Continuous Attractor Network Model Without Recurrent
              Excitation: Maintenance and Integration in the Head Direction
              Cell System",
  author   = "Boucheny, Christian and Brunel, Nicolas and Arleo, Angelo",
  abstract = "Motivated by experimental observations of the head direction
              system, we study a three population network model that operates
              as a continuous attractor network. This network is able to store
              in a short-term memory an angular variable (the head direction)
              as a spatial profile of activity across neurons in the absence of
              selective external inputs, and to accurately update this variable
              on the basis of angular velocity inputs. The network is composed
              of one excitatory population and two inhibitory populations, with
              inter-connections between populations but no connections within
              the neurons of a same population. In particular, there are no
              excitatory-to-excitatory connections. Angular velocity signals
              are represented as inputs in one inhibitory population (clockwise
              turns) or the other (counterclockwise turns). The system is
              studied using a combination of analytical and numerical methods.
              Analysis of a simplified model composed of threshold-linear
              neurons gives the conditions on the connectivity for (i) the
              emergence of the spatially selective profile, (ii) reliable
              integration of angular velocity inputs, and (iii) the range of
              angular velocities that can be accurately integrated by the
              model. Numerical simulations allow us to study the proposed
              scenario in a large network of spiking neurons and compare their
              dynamics with that of head direction cells recorded in the rat
              limbic system. In particular, we show that the directional
              representation encoded by the attractor network can be rapidly
              updated by external cues, consistent with the very short update
              latencies observed experimentally by Zugaro et al. (2003) in
              thalamic head direction cells.",
  journal  = "J. Comput. Neurosci.",
  volume   =  18,
  number   =  2,
  pages    = "205--227",
  month    =  mar,
  year     =  2005,
  issn     = "0929-5313, 1573-6873",
  doi      = "10.1007/s10827-005-6559-y"
}

@ARTICLE{Eliasmith2005-gx,
  title    = "A unified approach to building and controlling spiking attractor
              networks",
  author   = "Eliasmith, Chris",
  abstract = "Extending work in Eliasmith and Anderson (2003), we employ a
              general framework to construct biologically plausible simulations
              of the three classes of attractor networks relevant for
              biological systems: static (point, line, ring, and plane)
              attractors, cyclic attractors, and chaotic attractors. We discuss
              these attractors in the context of the neural systems that they
              have been posited to help explain: eye control, working memory,
              and head direction; locomotion (specifically swimming); and
              olfaction, respectively. We then demonstrate how to introduce
              control into these models. The addition of control shows how
              attractor networks can be used as subsystems in larger neural
              systems, demonstrates how a much larger class of networks can be
              related to attractor networks, and makes it clear how attractor
              networks can be exploited for various information processing
              tasks in neurobiological systems.",
  journal  = "Neural Comput.",
  volume   =  17,
  number   =  6,
  pages    = "1276--1314",
  month    =  jun,
  year     =  2005,
  language = "en",
  issn     = "0899-7667",
  pmid     = "15901399",
  doi      = "10.1162/0899766053630332"
}

@UNPUBLISHED{Schreiner2021-jk,
  title    = "Mice are not automatons; subjective experience in premotor
              circuits guides behavior",
  author   = "Schreiner, Drew C and Cazares, Christian and Renteria, Rafael and
              Gremel, Christina M",
  abstract = "Subjective experience is a powerful driver of decision-making and
              continuously accrues. However, most neurobiological studies
              constrain analyses to task-related variables and ignore how
              continuously and individually experienced internal, temporal, and
              contextual factors influence adaptive behavior during
              decision-making and the associated neural mechanisms. We show
              mice rely on learned information about recent and longer-term
              subjective experience of variables above and beyond prior actions
              and reward, including checking behavior and the passage of time,
              to guide self-initiated, self-paced, and self-generated actions.
              These experiential variables were represented in secondary motor
              cortex (M2) activity and its projections into dorsal medial
              striatum (DMS). M2 integrated this information to bias
              strategy-level decision-making, and DMS projections used specific
              aspects of this recent experience to plan upcoming actions. This
              suggests diverse aspects of experience drive decision-making and
              its neural representation, and shows premotor corticostriatal
              circuits are crucial for using selective aspects of experiential
              information to guide adaptive behavior. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.06.23.449617",
  month    =  jun,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.06.23.449617"
}

@UNPUBLISHED{Javadzadeh2021-wb,
  title    = "Dynamic causal communication channels between neocortical areas",
  author   = "Javadzadeh, Mitra and Hofer, Sonja B",
  abstract = "Dynamic pathways of information flow between distributed brain
              regions underlie the diversity of behaviour. However, it remains
              unclear how neuronal activity in one area causally influences
              ongoing population activity in another, and how such interactions
              change over time. Here we introduce a causal approach to quantify
              cortical interactions by pairing simultaneous
              electrophysiological recordings with neural perturbations. We
              found that the influence visual cortical areas had on each other
              was surprisingly variable over time. Both feedforward and
              feedback pathways reliably affected different subpopulations of
              target neurons at different moments during processing of a visual
              stimulus, resulting in dynamically rotating communication
              dimensions between the two cortical areas. The influence of
              feedback on primary visual cortex (V1) became even more dynamic
              when visual stimuli were associated with a reward, impacting
              different subsets of V1 neurons within tens of milliseconds.
              This, in turn, controlled the geometry of V1 population activity
              in a behaviourally relevant manner. Thus, distributed neural
              populations interact through dynamically reorganizing and
              context- dependent communication channels to evaluate sensory
              information. \#\#\# Competing Interest Statement The authors have
              declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.06.28.449892",
  month    =  jun,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.06.28.449892"
}

@ARTICLE{Gao2015-ui,
  title    = "On simplicity and complexity in the brave new world of
              large-scale neuroscience",
  author   = "Gao, Peiran and Ganguli, Surya",
  abstract = "Technological advances have dramatically expanded our ability to
              probe multi-neuronal dynamics and connectivity in the brain.
              However, our ability to extract a simple conceptual understanding
              from complex data is increasingly hampered by the lack of
              theoretically principled data analytic procedures, as well as
              theoretical frameworks for how circuit connectivity and dynamics
              can conspire to generate emergent behavioral and cognitive
              functions. We review and outline potential avenues for progress,
              including new theories of high dimensional data analysis, the
              need to analyze complex artificial networks, and methods for
              analyzing entire spaces of circuit models, rather than one model
              at a time. Such interplay between experiments, data analysis and
              theory will be indispensable in catalyzing conceptual advances in
              the age of large-scale neuroscience.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  32,
  pages    = "148--155",
  month    =  jun,
  year     =  2015,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "25932978",
  doi      = "10.1016/j.conb.2015.04.003"
}

@ARTICLE{Seeholzer2017-do,
  title         = "Efficient low-dimensional approximation of continuous
                   attractor networks",
  author        = "Seeholzer, Alexander and Deger, Moritz and Gerstner, Wulfram",
  abstract      = "Continuous ``bump'' attractors are an established model of
                   cortical working memory for continuous variables and can be
                   implemented using various neuron and network models. Here,
                   we develop a generalizable approach for the approximation of
                   bump states of continuous attractor networks implemented in
                   networks of both rate-based and spiking neurons. The method
                   relies on a low-dimensional parametrization of the spatial
                   shape of firing rates, allowing to apply efficient numerical
                   optimization methods. Using our theory, we can establish a
                   mapping between network structure and attractor properties
                   that allows the prediction of the effects of network
                   parameters on the steady state firing rate profile and the
                   existence of bumps, and vice-versa, to fine-tune a network
                   to produce bumps of a given shape.",
  month         =  nov,
  year          =  2017,
  archivePrefix = "arXiv",
  eprint        = "1711.08032",
  primaryClass  = "q-bio.NC",
  arxivid       = "1711.08032"
}

@ARTICLE{Eliav2021-jz,
  title     = "Multiscale representation of very large environments in the
               hippocampus of flying bats",
  author    = "Eliav, Tamir and Maimon, Shir R and Aljadeff, Johnatan and
               Tsodyks, Misha and Ginosar, Gily and Las, Liora and Ulanovsky,
               Nachum",
  abstract  = "Nearly all mammals navigate over large spatial scales in
               environments that span hundreds of meters to many kilometers.
               However, very little is known about the neural representations
               that underlie the coding of such large spaces. Eliav et al.
               recorded from place cells in the hippocampus of bats as they
               flew back and forth on an extremely long track (see the
               Perspective by Wood and Dudchenko). Many place cells had
               multiple place fields within this large environment. The place
               field sizes ranged from less than 1 meter up to 32 meters, and
               the sizes of the different place fields of an individual cell
               varied as much as 20-fold. Studying animals under naturalistic
               conditions can reveal new coding principles for the
               representation of their environment in the brain. Science ,
               abg4020, this issue p. [eabg4020][1]; see also abi9663, p.
               [913][2] \#\#\# INTRODUCTION Place cells are neurons in the
               hippocampus that represent the animal's position in space and
               are important for supporting navigation behaviors. These cells
               increase their spiking activity when the animal passes through a
               specific region of space, called the neuron's ``place field.''
               Since the discovery of place cells half a century ago, nearly
               all the research on spatial representations in the mammalian
               brain has focused on rats and mice as animal models and used
               small laboratory environments as experimental setups---usually
               small boxes or short linear tracks ~1 to 2 m in size. In such
               small environments, individual place cells typically have one
               place field, with a small field size. However, outdoor
               navigation of all mammals occurs in natural environments that
               span much larger spatial scales, of hundreds of meters or
               kilometers, and nothing is known about the neural codes for such
               large spatial scales. \#\#\# RATIONALE We reasoned that in very
               large environments, the hippocampus must exhibit a different
               coding scheme than seen in small environments because large
               environments cannot be tiled fully by the limited number of
               hippocampal neurons. We set out to discover this alternative
               coding scheme and thus to close the longstanding gap between the
               neurobiology of navigation as studied in the laboratory and
               natural large-scale navigation. To this end, we studied bats
               flying in a 200-m-long tunnel while we recorded the activity of
               hippocampal dorsal CA1 neurons using a custom
               wireless-electrophysiology system. \#\#\# RESULTS We found that
               place cells recorded in the large environment exhibited a
               multifield, multiscale representation of space: Individual
               neurons exhibited multiple place fields of diverse sizes,
               ranging from Multiscale hippocampal spatial code for very large
               environments. (Methods) We wirelessly recorded neural activity
               from hippocampal neurons of bats flying in a 200-m tunnel.
               (Findings) Single neurons exhibited multiple place fields with
               highly heterogeneous field sizes for the same neuron. (Function)
               This multiscale neural code for space strongly outperforms
               classical single-field place codes. (Modeling) Modeling by using
               interacting attractor networks and feedforward models
               recapitulated the multiscale coding. Hippocampal place cells
               encode the animal's location. Place cells were traditionally
               studied in small environments, and nothing is known about large
               ethologically relevant spatial scales. We wirelessly recorded
               from hippocampal dorsal CA1 neurons of wild-born bats flying in
               a long tunnel (200 meters). The size of place fields ranged from
               0.6 to 32 meters. Individual place cells exhibited multiple
               fields and a multiscale representation: Place fields of the same
               neuron differed up to 20-fold in size. This multiscale coding
               was observed from the first day of exposure to the environment,
               and also in laboratory-born bats that never experienced large
               environments. Theoretical decoding analysis showed that the
               multiscale code allows representation of very large environments
               with much higher precision than that of other codes. Together,
               by increasing the spatial scale, we discovered a neural code
               that is radically different from classical place codes. [1]:
               /lookup/doi/10.1126/science.abg4020 [2]:
               /lookup/doi/10.1126/science.abi9663 [3]: pending:yes",
  journal   = "Science",
  publisher = "American Association for the Advancement of Science",
  volume    =  372,
  number    =  6545,
  month     =  may,
  year      =  2021,
  language  = "en",
  issn      = "0036-8075, 1095-9203",
  pmid      = "34045327",
  doi       = "10.1126/science.abg4020"
}

@MISC{Sidney_I_Wiener_undated-qw,
  title  = "Head Direction Cells and the Neural Mechanisms of Spatial
            Orientation",
  author = "Sidney I. Wiener, Jeffrey S Taube"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Jeffery2016-lu,
  title     = "Optimal cue combination and landmark-stability learning in the
               head direction system",
  author    = "Jeffery, Kate J and Page, Hector J I and Stringer, Simon M",
  abstract  = "Maintaining a sense of direction requires combining information
               from static environmental landmarks with dynamic information
               about self‐motion. This is accomplished by the head direction
               system, whose neurons--head direction cells--encode specific
               head directions. When the brain integrates information in
               sensory domains, this process is almost always 'optimal'--that
               is, inputs are weighted according to their reliability. Evidence
               suggests cue combination by head direction cells may also be
               optimal. The simplicity of the head direction …",
  journal   = "J. Physiol.",
  publisher = "Wiley",
  volume    =  594,
  number    =  22,
  pages     = "6527--6534",
  month     =  nov,
  year      =  2016,
  issn      = "0022-3751, 1469-7793",
  doi       = "10.1113/jp272945"
}

@ARTICLE{Beer1995-wn,
  title     = "On the Dynamics of Small {Continuous-Time} Recurrent Neural
               Networks",
  author    = "Beer, Randall D",
  abstract  = "Dynamical neural networks are being increasingly employed in a
               variety of contexts, including as simple model nervous systems
               for autonomous agents. For this reason, there is a growing need
               for a comprehensive understanding of their dynamical properties.
               Using a combination of elementary analysis and numerical
               studies, this article begins a systematic examination of the
               dynamics of continuous-time recurrent neural networks.
               Specifically, a fairly complete description of the possible
               dynamical behavior and bifurcations of one- and two-neuron
               circuits is given, along with a few specific results for larger
               networks. This analysis provides both qualitative insight and,
               in many cases, quantitative formulas for predicting the
               dynamical behavior of particular circuits and how that behavior
               changes as network parameters are varied. These results
               demonstrate that even small circuits are capable of a rich
               variety of dynamical behavior (including chaotic dynamics). An
               approach to understanding the dynamics of circuits with
               time-varying inputs is also presented. Finally, based on this
               analysis, several strategies for focusing evolutionary searches
               into fruitful regions of network parameter space are suggested.",
  journal   = "Adapt. Behav.",
  publisher = "SAGE Publications Ltd STM",
  volume    =  3,
  number    =  4,
  pages     = "469--509",
  month     =  mar,
  year      =  1995,
  keywords  = "RNN",
  issn      = "1059-7123",
  doi       = "10.1177/105971239500300405"
}

@ARTICLE{Compte2000-xq,
  title     = "Synaptic mechanisms and network dynamics underlying spatial
               working memory in a cortical network model",
  author    = "Compte, A and Brunel, N and Goldman-Rakic, P S and Wang, X J",
  abstract  = "Single-neuron recordings from behaving primates have established
               a link between working memory processes and information-specific
               neuronal persistent activity in the prefrontal cortex. Using a
               network model endowed with a columnar architecture and based on
               the physiological properties of cortical neurons and synapses,
               we have examined the synaptic mechanisms of selective persistent
               activity underlying spatial working memory in the prefrontal
               cortex. Our model reproduces the phenomenology of the oculomotor
               delayed-response experiment of Funahashi et al. (S. Funahashi,
               C.J. Bruce and P.S. Goldman-Rakic, Mnemonic coding of visual
               space in the monkey's dorsolateral prefrontal cortex. J
               Neurophysiol 61:331-349, 1989). To observe stable spontaneous
               and persistent activity, we find that recurrent synaptic
               excitation should be primarily mediated by NMDA receptors, and
               that overall recurrent synaptic interactions should be dominated
               by inhibition. Isodirectional tuning of adjacent pyramidal cells
               and interneurons can be accounted for by a structured
               pyramid-to-interneuron connectivity. Robust memory storage
               against random drift of the tuned persistent activity and
               against distractors (intervening stimuli during the delay
               period) may be enhanced by neuromodulation of recurrent
               synapses. Experimentally testable predictions concerning the
               neural basis of working memory are discussed.",
  journal   = "Cereb. Cortex",
  publisher = "academic.oup.com",
  volume    =  10,
  number    =  9,
  pages     = "910--923",
  month     =  sep,
  year      =  2000,
  language  = "en",
  issn      = "1047-3211",
  pmid      = "10982751",
  doi       = "10.1093/cercor/10.9.910"
}

@ARTICLE{Pedregosa2011-kw,
  title    = "Scikit-learn: Machine Learning in Python",
  author   = "Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre
              and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and
              Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and
              Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and
              Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and
              Duchesnay, {\'E}douard",
  journal  = "J. Mach. Learn. Res.",
  volume   =  12,
  number   =  85,
  pages    = "2825--2830",
  year     =  2011,
  issn     = "1532-4435, 1533-7928"
}

@ARTICLE{Jazayeri2021-tn,
  title         = "Interpreting neural computations by examining intrinsic and
                   embedding dimensionality of neural activity",
  author        = "Jazayeri, Mehrdad and Ostojic, Srdjan",
  abstract      = "The current exponential rise in recording capacity calls for
                   new approaches for analysing and interpreting neural data.
                   Effective dimensionality has emerged as a key concept for
                   describing neural activity at the collective level, yet
                   different studies rely on a variety of definitions of it.
                   Here we focus on the complementary notions of intrinsic and
                   embedding dimensionality, and argue that they provide a
                   useful framework for extracting computational principles
                   from data. Reviewing recent works, we propose that the
                   intrinsic dimensionality reflects information about the
                   latent variables encoded in collective activity, while
                   embedding dimensionality reveals the manner in which this
                   information is processed. Network models form an ideal
                   substrate for testing more specifically the hypotheses on
                   the computational principles reflected through intrinsic and
                   embedding dimensionality.",
  month         =  jul,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2107.04084",
  primaryClass  = "q-bio.NC",
  arxivid       = "2107.04084"
}

@ARTICLE{Nieh2021-ii,
  title    = "Geometry of abstract learned knowledge in the hippocampus",
  author   = "Nieh, Edward H and Schottdorf, Manuel and Freeman, Nicolas W and
              Low, Ryan J and Lewallen, Sam and Koay, Sue Ann and Pinto, Lucas
              and Gauthier, Jeffrey L and Brody, Carlos D and Tank, David W",
  abstract = "Hippocampal neurons encode physical variables1-7 such as space1
              or auditory frequency6 in cognitive maps8. In addition,
              functional magnetic resonance imaging studies in humans have
              shown that the hippocampus can also encode more abstract, learned
              variables9-11. However, their integration into existing neural
              representations of physical variables12,13 is unknown. Here,
              using two-photon calcium imaging, we show that individual neurons
              in the dorsal hippocampus jointly encode accumulated evidence
              with spatial position in mice performing a decision-making task
              in virtual reality14-16. Nonlinear dimensionality reduction13
              showed that population activity was well-described by
              approximately four to six latent variables, which suggests that
              neural activity is constrained to a low-dimensional manifold.
              Within this low-dimensional space, both physical and abstract
              variables were jointly mapped in an orderly manner, creating a
              geometric representation that we show is similar across mice. The
              existence of conjoined cognitive maps suggests that the
              hippocampus performs a general computation-the creation of
              task-specific low-dimensional manifolds that contain a geometric
              representation of learned knowledge.",
  journal  = "Nature",
  volume   =  595,
  number   =  7865,
  pages    = "80--84",
  month    =  jul,
  year     =  2021,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "34135512",
  doi      = "10.1038/s41586-021-03652-7"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Chung2018-tx,
  title     = "Classification and Geometry of General Perceptual Manifolds",
  author    = "Chung, Sueyeon and Lee, Daniel D and Sompolinsky, Haim",
  abstract  = "Perceptual manifolds arise when a neural population responds to
               an ensemble of sensory signals associated with different
               physical features (eg, orientation, pose, scale, location, and
               intensity) of the same perceptual object. Object recognition and
               discrimination require classifying the manifolds in a manner
               that is insensitive to variability within a manifold. How
               neuronal systems give rise to invariant object classification
               and recognition is a fundamental problem in brain theory as well
               as in machine learning. Here, we study the ability of a …",
  journal   = "Phys. Rev. X",
  publisher = "American Physical Society",
  volume    =  8,
  number    =  3,
  pages     = "031003",
  month     =  jul,
  year      =  2018,
  doi       = "10.1103/PhysRevX.8.031003"
}

@ARTICLE{Umakantha2021-aa,
  title     = "Bridging neuronal correlations and dimensionality reduction",
  author    = "Umakantha, Akash and Morina, Rudina and Cowley, Benjamin R and
               Snyder, Adam C and Smith, Matthew A and Yu, Byron M",
  abstract  = "SummaryTwo commonly used approaches to study interactions among
               neurons are spike count correlation, which describes pairs of
               neurons, and dimensionality reduction, applied to a population
               of neurons. Although both approaches have been used to study
               trial-to-trial neuronal variability correlated among neurons,
               they are often used in isolation and have not been directly
               related. We first established concrete mathematical and
               empirical relationships between pairwise correlation and metrics
               of population-wide covariability based on dimensionality
               reduction. Applying these insights to macaque V4 population
               recordings, we found that the previously reported decrease in
               mean pairwise correlation associated with attention stemmed from
               three distinct changes in population-wide covariability.
               Overall, our work builds the intuition and formalism to bridge
               between pairwise correlation and population-wide covariability
               and presents a cautionary tale about the inferences one can make
               about population activity by using a single statistic, whether
               it be mean pairwise correlation or dimensionality.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  0,
  number    =  0,
  month     =  jul,
  year      =  2021,
  keywords  = "neuronal population; spike count correlation; dimensionality
               reduction; visual area V4; spatial attention;To Read;BCI",
  language  = "en",
  issn      = "0896-6273",
  doi       = "10.1016/j.neuron.2021.06.028"
}

@ARTICLE{Brown2021-lj,
  title    = "A unified energy-optimality criterion predicts human navigation
              paths and speeds",
  author   = "Brown, Geoffrey L and Seethapathi, Nidhi and Srinivasan, Manoj",
  abstract = "Navigating our physical environment requires changing directions
              and turning. Despite its ecological importance, we do not have a
              unified theoretical account of non-straight-line human movement.
              Here, we present a unified optimality criterion that predicts
              disparate non-straight-line walking phenomena, with straight-line
              walking as a special case. We first characterized the metabolic
              cost of turning, deriving the cost landscape as a function of
              turning radius and rate. We then generalized this cost landscape
              to arbitrarily complex trajectories, allowing the velocity
              direction to deviate from body orientation (holonomic walking).
              We used this generalized optimality criterion to mathematically
              predict movement patterns in multiple contexts of varying
              complexity: walking on prescribed paths, turning in place,
              navigating an angled corridor, navigating freely with end-point
              constraints, walking through doors, and navigating around
              obstacles. In these tasks, humans moved at speeds and paths
              predicted by our optimality criterion, slowing down to turn and
              never using sharp turns. We show that the shortest path between
              two points is, counterintuitively, often not energy-optimal, and,
              indeed, humans do not use the shortest path in such cases. Thus,
              we have obtained a unified theoretical account that predicts
              human walking paths and speeds in diverse contexts. Our model
              focuses on walking in healthy adults; future work could
              generalize this model to other human populations, other animals,
              and other locomotor tasks.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  118,
  number   =  29,
  month    =  jul,
  year     =  2021,
  keywords = "human movement; locomotion; metabolic energy; optimization;
              predictive theory",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "34266945",
  doi      = "10.1073/pnas.2020327118"
}

@ARTICLE{Ferreira-Pinto2021-yf,
  title    = "Functional diversity for body actions in the mesencephalic
              locomotor region",
  author   = "Ferreira-Pinto, Manuel J and Kanodia, Harsh and Falasconi,
              Antonio and Sigrist, Markus and Esposito, Maria S and Arber,
              Silvia",
  abstract = "Summary The mesencephalic locomotor region (MLR) is a key
              midbrain center with roles in locomotion. Despite extensive
              studies and clinical trials aimed at therapy-resistant
              Parkinson's disease (PD), debate on its function remains. Here,
              we reveal the existence of functionally diverse neuronal
              populations with distinct roles in control of body movements. We
              identify two spatially intermingled glutamatergic populations
              separable by axonal projections, mouse genetics, neuronal
              activity profiles, and motor functions. Most spinally projecting
              MLR neurons encoded the full-body behavior rearing. Loss- and
              gain-of-function optogenetic perturbation experiments establish a
              function for these neurons in controlling body extension. In
              contrast, Rbp4-transgene-positive MLR neurons project in an
              ascending direction to basal ganglia, preferentially encode the
              forelimb behaviors handling and grooming, and exhibit a role in
              modulating movement. Thus, the MLR contains glutamatergic
              neuronal subpopulations stratified by projection target
              exhibiting roles in action control not restricted to locomotion.",
  journal  = "Cell",
  month    =  jul,
  year     =  2021,
  keywords = "Motor controls; locomotion; rearing; forelimb behaviors;
              brainstem; mesencephalic locomotor region; basal ganglia;
              substantia nigra; spinal cord; deep brain stimulation;Locomotion",
  issn     = "0092-8674",
  doi      = "10.1016/j.cell.2021.07.002"
}

@UNPUBLISHED{Yatsenko2015-ty,
  title    = "{DataJoint}: managing big scientific data using {MATLAB} or
              Python",
  author   = "Yatsenko, Dimitri and Reimer, Jacob and Ecker, Alexander S and
              Walker, Edgar Y and Sinz, Fabian and Berens, Philipp and
              Hoenselaar, Andreas and James Cotton, R and Siapas, Athanassios S
              and Tolias, Andreas S",
  abstract = "Abstract The rise of big data in modern research poses serious
              challenges for data management: Large and intricate datasets from
              diverse instrumentation must be precisely aligned, annotated, and
              processed in a variety of ways to extract new insights. While
              high levels of data integrity are expected, research teams have
              diverse backgrounds, are geographically dispersed, and rarely
              possess a primary interest in data science. Here we describe
              DataJoint, an open-source toolbox designed for manipulating and
              processing scientific data under the relational data model.
              Designed for scientists who need a flexible and expressive
              database language with few basic concepts and operations,
              DataJoint facilitates multiuser access, efficient queries, and
              distributed computing. With implementations in both MATLAB and
              Python, DataJoint is not limited to particular file formats,
              acquisition systems, or data modalities and can be quickly
              adapted to new experimental designs. DataJoint and related
              resources are available at http://datajoint.github.com.",
  journal  = "bioRxiv",
  pages    = "031658",
  month    =  nov,
  year     =  2015,
  language = "en",
  doi      = "10.1101/031658"
}

@MISC{Reback2020-jj,
  title  = "pandas-dev/pandas: Pandas 1.0.3",
  author = "Reback, Jeff and McKinney, Wes and {jbrockmendel} and Van den
            Bossche, Joris and Augspurger, Tom and Cloud, Phillip and {gfyoung}
            and {Sinhrks} and Klein, Adam and Roeschke, Matthew and Hawkins,
            Simon and Tratner, Jeff and She, Chang and Ayd, William and
            Petersen, Terji and Garcia, Marc and Schendel, Jeremy and Hayden,
            Andy and {MomIsBestFriend} and Jancauskas, Vytautas and Battiston,
            Pietro and Seabold, Skipper and {chris-b} and {h-vetinari} and
            Hoyer, Stephan and Overmeire, Wouter and {alimcmaster} and Dong,
            Kaiqi and Whelan, Christopher and Mehyar, Mortada",
  month  =  mar,
  year   =  2020,
  doi    = "10.5281/zenodo.3715232"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Bradski2000-jt,
  title     = "{OpenCV}",
  author    = "Bradski, Gary and Kaehler, Adrian",
  abstract  = "… 35 Depth ``Z'' and disparity ``d'' are inversly related: Page
               36. ICRA 2010 ROS Tutorial Stereo • In aligned stereo, depth is
               from similar triangles: • Problem: Cameras are almost impossible
               to align • Solution: Mathematically align them: 36 r l r l x x
               fT Z Z T f Z x x T - = $\Rightarrow$ = - All: Gary Bradski …",
  journal   = "Dr. Dobb's journal of software tools",
  publisher = "roswiki.autolabor.com.cn",
  volume    =  3,
  year      =  2000
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Gao2017-rk,
  title     = "A theory of multineuronal dimensionality, dynamics and
               measurement",
  author    = "Gao, P and Trautmann, E and Yu, B and Santhanam, G and Ryu, S
               and {others}",
  abstract  = "In many experiments, neuroscientists tightly control behavior,
               record many trials, and obtain trial-averaged firing rates from
               hundreds of neurons in circuits containing billions of
               behaviorally relevant neurons. Di-mensionality reduction methods
               reveal a striking simplicity …",
  journal   = "BioRxiv",
  publisher = "biorxiv.org",
  year      =  2017
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Perez-Nieves2021-nv,
  title     = "Neural heterogeneity promotes robust learning",
  author    = "Perez-Nieves, N and Leung, V C H and Dragotti, P L and {others}",
  abstract  = "The brain has a hugely diverse, heterogeneous structure. Whether
               or not heterogeneity at the neural level plays a functional role
               remains unclear, and has been relatively little explored in
               models which are often highly homogeneous. We compared the
               performance of …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2021
}

@UNPUBLISHED{Anwar2021-zy,
  title    = "Training a spiking neuronal network model of visual-motor cortex
              to play a virtual racket-ball game using reinforcement learning",
  author   = "Anwar, Haroon and Caby, Simon and Dura-Bernal, Salvador and
              D'Onofrio, David and Hasegan, Daniel and Deible, Matt and
              Grunblatt, Sara and Chadderdon, George L and Kerr, Cliff C and
              Lakatos, Peter and Lytton, William W and Hazan, Hananel and
              Neymotin, Samuel A",
  abstract = "Recent models of spiking neuronal networks have been trained to
              perform behaviors in static environments using a variety of
              learning rules, with varying degrees of biological realism. Most
              of these models have not been tested in dynamic visual
              environments where models must make predictions on future states
              and adjust their behavior accordingly. The models using these
              learning rules are often treated as black boxes, with little
              analysis on circuit architectures and learning mechanisms
              supporting optimal performance. Here we developed visual/motor
              spiking neuronal network models and trained them to play a
              virtual racket-ball game using several reinforcement learning
              algorithms inspired by the dopaminergic reward system. We
              systematically investigated how different architectures and
              circuit-motifs (feed-forward, recurrent, feedback) contributed to
              learning and performance. We also developed a new
              biologically-inspired learning rule that significantly enhanced
              performance, while reducing training time. Our models included
              visual areas encoding game inputs and relaying the information to
              motor areas, which used this information to learn to move the
              racket to hit the ball. Neurons in the early visual area relayed
              information encoding object location and motion direction across
              the network. Neuronal association areas encoded spatial
              relationships between objects in the visual scene. Motor
              populations received inputs from visual and association areas
              representing the dorsal pathway. Two populations of motor neurons
              generated commands to move the racket up or down. Model-generated
              actions updated the environment and triggered reward or
              punishment signals that adjusted synaptic weights so that the
              models could learn which actions led to reward. Here we
              demonstrate that our biologically-plausible learning rules were
              effective in training spiking neuronal network models to solve
              problems in dynamic environments. We used our models to dissect
              the circuit architectures and learning rules most effective for
              learning. Our models offer novel predictions on the biological
              mechanisms supporting learning behaviors. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest.",
  journal  = "bioRxiv",
  pages    = "2021.07.29.454361",
  month    =  jul,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.07.29.454361"
}

@ARTICLE{Khan2018-lc,
  title     = "Distinct learning-induced changes in stimulus selectivity and
               interactions of {GABAergic} interneuron classes in visual cortex",
  author    = "Khan, Adil G and Poort, Jasper and Chadwick, Angus and Blot,
               Antonin and Sahani, Maneesh and Mrsic-Flogel, Thomas D and
               Hofer, Sonja B",
  abstract  = "How learning enhances neural representations for behaviorally
               relevant stimuli via activity changes of cortical cell types
               remains unclear. We simultaneously imaged responses of pyramidal
               cells (PYR) along with parvalbumin (PV), somatostatin (SOM), and
               vasoactive intestinal peptide (VIP) inhibitory interneurons in
               primary visual cortex while mice learned to discriminate visual
               patterns. Learning increased selectivity for task-relevant
               stimuli of PYR, PV and SOM subsets but not VIP cells.
               Strikingly, PV neurons became as selective as PYR cells, and
               their functional interactions reorganized, leading to the
               emergence of stimulus-selective PYR-PV ensembles. Conversely,
               SOM activity became strongly decorrelated from the network, and
               PYR-SOM coupling before learning predicted selectivity increases
               in individual PYR cells. Thus, learning differentially shapes
               the activity and interactions of multiple cell classes: while
               SOM inhibition may gate selectivity changes, PV interneurons
               become recruited into stimulus-specific ensembles and provide
               more selective inhibition as the network becomes better at
               discriminating behaviorally relevant stimuli.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  21,
  number    =  6,
  pages     = "851--859",
  month     =  jun,
  year      =  2018,
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "29786081",
  doi       = "10.1038/s41593-018-0143-z",
  pmc       = "PMC6390950"
}

@ARTICLE{Lee2021-jt,
  title         = "Discovering sparse control strategies in C. elegans",
  author        = "Lee, Edward D and Chen, Xiaowen and Daniels, Bryan C",
  abstract      = "Biological circuits such as neural or gene regulation
                   networks use internal states to map sensory input to an
                   adaptive repertoire of behavior. Characterizing this mapping
                   is a major challenge for systems biology, and though
                   experiments that probe internal states are developing
                   rapidly, organismal complexity presents a fundamental
                   obstacle given the many possible ways internal states could
                   map to behavior. Using C. elegans as an example, we propose
                   a protocol for systematic perturbation of neural states that
                   limits experimental complexity but still characterizes
                   collective aspects of the neural-behavioral map. We consider
                   experimentally motivated small perturbations -- ones that
                   are most likely to preserve natural dynamics and are closer
                   to internal control mechanisms -- to neural states and their
                   impact on collective neural behavior. Then, we connect such
                   perturbations to the local information geometry of
                   collective statistics, which can be fully characterized
                   using pairwise perturbations. Applying the protocol to a
                   minimal model of C. elegans neural activity, we find that
                   collective neural statistics are most sensitive to a few
                   principal perturbative modes. Dominant eigenvalues decay
                   initially as a power law, unveiling a hierarchy that arises
                   from variation in individual neural activity and pairwise
                   interactions. Highest-ranking modes tend to be dominated by
                   a few, ``pivotal'' neurons that account for most of the
                   system's sensitivity, suggesting a sparse mechanism for
                   control of collective behavior.",
  month         =  aug,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2108.00837",
  primaryClass  = "q-bio.NC",
  arxivid       = "2108.00837"
}

@UNPUBLISHED{Mertens2021-vs,
  title    = "Coherent mapping of position and head direction across auditory
              and visual cortex",
  author   = "Mertens, Paul E C and Marchesi, Pietro and Lohuis, Matthijs Oude
              and Krijger, Quincy and Pennartz, Cyriel M A and Lansink, Carien
              S",
  abstract = "Neurons in primary visual cortex (V1) may not only signal current
              visual input but also relevant contextual information such as
              reward expectancy and the subject's spatial position. Such
              location-specific representations need not be restricted to V1
              but could participate in a coherent mapping throughout sensory
              cortices. Here we show that spiking activity in primary auditory
              cortex (A1) and lateral, secondary visual cortex (V2L) of freely
              moving rats coherently represents a location-specific mapping in
              a sensory detection task performed on a figure-8 maze.
              Single-unit activity of both areas showed extensive similarities
              in terms of spatial distribution, reliability and position
              coding. Importantly, reconstructions of subject position on the
              basis of spiking activity displayed decoding errors that were
              correlated between areas in magnitude and direction. In addition
              to position, we found that head direction, but not locomotor
              speed or head angular velocity, was an important determinant of
              activity in A1 and V2L. Finally, pairs of units within and across
              areas showed significant correlations in instantaneous
              variability of firing rates (noise correlations). These were
              dependent on the spatial tuning of cells as well as the spatial
              position of the animal. We conclude that sensory cortices
              participate in coherent, multimodal representations of the
              subject's sensory-specific location. These may provide a common
              reference frame for distributed cortical sensory and motor
              processes and may support crossmodal predictive processing.
              \#\#\# Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.07.30.452931",
  month    =  jul,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.07.30.452931"
}

@ARTICLE{Huang2021-um,
  title     = "The tectonigral pathway regulates appetitive locomotion in
               predatory hunting in mice",
  author    = "Huang, Meizhu and Li, Dapeng and Cheng, Xinyu and Pei, Qing and
               Xie, Zhiyong and Gu, Huating and Zhang, Xuerong and Chen, Zijun
               and Liu, Aixue and Wang, Yi and Sun, Fangmiao and Li, Yulong and
               Zhang, Jiayi and He, Miao and Xie, Yuan and Zhang, Fan and Qi,
               Xiangbing and Shang, Congping and Cao, Peng",
  abstract  = "Appetitive locomotion is essential for animals to approach
               rewards, such as food and prey. The neuronal circuitry
               controlling appetitive locomotion is unclear. In a goal-directed
               behavior-predatory hunting, we show an excitatory brain circuit
               from the superior colliculus (SC) to the substantia nigra pars
               compacta (SNc) to enhance appetitive locomotion in mice. This
               tectonigral pathway transmits locomotion-speed signals to
               dopamine neurons and triggers dopamine release in the dorsal
               striatum. Synaptic inactivation of this pathway impairs
               appetitive locomotion but not defensive locomotion. Conversely,
               activation of this pathway increases the speed and frequency of
               approach during predatory hunting, an effect that depends on the
               activities of SNc dopamine neurons. Together, these data reveal
               that the SC regulates locomotion-speed signals to SNc dopamine
               neurons to enhance appetitive locomotion in mice.",
  journal   = "Nat. Commun.",
  publisher = "nature.com",
  volume    =  12,
  number    =  1,
  pages     = "4409",
  month     =  jul,
  year      =  2021,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "2041-1723",
  pmid      = "34285209",
  doi       = "10.1038/s41467-021-24696-3",
  pmc       = "PMC8292483"
}

@ARTICLE{Sachuriga2021-ig,
  title     = "Neuronal representation of locomotion during motivated behavior
               in the mouse anterior cingulate cortex",
  author    = "{Sachuriga} and Nishimaru, Hiroshi and Takamura, Yusaku and
               Matsumoto, Jumpei and Ferreira Pereira de Ara{\'u}jo, Mariana
               and Ono, Taketoshi and Nishijo, Hisao",
  abstract  = "The anterior cingulate cortex (ACC) is located within the
               dorsomedial prefrontal cortex (PFC), and processes and
               facilitates goal-directed behaviors relating to emotion, reward,
               and motor control. However, it is unclear how ACC neurons
               dynamically encode motivated behavior during locomotion. In this
               study, we examined how information for locomotion and behavioral
               outcomes is temporally represented by individual and ensembles
               of ACC neurons in mice during a self-paced locomotor
               reward-based task. By recording and analyzing the activity of
               ACC neurons with a microdrive tetrode array while the mouse
               performed the locomotor task, we found that more than two-fifths
               of the neurons showed phasic activity relating to locomotion or
               the reward behavior. Some of these neurons showed significant
               differences in their firing rate depending on the behavioral
               outcome. Furthermore, by applying a demixed principal component
               analysis, the ACC population activity was decomposed into
               components representing locomotion and the previous/future
               outcome. These results indicated that ACC neurons dynamically
               integrate motor and behavioral inputs during goal-directed
               behaviors.",
  journal   = "Front. Syst. Neurosci.",
  publisher = "Frontiers Media SA",
  volume    =  15,
  month     =  apr,
  year      =  2021,
  keywords  = "Locomotion",
  copyright = "https://creativecommons.org/licenses/by/4.0/",
  issn      = "1662-5137",
  doi       = "10.3389/fnsys.2021.655110"
}

@ARTICLE{Goulding2009-hv,
  title    = "Circuits controlling vertebrate locomotion: moving in a new
              direction",
  author   = "Goulding, Martyn",
  abstract = "Neurobiologists have long sought to understand how circuits in
              the nervous system are organized to generate the precise neural
              outputs that underlie particular behaviours. The motor circuits
              in the spinal cord that control locomotion, commonly referred to
              as central pattern generator networks, provide an experimentally
              tractable model system for investigating how moderately complex
              ensembles of neurons generate select motor behaviours. The advent
              of novel molecular and genetic techniques coupled with recent
              advances in our knowledge of spinal cord development means that a
              comprehensive understanding of how the motor circuitry is
              organized and operates may be within our grasp.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  10,
  number   =  7,
  pages    = "507--518",
  month    =  jul,
  year     =  2009,
  keywords = "Locomotion",
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "19543221",
  doi      = "10.1038/nrn2608",
  pmc      = "PMC2847453"
}

@ARTICLE{Jin2010-du,
  title     = "Start/stop signals emerge in nigrostriatal circuits during
               sequence learning",
  author    = "Jin, Xin and Costa, Rui M",
  abstract  = "Learning new action sequences subserves a plethora of different
               abilities such as escaping a predator, playing the piano, or
               producing fluent speech. Proper initiation and termination of
               each action sequence is critical for the organization of
               behaviour, and is compromised in nigrostriatal disorders like
               Parkinson's and Huntington's diseases. Using a self-paced
               operant task in which mice learn to perform a particular
               sequence of actions to obtain an outcome, we found neural
               activity in nigrostriatal circuits specifically signalling the
               initiation or the termination of each action sequence. This
               start/stop activity emerged during sequence learning, was
               specific for particular actions, and did not reflect interval
               timing, movement speed or action value. Furthermore, genetically
               altering the function of striatal circuits disrupted the
               development of start/stop activity and selectively impaired
               sequence learning. These results have important implications for
               understanding the functional organization of actions and the
               sequence initiation and termination impairments observed in
               basal ganglia disorders.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  466,
  number    =  7305,
  pages     = "457--462",
  month     =  jul,
  year      =  2010,
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "20651684",
  doi       = "10.1038/nature09263",
  pmc       = "PMC3477867"
}

@ARTICLE{Steinmetz2021-eh,
  title     = "Neuropixels 2.0: A miniaturized high-density probe for stable,
               long-term brain recordings",
  author    = "Steinmetz, Nicholas A and Aydin, Cagatay and Lebedeva, Anna and
               Okun, Michael and Pachitariu, Marius and Bauza, Marius and Beau,
               Maxime and Bhagat, Jai and B{\"o}hm, Claudia and Broux, Martijn
               and Chen, Susu and Colonell, Jennifer and Gardner, Richard J and
               Karsh, Bill and Kloosterman, Fabian and Kostadinov, Dimitar and
               Mora-Lopez, Carolina and O'Callaghan, John and Park, Junchol and
               Putzeys, Jan and Sauerbrei, Britton and van Daal, Rik J J and
               Vollan, Abraham Z and Wang, Shiwei and Welkenhuysen, Marleen and
               Ye, Zhiwen and Dudman, Joshua T and Dutta, Barundeb and Hantman,
               Adam W and Harris, Kenneth D and Lee, Albert K and Moser, Edvard
               I and O'Keefe, John and Renart, Alfonso and Svoboda, Karel and
               H{\"a}usser, Michael and Haesler, Sebastian and Carandini,
               Matteo and Harris, Timothy D",
  abstract  = "Measuring the dynamics of neural processing across time scales
               requires following the spiking of thousands of individual
               neurons over milliseconds and months. To address this need, we
               introduce the Neuropixels 2.0 probe together with newly designed
               analysis algorithms. The probe has more than 5000 sites and is
               miniaturized to facilitate chronic implants in small mammals and
               recording during unrestrained behavior. High-quality recordings
               over long time scales were reliably obtained in mice and rats in
               six laboratories. Improved site density and arrangement combined
               with newly created data processing methods enable automatic post
               hoc correction for brain movements, allowing recording from the
               same neurons for more than 2 months. These probes and algorithms
               enable stable recordings from thousands of sites during free
               behavior, even in small animals such as mice.",
  journal   = "Science",
  publisher = "science.sciencemag.org",
  volume    =  372,
  number    =  6539,
  month     =  apr,
  year      =  2021,
  language  = "en",
  issn      = "0036-8075, 1095-9203",
  pmid      = "33859006",
  doi       = "10.1126/science.abf4588",
  pmc       = "PMC8244810"
}

@UNPUBLISHED{MICrONS_Consortium2021-du,
  title    = "Functional connectomics spanning multiple areas of mouse visual
              cortex",
  author   = "{MICrONS Consortium} and Alexander Bae, J and Baptiste, Mahaly
              and Bodor, Agnes L and Brittain, Derrick and Buchanan, Joann and
              Bumbarger, Daniel J and Castro, Manuel A and Celii, Brendan and
              Cobos, Erick and Collman, Forrest and da Costa, Nuno Ma{\c
              c}arico and Dorkenwald, Sven and Elabbady, Leila and Fahey, Paul
              G and Fliss, Tim and Froudakis, Emmanouil and Gager, Jay and
              Gamlin, Clare and Halageri, Akhilesh and Hebditch, James and Jia,
              Zhen and Jordan, Chris and Kapner, Daniel and Kemnitz, Nico and
              Kinn, Sam and Koolman, Selden and Kuehner, Kai and Lee, Kisuk and
              Li, Kai and Lu, Ran and Macrina, Thomas and Mahalingam, Gayathri
              and McReynolds, Sarah and Miranda, Elanine and Mitchell, Eric and
              Mondal, Shanka Subhra and Moore, Merlin and Mu, Shang and
              Muhammad, Taliah and Nehoran, Barak and Ogedengbe, Oluwaseun and
              Papadopoulos, Christos and Papadopoulos, Stelios and Patel,
              Saumil and Pitkow, Xaq and Popovych, Sergiy and Ramos, Anthony
              and Clay Reid, R and Reimer, Jacob and Schneider-Mizell, Casey M
              and Sebastian Seung, H and Silverman, Ben and Silversmith,
              William and Sterling, Amy and Sinz, Fabian H and Smith, Cameron L
              and Suckow, Shelby and Tan, Zheng H and Tolias, Andreas S and
              Torres, Russel and Turner, Nicholas L and Walker, Edgar Y and
              Wang, Tianyu and Williams, Grace and Williams, Sarah and Willie,
              Kyle and Willie, Ryan and Wong, William and Wu, Jingpeng and Xu,
              Chris and Yang, Runzhe and Yatsenko, Dimitri and Ye, Fei and Yin,
              Wenjing and Yu, Szi-Chieh",
  abstract = "The value of an integrated approach for understanding the
              neocortex by combining functional characterization of single
              neuron activity with the underlying circuit architecture has been
              understood since the dawn of modern neuroscience. However, in
              practice, anatomical connectivity and physiology have been
              studied mostly separately. Following in the footsteps of previous
              studies that have combined physiology and anatomy in the same
              tissue, here we present a unique functional connectomics dataset
              that contains calcium imaging of an estimated 75,000 neurons from
              primary visual cortex (VISp) and three higher visual areas
              (VISrl, VISal and VISlm), that were recorded while a mouse viewed
              natural movies and parametric stimuli. The functional data were
              co-registered with electron microscopy (EM) data of the same
              volume which were automatically segmented, reconstructing more
              than 200,000 cells (neuronal and non-neuronal) and 524 million
              synapses. Subsequent proofreading of some neurons in this volume
              yielded reconstructions that include complete dendritic trees as
              well the local and inter-areal axonal projections. The largest
              proofread excitatory axon reached a length of 19 mm and formed
              1893 synapses, while the largest inhibitory axon formed 10081
              synapses. Here we release this dataset as an open access resource
              to the scientific community including a set of analysis tools
              that allows easy data access, both programmatically and through a
              web user interface. \#\#\# Competing Interest Statement TM and
              HSS disclose financial interests in Zetta AI LLC. JR and AST
              disclose financial interests in Vathes LLC.",
  journal  = "bioRxiv",
  pages    = "2021.07.28.454025",
  month    =  jul,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.07.28.454025"
}

@UNPUBLISHED{Dabaghian2021-wm,
  title    = "Learning Orientations: a Discrete Geometry Model",
  author   = "Dabaghian, Yuri Alexander",
  abstract = "In the mammalian brain, many neuronal ensembles are involved in
              representing spatial structure of the environment. In particular,
              there exist cells that encode the animal's location and cells
              that encode head direction. A number of studies have addressed
              properties of the spatial maps produced by these two populations
              of neurons, mainly by establishing correlations between their
              spiking parameters and geometric characteristics of the animal's
              environments. The question remains however, how the brain may
              intrinsically combine the direction and the location information
              into a unified spatial framework that enables animals'
              orientation. Below we propose a model of such a framework, using
              ideas and constructs from algebraic topology and synthetic affine
              geometry. \#\#\# Competing Interest Statement The authors have
              declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.08.08.455577",
  month    =  aug,
  year     =  2021,
  keywords = "navigation",
  language = "en",
  doi      = "10.1101/2021.08.08.455577"
}

@UNPUBLISHED{Chadwick2021-lq,
  title    = "Learning shapes cortical dynamics to enhance integration of
              relevant sensory input",
  author   = "Chadwick, Angus and Khan, Adil and Poort, Jasper and Blot,
              Antonin and Hofer, Sonja and Mrsic-Flogel, Thomas and Sahani,
              Maneesh",
  abstract = "Adaptive sensory behavior is thought to depend on processing in
              recurrent cortical circuits, but how dynamics in these circuits
              shapes the integration and transmission of sensory information is
              not well understood. Here, we study neural coding in recurrently
              connected networks of neurons driven by sensory input. We show
              analytically how information available in the network output
              varies with the alignment between feedforward input and the
              integrating modes of the circuit dynamics. In light of this
              theory, we analyzed neural population activity in the visual
              cortex of mice that learned to discriminate visual features. We
              found that over learning, slow patterns of network dynamics
              realigned to better integrate input relevant to the
              discrimination task. This realignment of network dynamics could
              be explained by changes in excitatory-inhibitory connectivity
              amongst neurons tuned to relevant features. These results suggest
              that learning tunes the temporal dynamics of cortical circuits to
              optimally integrate relevant sensory input. Highlights \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.08.02.454726",
  month    =  aug,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.08.02.454726"
}

@ARTICLE{Bruel-Gabrielsson2018-nr,
  title         = "{Topology-Aware} Surface Reconstruction for Point Clouds",
  author        = "Br{\"u}el-Gabrielsson, Rickard and Ganapathi-Subramanian,
                   Vignesh and Skraba, Primoz and Guibas, Leonidas J",
  abstract      = "We present an approach to inform the reconstruction of a
                   surface from a point scan through topological priors. The
                   reconstruction is based on basis functions which are
                   optimized to provide a good fit to the point scan while
                   satisfying predefined topological constraints. We optimize
                   the parameters of a model to obtain likelihood function over
                   the reconstruction domain. The topological constraints are
                   captured by persistence diagrams which are incorporated in
                   the optimization algorithm promote the correct topology. The
                   result is a novel topology-aware technique which can: 1.)
                   weed out topological noise from point scans, and 2.) capture
                   certain nuanced properties of the underlying shape which
                   could otherwise be lost while performing surface
                   reconstruction. We showcase results reconstructing shapes
                   with multiple potential topologies, compare to other
                   classical surface construction techniques, and show the
                   completion of real scan data.",
  month         =  nov,
  year          =  2018,
  archivePrefix = "arXiv",
  eprint        = "1811.12543",
  primaryClass  = "cs.CG",
  arxivid       = "1811.12543"
}

@ARTICLE{Suarez2021-ra,
  title     = "Learning function from structure in neuromorphic networks",
  author    = "Su{\'a}rez, Laura E and Richards, Blake A and Lajoie, Guillaume
               and Misic, Bratislav",
  abstract  = "The connection patterns of neural circuits in the brain form a
               complex network. Collective signalling within the network
               manifests as patterned neural activity and is thought to support
               human cognition and adaptive behaviour. Recent technological
               advances permit macroscale reconstructions of biological brain
               networks. These maps, termed connectomes, display multiple
               non-random architectural features, including heavy-tailed degree
               distributions, segregated communities and a densely
               interconnected core. Yet, how computation and functional
               specialization emerge from network architecture remains unknown.
               Here we reconstruct human brain connectomes using in vivo
               diffusion-weighted imaging and use reservoir computing to
               implement connectomes as artificial neural networks. We then
               train these neuromorphic networks to learn a memory-encoding
               task. We show that biologically realistic neural architectures
               perform best when they display critical dynamics. We find that
               performance is driven by network topology and that the modular
               organization of intrinsic networks is computationally relevant.
               We observe a prominent interaction between network structure and
               dynamics throughout, such that the same underlying architecture
               can support a wide range of memory capacity values as well as
               different functions (encoding or decoding), depending on the
               dynamical regime the network is in. This work opens new
               opportunities to discover how the network organization of the
               brain optimizes cognitive capacity. The relationship between
               brain organization, connectivity and computation is not well
               understood. The authors construct neuromorphic artificial neural
               networks endowed with biological connection patterns derived
               from diffusion-weighted imaging. The neuromorphic networks are
               trained to perform a memory task, revealing an interaction
               between network structure and dynamics.",
  journal   = "Nature Machine Intelligence",
  publisher = "Nature Publishing Group",
  pages     = "1--16",
  month     =  aug,
  year      =  2021,
  language  = "en",
  issn      = "2522-5839, 2522-5839",
  doi       = "10.1038/s42256-021-00376-1"
}

@ARTICLE{Esnaola-Acebes_undated-vn,
  title  = "1 Bump attractor dynamics underlying stimulus integration in
            perceptual 2 estimation tasks",
  author = "Esnaola-Acebes, Jose M and Roxin, Alex and Wimmer, Klaus",
  doi    = "10.1101/2021.03.15.434192"
}

@ARTICLE{Shamash2021-sc,
  title    = "Mice learn multi-step routes by memorizing subgoal locations",
  author   = "Shamash, Philip and Olesen, Sarah F and Iordanidou, Panagiota and
              Campagner, Dario and Banerjee, Nabhojit and Branco, Tiago",
  abstract = "The behavioral strategies that mammals use to learn multi-step
              routes are unknown. In this study, we investigated how mice
              navigate to shelter in response to threats when the direct path
              is blocked. Initially, they fled toward the shelter and
              negotiated obstacles using sensory cues. Within 20 min, they
              spontaneously adopted a subgoal strategy, initiating escapes by
              running directly to the obstacle's edge. Mice continued to escape
              in this manner even after the obstacle had been removed,
              indicating use of spatial memory. However, standard models of
              spatial learning-habitual movement repetition and internal map
              building-did not explain how subgoal memories formed. Instead,
              mice used a hybrid approach: memorizing salient locations
              encountered during spontaneous 'practice runs' to the shelter.
              This strategy was also used during a geometrically identical
              food-seeking task. These results suggest that subgoal
              memorization is a fundamental strategy by which rodents learn
              efficient multi-step routes in new environments.",
  journal  = "Nat. Neurosci.",
  month    =  jul,
  year     =  2021,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "34326540",
  doi      = "10.1038/s41593-021-00884-8"
}

@ARTICLE{Friedrich2021-lu,
  title         = "Neural optimal feedback control with local learning rules",
  author        = "Friedrich, Johannes and Golkar, Siavash and Farashahi, Shiva
                   and Genkin, Alexander and Sengupta, Anirvan M and
                   Chklovskii, Dmitri B",
  abstract      = "A major problem in motor control is understanding how the
                   brain plans and executes proper movements in the face of
                   delayed and noisy stimuli. A prominent framework for
                   addressing such control problems is Optimal Feedback Control
                   (OFC). OFC generates control actions that optimize
                   behaviorally relevant criteria by integrating noisy sensory
                   stimuli and the predictions of an internal model using the
                   Kalman filter or its extensions. However, a satisfactory
                   neural model of Kalman filtering and control is lacking
                   because existing proposals have the following limitations:
                   not considering the delay of sensory feedback, training in
                   alternating phases, and requiring knowledge of the noise
                   covariance matrices, as well as that of systems dynamics.
                   Moreover, the majority of these studies considered Kalman
                   filtering in isolation, and not jointly with control. To
                   address these shortcomings, we introduce a novel online
                   algorithm which combines adaptive Kalman filtering with a
                   model free control approach (i.e., policy gradient
                   algorithm). We implement this algorithm in a biologically
                   plausible neural network with local synaptic plasticity
                   rules. This network performs system identification and
                   Kalman filtering, without the need for multiple phases with
                   distinct update rules or the knowledge of the noise
                   covariances. It can perform state estimation with delayed
                   sensory feedback, with the help of an internal model. It
                   learns the control policy without requiring any knowledge of
                   the dynamics, thus avoiding the need for weight transport.
                   In this way, our implementation of OFC solves the credit
                   assignment problem needed to produce the appropriate
                   sensory-motor control in the presence of stimulus delay.",
  month         =  nov,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2111.06920",
  primaryClass  = "q-bio.NC",
  arxivid       = "2111.06920"
}

@ARTICLE{Campbell2021-bi,
  title     = "Distance-tuned neurons drive specialized path integration
               calculations in medial entorhinal cortex",
  author    = "Campbell, Malcolm G and Attinger, Alexander and Ocko, Samuel A
               and Ganguli, Surya and Giocomo, Lisa M",
  abstract  = "SummaryDuring navigation, animals estimate their position using
               path integration and landmarks, engaging many brain areas.
               Whether these areas follow specialized or universal cue
               integration principles remains incompletely understood. We
               combine electrophysiology with virtual reality to quantify cue
               integration across thousands of neurons in three
               navigation-relevant areas: primary visual cortex (V1),
               retrosplenial cortex (RSC), and medial entorhinal cortex (MEC).
               Compared with V1 and RSC, path integration influences position
               estimates more in MEC, and conflicts between path integration
               and landmarks trigger remapping more readily. Whereas MEC codes
               position prospectively, V1 codes position retrospectively, and
               RSC is intermediate between the two. Lowered visual contrast
               increases the influence of path integration on position
               estimates only in MEC. These properties are most pronounced in a
               population of MEC neurons, overlapping with grid cells, tuned to
               distance run in darkness. These results demonstrate the
               specialized role that path integration plays in MEC compared
               with other navigation-relevant cortical areas.",
  journal   = "Cell Rep.",
  publisher = "Elsevier",
  volume    =  36,
  number    =  10,
  month     =  sep,
  year      =  2021,
  keywords  = "navigation; path integration; landmarks; cue integration; grid
               cells; medial entorhinal cortex; visual cortex; retrosplenial
               cortex",
  language  = "en",
  issn      = "2211-1247",
  doi       = "10.1016/j.celrep.2021.109669"
}

@ARTICLE{Capone2021-qi,
  title         = "Behavioral cloning in recurrent spiking networks: A
                   comprehensive framework",
  author        = "Capone, Cristiano and Muratore, Paolo and Paolucci, Pier
                   Stanislao",
  abstract      = "Learning in biological or artificial networks means changing
                   the laws governing the network dynamics in order to better
                   behave in a specific situation. In the field of supervised
                   learning, two complementary approaches stand out:
                   error-based and target-based learning. However, there exists
                   no consensus on which is better suited for which task, and
                   what is the most biologically plausible. Here we propose a
                   comprehensive theoretical framework that includes these two
                   frameworks as special cases. This novel theoretical
                   formulation offers major insights into the differences
                   between the two approaches. In particular, we show how
                   target-based naturally emerges from error-based when the
                   number of constraints on the target dynamics, and as a
                   consequence on the internal network dynamics, is comparable
                   to the degrees of freedom of the network. Moreover, given
                   the experimental evidences on the relevance that spikes have
                   in biological networks, we investigate the role of coding
                   with specific patterns of spikes by introducing a parameter
                   that defines the tolerance to precise spike timing during
                   learning. Our approach naturally lends itself to Imitation
                   Learning (and Behavioral Cloning in particular) and we apply
                   it to solve relevant closed-loop tasks such as the
                   button-and-food task, and the 2D Bipedal Walker. We show
                   that a high dimensionality feedback structure is extremely
                   important when it is necessary to solve a task that requires
                   retaining memory for a long time (button-and-food). On the
                   other hand, we find that coding with specific patterns of
                   spikes enables optimal performances in a motor task (the 2D
                   Bipedal Walker). Finally, we show that our theoretical
                   formulation suggests protocols to deduce the structure of
                   learning feedback in biological networks.",
  month         =  sep,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2109.01039",
  primaryClass  = "q-bio.NC",
  arxivid       = "2109.01039"
}

@ARTICLE{Draelos2021-zm,
  title         = "Bubblewrap: Online tiling and real-time flow prediction on
                   neural manifolds",
  author        = "Draelos, Anne and Gupta, Pranjal and Jun, Na Young and
                   Sriworarat, Chaichontat and Pearson, John",
  abstract      = "While most classic studies of function in experimental
                   neuroscience have focused on the coding properties of
                   individual neurons, recent developments in recording
                   technologies have resulted in an increasing emphasis on the
                   dynamics of neural populations. This has given rise to a
                   wide variety of models for analyzing population activity in
                   relation to experimental variables, but direct testing of
                   many neural population hypotheses requires intervening in
                   the system based on current neural state, necessitating
                   models capable of inferring neural state online. Existing
                   approaches, primarily based on dynamical systems, require
                   strong parametric assumptions that are easily violated in
                   the noise-dominated regime and do not scale well to the
                   thousands of data channels in modern experiments. To address
                   this problem, we propose a method that combines fast, stable
                   dimensionality reduction with a soft tiling of the resulting
                   neural manifold, allowing dynamics to be approximated as a
                   probability flow between tiles. This method can be fit
                   efficiently using online expectation maximization, scales to
                   tens of thousands of tiles, and outperforms existing methods
                   when dynamics are noise-dominated or feature multi-modal
                   transition probabilities. The resulting model can be trained
                   at kiloHertz data rates, produces accurate approximations of
                   neural dynamics within minutes, and generates predictions on
                   submillisecond time scales. It retains predictive
                   performance throughout many time steps into the future and
                   is fast enough to serve as a component of closed-loop causal
                   experiments.",
  month         =  aug,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2108.13941",
  primaryClass  = "cs.LG",
  arxivid       = "2108.13941"
}

@UNPUBLISHED{Linden2021-ws,
  title    = "Movement is governed by rotational population dynamics in spinal
              motor networks",
  author   = "Linden, Henrik and Petersen, Peter and Vestergaard, Mikkel and
              Berg, Rune W",
  abstract = "Although the nervous system is elegantly orchestrating movements,
              the underlying neural principles remain unknown. Since flexor-
              and extensor-muscles alternate during movements like walking, it
              is often assumed that the responsible neural circuitry is
              similarly alternating in opposition. Here, we present
              ensemble-recordings of neurons in the turtle lumbar spinal cord
              that indicate that, rather than alternation, the population is
              performing a ``rotation'' in neural space, i.e. the neural
              activity is cycling through all phases continuously during the
              rhythmic behavior. The radius of rotation correlates with the
              intended muscle force. Since existing models of spinal motor
              control offer inadequate explanation of this dynamics, we propose
              a new theory of neural generation of movement from which rotation
              and other unresolved issues, such as speed regulation, force
              control, and multi-functionalism, are conveniently explained.
              \#\#\# Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.08.31.458405",
  month    =  sep,
  year     =  2021,
  keywords = "Locomotion",
  language = "en",
  doi      = "10.1101/2021.08.31.458405"
}

@MISC{Pei_undated-sr,
  title        = "Neural Latents Benchmark '21: Evaluating latent variable
                  models of neural population activity",
  author       = "Pei, Felix and Ye, Joel and Zoltowski, David and Wu, Anqi and
                  Chowdhury, Raeed H and Sohn, Hansem and O'Doherty, Joseph E
                  and Shenoy, Krishna V and Kaufman, Matthew T and Churchland,
                  Mark and Jazayeri, Mehrdad and Miller, Lee E and Park, Il
                  Memming and Dyer, Eva and Pillow, Jonathan and Pandarinath,
                  Chethan",
  howpublished = "\url{https://openreview.net/pdf?id=KVMS3fl4Rsv}",
  note         = "Accessed: 2021-9-5"
}

@ARTICLE{Koralek2021-ro,
  title    = "Dichotomous dopaminergic and noradrenergic neural states mediate
              distinct aspects of exploitative behavioral states",
  author   = "Koralek, Aaron C and Costa, Rui M",
  abstract = "The balance between exploiting known actions and exploring
              alternatives is critical for survival and hypothesized to rely on
              shifts in neuromodulation. We developed a behavioral paradigm to
              capture exploitative and exploratory states and imaged calcium
              dynamics in genetically identified dopaminergic and noradrenergic
              neurons. During exploitative states, characterized by motivated
              repetition of the same action choice, dopamine neurons in SNc
              encoding movement vigor showed sustained elevation of basal
              activity that lasted many seconds. This sustained activity
              emerged from longer positive responses, which accumulated during
              exploitative action-reward bouts, and hysteretic dynamics.
              Conversely, noradrenergic neurons in LC showed sustained
              inhibition of basal activity due to the accumulation of longer
              negative responses in LC. Chemogenetic manipulation of these
              sustained dynamics revealed that dopaminergic activity mediates
              action drive, whereas noradrenergic activity modulates choice
              diversity. These data uncover the emergence of sustained neural
              states in dopaminergic and noradrenergic networks that mediate
              dissociable aspects of exploitative bouts.",
  journal  = "Sci Adv",
  volume   =  7,
  number   =  30,
  month    =  jul,
  year     =  2021,
  language = "en",
  issn     = "2375-2548",
  pmid     = "34301604",
  doi      = "10.1126/sciadv.abh2059",
  pmc      = "PMC8302134"
}

@ARTICLE{McElvain2021-rh,
  title    = "Specific populations of basal ganglia output neurons target
              distinct brain stem areas while collateralizing throughout the
              diencephalon",
  author   = "McElvain, Lauren E and Chen, Yuncong and Moore, Jeffrey D and
              Brigidi, G Stefano and Bloodgood, Brenda L and Lim, Byung Kook
              and Costa, Rui M and Kleinfeld, David",
  abstract = "Basal ganglia play a central role in regulating behavior, but the
              organization of their outputs to other brain areas is
              incompletely understood. We investigate the largest output
              nucleus, the substantia nigra pars reticulata (SNr), and
              delineate the organization and physiology of its projection
              populations in mice. Using genetically targeted viral tracing and
              whole-brain anatomical analysis, we identify over 40 SNr targets
              that encompass a roughly 50-fold range of axonal densities.
              Retrograde tracing from the volumetrically largest targets
              indicates that the SNr contains segregated subpopulations that
              differentially project to functionally distinct brain stem
              regions. These subpopulations are electrophysiologically
              specialized and topographically organized and collateralize to
              common diencephalon targets, including the motor and intralaminar
              thalamus as well as the pedunculopontine nucleus and the midbrain
              reticular formation. These findings establish that SNr signaling
              is organized as dense, parallel outputs to specific brain stem
              targets concurrent with extensive collateral branches that
              encompass the majority of SNr axonal boutons.",
  journal  = "Neuron",
  volume   =  109,
  number   =  10,
  pages    = "1721--1738.e4",
  month    =  may,
  year     =  2021,
  keywords = "brain anatomy; circuit; electrophysiology; motor system;
              movement; substantia nigra; thalamus",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "33823137",
  doi      = "10.1016/j.neuron.2021.03.017",
  pmc      = "PMC8169061"
}

@ARTICLE{Akam2021-jc,
  title    = "The Anterior Cingulate Cortex Predicts Future States to Mediate
              {Model-Based} Action Selection",
  author   = "Akam, Thomas and Rodrigues-Vaz, Ines and Marcelo, Ivo and Zhang,
              Xiangyu and Pereira, Michael and Oliveira, Rodrigo Freire and
              Dayan, Peter and Costa, Rui M",
  abstract = "Behavioral control is not unitary. It comprises parallel systems,
              model based and model free, that respectively generate flexible
              and habitual behaviors. Model-based decisions use predictions of
              the specific consequences of actions, but how these are
              implemented in the brain is poorly understood. We used calcium
              imaging and optogenetics in a sequential decision task for mice
              to show that the anterior cingulate cortex (ACC) predicts the
              state that actions will lead to, not simply whether they are good
              or bad, and monitors whether outcomes match these predictions.
              ACC represents the complete state space of the task, with reward
              signals that depend strongly on the state where reward is
              obtained but minimally on the preceding choice. Accordingly, ACC
              is necessary only for updating model-based strategies, not for
              basic reward-driven action reinforcement. These results reveal
              that ACC is a critical node in model-based control, with a
              specific role in predicting future states given chosen actions.",
  journal  = "Neuron",
  volume   =  109,
  number   =  1,
  pages    = "149--163.e7",
  month    =  jan,
  year     =  2021,
  keywords = "anterior cingulate cortex (ACC); behavior; calcium imaging;
              decision making; model-based; optogenetics; reinforcement
              learning",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "33152266",
  doi      = "10.1016/j.neuron.2020.10.013",
  pmc      = "PMC7837117"
}

@ARTICLE{Botta2020-cf,
  title    = "An Amygdala Circuit Mediates {Experience-Dependent} Momentary
              Arrests during Exploration",
  author   = "Botta, Paolo and Fushiki, Akira and Vicente, Ana Mafalda and
              Hammond, Luke A and Mosberger, Alice C and Gerfen, Charles R and
              Peterka, Darcy and Costa, Rui M",
  abstract = "Exploration of novel environments ensures survival and
              evolutionary fitness. It is expressed through exploratory bouts
              and arrests that change dynamically based on experience. Neural
              circuits mediating exploratory behavior should therefore
              integrate experience and use it to select the proper behavioral
              output. Using a spatial exploration assay, we uncovered an
              experience-dependent increase in momentary arrests in locations
              where animals arrested previously. Calcium imaging in freely
              exploring mice revealed a genetically and projection-defined
              neuronal ensemble in the basolateral amygdala that is active
              during self-paced behavioral arrests. This ensemble was recruited
              in an experience-dependent manner, and closed-loop optogenetic
              manipulation of these neurons revealed that they are sufficient
              and necessary to drive experience-dependent arrests during
              exploration. Projection-specific imaging and optogenetic
              experiments revealed that these arrests are effected by
              basolateral amygdala neurons projecting to the central amygdala,
              uncovering an amygdala circuit that mediates momentary arrests in
              familiar places but not avoidance or anxiety/fear-like behaviors.",
  journal  = "Cell",
  volume   =  183,
  number   =  3,
  pages    = "605--619.e22",
  month    =  oct,
  year     =  2020,
  keywords = "amygdala; experience; exploration; familiarity; latent learning;
              momentary arrest; movement; novelty",
  language = "en",
  issn     = "0092-8674, 1097-4172",
  pmid     = "33031743",
  doi      = "10.1016/j.cell.2020.09.023",
  pmc      = "PMC8276519"
}

@ARTICLE{Athalye2020-kl,
  title    = "Neural reinforcement: re-entering and refining neural dynamics
              leading to desirable outcomes",
  author   = "Athalye, Vivek R and Carmena, Jose M and Costa, Rui M",
  abstract = "How do organisms learn to do again, on-demand, a behavior that
              led to a desirable outcome? Dopamine-dependent cortico-striatal
              plasticity provides a framework for learning behavior's value,
              but it is less clear how it enables the brain to re-enter desired
              behaviors and refine them over time. Reinforcing behavior is
              achieved by re-entering and refining the neural patterns that
              produce it. We review studies using brain-machine interfaces
              which reveal that reinforcing cortical population activity
              requires cortico-basal ganglia circuits. Then, we propose a
              formal framework for how reinforcement in cortico-basal ganglia
              circuits acts on the neural dynamics of cortical populations. We
              propose two parallel mechanisms: i) fast reinforcement which
              selects the inputs that permit the re-entrance of the particular
              cortical population dynamics which naturally produced the desired
              behavior, and ii) slower reinforcement which leads to refinement
              of cortical population dynamics and more reliable production of
              neural trajectories driving skillful behavior on-demand.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  60,
  pages    = "145--154",
  month    =  feb,
  year     =  2020,
  keywords = "To Read;BCI",
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "31877493",
  doi      = "10.1016/j.conb.2019.11.023"
}

@ARTICLE{Nogueira_undated-fv,
  title  = "The geometry of cortical representations of touch in rodents",
  author = "Nogueira, Ramon and Rodgers, Chris C and Bruno, Randy M and Fusi,
            Stefano",
  doi    = "10.1101/2021.02.11.430704"
}

@ARTICLE{La_Camera2021-bj,
  title         = "The mean field approach for populations of spiking neurons",
  author        = "La Camera, Giancarlo",
  abstract      = "Mean field theory is a device to analyze the collective
                   behavior of a dynamical system comprising many interacting
                   particles. The theory allows to reduce the behavior of the
                   system to the properties of a handful of parameters. In
                   neural circuits, these parameters are typically the firing
                   rates of distinct, homogeneous subgroups of neurons.
                   Knowledge of the firing rates under conditions of interest
                   can reveal essential information on both the dynamics of
                   neural circuits and the way they can subserve brain
                   function. The goal of this chapter is to provide an
                   elementary introduction to the mean field approach for
                   populations of spiking neurons. We introduce the general
                   idea in networks of binary neurons, starting from the most
                   basic results and then generalizing to more relevant
                   situations. This allows to derive the mean field equations
                   in a simplified setting. We then derive the mean field
                   equations for populations of integrate-and-fire neurons. An
                   effort is made to derive the main equations of the theory
                   using only elementary methods from calculus and probability
                   theory. The chapter ends with a discussion of the
                   assumptions of the theory and some of the consequences of
                   violating those assumptions. This discussion includes an
                   introduction to balanced and metastable networks, and a
                   brief catalogue of successful applications of the mean field
                   approach to the study of neural circuits.",
  month         =  sep,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2109.01279",
  primaryClass  = "q-bio.NC",
  arxivid       = "2109.01279"
}

@ARTICLE{Zimnik2021-ia,
  title    = "Independent generation of sequence elements by motor cortex",
  author   = "Zimnik, Andrew J and Churchland, Mark M",
  abstract = "Rapid execution of motor sequences is believed to depend on
              fusing movement elements into cohesive units that are executed
              holistically. We sought to determine the contribution of primary
              motor and dorsal premotor cortex to this ability. Monkeys
              performed highly practiced two-reach sequences, interleaved with
              matched reaches performed alone or separated by a delay. We
              partitioned neural population activity into components pertaining
              to preparation, initiation and execution. The hypothesis that
              movement elements fuse makes specific predictions regarding all
              three forms of activity. We observed none of these predicted
              effects. Rapid two-reach sequences involved the same set of
              neural events as individual reaches but with preparation for the
              second reach occurring as the first was in flight. Thus, at the
              level of dorsal premotor and primary motor cortex, skillfully
              executing a rapid sequence depends not on fusing elements, but on
              the ability to perform two key processes at the same time.",
  journal  = "Nat. Neurosci.",
  volume   =  24,
  number   =  3,
  pages    = "412--424",
  month    =  mar,
  year     =  2021,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "33619403",
  doi      = "10.1038/s41593-021-00798-5",
  pmc      = "PMC7933118"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Saxena2021-yi,
  title     = "Motor cortex activity across movement speeds is predicted by
               network-level strategies for generating muscle activity",
  author    = "Saxena, S and Russo, A and Cunningham, J and Churchland, M M",
  abstract  = "Learned movements can be skillfully performed at different
               paces. What neural strategies produce this flexibility? Can they
               be predicted and understood by network modeling? We trained
               monkeys to perform a cycling task at different speeds, and
               trained artificial recurrent …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2021
}

@ARTICLE{Russo2020-uc,
  title    = "Neural Trajectories in the Supplementary Motor Area and Motor
              Cortex Exhibit Distinct Geometries, Compatible with Different
              Classes of Computation",
  author   = "Russo, Abigail A and Khajeh, Ramin and Bittner, Sean R and
              Perkins, Sean M and Cunningham, John P and Abbott, L F and
              Churchland, Mark M",
  abstract = "The supplementary motor area (SMA) is believed to contribute to
              higher order aspects of motor control. We considered a key higher
              order role: tracking progress throughout an action. We propose
              that doing so requires population activity to display low
              ``trajectory divergence'': situations with different future motor
              outputs should be distinct, even when present motor output is
              identical. We examined neural activity in SMA and primary motor
              cortex (M1) as monkeys cycled various distances through a virtual
              environment. SMA exhibited multiple response features that were
              absent in M1. At the single-neuron level, these included ramping
              firing rates and cycle-specific responses. At the population
              level, they included a helical population-trajectory geometry
              with shifts in the occupied subspace as movement unfolded. These
              diverse features all served to reduce trajectory divergence,
              which was much lower in SMA versus M1. Analogous
              population-trajectory geometry, also with low divergence,
              naturally arose in networks trained to internally guide
              multi-cycle movement.",
  journal  = "Neuron",
  volume   =  107,
  number   =  4,
  pages    = "745--758.e6",
  month    =  aug,
  year     =  2020,
  keywords = "motor control; motor cortex; neural computation; neural dynamics;
              population coding; population geometry; recurrent neural network;
              supplementary motor area",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "32516573",
  doi      = "10.1016/j.neuron.2020.05.020"
}

@UNPUBLISHED{Schroeder2021-zz,
  title    = "Cortical control of virtual self-motion using task-specific
              subspaces",
  author   = "Schroeder, Karen E and Perkins, Sean M and Wang, Qi and
              Churchland, Mark M",
  abstract = "Brain-machine interfaces (BMIs) for reaching have enjoyed
              continued performance improvements, yet there remains significant
              need for BMIs that control other movement classes. Recent
              scientific findings suggest that the intrinsic covariance
              structure of neural activity depends strongly on movement class,
              potentially necessitating different decode algorithms across
              classes. To address this, we developed a self-motion BMI based on
              cortical activity as monkeys performed non-reaching arm
              movements: cycling a hand-held pedal to progress along a virtual
              track. Unlike during reaching, we found no high-variance
              dimensions that directly correlated with to-be-decoded variables.
              Yet we could decode a single variable -- self-motion -- by
              non-linearly leveraging structure that spanned many high-variance
              neural dimensions. Resulting online BMI-control success rates
              approached those during manual control. These findings make two
              broad points regarding how to build decode algorithms that
              harmonize with the empirical structure of neural activity in
              motor cortex. First, even when decoding from the same cortical
              region (e.g., arm-related motor cortex) different movement
              classes may need to employ very different strategies. Although
              correlations between neural activity and hand velocity are
              prominent during reaching tasks, they are not a fundamental
              property of motor cortex and cannot be counted on to be present
              in general. Second, although one generally desires a
              low-dimensional readout, it can be beneficial to leverage a
              multi-dimensional high-variance subspace. Fully embracing this
              approach requires highly non-linear approaches tailored to the
              task at hand, but can produce near-native levels of performance.
              Significance Statement Many BMI decoders have been constructed
              for controlling movements normally performed with the arm. Yet it
              is unclear how these will function beyond the reach-like
              scenarios where they were developed. Existing decoders implicitly
              assume that neural covariance structure, and correlations with
              to-be-decoded kinematic variables, will be largely preserved
              across tasks. We find that the correlation between neural
              activity and hand kinematics, a feature typically exploited when
              decoding reach-like movements, is essentially absent during
              another task performed with the arm: cycling through a virtual
              environment. Nevertheless, the use of a different strategy, one
              focused on leveraging the highest-variance neural signals,
              supported high performance real-time BMI control. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2019.12.13.862532",
  month    =  apr,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2019.12.13.862532"
}

@ARTICLE{Farag2020-dy,
  title    = "Complex Trajectory Tracking Using {PID} Control for Autonomous
              Driving",
  author   = "Farag, Wael",
  abstract = "In this paper, a Proportional-Integral-Differential (PID)
              controller that facilitates track maneuvering for self-driving
              cars is proposed. Three different design approaches are used to
              find and tune the controller hyper-parameters. One of them is
              ``WAF-Tune'', which is an ad hoc trial-and-error based technique
              that is specifically proposed in this paper for this specific
              application. The proposed controller uses only the
              Cross-Track-Error (CTE) as an input to the controller, whereas
              the output is the steering command. Extensive simulation studies
              in complex tracks with many sharp turns have been carried out to
              evaluate the performance of the proposed controller at different
              speeds. The analysis shows that the proposed technique
              outperforms the other ones. The usefulness and the shortcomings
              of the proposed tuning mechanism are also discussed in details.",
  journal  = "International Journal of Intelligent Transportation Systems
              Research",
  volume   =  18,
  number   =  2,
  pages    = "356--366",
  month    =  may,
  year     =  2020,
  keywords = "control",
  issn     = "1868-8659",
  doi      = "10.1007/s13177-019-00204-2"
}

@ARTICLE{Pacheco2015-yh,
  title     = "Testing {PID} and {MPC} Performance for Mobile Robot Local
               {Path-Following}",
  author    = "Pacheco, Lluis and Luo, Ningsu",
  abstract  = "This paper outlines the online performance of a control law
               based on PID (proportional-integral-derivative) controllers and
               MPC (model predictive control) for mobile robot local
               path-following. Both techniques share the use of a set of
               different dynamic models. PID controllers are used for
               controlling the speed of the robot's wheels, while high level
               algorithms compute the necessary wheel speeds in order to
               generate a motion that approaches the vehicle towards the
               desired path. Meanwhile, local MPC is implemented by computing
               the horizon of suitable coordinates that arise from the set of
               command input combinations. Therefore, command speeds that
               correspond to the desired point are obtained by minimizing a
               cost function in which the population of the available
               coordinates is taken into account.",
  journal   = "Int. J. Adv. Rob. Syst.",
  publisher = "SAGE Publications",
  volume    =  12,
  number    =  11,
  pages     = "155",
  month     =  nov,
  year      =  2015,
  keywords  = "control",
  issn      = "1729-8814",
  doi       = "10.5772/61312"
}

@UNPUBLISHED{Athalye2021-nw,
  title    = "The brain uses invariant dynamics to generalize outputs across
              movements",
  author   = "Athalye, Vivek R and Khanna, Preeya and Gowda, Suraj and Orsborn,
              Amy L and Costa, Rui M and Carmena, Jose M",
  abstract = "The nervous system uses a repertoire of outputs to produce
              diverse movements. Thus, the brain must solve how to issue and
              transition the same outputs in different movements. A recent
              proposal states that network connectivity constrains the
              transitions of neural activity to follow invariant rules across
              different movements, which we term `invariant dynamics'. However,
              it is unknown whether invariant dynamics are actually used to
              drive and generalize outputs across movements, and what advantage
              they provide for controlling movement. Using a brain-machine
              interface that transformed motor cortex activity into outputs for
              a neuroprosthetic cursor, we discovered that the same output is
              issued by different activity patterns in different movements.
              These distinct patterns then transition according to a model of
              invariant dynamics, leading to patterns that drive distinct
              future outputs. Optimal control theory revealed this use of
              invariant dynamics reduces the feedback input needed to control
              movement. Our results demonstrate that the brain uses invariant
              dynamics to generalize outputs across movements. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest.",
  journal  = "bioRxiv",
  pages    = "2021.08.27.457931",
  month    =  aug,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.08.27.457931"
}

@ARTICLE{Klukas2020-vo,
  title    = "Efficient and flexible representation of higher-dimensional
              cognitive variables with grid cells",
  author   = "Klukas, Mirko and Lewis, Marcus and Fiete, Ila",
  abstract = "We shed light on the potential of entorhinal grid cells to
              efficiently encode variables of dimension greater than two, while
              remaining faithful to empirical data on their low-dimensional
              structure. Our model constructs representations of
              high-dimensional inputs through a combination of low-dimensional
              random projections and ``classical'' low-dimensional hexagonal
              grid cell responses. Without reconfiguration of the recurrent
              circuit, the same system can flexibly encode multiple variables
              of different dimensions while maximizing the coding range (per
              dimension) by automatically trading-off dimension with an
              exponentially large coding range. It achieves high efficiency and
              flexibility by combining two powerful concepts, modularity and
              mixed selectivity, in what we call ``mixed modular coding''. In
              contrast to previously proposed schemes, the model does not
              require the formation of higher-dimensional grid responses, a
              cell-inefficient and rigid mechanism. The firing fields observed
              in flying bats or climbing rats can be generated by neurons that
              combine activity from multiple grid modules, each representing
              higher-dimensional spaces according to our model. The idea
              expands our understanding of grid cells, suggesting that they
              could implement a general circuit that generates on-demand coding
              and memory states for variables in high-dimensional vector
              spaces.",
  journal  = "PLoS Comput. Biol.",
  volume   =  16,
  number   =  4,
  pages    = "e1007796",
  month    =  apr,
  year     =  2020,
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "32343687",
  doi      = "10.1371/journal.pcbi.1007796",
  pmc      = "PMC7209352"
}

@ARTICLE{Kriener2020-go,
  title    = "Robust parallel decision-making in neural circuits with nonlinear
              inhibition",
  author   = "Kriener, Birgit and Chaudhuri, Rishidev and Fiete, Ila R",
  abstract = "An elemental computation in the brain is to identify the best in
              a set of options and report its value. It is required for
              inference, decision-making, optimization, action selection,
              consensus, and foraging. Neural computing is considered powerful
              because of its parallelism; however, it is unclear whether
              neurons can perform this max-finding operation in a way that
              improves upon the prohibitively slow optimal serial max-finding
              computation (which takes [Formula: see text] time for N noisy
              candidate options) by a factor of N, the benchmark for parallel
              computation. Biologically plausible architectures for this task
              are winner-take-all (WTA) networks, where individual neurons
              inhibit each other so only those with the largest input remain
              active. We show that conventional WTA networks fail the
              parallelism benchmark and, worse, in the presence of noise,
              altogether fail to produce a winner when N is large. We introduce
              the nWTA network, in which neurons are equipped with a second
              nonlinearity that prevents weakly active neurons from
              contributing inhibition. Without parameter fine-tuning or
              rescaling as N varies, the nWTA network achieves the parallelism
              benchmark. The network reproduces experimentally observed
              phenomena like Hick's law without needing an additional readout
              stage or adaptive N-dependent thresholds. Our work bridges scales
              by linking cellular nonlinearities to circuit-level
              decision-making, establishes that distributed computation
              saturating the parallelism benchmark is possible in networks of
              noisy, finite-memory neurons, and shows that Hick's law may be a
              symptom of near-optimal parallel decision-making with noisy
              input.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  117,
  number   =  41,
  pages    = "25505--25516",
  month    =  oct,
  year     =  2020,
  keywords = "neural circuits; noisy computation; optimal decision-making;
              speed--accuracy trade-off",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "33008882",
  doi      = "10.1073/pnas.1917551117",
  pmc      = "PMC7568288"
}

@ARTICLE{Rosenberg2021-fk,
  title     = "Mice in a labyrinth show rapid learning, sudden insight, and
               efficient exploration",
  author    = "Rosenberg, Matthew and Zhang, Tony and Perona, Pietro and
               Meister, Markus",
  abstract  = "Animals learn certain complex tasks remarkably fast, sometimes
               after a single experience. What behavioral algorithms support
               this efficiency? Many contemporary studies based on
               two-alternative-forced-choice (2AFC) tasks observe only slow or
               incomplete learning. As an alternative, we study the
               unconstrained behavior of mice in a complex labyrinth and
               measure the dynamics of learning and the behaviors that enable
               it. A mouse in the labyrinth makes ~2000 navigation decisions
               per hour. The animal explores the maze, quickly discovers the
               location of a reward, and executes correct 10-bit choices after
               only 10 reward experiences - a learning rate 1000-fold higher
               than in 2AFC experiments. Many mice improve discontinuously from
               one minute to the next, suggesting moments of sudden insight
               about the structure of the labyrinth. The underlying search
               algorithm does not require a global memory of places visited and
               is largely explained by purely local turning rules.",
  journal   = "Elife",
  publisher = "elifesciences.org",
  volume    =  10,
  month     =  jul,
  year      =  2021,
  keywords  = "behavior; cognitive map; computational biology; decision-making;
               few-shot learning; mouse; navigation; neuroscience; predictive
               models; systems biology",
  language  = "en",
  issn      = "2050-084X",
  pmid      = "34196271",
  doi       = "10.7554/eLife.66175",
  pmc       = "PMC8294850"
}

@ARTICLE{International_Brain_Laboratory2021-tb,
  title     = "Standardized and reproducible measurement of decision-making in
               mice",
  author    = "{International Brain Laboratory} and Aguillon-Rodriguez, Valeria
               and Angelaki, Dora and Bayer, Hannah and Bonacchi, Niccolo and
               Carandini, Matteo and Cazettes, Fanny and Chapuis, Gaelle and
               Churchland, Anne K and Dan, Yang and Dewitt, Eric and Faulkner,
               Mayo and Forrest, Hamish and Haetzel, Laura and H{\"a}usser,
               Michael and Hofer, Sonja B and Hu, Fei and Khanal, Anup and
               Krasniak, Christopher and Laranjeira, Ines and Mainen, Zachary F
               and Meijer, Guido and Miska, Nathaniel J and Mrsic-Flogel,
               Thomas D and Murakami, Masayoshi and Noel, Jean-Paul and
               Pan-Vazquez, Alejandro and Rossant, Cyrille and Sanders, Joshua
               and Socha, Karolina and Terry, Rebecca and Urai, Anne E and
               Vergara, Hernando and Wells, Miles and Wilson, Christian J and
               Witten, Ilana B and Wool, Lauren E and Zador, Anthony M",
  abstract  = "Progress in science requires standardized assays whose results
               can be readily shared, compared, and reproduced across
               laboratories. Reproducibility, however, has been a concern in
               neuroscience, particularly for measurements of mouse behavior.
               Here, we show that a standardized task to probe decision-making
               in mice produces reproducible results across multiple
               laboratories. We adopted a task for head-fixed mice that assays
               perceptual and value-based decision making, and we standardized
               training protocol and experimental hardware, software, and
               procedures. We trained 140 mice across seven laboratories in
               three countries, and we collected 5 million mouse choices into a
               publicly available database. Learning speed was variable across
               mice and laboratories, but once training was complete there were
               no significant differences in behavior across laboratories. Mice
               in different laboratories adopted similar reliance on visual
               stimuli, on past successes and failures, and on estimates of
               stimulus prior probability to guide their choices. These results
               reveal that a complex mouse behavior can be reproduced across
               multiple laboratories. They establish a standard for
               reproducible rodent behavior, and provide an unprecedented
               dataset and open-access tools to study decision-making in mice.
               More generally, they indicate a path toward achieving
               reproducibility in neuroscience through collaborative
               open-science approaches.",
  journal   = "Elife",
  publisher = "eLife Sciences Publications, Ltd",
  volume    =  10,
  month     =  may,
  year      =  2021,
  keywords  = "behavior; decision making; mouse; neuroscience; reproducibility",
  copyright = "http://creativecommons.org/licenses/by/4.0/",
  language  = "en",
  issn      = "2050-084X",
  pmid      = "34011433",
  doi       = "10.7554/eLife.63711",
  pmc       = "PMC8137147"
}

@ARTICLE{Silver2018-ak,
  title    = "A general reinforcement learning algorithm that masters chess,
              shogi, and Go through self-play",
  author   = "Silver, David and Hubert, Thomas and Schrittwieser, Julian and
              Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and
              Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and
              Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and
              Hassabis, Demis",
  abstract = "The game of chess is the longest-studied domain in the history of
              artificial intelligence. The strongest programs are based on a
              combination of sophisticated search techniques, domain-specific
              adaptations, and handcrafted evaluation functions that have been
              refined by human experts over several decades. By contrast, the
              AlphaGo Zero program recently achieved superhuman performance in
              the game of Go by reinforcement learning from self-play. In this
              paper, we generalize this approach into a single AlphaZero
              algorithm that can achieve superhuman performance in many
              challenging games. Starting from random play and given no domain
              knowledge except the game rules, AlphaZero convincingly defeated
              a world champion program in the games of chess and shogi
              (Japanese chess), as well as Go.",
  journal  = "Science",
  volume   =  362,
  number   =  6419,
  pages    = "1140--1144",
  month    =  dec,
  year     =  2018,
  language = "en",
  issn     = "0036-8075, 1095-9203",
  pmid     = "30523106",
  doi      = "10.1126/science.aar6404"
}

@ARTICLE{Fiete2008-bx,
  title    = "What grid cells convey about rat location",
  author   = "Fiete, Ila R and Burak, Yoram and Brookings, Ted",
  abstract = "We characterize the relationship between the simultaneously
              recorded quantities of rodent grid cell firing and the position
              of the rat. The formalization reveals various properties of grid
              cell activity when considered as a neural code for representing
              and updating estimates of the rat's location. We show that,
              although the spatially periodic response of grid cells appears
              wasteful, the code is fully combinatorial in capacity. The
              resulting range for unambiguous position representation is vastly
              greater than the approximately 1-10 m periods of individual
              lattices, allowing for unique high-resolution position
              specification over the behavioral foraging ranges of rats, with
              excess capacity that could be used for error correction. Next, we
              show that the merits of the grid cell code for position
              representation extend well beyond capacity and include arithmetic
              properties that facilitate position updating. We conclude by
              considering the numerous implications, for downstream readouts
              and experimental tests, of the properties of the grid cell code.",
  journal  = "J. Neurosci.",
  volume   =  28,
  number   =  27,
  pages    = "6858--6871",
  month    =  jul,
  year     =  2008,
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "18596161",
  doi      = "10.1523/JNEUROSCI.5684-07.2008",
  pmc      = "PMC6670990"
}

@ARTICLE{Recanatesi2021-xt,
  title     = "Predictive learning as a network mechanism for extracting
               low-dimensional latent space representations",
  author    = "Recanatesi, Stefano and Farrell, Matthew and Lajoie, Guillaume
               and Deneve, Sophie and Rigotti, Mattia and Shea-Brown, Eric",
  abstract  = "Artificial neural networks have recently achieved many successes
               in solving sequential processing and planning tasks. Their
               success is often ascribed to the emergence of the task's
               low-dimensional latent structure in the network activity - i.e.,
               in the learned neural representations. Here, we investigate the
               hypothesis that a means for generating representations with
               easily accessed low-dimensional latent structure, possibly
               reflecting an underlying semantic organization, is through
               learning to predict observations about the world. Specifically,
               we ask whether and when network mechanisms for sensory
               prediction coincide with those for extracting the underlying
               latent variables. Using a recurrent neural network model trained
               to predict a sequence of observations we show that network
               dynamics exhibit low-dimensional but nonlinearly transformed
               representations of sensory inputs that map the latent structure
               of the sensory environment. We quantify these results using
               nonlinear measures of intrinsic dimensionality and linear
               decodability of latent variables, and provide mathematical
               arguments for why such useful predictive representations emerge.
               We focus throughout on how our results can aid the analysis and
               interpretation of experimental data.",
  journal   = "Nat. Commun.",
  publisher = "nature.com",
  volume    =  12,
  number    =  1,
  pages     = "1417",
  month     =  mar,
  year      =  2021,
  language  = "en",
  issn      = "2041-1723",
  pmid      = "33658520",
  doi       = "10.1038/s41467-021-21696-1",
  pmc       = "PMC7930246"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Recanatesi2018-wl,
  title     = "Signatures and mechanisms of low-dimensional neural predictive
               manifolds",
  author    = "Recanatesi, S and Farrell, M and Lajoie, G and Deneve, S and
               Rigotti, M and {others}",
  abstract  = "Many of the recent advances of neural networks in sequential
               tasks such as natural language processing applications hinge on
               the use of representations obtained by predictive models. This
               success is usually ascribed to the emergence of neural …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2018
}

@ARTICLE{Zong_undated-gd,
  title  = "Large-scale two-photon calcium imaging in freely moving mice",
  author = "Zong, Weijian and Obenhaus, Horst A and Skyt{\o}en, Emilie R and
            Eneqvist, Hanna and de Jong, Nienke L and Jorge, Marina R and
            Moser, May-Britt and Moser, Edvard I",
  doi    = "10.1101/2021.09.20.461015"
}

@ARTICLE{Zhang_undated-tx,
  title    = "Endotaxis: A Universal Algorithm for Mapping, {Goal-Learning},
              and Navigation",
  author   = "Zhang, Tony and Rosenberg, Matthew and Perona, Pietro and
              Meister, Markus",
  keywords = "navigation",
  doi      = "10.1101/2021.09.24.461751"
}

@ARTICLE{Rouse_undated-dv,
  title  = "Topological insights into the neural basis of flexible behavior",
  author = "Rouse, Tevin C and Ni, Amy M and Huang, Chengcheng and Cohen,
            Marlene R",
  doi    = "10.1101/2021.09.24.461717"
}

@ARTICLE{McNamee2019-cz,
  title    = "Internal Models in Biological Control",
  author   = "McNamee, Daniel and Wolpert, Daniel M",
  abstract = "Rationality principles such as optimal feedback control and
              Bayesian inference underpin a probabilistic framework that has
              accounted for a range of empirical phenomena in biological
              sensorimotor control. To facilitate the optimization of flexible
              and robust behaviors consistent with these theories, the ability
              to construct internal models of the motor system and
              environmental dynamics can be crucial. In the context of this
              theoretic formalism, we review the computational roles played by
              such internal models and the neural and behavioral evidence for
              their implementation in the brain.",
  journal  = "Annu Rev Control Robot Auton Syst",
  volume   =  2,
  pages    = "339--364",
  month    =  may,
  year     =  2019,
  language = "en",
  issn     = "2573-5144",
  pmid     = "31106294",
  doi      = "10.1146/annurev-control-060117-105206",
  pmc      = "PMC6520231"
}

@ARTICLE{Thirugnanam2021-dj,
  title         = "A Fast Computational Optimization for Optimal Control and
                   Trajectory Planning for Obstacle Avoidance between Polytopes",
  author        = "Thirugnanam, Akshay and Zeng, Jun and Sreenath, Koushil",
  abstract      = "Obstacle avoidance between polytopes is a challenging topic
                   for optimal control and optimization-based trajectory
                   planning problems. Existing work either solves this problem
                   through mixed-integer optimization, relying on
                   simplification of system dynamics, or through model
                   predictive control with dual variables using distance
                   constraints, requiring long horizons for obstacle avoidance.
                   In either case, the solution can only be applied as an
                   offline planning algorithm. In this paper, we exploit the
                   property that a smaller horizon is sufficient for obstacle
                   avoidance by using discrete-time control barrier function
                   (DCBF) constraints and we propose a novel optimization
                   formulation with dual variables based on DCBFs to generate a
                   collision-free dynamically-feasible trajectory. The proposed
                   optimization formulation has lower computational complexity
                   compared to existing work and can be used as a fast online
                   algorithm for control and planning for general nonlinear
                   dynamical systems. We validate our algorithm on different
                   robot shapes using numerical simulations with a kinematic
                   bicycle model, resulting in successful navigation through
                   maze environments with polytopic obstacles.",
  month         =  sep,
  year          =  2021,
  keywords      = "control",
  archivePrefix = "arXiv",
  eprint        = "2109.12313",
  primaryClass  = "cs.RO",
  arxivid       = "2109.12313"
}

@ARTICLE{Lin2018-yy,
  title    = "{Core-Shell-Shell} Upconversion Nanoparticles with Enhanced
              Emission for Wireless Optogenetic Inhibition",
  author   = "Lin, Xudong and Chen, Xian and Zhang, Wenchong and Sun, Tianying
              and Fang, Peilin and Liao, Qinghai and Chen, Xi and He, Jufang
              and Liu, Ming and Wang, Feng and Shi, Peng",
  abstract = "Recent advances in upconversion technology have enabled
              optogenetic neural stimulation using remotely applied optical
              signals, but limited success has been demonstrated for neural
              inhibition by using this method, primarily due to the much higher
              optical power and more red-shifted excitation spectrum that are
              required to work with the appropriate inhibitory opsin proteins.
              To overcome these limitations, core-shell-shell upconversion
              nanoparticles (UCNPs) with a hexagonal phase are synthesized to
              optimize the doping contents of ytterbium ions (Yb3+) and to
              mitigate Yb-associated concentration quenching. Such UCNPs'
              emission contains an almost three-fold enhanced peak around
              540-570 nm, matching the excitation spectrum of a commonly used
              inhibitory opsin protein, halorhodopsin. The enhanced UCNPs are
              utilized as optical transducers to develop a fully implantable
              upconversion-based device for in vivo tetherless optogenetic
              inhibition, which is actuated by near-infrared (NIR) light
              irradiation without any electronics. When the device is implanted
              into targeted sites deep in the rat brain, the electrical
              activity of the neurons is reliably inhibited with NIR
              irradiation and restores to normal level upon switching off the
              NIR light. The system is further used to perform tetherless
              unilateral inhibition of the secondary motor cortex in behaving
              mice, achieving control of their motor functions. This study
              provides an important and useful supplement to the
              upconversion-based optogenetic toolset, which is beneficial for
              both basic and translational neuroscience investigations.",
  journal  = "Nano Lett.",
  volume   =  18,
  number   =  2,
  pages    = "948--956",
  month    =  feb,
  year     =  2018,
  keywords = "Neural inhibition; halorhodopsin; lanthanide-doped nanoparticles;
              near-infrared light; upconversion; wireless optogenetics",
  language = "en",
  issn     = "1530-6984, 1530-6992",
  pmid     = "29278506",
  doi      = "10.1021/acs.nanolett.7b04339"
}

@ARTICLE{Fischer2021-by,
  title         = "Optimal Feedback Control for Modeling {Human-Computer}
                   Interaction",
  author        = "Fischer, Florian and Fleig, Arthur and Klar, Markus and
                   M{\"u}ller, J{\"o}rg",
  abstract      = "Optimal feedback control (OFC) is a theory from the motor
                   control literature that explains how humans move their body
                   to achieve a certain goal, e.g., pointing with the finger.
                   OFC is based on the assumption that humans aim to control
                   their body optimally, within the constraints imposed by
                   body, environment, and task. In this paper, we explain how
                   this theory can be applied to understanding Human-Computer
                   Interaction. We propose that in this case, the dynamics of
                   the human body and computer can be interpreted as a single
                   dynamical system. The state of this system is controlled by
                   the user via muscle control signals, and estimated from
                   observations. Between-trial variability arises from
                   signal-dependent control noise and observation noise. We
                   compare four different models from optimal control theory
                   and evaluate to what degree these models can replicate
                   movements in the case of mouse pointing. We introduce a
                   procedure to identify parameters that best explain observed
                   user behavior, and show how these parameters can be used to
                   gain insights regarding user characteristics and
                   preferences. We conclude that OFC presents a powerful
                   framework for HCI to understand and simulate motion of the
                   human body and of the interface on a moment by moment basis.",
  month         =  oct,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2110.00443",
  primaryClass  = "cs.HC",
  arxivid       = "2110.00443"
}

@ARTICLE{Ritz2021-xz,
  title         = "Cognitive control as a multivariate optimization problem",
  author        = "Ritz, Harrison and Leng, Xiamin and Shenhav, Amitai",
  abstract      = "Research has characterized the various forms cognitive
                   control can take, including enhancement of goal-relevant
                   information, suppression of goal-irrelevant information, and
                   overall inhibition of potential responses, and has
                   identified computations and neural circuits that underpin
                   this multitude of control types. Studies have also
                   identified a wide range of situations that elicit
                   adjustments in control allocation (e.g., those eliciting
                   signals indicating an error or increased processing
                   conflict), but the rules governing when a given situation
                   will give rise to a given control adjustment remain poorly
                   understood. Significant progress has recently been made on
                   this front by casting the allocation of control as a
                   decision-making problem, and developing unifying and
                   normative models that prescribe when and how a change in
                   incentives and task demands will result in changes in a
                   given form of control. Despite their successes, these
                   models, and the experiments that have been developed to test
                   them, have yet to face their greatest challenge: deciding
                   how to allocate control across the multiplicity of control
                   signals that one could engage at any given time. Here, we
                   will lay out the complexities of the inverse problem
                   inherent to cognitive control allocation, and their close
                   parallels to inverse problems within motor control (e.g.,
                   choosing between redundant limb movements). We discuss
                   existing solutions to motor control`s inverse problems drawn
                   from optimal control theory, which have proposed that effort
                   costs act to regularize actions and transform motor planning
                   into a well-posed problem. These same principles may help
                   shed light on how our brains optimize over complex control
                   configuration, while providing a new normative perspective
                   on the origins of mental effort.",
  month         =  oct,
  year          =  2021,
  copyright     = "http://creativecommons.org/licenses/by-sa/4.0/",
  archivePrefix = "arXiv",
  eprint        = "2110.00668",
  primaryClass  = "q-bio.NC",
  arxivid       = "2110.00668"
}

@UNPUBLISHED{Fujiwara2021-dn,
  title    = "Walking strides direct rapid and flexible recruitment of visual
              circuits for course control in Drosophila",
  author   = "Fujiwara, Terufumi and Brotas, Margarida and Eugenia Chiappe, M",
  abstract = "Flexible mapping between activity in sensory systems and movement
              parameters is a hallmark of successful motor control. This
              flexibility depends on continuous comparison of short-term
              postural dynamics and the longer-term goals of an animal, thereby
              necessitating neural mechanisms that can operate across multiple
              timescales. To understand how such body-brain interactions emerge
              to control movement across timescales, we performed whole-cell
              patch recordings from visual neurons involved in course control
              in Drosophila . We demonstrate that the activity of leg
              mechanosensory cells, propagating via specific ascending neurons,
              is critical to provide a clock signal to the visual circuit for
              stride-by-stride steering adjustments and, at longer timescales,
              information on speed-associated motor context to flexibly recruit
              visual circuits for course control. Thus, our data reveal a
              stride-based mechanism for the control of high-performance
              walking operating at multiple timescales. We propose that this
              mechanism functions as a general basis for adaptive control of
              locomotion. \#\#\# Competing Interest Statement The authors have
              declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.10.10.463817",
  month    =  oct,
  year     =  2021,
  keywords = "Locomotion",
  language = "en",
  doi      = "10.1101/2021.10.10.463817"
}

@UNPUBLISHED{Schimel2021-tx,
  title    = "{iLQR-VAE} : control-based learning of input-driven dynamics with
              applications to neural data",
  author   = "Schimel, Marine and Kao, Ta-Chu and Jensen, Kristopher T and
              Hennequin, Guillaume",
  abstract = "Understanding how neural dynamics give rise to behaviour is one
              of the most fundamental questions in systems neuroscience. To
              achieve this, a common approach is to record neural populations
              in behaving animals, and model these data as emanating from a
              latent dynamical system whose state trajectories can then be
              related back to behavioural observations via some form of
              decoding. As recordings are typically performed in localized
              circuits that form only a part of the wider implicated network,
              it is important to simultaneously learn the local dynamics and
              infer any unobserved external input that might drive them. Here,
              we introduce iLQR-VAE, a novel control-based approach to
              variational inference in nonlinear dynamical systems, capable of
              learning both latent dynamics, initial conditions, and ongoing
              external inputs. As in recent deep learning approaches, our
              method is based on an input-driven sequential variational
              autoencoder (VAE). The main novelty lies in the use of the
              powerful iterative linear quadratic regulator algorithm (iLQR) in
              the recognition model. Optimization of the standard evidence
              lower-bound requires differentiating through iLQR solutions,
              which is made possible by recent advances in differentiable
              control. Importantly, having the recognition model implicitly
              defined by the generative model greatly reduces the number of
              free parameters and allows for flexible, high-quality inference.
              This makes it possible for instance to evaluate the model on a
              single long trial after training on smaller chunks. We
              demonstrate the effectiveness of iLQR-VAE on a range of synthetic
              systems, with autonomous as well as input-driven dynamics. We
              further show state-of-the-art performance on neural and
              behavioural recordings in non-human primates during two different
              reaching tasks. \#\#\# Competing Interest Statement The authors
              have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.10.07.463540",
  month    =  oct,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.10.07.463540"
}

@ARTICLE{Barak2021-ko,
  title    = "Mapping {Low-Dimensional} Dynamics to {High-Dimensional} Neural
              Activity: A Derivation of the Ring Model From the Neural
              Engineering Framework",
  author   = "Barak, Omri and Romani, Sandro",
  abstract = "Empirical estimates of the dimensionality of neural population
              activity are often much lower than the population size. Similar
              phenomena are also observed in trained and designed neural
              network models. These experimental and computational results
              suggest that mapping low-dimensional dynamics to high-dimensional
              neural space is a common feature of cortical computation. Despite
              the ubiquity of this observation, the constraints arising from
              such mapping are poorly understood. Here we consider a specific
              example of mapping low-dimensional dynamics to high-dimensional
              neural activity-the neural engineering framework. We analytically
              solve the framework for the classic ring model-a neural network
              encoding a static or dynamic angular variable. Our results
              provide a complete characterization of the success and failure
              modes for this model. Based on similarities between this and
              other frameworks, we speculate that these results could apply to
              more general scenarios.",
  journal  = "Neural Comput.",
  volume   =  33,
  number   =  3,
  pages    = "827--852",
  month    =  mar,
  year     =  2021,
  language = "en",
  issn     = "0899-7667, 1530-888X",
  pmid     = "33513322",
  doi      = "10.1162/neco\_a\_01361"
}

@ARTICLE{Logiaco2021-th,
  title    = "Thalamic control of cortical dynamics in a model of flexible
              motor sequencing",
  author   = "Logiaco, Laureline and Abbott, L F and Escola, Sean",
  abstract = "The neural mechanisms that generate an extensible library of
              motor motifs and flexibly string them into arbitrary sequences
              are unclear. We developed a model in which inhibitory basal
              ganglia output neurons project to thalamic units that are
              themselves bidirectionally connected to a recurrent cortical
              network. We model the basal ganglia inhibitory patterns as
              silencing some thalamic neurons while leaving others disinhibited
              and free to interact with cortex during specific motifs. We show
              that a small number of disinhibited thalamic neurons can control
              cortical dynamics to generate specific motor output in a
              noise-robust way. Additionally, a single ``preparatory''
              thalamocortical network can produce fast cortical dynamics that
              support rapid transitions between any pair of learned motifs. If
              the thalamic units associated with each sequence component are
              segregated, many motor outputs can be learned without
              interference and then combined in arbitrary orders for the
              flexible production of long and complex motor sequences.",
  journal  = "Cell Rep.",
  volume   =  35,
  number   =  9,
  pages    = "109090",
  month    =  jun,
  year     =  2021,
  keywords = "control; hierarchical behaviors; low-rank connectivity
              perturbation; motor cortex; motor sequencing; recurrent neural
              networks; switching linear dynamics; thalamocortical loops;
              thalamus",
  language = "en",
  issn     = "2211-1247",
  pmid     = "34077721",
  doi      = "10.1016/j.celrep.2021.109090",
  pmc      = "PMC8449509"
}

@ARTICLE{Basu2021-nw,
  title     = "The orbitofrontal cortex maps future navigational goals",
  author    = "Basu, Raunak and Gebauer, Robert and Herfurth, Tim and Kolb,
               Simon and Golipour, Zahra and Tchumatchenko, Tatjana and Ito,
               Hiroshi T",
  abstract  = "Accurate navigation to a desired goal requires consecutive
               estimates of spatial relationships between the current position
               and future destination throughout the journey. Although neurons
               in the hippocampal formation can represent the position of an
               animal as well as its nearby trajectories1--7, their role in
               determining the destination of the animal has been
               questioned8,9. It is, thus, unclear whether the brain can
               possess a precise estimate of target location during active
               environmental exploration. Here we describe neurons in the rat
               orbitofrontal cortex (OFC) that form spatial representations
               persistently pointing to the subsequent goal destination of an
               animal throughout navigation. This destination coding emerges
               before the onset of navigation, without direct sensory access to
               a distal goal, and even predicts the incorrect destination of an
               animal at the beginning of an error trial. Goal representations
               in the OFC are maintained by destination-specific neural
               ensemble dynamics, and their brief perturbation at the onset of
               a journey led to a navigational error. These findings suggest
               that the OFC is part of the internal goal map of the brain,
               enabling animals to navigate precisely to a chosen destination
               that is beyond the range of sensory perception. Dedicated cells
               in the hippocampus and entorhinal cortex map an animal s
               instantaneous position in space; by contrast, its future goal
               location is represented in the orbitofrontal cortex, a structure
               within the broader circuit.",
  journal   = "Nature",
  publisher = "Nature Publishing Group",
  pages     = "1--4",
  month     =  oct,
  year      =  2021,
  language  = "en",
  issn      = "0028-0836",
  doi       = "10.1038/s41586-021-04042-9"
}

@ARTICLE{Noel_undated-jt,
  title  = "Flexible neural coding in",
  author = "Noel, Jean-Paul and Alefantis, Edoardo Balzani",
  doi    = "10.1101/2021.10.22.465526"
}

@ARTICLE{Cisek_undated-rd,
  title  = "Evolution of behavioural control from chordates to primates",
  author = "Cisek, Paul",
  doi    = "10.1098/rstb.2020.0522"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Hicheur2005-yw,
  title       = "How do humans turn? Head and body movements for the steering
                 of locomotion Halim Hicheur and Alain Berthoz",
  booktitle   = "5th {IEEE-RAS} International Conference on Humanoid Robots,
                 2005.",
  author      = "Hicheur, Halim and Berthoz, Alain",
  abstract    = "Turning in humans represents a greater challenge than straight
                 ahead walking in terms of postural control. Indeed, when
                 steering along a curved path humans have to adapt their
                 locomotor pattern by taking into account centrifugal
                 acceleration, which tends to keep their …",
  publisher   = "ieeexplore.ieee.org",
  pages       = "265--270",
  institution = "IEEE",
  year        =  2005
}

@ARTICLE{Hicheur2007-cy,
  title     = "The formation of trajectories during goal-oriented locomotion in
               humans. I. A stereotyped behaviour",
  author    = "Hicheur, Halim and Pham, Quang-Cuong and Arechavaleta, Gustavo
               and Laumond, Jean-Paul and Berthoz, Alain",
  abstract  = "Human locomotion was investigated in a goal-oriented task where
               subjects had to walk to and through a doorway starting from a
               fixed position and orientation in space. The door was located at
               different positions and orientations in space, resulting in a
               total of 40 targets. While no specific constraint was provided
               to subjects in terms of the path they were to follow or the
               expected walking speeds, all of them generated very similar
               trajectories in terms of both path geometry and velocity
               profiles. These results are reminiscent of the stereotyped
               properties of the hand trajectories observed in arm reaching
               movements in studies over the last 20 years. This observation
               supports the hypothesis that common constraining mechanisms
               govern the generation of segmental and whole-body trajectories.
               In contrast, we observed that the subjects placed their feet at
               different spatial positions across repetitions, making unlikely
               the hypothesis that goal-oriented locomotion is planned as a
               succession of steps. Rather, our results suggest that common
               planning and/or control strategies underlie the formation of the
               whole locomotor trajectory during a spatially oriented task.",
  journal   = "Eur. J. Neurosci.",
  publisher = "Wiley",
  volume    =  26,
  number    =  8,
  pages     = "2376--2390",
  month     =  oct,
  year      =  2007,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "0953-816X, 1460-9568",
  pmid      = "17953625",
  doi       = "10.1111/j.1460-9568.2007.05836.x"
}

@ARTICLE{Pham2007-bg,
  title     = "The formation of trajectories during goal-oriented locomotion in
               humans. {II}. A maximum smoothness model",
  author    = "Pham, Quang-Cuong and Hicheur, Halim and Arechavaleta, Gustavo
               and Laumond, Jean-Paul and Berthoz, Alain",
  abstract  = "Despite the theoretically infinite number of possible
               trajectories a human may take to reach a distant doorway, we
               observed that locomotor trajectories corresponding to this task
               were actually stereotyped, both at the geometric and the
               kinematic levels. In this paper, we propose a computational
               model for the formation of human locomotor trajectories. Our
               model is adapted from smoothness maximization models that have
               been studied in the context of hand trajectory generation. The
               trajectories predicted by our model are very similar to the
               experimentally recorded ones. We discuss the theoretical
               implications of this result in the context of movement planning
               and control in humans. In particular, this result supports the
               hypothesis that common principles, such as smoothness
               maximization, may govern the generation of very different types
               of movements (in this case, hand movements and whole-body
               movements).",
  journal   = "Eur. J. Neurosci.",
  publisher = "Wiley",
  volume    =  26,
  number    =  8,
  pages     = "2391--2403",
  month     =  oct,
  year      =  2007,
  keywords  = "Locomotion",
  language  = "en",
  issn      = "0953-816X, 1460-9568",
  pmid      = "17953626",
  doi       = "10.1111/j.1460-9568.2007.05835.x"
}

@ARTICLE{Maroger2021-wy,
  title    = "Inverse optimal control to model human trajectories during
              locomotion",
  author   = "Maroger, Isabelle and Stasse, Olivier and Watier, Bruno",
  abstract = "Cobotic applications require a good knowledge of human behaviour
              in order to be cleverly, securely and fluidly performed. For
              example, to make a human and a humanoid robot perform a
              co-navigation or a co-manipulation task, a model of human walking
              trajectories is essential to make the robot follow or even
              anticipate the human movements. This paper aims to study the
              Center of Mass (CoM) path during locomotion and generate
              human-like trajectories with an optimal control scheme. It also
              proposes a metric which allows to assess this model compared to
              the human behaviour. CoM trajectories during locomotion of 10
              healthy subjects were recorded and analysed as part of this
              study. Inverse optimal control was used to find the optimal cost
              function which best fits the model to the measurements. Then, the
              measurements and the generated data were compared in order to
              assess the performance of the presented model. Even if the
              experiments show a great variability in human behaviours, the
              model presented in this study gives an accurate approximation of
              the average human walking trajectories. Furthermore, this model
              gives an approximation of human locomotion good enough to improve
              cobotic tasks allowing a humanoid robot to anticipate the human
              behaviour.",
  journal  = "Comput. Methods Biomech. Biomed. Engin.",
  pages    = "1--13",
  month    =  aug,
  year     =  2021,
  keywords = "Locomotion analysis; human-robot interaction; model-based
              simulation; modeling; optimal control;Locomotion",
  language = "en",
  issn     = "1025-5842, 1476-8259",
  pmid     = "34392752",
  doi      = "10.1080/10255842.2021.1962311"
}

@ARTICLE{Mombaur2010-hj,
  title    = "From human to humanoid locomotion---an inverse optimal control
              approach",
  author   = "Mombaur, Katja and Truong, Anh and Laumond, Jean-Paul",
  abstract = "The purpose of this paper is to present inverse optimal control
              as a promising approach to transfer biological motions to robots.
              Inverse optimal control helps (a) to understand and identify the
              underlying optimality criteria of biological motions based on
              measurements, and (b) to establish optimal control models that
              can be used to control robot motion. The aim of inverse optimal
              control problems is to determine---for a given dynamic process
              and an observed solution---the optimization criterion that has
              produced the solution. Inverse optimal control problems are
              difficult from a mathematical point of view, since they require
              to solve a parameter identification problem inside an optimal
              control problem. We propose a pragmatic new bilevel approach to
              solve inverse optimal control problems which rests on two
              pillars: an efficient direct multiple shooting technique to
              handle optimal control problems, and a state-of-the art
              derivative free trust region optimization technique to guarantee
              a match between optimal control problem solution and
              measurements. In this paper, we apply inverse optimal control to
              establish a model of human overall locomotion path generation to
              given target positions and orientations, based on newly collected
              motion capture data. It is shown how the optimal control model
              can be implemented on the humanoid robot HRP-2 and thus enable it
              to autonomously generate natural locomotion paths.",
  journal  = "Auton. Robots",
  volume   =  28,
  number   =  3,
  pages    = "369--383",
  month    =  apr,
  year     =  2010,
  keywords = "Locomotion",
  issn     = "0929-5593, 1573-7527",
  doi      = "10.1007/s10514-009-9170-7"
}

@INPROCEEDINGS{Chitour2010-gc,
  title           = "Analysis of optimal control models for the human
                     locomotion",
  booktitle       = "49th {IEEE} Conference on Decision and Control ({CDC})",
  author          = "Chitour, Yacine and Chittaro, Francesca and Jean, Frederic
                     and Mason, Paolo",
  abstract        = "The main results describe the asymptotic behavior of the
                     optimal trajectories as the target point goes to infinity.
                     In recent papers it has been suggested that human
                     locomotion may be modeled as an inverse optimal control
                     problem. In this paradigm, the trajectories are assumed to
                     be solutions of an optimal control problem that has to be
                     determined. We discuss the modeling of both the dynamical
                     system and the cost to be minimized, and we analyse the
                     corresponding optimal synthesis. The main results describe
                     the asymptotic behavior of the optimal trajectories as the
                     target point goes to infinity.",
  publisher       = "IEEE",
  month           =  dec,
  year            =  2010,
  keywords        = "Locomotion",
  conference      = "2010 49th IEEE Conference on Decision and Control (CDC)",
  location        = "Atlanta, GA, USA",
  isbn            = "9781424477456",
  doi             = "10.1109/cdc.2010.5717396"
}

@ARTICLE{Arechavaleta2008-gu,
  title     = "An optimality principle governing human walking",
  author    = "Arechavaleta, Gustavo and Laumond, Jean-Paul and Hicheur, Halim
               and Berthoz, Alain",
  abstract  = "This paper investigates different possible strategies underlying
               the formation of human locomotor trajectories in goal-directed
               walking and finds that the variation (time derivative) of the
               curvature of the locomotor paths is minimized. In this paper, we
               investigate different possible strategies underlying the
               formation of human locomotor trajectories in goal-directed
               walking. Seven subjects were asked to walk within a motion
               capture facility from a fixed starting point and direction, and
               to cross over distant porches for which both position and
               direction in the room were changed over trials. Stereotyped
               trajectories were observed in the different subjects. The
               underlying idea to attack this question has been to relate this
               problem to an optimal control scheme: the trajectory is chosen
               according to some optimization principle. This is our basic
               starting assumption. The subject being viewed as a controlled
               system, we tried to identify several criteria that could be
               optimized. Is it the time to perform the trajectory? The length
               of the path? The minimum jerk along the path? We found that the
               variation (time derivative) of the curvature of the locomotor
               paths is minimized. Moreover, we show that the human locomotor
               trajectories are well approximated by the geodesics of a
               differential system minimizing the norm of the control. Such
               geodesics are made of arcs of clothoids. The clothoid or Cornu
               spiral is a curve, whose curvature grows with the distance from
               the origin.",
  journal   = "IEEE Trans. Robot.",
  publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
  volume    =  24,
  number    =  1,
  pages     = "5--14",
  month     =  feb,
  year      =  2008,
  keywords  = "Locomotion",
  issn      = "1552-3098, 1941-0468",
  doi       = "10.1109/tro.2008.915449"
}

@INCOLLECTION{Mombaur2017-mw,
  title     = "Inverse Optimal Control as a Tool to Understand Human Movement",
  booktitle = "Geometric and Numerical Foundations of Movements",
  author    = "Mombaur, Katja and Clever, Debora",
  editor    = "Laumond, Jean-Paul and Mansard, Nicolas and Lasserre,
               Jean-Bernard",
  abstract  = "In this paper, we discuss numerical foundations and
               computational results for inverse optimal control of human
               locomotion based on human motion capture data. The task of
               inverse optimal control is to identify the precise underlying
               objective function that is optimized in an observed motion. The
               presented methods can cope with partial and imprecise
               measurements of the state variables which is typically the case
               for motion capture recordings. We investigate human walking and
               running motions on different levels of detail and consequently
               different underlying models which all have their own motivation
               depending on the question asked. Whole-body models are used to
               explore the mechanisms of motions on joint level, while simple
               models describing the subject as a single entity can be used to
               describe overall locomotion behavior. At an intermediate level,
               template models describe some relative motions of bodies while
               maintaining simplicity and computational efficiency. Results
               will be presented for all model types and different walking
               tasks. We also show for some of them how the identified
               objective functions can be used to generate new waking motions
               for humanoid robots in novel scenarios.",
  publisher = "Springer International Publishing",
  pages     = "163--186",
  year      =  2017,
  address   = "Cham",
  keywords  = "Locomotion",
  isbn      = "9783319515472",
  doi       = "10.1007/978-3-319-51547-2\_8"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Van_Koutrik2015-co,
  title        = "Optimal Control for Race Car Minimum Time Maneuvering",
  author       = "Van Koutrik, S",
  abstract     = "Minimizing the time needed to travel a prescribed distance is
                  the main development goal in motorsports. In racing car
                  development, simulations are used to predict the effect of
                  design parameter changes on vehicle performance. If
                  approached as an optimal trajectory planning problem, a
                  maneuver simulation can be used to determine not only the
                  maneuver time, but also to identify the performance
                  limitations on the system. This thesis describes the
                  development and implementation of an optimal trajectory
                  planning method using optimal …",
  publisher    = "researchgate.net",
  year         =  2015,
  howpublished = "\url{https://www.researchgate.net/file.PostFileLoader.html?id=5850ffea3d7f4b042e5a0786&assetKey=AS%3A439110046359560%401481703402034}",
  note         = "Accessed: 2021-11-2"
}

@PHDTHESIS{Xiong2010-bz,
  title  = "Racing line optimization",
  author = "Xiong, Ying and {Others}",
  year   =  2010,
  school = "Massachusetts Institute of Technology"
}

@INPROCEEDINGS{Takahashi1989-mr,
  title     = "Local Path Planning And Motion Control For Agv In Positioning",
  booktitle = "Proceedings. {IEEE/RSJ} International Workshop on Intelligent
               Robots and Systems '. ({IROS} '89) 'The Autonomous Mobile Robots
               and Its Applications",
  author    = "Takahashi, A and Hongo, T and Ninomiya, Y and Sugimoto, G",
  pages     = "392--397",
  month     =  sep,
  year      =  1989,
  keywords  = "Path planning;Motion control;Cost
               function;Guidelines;Wire;Cables;Acceleration;Remotely operated
               vehicles;Mobile robots;Workstations",
  doi       = "10.1109/IROS.1989.637936"
}

@ARTICLE{Sharma2021-yu,
  title         = "Map Induction: Compositional spatial submap learning for
                   efficient exploration in novel environments",
  author        = "Sharma, Sugandha and Curtis, Aidan and Kryven, Marta and
                   Tenenbaum, Josh and Fiete, Ila",
  abstract      = "Humans are expert explorers. Understanding the computational
                   cognitive mechanisms that support this efficiency can
                   advance the study of the human mind and enable more
                   efficient exploration algorithms. We hypothesize that humans
                   explore new environments efficiently by inferring the
                   structure of unobserved spaces using spatial information
                   collected from previously explored spaces. This cognitive
                   process can be modeled computationally using program
                   induction in a Hierarchical Bayesian framework that
                   explicitly reasons about uncertainty with strong spatial
                   priors. Using a new behavioral Map Induction Task, we
                   demonstrate that this computational framework explains human
                   exploration behavior better than non-inductive models and
                   outperforms state-of-the-art planning algorithms when
                   applied to a realistic spatial navigation domain.",
  month         =  oct,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2110.12301",
  primaryClass  = "cs.LG",
  arxivid       = "2110.12301"
}

@UNPUBLISHED{Khona2021-zd,
  title    = "Spontaneous emergence of topologically robust grid cell modules:
              A multiscale instability theory",
  author   = "Khona, Mikail and Chandra, Sarthak and Fiete, Ila",
  abstract = "Modular structures in the brain play a central role in
              compositionality and intelligence, however the general mechanisms
              driving module emergence have remained elusive. Studying
              entorhinal grid cells as paradigmatic examples of modular
              architecture and function, we demonstrate the spontaneous
              emergence of a small number of discrete spatial and functional
              modules from an interplay between continuously varying lateral
              interactions generated by smooth cortical gradients. We derive a
              comprehensive analytic theory of modularization, revealing that
              the process is highly generic with its robustness deriving from
              topological origins. The theory generates universal predictions
              for the sequence of grid period ratios, furnishing the most
              accurate explanation of grid cell data to date. Altogether, this
              work reveals novel principles by which simple bottom-up dynamical
              interactions lead to macroscopic modular organization. One
              sentence summary A novel bottom-up pathway for the
              self-organization of modules in biology provides quantitative
              match to grid cell experiments. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.10.28.466284",
  month    =  oct,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.10.28.466284"
}

@PHDTHESIS{Kao2021-cl,
  title  = "Optimal anticipatory control as a theory of motor preparation",
  author = "Kao, Ta-Chu",
  year   =  2021,
  school = "University of Cambridge"
}

@ARTICLE{Cesonis2021-fj,
  title         = "Mixed-horizon optimal feedback control as a model of human
                   movement",
  author        = "{\v C}esonis, Justinas and Franklin, David W",
  abstract      = "Computational optimal feedback control (OFC) models in the
                   sensorimotor control literature span a vast range of
                   different implementations. Among the popular algorithms,
                   finite-horizon, receding-horizon or infinite-horizon
                   linear-quadratic regulators (LQR) have been broadly used to
                   model human reaching movements. While these different
                   implementations have their unique merits, all three have
                   limitations in simulating the temporal evolution of
                   visuomotor feedback responses. Here we propose a novel
                   approach - a mixed-horizon OFC - by combining the strengths
                   of the traditional finite-horizon and the infinite-horizon
                   controllers to address their individual limitations.
                   Specifically, we use the infinite-horizon OFC to generate
                   durations of the movements, which are then fed into the
                   finite-horizon controller to generate control gains. We then
                   demonstrate the stability of our model by performing
                   extensive sensitivity analysis of both re-optimisation and
                   different cost functions. Finally, we use our model to
                   provide a fresh look to previously published studies by
                   reinforcing the previous results, providing alternative
                   explanations to previous studies, or generating new
                   predictive results for prior experiments.",
  month         =  apr,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2104.06275",
  primaryClass  = "q-bio.QM",
  arxivid       = "2104.06275"
}

@ARTICLE{Nelson2021-lv,
  title     = "Corticospinal populations broadcast complex motor signals to
               coordinated spinal and striatal circuits",
  author    = "Nelson, Anders and Abdelmesih, Brenda and Costa, Rui M",
  abstract  = "Many models of motor control emphasize the role of sensorimotor
               cortex in movement, principally through the projections that
               corticospinal neurons (CSNs) make to the spinal cord.
               Additionally, CSNs possess expansive supraspinal axon
               collaterals, the functional organization of which is largely
               unknown. Using anatomical and electrophysiological
               circuit-mapping techniques in the mouse, we reveal dorsolateral
               striatum as the preeminent target of CSN collateral innervation.
               We found that this innervation is biased so that CSNs targeting
               different striatal pathways show biased targeting of spinal cord
               circuits. Contrary to more conventional perspectives, CSNs
               encode not only individual movements, but also information
               related to the onset and offset of motor sequences. Furthermore,
               similar activity patterns are broadcast by CSN populations
               targeting different striatal circuits. Our results reveal a
               logic of coordinated connectivity between forebrain and spinal
               circuits, where separate CSN modules broadcast similarly complex
               information to downstream circuits, suggesting that differences
               in postsynaptic connectivity dictate motor specificity. The
               authors detail principles underlying the innervation of spinal
               and striatal circuits by populations of corticospinal neurons,
               and characterize the behavioral information broadcast through
               this motor control network.",
  journal   = "Nat. Neurosci.",
  publisher = "Nature Publishing Group",
  pages     = "1--12",
  month     =  nov,
  year      =  2021,
  language  = "en",
  issn      = "1097-6256",
  doi       = "10.1038/s41593-021-00939-w"
}

@ARTICLE{Naumann_undated-hh,
  title  = "Invariant neural subspaces maintained by feedback modulation",
  author = "Naumann, Laura Bella and Keijser, Joram and Sprekeler, Henning",
  doi    = "10.1101/2021.10.29.466453"
}

@ARTICLE{Lacquaniti1983-ro,
  title    = "The law relating the kinematic and figural aspects of drawing
              movements",
  author   = "Lacquaniti, F and Terzuolo, C and Viviani, P",
  journal  = "Acta Psychol.",
  volume   =  54,
  number   = "1-3",
  pages    = "115--130",
  month    =  oct,
  year     =  1983,
  language = "en",
  issn     = "0001-6918",
  pmid     = "6666647",
  doi      = "10.1016/0001-6918(83)90027-6"
}

@ARTICLE{Kelly2010-pe,
  title     = "Time-optimal control of the race car: a numerical method to
               emulate the ideal driver",
  author    = "Kelly, D P and Sharp, R S",
  abstract  = "A numerical method for the time-optimal control of the race car
               is presented. The method is then used to perform the role of the
               driver in numerical simulations of manoeuvres at the limit of
               race car performance. The method does not attempt to model the
               driver but rather replaces the driver with methods normally
               associated with numerical optimal control. The method
               simultaneously finds the optimal driven line and the driver
               control inputs (steer, throttle and brake) to drive this line in
               minimum time. In principle, the method is capable of operation
               with arbitrarily complex vehicle models as it requires only
               limited access to the vehicle model state vector. It also
               requires solution of the differential equation representing the
               vehicle model in only the forward time direction and is hence
               capable of simulating the full vehicle transient response.",
  journal   = "Veh. Syst. Dyn.",
  publisher = "Taylor \& Francis",
  volume    =  48,
  number    =  12,
  pages     = "1461--1474",
  month     =  dec,
  year      =  2010,
  issn      = "0042-3114",
  doi       = "10.1080/00423110903514236"
}

@PHDTHESIS{Casanova2000-av,
  title     = "On minimum time vehicle manoeuvring: the theoretical optimal lap",
  author    = "Casanova, D",
  abstract  = "This work is a research on the minimum time vehicle manoeuvring
               problem, with a particular application to finding the minimum
               lap time for a Formula One racing car. The proposed method
               allows to solve the general problem of evaluating the vehicle
               lateral and longitudinal controls which yield the minimum time
               required to traverse a lap of a circuit. The minimum time
               vehicle manoeuvring problem is formulated as one of Optimal
               Control and is solved using mathematical programming methods.
               Novel techniques are employed to solve the resulting non-linear
               programming problem which allow to achieve effective
               optimisation with satisfactory accuracy, robustness and
               computational efficiency. Particularly, the proposed solution
               strategy is generally applicable to any arbitrarily complex
               vehicle mathematical model. Car and circuit models are set up,
               and the optimisation program is applied to investigate the
               sensitivity of the vehicle performance with respect to vehicle
               design parameters, such as the yaw moment of inertia, the total
               mass and the weight distribution. Furthermore, the minimum time
               manoeuvring problem is solved for very different vehicle
               configurations. The optimisation program accurately quantifies
               the vehicle performance in terms of manoeuvre time, and the
               nature of the optimal solution is shown to be always in
               excellent agreement with the dynamic properties of the vehicle
               model. A part of the work is devoted to the development of a
               strategy to obtain an initial estimate of the racing line and of
               the vehicle lateral and longitudinal controls to be used at the
               start of the optimisation. Two algorithms to compute the racing
               line using on board measured data from the real car are
               presented. A new mathematical model for the vehicle steering
               control is derived. The model uses multiple preview information
               of the intended path. Its structure derives from linear optimal
               preview control theory, but it is adapted to deal with
               non-linear vehicle operations arising from the inevitable tyre
               force saturation in vigorous manoeuvring. The excellent path
               following capability of the model is demonstrated by solving
               various path following tasks involving moderate manoeuvring and
               racing speeds.",
  publisher = "Cranfield University",
  month     =  nov,
  year      =  2000,
  keywords  = "Thesis or dissertation"
}

@ARTICLE{Veneri2020-vr,
  title     = "A free-trajectory quasi-steady-state optimal-control method for
               minimum lap-time of race vehicles",
  author    = "Veneri, M and Massaro, M",
  abstract  = "ABSTRACTMinimum lap time problems are usually solved employing
               quasi-steady-state models on a predetermined (fixed) trajectory
               or employing dynamic models on a free (i.e. not predetermined)
               trajectory. This work describes a third approach, where the
               minimum-lap-time problem is solved using quasi-steady-state
               models and free trajectory. The method builds upon g-g maps that
               can either be derived numerically or experimentally. Such
               g-g-speed surfaces can either represent the performance of a car
               or a motorcycle. Both a double-track car model and a motorcycle
               model are employed as examples of applications. The effect of
               the free-trajectory vs. fixed-trajectory assumption is also
               discussed.",
  journal   = "Veh. Syst. Dyn.",
  publisher = "Taylor \& Francis",
  volume    =  58,
  number    =  6,
  pages     = "933--954",
  month     =  jun,
  year      =  2020,
  issn      = "0042-3114",
  doi       = "10.1080/00423114.2019.1608364"
}

@ARTICLE{Perantoni2014-tb,
  title     = "Optimal control for a Formula One car with variable parameters",
  author    = "Perantoni, Giacomo and Limebeer, David J N",
  abstract  = "The minimum-lap-time optimal control problem for a Formula One
               race car is solved using direct transcription and nonlinear
               programming. Features of this work include significantly reduced
               full-lap solution times and the simultaneous optimisation of the
               driven line, the driver controls and multiple car set-up
               parameters. It is shown that significant reductions in the
               driven lap time can be obtained from track-specific set-up
               parameter optimisation. Reduced computing times are achieved
               using a combination of a track description based on curvilinear
               coordinates, analytical derivatives and model
               non-dimensionalisation. The curvature of the track centre line
               is found by solving an auxiliary optimal control problem that
               negates the difficulties associated with integration drift and
               trajectory closure.",
  journal   = "Veh. Syst. Dyn.",
  publisher = "Taylor \& Francis",
  volume    =  52,
  number    =  5,
  pages     = "653--678",
  month     =  may,
  year      =  2014,
  issn      = "0042-3114",
  doi       = "10.1080/00423114.2014.889315"
}

@ARTICLE{Williams2017-za,
  title         = "Autonomous Racing with {AutoRally} Vehicles and Differential
                   Games",
  author        = "Williams, Grady and Goldfain, Brian and Drews, Paul and
                   Rehg, James M and Theodorou, Evangelos A",
  abstract      = "Safe autonomous vehicles must be able to predict and react
                   to the drivers around them. Previous control methods rely
                   heavily on pre-computation and are unable to react to
                   dynamic events as they unfold in real-time. In this paper,
                   we extend Model Predictive Path Integral Control (MPPI)
                   using differential game theory and introduce Best-Response
                   MPPI (BR-MPPI) for real-time multi-vehicle interactions.
                   Experimental results are presented using two AutoRally
                   platforms in a racing format with BR-MPPI competing against
                   a skilled human driver at the Georgia Tech Autonomous Racing
                   Facility.",
  month         =  jul,
  year          =  2017,
  archivePrefix = "arXiv",
  eprint        = "1707.04540",
  primaryClass  = "cs.RO",
  arxivid       = "1707.04540"
}

@ARTICLE{Dacre2021-fd,
  title    = "A cerebellar-thalamocortical pathway drives behavioral
              context-dependent movement initiation",
  author   = "Dacre, Joshua and Colligan, Matt and Clarke, Thomas and Ammer,
              Julian J and Schiemann, Julia and Chamosa-Pino, Victor and
              Claudi, Federico and Harston, J Alex and Eleftheriou,
              Constantinos and Pakan, Janelle M P and Huang, Cheng-Chiu and
              Hantman, Adam W and Rochefort, Nathalie L and Duguid, Ian",
  abstract = "Executing learned motor behaviors often requires the
              transformation of sensory cues into patterns of motor commands
              that generate appropriately timed actions. The cerebellum and
              thalamus are two key areas involved in shaping cortical output
              and movement, but the contribution of a
              cerebellar-thalamocortical pathway to voluntary movement
              initiation remains poorly understood. Here, we investigated how
              an auditory ``go cue'' transforms thalamocortical activity
              patterns and how these changes relate to movement initiation.
              Population responses in dentate/interpositus-recipient regions of
              motor thalamus reflect a time-locked increase in activity
              immediately prior to movement initiation that is temporally
              uncoupled from the go cue, indicative of a fixed-latency
              feedforward motor timing signal. Blocking cerebellar or motor
              thalamic output suppresses movement initiation, while stimulation
              triggers movements in a behavioral context-dependent manner. Our
              findings show how cerebellar output, via the thalamus, shapes
              cortical activity patterns necessary for learned
              context-dependent movement initiation.",
  journal  = "Neuron",
  volume   =  109,
  number   =  14,
  pages    = "2326--2338.e8",
  month    =  jul,
  year     =  2021,
  keywords = "2-photon imaging; behavioural context; cerebellar nuclei;
              cerebellar thalamocortical pathway; in vivo patch-clamp; motor
              cortex; motor thalamus; motor timing; movement initiation;
              photoactivation",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "34146469",
  doi      = "10.1016/j.neuron.2021.05.016",
  pmc      = "PMC8315304"
}

@ARTICLE{Turner2021-eb,
  title         = "Charting and navigating the space of solutions for recurrent
                   neural networks",
  author        = "Turner, Elia and Dabholkar, Kabir and Barak, Omri",
  abstract      = "Recurrent Neural Networks (RNNs) were recently successfully
                   used to model the way neural activity drives task-related
                   behavior in animals, operating under the implicit assumption
                   that the obtained solutions are universal. Observations in
                   both neuroscience and machine learning challenge this
                   assumption. Animals can approach a given task with a variety
                   of strategies, and training machine learning algorithms
                   introduces the phenomenon of underspecification. These
                   observations imply that every task is associated with a
                   space of solutions. To date, the structure of this space is
                   not understood, limiting the approach of comparing RNNs with
                   neural data. Here, we characterize the space of solutions
                   associated with various tasks. We first study a simple
                   two-neuron network on a task that leads to multiple
                   solutions. We trace the nature of the final solution back to
                   the network's initial connectivity and identify discrete
                   dynamical regimes that underlie this diversity. We then
                   examine three neuroscience-inspired tasks: Delayed and
                   interval discrimination, and Time reproduction. For each
                   task, we find a rich set of solutions. Variability can be
                   found directly in the neural activity of the networks, and
                   additionally by testing the trained networks' ability to
                   extrapolate, as a perturbation to a system often reveals
                   hidden structure. Furthermore, we relate extrapolation
                   patterns to specific dynamical objects and effective
                   algorithms found by the networks. We introduce a tool to
                   derive the reduced dynamics of networks by generating a
                   compact directed graph describing the essence of the
                   dynamics with regards to behavioral inputs and outputs.
                   Using this representation, we can partition the solutions to
                   each task into a handful of types and partially predict them
                   from neural features. Our results shed light on the concept
                   of the space of solutions and its uses in Machine learning
                   and in Neuroscience.",
  month         =  nov,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2111.09356",
  primaryClass  = "q-bio.NC",
  arxivid       = "2111.09356"
}

@ARTICLE{Christ2021-ai,
  title     = "Time-optimal trajectory planning for a race car considering
               variable tyre-road friction coefficients",
  author    = "Christ, Fabian and Wischnewski, Alexander and Heilmeier,
               Alexander and Lohmann, Boris",
  abstract  = "This paper shows the planning of time-optimal trajectories,
               which allows an autonomous race car to drive at the handling
               limits, taking into account locally changing road friction
               values. For this purpose, the minimum lap time problem is
               described as an optimal control problem, converted to a
               nonlinear programme using direct orthogonal Gauss-Legendre
               collocation and then solved by the interior-point method IPOPT.
               Reduced computing times are achieved using a curvilinear
               abscissa approach for track description, algorithmic
               differentiation using the software framework CasADi, and a
               smoothing of the track input data by approximate spline
               regression. The vehicle's behaviour is approximated as a single
               track and double track model with quasi-steady state tyre load
               simplification and nonlinear tyre model. The results are used to
               evaluate which vehicle physics are important for the calculation
               of the time-optimal trajectory. The novelty of this work is the
               consideration of wheel-specific tyre-road friction coefficients
               along the racetrack using a track friction map. It is shown that
               variable friction coefficients have a significant impact on the
               trajectory, and therefore significantly improve lap times on
               inhomogenous racetracks. The proposed trajectory planning has
               proven its practical suitability in first tests on an autonomous
               race car and will be used in the coming racing season in the
               Roborace competition.",
  journal   = "Veh. Syst. Dyn.",
  publisher = "Taylor \& Francis",
  volume    =  59,
  number    =  4,
  pages     = "588--612",
  month     =  apr,
  year      =  2021,
  issn      = "0042-3114",
  doi       = "10.1080/00423114.2019.1704804"
}

@INPROCEEDINGS{Williams2016-gn,
  title     = "Aggressive driving with model predictive path integral control",
  booktitle = "2016 {IEEE} International Conference on Robotics and Automation
               ({ICRA})",
  author    = "Williams, Grady and Drews, Paul and Goldfain, Brian and Rehg,
               James M and Theodorou, Evangelos A",
  abstract  = "In this paper we present a model predictive control algorithm
               designed for optimizing non-linear systems subject to complex
               cost criteria. The algorithm is based on a stochastic optimal
               control framework using a fundamental relationship between the
               information theoretic notions of free energy and relative
               entropy. The optimal controls in this setting take the form of a
               path integral, which we approximate using an efficient
               importance sampling scheme. We experimentally verify the
               algorithm by implementing it on a Graphics Processing Unit (GPU)
               and apply it to the problem of controlling a fifth-scale
               Auto-Rally vehicle in an aggressive driving task.",
  pages     = "1433--1440",
  month     =  may,
  year      =  2016,
  keywords  = "Trajectory;Optimal control;Entropy;Vehicles;Prediction
               algorithms;Q measurement;Stochastic processes",
  doi       = "10.1109/ICRA.2016.7487277"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Yilmaz2013-ld,
  title    = "Rapid innate defensive responses of mice to looming visual
              stimuli",
  author   = "Yilmaz, Melis and Meister, Markus",
  abstract = "Much of brain science is concerned with understanding the neural
              circuits that underlie specific behaviors. While the mouse has
              become a favorite experimental subject, the behaviors of this
              species are still poorly explored. For example, the mouse retina,
              like that of other mammals, contains ∼20 different circuits that
              compute distinct features of the visual scene [1, 2]. By
              comparison, only a handful of innate visual behaviors are known
              in this species--the pupil reflex [3], phototaxis [4], the
              optomotor response [5], and the cliff response [6]--two of which
              are simple reflexes that require little visual processing. We
              explored the behavior of mice under a visual display that
              simulates an approaching object, which causes defensive reactions
              in some other species [7, 8]. We show that mice respond to this
              stimulus either by initiating escape within a second or by
              freezing for an extended period. The probability of these
              defensive behaviors is strongly dependent on the parameters of
              the visual stimulus. Directed experiments identify candidate
              retinal circuits underlying the behavior and lead the way into
              detailed study of these neural pathways. This response is a new
              addition to the repertoire of innate defensive behaviors in the
              mouse that allows the detection and avoidance of aerial
              predators.",
  journal  = "Curr. Biol.",
  volume   =  23,
  number   =  20,
  pages    = "2011--2015",
  month    =  oct,
  year     =  2013,
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "24120636",
  doi      = "10.1016/j.cub.2013.08.015",
  pmc      = "PMC3809337"
}

@ARTICLE{Mongeau2003-hv,
  title    = "Neural correlates of competing fear behaviors evoked by an
              innately aversive stimulus",
  author   = "Mongeau, Raymond and Miller, Gabriel A and Chiang, Elizabeth and
              Anderson, David J",
  abstract = "Environment and experience influence defensive behaviors, but the
              neural circuits mediating such effects are not well understood.
              We describe a new experimental model in which either flight or
              freezing reactions can be elicited from mice by innately aversive
              ultrasound. Flight and freezing are negatively correlated,
              suggesting a competition between fear motor systems. An
              unfamiliar environment or a previous aversive event, moreover,
              can alter the balance between these behaviors. To identify
              potential circuits controlling this competition, global activity
              patterns in the whole brain were surveyed in an unbiased manner
              by c-fos in situ hybridization, using novel experimental and
              analytical methods. Mice predominantly displaying freezing
              behavior had preferential neural activity in the lateral septum
              ventral and several medial and periventricular hypothalamic
              nuclei, whereas mice predominantly displaying flight had more
              activity in cortical, amygdalar, and striatal motor areas, the
              dorsolateral posterior zone of the hypothalamus, and the vertical
              limb of the diagonal band. These complementary patterns of c-fos
              induction, taken together with known connections between these
              structures, suggest ways in which the brain may mediate the
              balance between these opponent defensive behaviors.",
  journal  = "J. Neurosci.",
  volume   =  23,
  number   =  9,
  pages    = "3855--3868",
  month    =  may,
  year     =  2003,
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "12736356",
  doi      = "10.1523/JNEUROSCI.23-09-03855.2003",
  pmc      = "PMC6742203"
}

@INPROCEEDINGS{Hwan_Jeon2013-vs,
  title     = "Optimal motion planning with the half-car dynamical model for
               autonomous high-speed driving",
  booktitle = "2013 American Control Conference",
  author    = "hwan Jeon, Jeong and Cowlagi, Raghvendra V and Peters, Steven C
               and Karaman, Sertac and Frazzoli, Emilio and Tsiotras,
               Panagiotis and Iagnemma, Karl",
  abstract  = "We discuss an implementation of the RRT* optimal motion planning
               algorithm for the half-car dynamical model to enable autonomous
               high-speed driving. To develop fast solutions of the associated
               local steering problem, we observe that the motion of a special
               point (namely, the front center of oscillation) can be modeled
               as a double integrator augmented with fictitious inputs. We
               first map the constraints on tire friction forces to constraints
               on these augmented inputs, which provides instantaneous,
               state-dependent bounds on the curvature of geometric paths
               feasibly traversable by the front center of oscillation. Next,
               we map the vehicle's actual inputs to the augmented inputs. The
               local steering problem for the half-car dynamical model can then
               be transformed to a simpler steering problem for the front
               center of oscillation, which we solve efficiently by first
               constructing a curvature-bounded geometric path and then
               imposing a suitable speed profile on this geometric path.
               Finally, we demonstrate the efficacy of the proposed motion
               planner via numerical simulation results.",
  publisher = "ieeexplore.ieee.org",
  pages     = "188--193",
  month     =  jun,
  year      =  2013,
  keywords  = "Tires;Vehicles;Trajectory;Acceleration;Planning;Heuristic
               algorithms;Friction",
  issn      = "2378-5861",
  doi       = "10.1109/ACC.2013.6579835"
}

@INPROCEEDINGS{Pepy2006-ac,
  title     = "Path Planning using a Dynamic Vehicle Model",
  booktitle = "2006 2nd International Conference on Information Communication
               Technologies",
  author    = "Pepy, R and Lambert, A and Mounier, H",
  abstract  = "This paper addresses the problem of path planning using a
               dynamic vehicle model. Previous works which include a basic
               kinematic model generate paths that are only realistic at very
               low speed. By considering higher vehicle speed during
               navigation, the vehicle can significantly deviate from the
               planned trajectory. Consequently, the planned path becomes
               unusable for the mission achievement. So, to bridge a gap
               between planning and navigation, we propose a realistic path
               planner based on a dynamic vehicle model",
  publisher = "ieeexplore.ieee.org",
  volume    =  1,
  pages     = "781--786",
  month     =  apr,
  year      =  2006,
  keywords  = "Path planning;Vehicle dynamics;Kinematics;Navigation;Remotely
               operated vehicles;Ellipsoids;Mobile robots;Kalman
               filters;Bridges;Process planning",
  doi       = "10.1109/ICTTA.2006.1684472"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Gustafsson2008-bp,
  title     = "Computing the ideal racing line using optimal control",
  author    = "Gustafsson, Thomas",
  abstract  = "In racing, it is useful to analyze vehicle performance and
               driving strategies to achieve the best result possible in
               competitions. This is often done by simulations and test
               driving. In this thesis optimal control is used to examine how a
               racing car should be driven to minimize the lap time. This is
               achieved by calculating the optimal racing line at various
               tracks. The tracks can have arbitrary layout and consist of
               corners with non-constant radius. The road can have variable
               width. A four wheel vehicle model with lateral and longitudinal
               weight transfer is …",
  publisher = "Institutionen f{\"o}r systemteknik",
  year      =  2008
}

@ARTICLE{Massaro2021-zs,
  title     = "Minimum-lap-time optimisation and simulation",
  author    = "Massaro, M and Limebeer, D J N",
  abstract  = "The paper begins with a survey of advances in state-of-the-art
               minimum-time simulation for road vehicles. The techniques
               covered include both quasi-steady-state and transient vehicle
               models, which are combined with trajectories that are either
               pre-assigned or free to be optimised. The fundamentals of
               nonlinear optimal control are summarised. These fundamentals are
               the basis of most of the vehicular optimal control methodologies
               and solution procedures reported in the literature. The key
               features of three-dimensional road modelling, vehicle
               positioning and vehicle modelling are also summarised with a
               focus on recent developments. Both cars and motorcycles are
               considered.",
  journal   = "Veh. Syst. Dyn.",
  publisher = "Taylor \& Francis",
  volume    =  59,
  number    =  7,
  pages     = "1069--1113",
  month     =  jul,
  year      =  2021,
  issn      = "0042-3114",
  doi       = "10.1080/00423114.2021.1910718"
}

@ARTICLE{Heilmeier2020-ii,
  title     = "Minimum curvature trajectory planning and control for an
               autonomous race car",
  author    = "Heilmeier, Alexander and Wischnewski, Alexander and
               Hermansdorfer, Leonhard and Betz, Johannes and Lienkamp, Markus
               and Lohmann, Boris",
  abstract  = "ABSTRACT This paper shows a software stack capable of planning a
               minimum curvature trajectory for an autonomous race car on the
               basis of an occupancy grid map and introduces a controller
               design that allows to follow the trajectory at the handling
               limits. The minimum curvature path is generated using a
               quadratic optimisation problem (QP) formulation. The key
               contributions of this paper are the extension of the QP for an
               improved accuracy of the curvature approximation, the
               introduction of curvature constraints and the iterative
               invocation of the QP to significantly reduce linearisation
               errors in corners. On the basis of the resulting raceline, a
               velocity profile is calculated using a forward-backward-solver
               that considers the velocity dependent longitudinal and lateral
               acceleration limits of the car. The advantages and disadvantages
               of the proposed trajectory planning approach are discussed
               critically with respect to practical experience from various
               racetracks. The software stack showed to be robust in a real
               world environment as it ran successfully on the Roborace DevBot
               during the Berlin Formula E event in May 2018. The lap time
               achieved was within a tenth of a second of a human driver and
               the car reached about 150 k m / h and 80\% of its acceleration
               limits.",
  journal   = "Veh. Syst. Dyn.",
  publisher = "Taylor \& Francis",
  volume    =  58,
  number    =  10,
  pages     = "1497--1527",
  month     =  oct,
  year      =  2020,
  issn      = "0042-3114",
  doi       = "10.1080/00423114.2019.1631455"
}

@ARTICLE{Kapania2019-wn,
  title         = "A Sequential {Two-Step} Algorithm for Fast Generation of
                   Vehicle Racing Trajectories",
  author        = "Kapania, Nitin R and Subosits, John and Christian Gerdes, J",
  abstract      = "The problem of maneuvering a vehicle through a race course
                   in minimum time requires computation of both longitudinal
                   (brake and throttle) and lateral (steering wheel) control
                   inputs. Unfortunately, solving the resulting nonlinear
                   optimal control problem is typically computationally
                   expensive and infeasible for real-time trajectory planning.
                   This paper presents an iterative algorithm that divides the
                   path generation task into two sequential subproblems that
                   are significantly easier to solve. Given an initial path
                   through the race track, the algorithm runs a
                   forward-backward integration scheme to determine the
                   minimum-time longitudinal speed profile, subject to tire
                   friction constraints. With this fixed speed profile, the
                   algorithm updates the vehicle's path by solving a convex
                   optimization problem that minimizes the resulting path
                   curvature while staying within track boundaries and obeying
                   affine, time-varying vehicle dynamics constraints. This
                   two-step process is repeated iteratively until the predicted
                   lap time no longer improves. While providing no guarantees
                   of convergence or a globally optimal solution, the approach
                   performs very well when validated on the Thunderhill Raceway
                   course in Willows, CA. The predicted lap time converges
                   after four to five iterations, with each iteration over the
                   full 4.5 km race course requiring only thirty seconds of
                   computation time on a laptop computer. The resulting
                   trajectory is experimentally driven at the race circuit with
                   an autonomous Audi TTS test vehicle, and the resulting lap
                   time and racing line is comparable to both a nonlinear
                   gradient descent solution and a trajectory recorded from a
                   professional racecar driver. The experimental results
                   indicate that the proposed method is a viable option for
                   online trajectory planning in the near future.",
  month         =  feb,
  year          =  2019,
  archivePrefix = "arXiv",
  eprint        = "1902.00606",
  primaryClass  = "cs.RO",
  arxivid       = "1902.00606"
}

@ARTICLE{Goncalves2021-ca,
  title         = "Parallel locomotor control strategies in mice and flies",
  author        = "Gon{\c c}alves, Ana I and Zavatone-Veth, Jacob A and Carey,
                   Megan R and Clark, Damon A",
  abstract      = "Our understanding of the neural basis of locomotor behavior
                   can be informed by careful quantification of animal
                   movement. Classical descriptions of legged locomotion have
                   defined discrete locomotor gaits, characterized by distinct
                   patterns of limb movement. Recent technical advances have
                   enabled increasingly detailed characterization of limb
                   kinematics across many species, imposing tighter constraints
                   on neural control. Here, we highlight striking similarities
                   between coordination patterns observed in two genetic model
                   organisms: the laboratory mouse and Drosophila. Both species
                   exhibit continuously-variable coordination patterns with
                   similar low-dimensional structure, suggesting shared
                   principles for limb coordination and descending neural
                   control.",
  month         =  dec,
  year          =  2021,
  keywords      = "Locomotion",
  archivePrefix = "arXiv",
  eprint        = "2112.12227",
  primaryClass  = "q-bio.NC",
  arxivid       = "2112.12227"
}

@ARTICLE{Duncker2021-ap,
  title    = "Dynamics on the manifold: Identifying computational dynamical
              activity from neural population recordings",
  author   = "Duncker, Lea and Sahani, Maneesh",
  abstract = "The question of how the collective activity of neural populations
              gives rise to complex behaviour is fundamental to neuroscience.
              At the core of this question lie considerations about how neural
              circuits can perform computations that enable sensory perception,
              decision making, and motor control. It is thought that such
              computations are implemented through the dynamical evolution of
              distributed activity in recurrent circuits. Thus, identifying
              dynamical structure in neural population activity is a key
              challenge towards a better understanding of neural computation.
              At the same time, interpreting this structure in light of the
              computation of interest is essential for linking the time-varying
              activity patterns of the neural population to ongoing
              computational processes. Here, we review methods that aim to
              quantify structure in neural population recordings through a
              dynamical system defined in a low-dimensional latent variable
              space. We discuss advantages and limitations of different
              modelling approaches and address future challenges for the field.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  70,
  pages    = "163--170",
  month    =  nov,
  year     =  2021,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "34837752",
  doi      = "10.1016/j.conb.2021.10.014"
}

@INPROCEEDINGS{Pepy2006-hl,
  title     = "Path Planning using a Dynamic Vehicle Model",
  booktitle = "2006 2nd International Conference on Information Communication
               Technologies",
  author    = "Pepy, R and Lambert, A and Mounier, H",
  abstract  = "This paper addresses the problem of path planning using a
               dynamic vehicle model. Previous works which include a basic
               kinematic model generate paths that are only realistic at very
               low speed. By considering higher vehicle speed during
               navigation, the vehicle can significantly deviate from the
               planned trajectory. Consequently, the planned path becomes
               unusable for the mission achievement. So, to bridge a gap
               between planning and navigation, we propose a realistic path
               planner based on a dynamic vehicle model",
  volume    =  1,
  pages     = "781--786",
  month     =  apr,
  year      =  2006,
  keywords  = "Path planning;Vehicle dynamics;Kinematics;Navigation;Remotely
               operated vehicles;Ellipsoids;Mobile robots;Kalman
               filters;Bridges;Process planning",
  doi       = "10.1109/ICTTA.2006.1684472"
}

@ARTICLE{Aljadeff2016-ce,
  title    = "Low-dimensional dynamics of structured random networks",
  author   = "Aljadeff, Johnatan and Renfrew, David and Vegu{\'e}, Marina and
              Sharpee, Tatyana O",
  abstract = "Using a generalized random recurrent neural network model, and by
              extending our recently developed mean-field approach [J.
              Aljadeff, M. Stern, and T. Sharpee, Phys. Rev. Lett. 114, 088101
              (2015)], we study the relationship between the network
              connectivity structure and its low-dimensional dynamics. Each
              connection in the network is a random number with mean 0 and
              variance that depends on pre- and postsynaptic neurons through a
              sufficiently smooth function g of their identities. We find that
              these networks undergo a phase transition from a silent to a
              chaotic state at a critical point we derive as a function of g.
              Above the critical point, although unit activation levels are
              chaotic, their autocorrelation functions are restricted to a
              low-dimensional subspace. This provides a direct link between the
              network's structure and some of its functional characteristics.
              We discuss example applications of the general results to
              neuroscience where we derive the support of the spectrum of
              connectivity matrices with heterogeneous and possibly correlated
              degree distributions, and to ecology where we study the stability
              of the cascade model for food web structure.",
  journal  = "Phys Rev E",
  volume   =  93,
  number   =  2,
  pages    = "022302",
  month    =  feb,
  year     =  2016,
  keywords = "To Read;BCI",
  language = "en",
  issn     = "2470-0053, 2470-0045",
  pmid     = "26986347",
  doi      = "10.1103/PhysRevE.93.022302",
  pmc      = "PMC4820296"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Landau2021-rx,
  title     = "Macroscopic fluctuations emerge in balanced networks with
               incomplete recurrent alignment",
  author    = "Landau, Itamar D and Sompolinsky, Haim",
  abstract  = "Networks of strongly coupled neurons with random connectivity
               exhibit chaotic, asynchronous fluctuations. In a previous study,
               we showed that when endowed with an additional component of
               low-rank connectivity consisting of the outer product of
               orthogonal vectors, these networks generate macroscopic coherent
               fluctuations. Although a striking phenomenon, that result
               depended on a fine-tuned choice of low-rank structure. Here we
               extend that result by generalizing the theory of
               excitation-inhibition balance to networks with …",
  journal   = "Phys. Rev. Res.",
  publisher = "American Physical Society",
  volume    =  3,
  number    =  2,
  pages     = "023171",
  month     =  jun,
  year      =  2021,
  doi       = "10.1103/PhysRevResearch.3.023171"
}

@ARTICLE{Zhang2021-xs,
  title    = "Inhibitory control of synaptic signals preceding locomotion in
              mouse frontal cortex",
  author   = "Zhang, Chun-Lei and Koukouli, Fani and Allegra, Manuela and
              Ortiz, Cantin and Kao, Hsin-Lun and Maskos, Uwe and Changeux,
              Jean-Pierre and Schmidt-Hieber, Christoph",
  abstract = "The frontal cortex is essential for organizing voluntary
              movement. The secondary motor cortex (MOs) is a frontal subregion
              thought to integrate internal and external inputs before motor
              action. However, how excitatory and inhibitory synaptic inputs to
              MOs neurons are integrated preceding movement remains unclear.
              Here, we address this question by performing in vivo whole-cell
              recordings from MOs neurons of head-fixed mice moving on a
              treadmill. We find that principal neurons produce slowly
              increasing membrane potential and spike ramps preceding
              spontaneous running. After goal-directed training, ramps show
              larger amplitudes and accelerated kinetics. Chemogenetic
              suppression of interneurons combined with modeling suggests that
              the interplay between parvalbumin-positive (PV+) and
              somatostatin-positive (SOM+) interneurons, along with principal
              neuron recurrent connectivity, shape ramping signals. Plasticity
              of excitatory synapses on SOM+ interneurons can explain the ramp
              acceleration after training. Altogether, our data reveal that
              local interneurons differentially control task-dependent ramping
              signals when MOs neurons integrate inputs preceding movement.",
  journal  = "Cell Rep.",
  volume   =  37,
  number   =  8,
  pages    = "110035",
  month    =  nov,
  year     =  2021,
  keywords = "frontal cortex; go/no-go task; in vivo patch clamp; motor
              preparation; parvalbumin-expressing interneuron;
              somatostatin-expressing interneuron; virtual reality",
  language = "en",
  issn     = "2211-1247",
  pmid     = "34818555",
  doi      = "10.1016/j.celrep.2021.110035"
}

@ARTICLE{Shiller1998-tz,
  title     = "Emergency {Lane-Change} Maneuvers of Autonomous Vehicles",
  author    = "Shiller, Zvi and Sundar, Satish",
  journal   = "J. Dyn. Syst. Meas. Control",
  publisher = "American Society of Mechanical Engineers Digital Collection",
  volume    =  120,
  number    =  1,
  pages     = "37--44",
  month     =  mar,
  year      =  1998,
  keywords  = "Collisions (Physics)",
  issn      = "0022-0434",
  doi       = "10.1115/1.2801319"
}

@INPROCEEDINGS{Pagot2020-td,
  title     = "Real-time optimal control of an autonomous {RC} car with
               minimum-time maneuvers and a novel kineto-dynamical model",
  booktitle = "2020 {IEEE/RSJ} International Conference on Intelligent Robots
               and Systems ({IROS})",
  author    = "Pagot, Edoardo and Piccinini, Mattia and Biral, Francesco",
  abstract  = "In this paper, we present a real-time non-linear
               model-predictive control (NMPC) framework to perform
               minimum-time motion planning for autonomous racing cars. We
               introduce an innovative kineto-dynamical vehicle model, able to
               accurately predict non-linear longitudinal and lateral vehicle
               dynamics. The main parameters of this vehicle model can be tuned
               with only experimental or simulated maneuvers, aimed to identify
               the handling diagram and the maximum performance G-G envelope.
               The kineto-dynamical model is adopted to generate on-line
               minimum time trajectories with an indirect optimal control
               method. The motion planning framework is applied to control an
               autonomous 1:8 RC vehicle near the limits of handling along a
               test circuit. Finally, the effectiveness of the proposed
               algorithms is illustrated by comparing the experimental results
               with the solution of an off-line minimum-time optimal control
               problem.",
  pages     = "2390--2396",
  month     =  oct,
  year      =  2020,
  keywords  = "Optimal control;Real-time
               systems;Planning;Trajectory;Automobiles;Integrated circuit
               modeling;Vehicle dynamics",
  issn      = "2153-0866",
  doi       = "10.1109/IROS45743.2020.9340640"
}

@ARTICLE{Gerdts2008-sm,
  title    = "Generating locally optimal trajectories for an automatically
              driven car",
  author   = "Gerdts, Matthias and Karrenberg, Simon and M{\"u}ller-Be{\ss}ler,
              Bernhard and Stock, Gregor",
  abstract = "The test-drive of an automobile along a given test-course can be
              modeled by formulating a suitable optimal control problem.
              However, if the length of the course is very long or if it has a
              very complicated structure, the numerical solution of the optimal
              control problem becomes very difficult. Therefore a moving
              horizon technique is employed, which splits the optimal control
              problem into a sequence of local optimal control problems that
              are combined by suitable continuity conditions. This approach
              yields a reference trajectory. A controller and differential GPS
              are integrated in a real-world car and allows a reference
              trajectory to be followed in real-time. A benefit of this
              approach is the very high accuracy obtained in reproducing the
              reference trajectory. Hence, it can be used for testing different
              setups of cars under the same conditions while excluding the
              comparatively large influence of a real-world driver. In this
              article, we will focus on a method for generating the reference
              trajectory and report our experiences with this algorithm. The
              method allows an locally optimal solution to be computed for
              various handling courses in a robust way.",
  journal  = "Optim. Eng.",
  volume   =  10,
  number   =  4,
  pages    = "439",
  month    =  apr,
  year     =  2008,
  issn     = "1389-4420, 1573-2924",
  doi      = "10.1007/s11081-008-9047-1"
}

@ARTICLE{Williams2017-hl,
  title         = "Information Theoretic Model Predictive Control: Theory and
                   Applications to Autonomous Driving",
  author        = "Williams, Grady and Drews, Paul and Goldfain, Brian and
                   Rehg, James M and Theodorou, Evangelos A",
  abstract      = "We present an information theoretic approach to stochastic
                   optimal control problems that can be used to derive general
                   sampling based optimization schemes. This new mathematical
                   method is used to develop a sampling based model predictive
                   control algorithm. We apply this information theoretic model
                   predictive control (IT-MPC) scheme to the task of aggressive
                   autonomous driving around a dirt test track, and compare its
                   performance to a model predictive control version of the
                   cross-entropy method.",
  month         =  jul,
  year          =  2017,
  archivePrefix = "arXiv",
  eprint        = "1707.02342",
  primaryClass  = "cs.RO",
  arxivid       = "1707.02342"
}

@ARTICLE{Sheppard_undated-hr,
  title  = "Gait-level analysis of mouse open field behavior using deep
            learning-based pose estimation",
  author = "Sheppard, Keith and Gardin, Justin and Sabnis, Gautam S and Peer,
            Asaf and Darrell, Megan and Deats, Sean and Geuther, Brian and
            Lutz, Cathleen M and Kumar, Vivek",
  doi    = "10.1101/2020.12.29.424780"
}

@ARTICLE{Khona2021-vn,
  title         = "Attractor and integrator networks in the brain",
  author        = "Khona, Mikail and Fiete, Ila R",
  abstract      = "Attractor neural networks are some of the most-studied
                   circuit models of brain function. We discuss the utility of
                   low-dimensional attractors for computation in the brain,
                   provide a mechanistically unifying view of models for the
                   construction of these attractors, and discuss why it is now
                   possible to rigorously claim that the brain constructs and
                   uses such systems for computation. We describe notable
                   examples of brain systems in which continuous attractor
                   dynamics have been concretely identified. Finally, we
                   highlight recent advances in understanding how the
                   fundamental tradeoffs between robustness and capacity and
                   between structure and flexibility can be overcome by reusing
                   the same attractor for multiple functions and by multiple
                   modular attractors working together to produce vastly more
                   representations that are structurally constrained and robust
                   but also flexible.",
  month         =  dec,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2112.03978",
  primaryClass  = "q-bio.NC",
  arxivid       = "2112.03978"
}

@ARTICLE{Bolanos2021-hn,
  title    = "A three-dimensional virtual mouse generates synthetic training
              data for behavioral analysis",
  author   = "Bola{\~n}os, Luis A and Xiao, Dongsheng and Ford, Nancy L and
              LeDue, Jeff M and Gupta, Pankaj K and Doebeli, Carlos and Hu, Hao
              and Rhodin, Helge and Murphy, Timothy H",
  abstract = "We developed a three-dimensional (3D) synthetic animated mouse
              based on computed tomography scans that is actuated using
              animation and semirandom, joint-constrained movements to generate
              synthetic behavioral data with ground-truth label locations.
              Image-domain translation produced realistic synthetic videos used
              to train two-dimensional (2D) and 3D pose estimation models with
              accuracy similar to typical manual training datasets. The outputs
              from the 3D model-based pose estimation yielded better definition
              of behavioral clusters than 2D videos and may facilitate
              automated ethological classification.",
  journal  = "Nat. Methods",
  volume   =  18,
  number   =  4,
  pages    = "378--381",
  month    =  apr,
  year     =  2021,
  language = "en",
  issn     = "1548-7091, 1548-7105",
  pmid     = "33820989",
  doi      = "10.1038/s41592-021-01103-9",
  pmc      = "PMC8034498"
}

@ARTICLE{Tsuda_undated-sf,
  title  = "Neuromodulators generate multiple context-relevant behaviors in a
            recurrent neural network by shifting activity hypertubes",
  author = "Tsuda, Ben and Pate, Stefan C and Tye, Kay M and Siegelmann, Hava T
            and Sejnowski, Terrence J",
  doi    = "10.1101/2021.05.31.446462"
}

@ARTICLE{Muzzu2018-bj,
  title    = "Encoding of locomotion kinematics in the mouse cerebellum",
  author   = "Muzzu, Tomaso and Mitolo, Susanna and Gava, Giuseppe P and
              Schultz, Simon R",
  abstract = "The cerebellum is involved in coordinating motor behaviour, but
              how the cerebellar network regulates locomotion is still not well
              understood. We characterised the activity of putative cerebellar
              Purkinje cells, Golgi cells and mossy fibres in awake mice
              engaged in an active locomotion task, using high-density silicon
              electrode arrays. Analysis of the activity of over 300 neurons in
              response to locomotion revealed that the majority of cells (53\%)
              were significantly modulated by phase of the stepping cycle.
              However, in contrast to studies involving passive locomotion on a
              treadmill, we found that a high proportion of cells (45\%) were
              tuned to the speed of locomotion, and 19\% were tuned to yaw
              movements. The activity of neurons in the cerebellar vermis
              provided more information about future speed of locomotion than
              about past or present speed, suggesting a motor, rather than
              purely sensory, role. We were able to accurately decode the speed
              of locomotion with a simple linear algorithm, with only a
              relatively small number of well-chosen cells needed, irrespective
              of cell class. Our observations suggest that behavioural state
              modulates cerebellar sensorimotor integration, and advocate a
              role for the cerebellar vermis in control of high-level locomotor
              kinematic parameters such as speed and yaw.",
  journal  = "PLoS One",
  volume   =  13,
  number   =  9,
  pages    = "e0203900",
  month    =  sep,
  year     =  2018,
  language = "en",
  issn     = "1932-6203",
  pmid     = "30212563",
  doi      = "10.1371/journal.pone.0203900",
  pmc      = "PMC6136788"
}

@UNPUBLISHED{Beiran2021-hl,
  title    = "Parametric control of flexible timing through low-dimensional
              neural manifolds",
  author   = "Beiran, Manuel and Meirhaeghe, Nicolas and Sohn, Hansem and
              Jazayeri, Mehrdad and Ostojic, Srdjan",
  abstract = "Biological brains possess an unparalleled ability to generalize
              adaptive behavioral responses from only a few examples. How
              neural processes enable this capacity to extrapolate is a
              fundamental open question. A prominent but underexplored
              hypothesis suggests that generalization is facilitated by a
              low-dimensional organization of collective neural activity. Here
              we tested this hypothesis in the framework of flexible timing
              tasks where dynamics play a key role. Examining trained recurrent
              neural networks we found that confining the dynamics to a
              low-dimensional subspace allowed tonic inputs to parametrically
              control the overall input-output transform and enabled smooth
              extrapolation to inputs well beyond the training range.
              Reverse-engineering and theoretical analyses demonstrated that
              this parametric control of extrapolation relies on a mechanism
              where tonic inputs modulate the dynamics along non-linear
              manifolds in activity space while preserving their geometry.
              Comparisons with neural data from behaving monkeys confirmed the
              geometric and dynamical signatures of this mechanism. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.11.08.467806",
  month    =  nov,
  year     =  2021,
  language = "en",
  doi      = "10.1101/2021.11.08.467806"
}

@BOOK{Eliasmith2003-fh,
  title     = "Neural Engineering: Computation, Representation, and Dynamics in
               Neurobiological Systems",
  author    = "Eliasmith, Chris and Anderson, Charles H",
  abstract  = "For years, researchers have used the theoretical tools of
               engineering to understand neural systems, but much of this work
               has been conducted in relative isolation. In Neural Engineering,
               Chris Eliasmith and Charles Anderson provide a synthesis of the
               disparate approaches current in computational neuroscience,
               incorporating ideas from neural coding, neural computation,
               physiology, communications theory, control theory, dynamics, and
               probability theory. This synthesis, they argue, enables novel
               theoretical and practical insights into the functioning of
               neural systems. Such insights are pertinent to experimental and
               computational neuroscientists and to engineers, physicists, and
               computer scientists interested in how their quantitative tools
               relate to the brain. The authors present three principles of
               neural engineering based on the representation of signals by
               neural ensembles, transformations of these representations
               through neuronal coupling weights, and the integration of
               control theory and neural dynamics. Through detailed examples
               and in-depth discussion, they make the case that these guiding
               principles constitute a useful theory for generating large-scale
               models of neurobiological function. A software package written
               in MatLab for use with their methodology, as well as examples,
               course notes, exercises, documentation, and other material, are
               available on the Web.",
  publisher = "MIT Press",
  year      =  2003,
  language  = "en",
  isbn      = "9780262550604"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Guest2021-gl,
  title     = "On logical inference over brains, behaviour, and artificial
               neural networks",
  author    = "Guest, O and Martin, A E",
  abstract  = "In the cognitive, computational, and neuro-sciences, we often
               reason about what models (viz., formal and/or computational)
               represent, learn, or`` know'', as well as what algorithm they
               instantiate. The putative goal of such reasoning is to
               generalize claims about the model in question to claims about
               the mind and brain. This reasoning process typically presents as
               inference about the representations, processes, or algorithms
               the human mind and brain instantiate. Such inference is often
               based on a model's performance on a task, and whether …",
  publisher = "psyarxiv.com",
  year      =  2021
}

@ARTICLE{Leiras2022-dp,
  title    = "Brainstem Circuits for Locomotion",
  author   = "Leiras, Roberto and Cregg, Jared M and Kiehn, Ole",
  abstract = "Locomotion is a universal motor behavior that is expressed as the
              output of many integrated brain functions. Locomotion is
              organized at several levels of the nervous system, with brainstem
              circuits acting as the gate between brain areas regulating
              innate, emotional, or motivational locomotion and executive
              spinal circuits. Here we review recent advances on brainstem
              circuits involved in controlling locomotion. We describe how
              delineated command circuits govern the start, speed, stop, and
              steering of locomotion. We also discuss how these pathways
              interface between executive circuits in the spinal cord and
              diverse brain areas important for context-specific selection of
              locomotion. A recurrent theme is the need to establish a
              functional connectome to and from brainstem command circuits.
              Finally, we point to unresolved issues concerning the integrated
              function of locomotor control. Expected final online publication
              date for the Annual Review of Neuroscience, Volume 45 is July
              2022. Please see
              http://www.annualreviews.org/page/journal/pubdates for revised
              estimates.",
  journal  = "Annu. Rev. Neurosci.",
  month    =  jan,
  year     =  2022,
  language = "en",
  issn     = "0147-006X, 1545-4126",
  pmid     = "34985919",
  doi      = "10.1146/annurev-neuro-082321-025137"
}

@ARTICLE{Wang2022-ot,
  title         = "Manifoldron: Direct Space Partition via Manifold Discovery",
  author        = "Wang, Dayang and Fan, Feng-Lei and Hou, Bo-Jian and Zhang,
                   Hao and Lai, Rongjie and Yu, Hengyong and Wang, Fei",
  abstract      = "A neural network with the widely-used ReLU activation has
                   been shown to partition the sample space into many convex
                   polytopes for prediction. However, the parameterized way a
                   neural network and other machine learning models use to
                   partition the space has imperfections, e.g., the compromised
                   interpretability for complex models, the inflexibility in
                   decision boundary construction due to the generic character
                   of the model, and the risk of being trapped into shortcut
                   solutions. In contrast, although the non-parameterized
                   models can adorably avoid or downplay these issues, they are
                   usually insufficiently powerful either due to
                   over-simplification or the failure to accommodate the
                   manifold structures of data. In this context, we first
                   propose a new type of machine learning models referred to as
                   Manifoldron that directly derives decision boundaries from
                   data and partitions the space via manifold structure
                   discovery. Then, we systematically analyze the key
                   characteristics of the Manifoldron including
                   interpretability, manifold characterization capability, and
                   its link to neural networks. The experimental results on 9
                   small and 11 large datasets demonstrate that the proposed
                   Manifoldron performs competitively compared to the
                   mainstream machine learning models. We have shared our code
                   https://github.com/wdayang/Manifoldron for free download and
                   evaluation.",
  month         =  jan,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2201.05279",
  primaryClass  = "cs.LG",
  arxivid       = "2201.05279"
}

@UNPUBLISHED{Gut2022-ye,
  title    = "Selective inhibition of goal-directed actions in the
              mesencephalic locomotor region",
  author   = "Gut, Nadine K and Yilmaz, Duygu and Kondabolu, Krishnakanth and
              Huerta-Ocampo, Icnelia and Mena-Segovia, Juan",
  abstract = "Dopamine enables purposive behavior and adjusts vigor as a
              function of the relative value of actions. In Parkinson's
              disease, dopamine neurons die and give rise to a series of motor
              and cognitive changes that interfere with the expression of
              volitional actions. Here we report a novel inhibitory input to
              dopamine neurons originated in the mesencephalic locomotor region
              that selectively blocks purposive behavior. GABAergic neurons of
              the pedunculopontine nucleus (PPN) synapse onto dopamine neurons
              of the substantia nigra and decrease dopamine release in the
              dorsal striatum. Activation of PPN neurons abolished exploratory
              locomotion and goal-directed actions while preserved other motor
              behaviors; furthermore, PPN caused a decrease in movement vigor
              and interrupted motor sequences presumably by modulating the
              immediate value of the learned action. Our results reveal an
              inhibitory mechanism in the midbrain that rapidly and reversibly
              adjusts the intrinsic value of ongoing actions. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest.",
  journal  = "bioRxiv",
  pages    = "2022.01.18.476772",
  month    =  jan,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.01.18.476772"
}

@ARTICLE{Chalif2022-un,
  title    = "Control of mammalian locomotion by ventral spinocerebellar tract
              neurons",
  author   = "Chalif, Joshua I and Mart{\'\i}nez-Silva, Mar{\'\i}a de Lourdes
              and Pagiazitis, John G and Murray, Andrew J and Mentis, George Z",
  abstract = "Locomotion is a complex behavior required for animal survival.
              Vertebrate locomotion depends on spinal interneurons termed the
              central pattern generator (CPG), which generates activity
              responsible for the alternation of flexor and extensor muscles
              and the left and right side of the body. It is unknown whether
              multiple or a single neuronal type is responsible for the control
              of mammalian locomotion. Here, we show that ventral
              spinocerebellar tract neurons (VSCTs) drive generation and
              maintenance of locomotor behavior in neonatal and adult mice.
              Using mouse genetics, physiological, anatomical, and behavioral
              assays, we demonstrate that VSCTs exhibit rhythmogenic properties
              and neuronal circuit connectivity consistent with their essential
              role in the locomotor CPG. Importantly, optogenetic activation
              and chemogenetic silencing reveals that VSCTs are necessary and
              sufficient for locomotion. These findings identify VSCTs as
              critical components for mammalian locomotion and provide a
              paradigm shift in our understanding of neural control of complex
              behaviors.",
  journal  = "Cell",
  volume   =  185,
  number   =  2,
  pages    = "328--344.e26",
  month    =  jan,
  year     =  2022,
  keywords = "CPG; VSCT; central pattern generator; development; gap junctions;
              locomotion; motor neuron; rhythmogenic; spinal cord; ventral
              spinocerebellar tract neurons",
  language = "en",
  issn     = "0092-8674, 1097-4172",
  pmid     = "35063074",
  doi      = "10.1016/j.cell.2021.12.014"
}

@INPROCEEDINGS{Howell2019-pj,
  title           = "{ALTRO}: A fast solver for constrained trajectory
                     optimization",
  booktitle       = "2019 {IEEE/RSJ} International Conference on Intelligent
                     Robots and Systems ({IROS})",
  author          = "Howell, Taylor A and Jackson, Brian E and Manchester,
                     Zachary",
  abstract        = "Trajectory optimization is a widely used tool for robot
                     motion planning and control. Existing solvers for these
                     problems either rely on off-the-shelf nonlinear
                     programming solvers that are numerically robust and
                     capable of handling arbitrary constraints, but tend to be
                     slow because they are general purpose; or they use custom
                     numerical methods that take advantage of the problem
                     structure to be fast, but often lack robustness and have
                     limited or no ability to reason about constraints. This
                     paper presents ALTRO (Augmented Lagrangian TRajectory
                     Optimizer), a solver for constrained trajectory
                     optimization problems that handles general nonlinear state
                     and input constraints and offers fast convergence and
                     numerical robustness thanks to careful exploitation of
                     problem structure. We demonstrate its performance on a set
                     of benchmark motion-planning problems and offer
                     comparisons to the standard direct collocation method with
                     large-scale sequential quadratic programming and
                     interior-point solvers.",
  publisher       = "IEEE",
  month           =  nov,
  year            =  2019,
  conference      = "2019 IEEE/RSJ International Conference on Intelligent
                     Robots and Systems (IROS)",
  location        = "Macau, China",
  isbn            = "9781728140049",
  doi             = "10.1109/iros40897.2019.8967788"
}

@ARTICLE{Schumaker1994-gl,
  title     = "Curve and surface fitting with splines",
  author    = "Schumaker, Larry L and Dierckx, Paul",
  abstract  = "Part 1 Spline functions: univariate splines bivariate splines.
               Part 2 Curve fitting: an introduction least-squares spline curve
               fitting smoothing spline curve fitting more smoothing spline
               curves fitting with convexity constraints. Part 3 Surface
               fitting: an introduction scattered data surface fitting mesh
               data surface fitting more scattered data smoothing more mesh
               data smoothing Part 4 Fitpack: available software.",
  journal   = "Math. Comput.",
  publisher = "JSTOR",
  volume    =  63,
  number    =  207,
  pages     = "427",
  month     =  jul,
  year      =  1994,
  language  = "en",
  issn      = "0025-5718, 1088-6842",
  doi       = "10.2307/2153590"
}

@BOOK{Limebeer2018-qw,
  title     = "Dynamics and Optimal Control of Road Vehicles",
  author    = "Limebeer, D J N and Massaro, Matteo",
  abstract  = "Dynamics and Optimal Control of Road Vehicles uniquely offers a
               unified treatment of tyre, car and motorcycle dynamics, and the
               application of nonlinear optimal control to vehicle-related
               problems within a single book. This is a comprehensive and
               accessible text that emphasises the theoretical aspects of
               vehicular modelling and control. The book focuses on two major
               elements. The first is classical mechanics and its use in
               building vehicle and tyre dynamics models. The second focus is
               nonlinear optimal control, which is used to solve a range of
               minimum-time and minimum-fuel, as well as track curvature
               reconstruction problems. As is known classically, all of this
               material is bound together by the calculus of variations and
               stationary principles. The treatment of this material is
               supplemented with a number of examples that were designed to
               highlight obscurities and subtleties in the theory.",
  publisher = "Oxford University Press",
  month     =  aug,
  year      =  2018,
  language  = "en",
  isbn      = "9780192559814"
}

@ARTICLE{Humphries2003-nm,
  title     = "Book review",
  author    = "Humphries, Mark D",
  abstract  = "Neural Engineering: Computation, Representation, and Dynamics in
               Neurobiological Systems. By Chris Eliasmith and Charles H.
               Anderson (The MIT Press, Cambridge, MA, 2003), \pounds{}33.50
               hardcover, ISBN 0-262-05071-4.",
  journal   = "Conn. Sci.",
  publisher = "Taylor \& Francis",
  volume    =  15,
  number    = "2-3",
  pages     = "141--143",
  month     =  jun,
  year      =  2003,
  issn      = "0954-0091",
  doi       = "10.1080/09540090310001598448"
}

@ARTICLE{Anderson2018-bt,
  title     = "Modelling minimum-time manoeuvering with global optimisation of
               local receding horizon control",
  author    = "Anderson, Jeffery Ryan and Ayalew, Beshah",
  abstract  = "In this paper, we explore the notion that a human driver uses a
               receding horizon model predictive control (MPC) scheme for
               minimum-time manoeuvering. However, MPC is an inherently
               sub-optimal control scheme because not all future information is
               incorporated into its finite preview horizon. In many practical
               applications, this sub-optimality is tolerated as the solution
               is sufficiently close to optimal. However, it is known that
               professional drivers have the ability to learn driving circuits
               and exploit its features to minimise their global manoeuvering
               time. In this paper, we will model their process with a cascaded
               optimisation structure. Therein, the inner-loop features a local
               MPC scheme tasked with finding the control inputs that achieve a
               blended objective of minimising time and maximising velocity in
               each preview horizon/distance. The outer loop of this cascaded
               structure computes the best set of weights for the two
               components of the local objectives in order to minimise the
               global manoeuvering time. The proposed cascaded optimisation and
               control approach is compared against a straight-forward
               fixed-cost time optimal MPC applied to minimum-time manoeuvering
               over two well-known race courses. The paper also includes an
               extended literature review and details of the computational
               formulation of the model approach.",
  journal   = "Veh. Syst. Dyn.",
  publisher = "Taylor \& Francis",
  volume    =  56,
  number    =  10,
  pages     = "1508--1531",
  month     =  oct,
  year      =  2018,
  issn      = "0042-3114",
  doi       = "10.1080/00423114.2017.1420808"
}

@UNPUBLISHED{Dahmen2022-aq,
  title    = "Strong and localized recurrence controls dimensionality of neural
              activity across brain areas",
  author   = "Dahmen, David and Recanatesi, Stefano and Jia, Xiaoxuan and
              Ocker, Gabriel K and Campagnola, Luke and Jarsky, Tim and Seeman,
              Stephanie and Helias, Moritz and Shea-Brown, Eric",
  abstract = "The brain contains an astronomical number of neurons, but it is
              their collective activity that underlies brain function. The
              number of degrees of freedom that this collective activity
              explores -- its dimensionality -- is therefore a fundamental
              signature of neural dynamics and computation ([1][1]--[7][2]).
              However, it is not known what controls this dimensionality in the
              biological brain -- and in particular whether and how local
              synaptic networks play a role ([8][3]--[10][4]). Through analysis
              of high-density Neuropixels recordings ([11][5]), we argue that
              areas across the mouse cortex operate in a sensitive regime that
              gives these synaptic networks a very strong role in controlling
              dimensionality. Moreover, we show that this control is expressed
              through highly tractable features of these synaptic networks. We
              then analyze these key features via a massive synaptic physiology
              dataset ([12][6]). Quantifying these features in terms of
              cell-type specific network motifs, we find that the synaptic
              patterns that impact dimensionality are prevalent in both mouse
              and human brains. Thus local circuitry scales up systematically
              to help control the degrees of freedom that brain networks may
              explore and exploit. \#\#\# Competing Interest Statement The
              authors have declared no competing interest. [1]: \#ref-1 [2]:
              \#ref-7 [3]: \#ref-8 [4]: \#ref-10 [5]: \#ref-11 [6]: \#ref-12",
  journal  = "bioRxiv",
  pages    = "2020.11.02.365072",
  month    =  feb,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2020.11.02.365072"
}

@ARTICLE{Whittington2022-up,
  title         = "How to build a cognitive map: insights from models of the
                   hippocampal formation",
  author        = "Whittington, James C R and McCaffary, David and Bakermans,
                   Jacob J W and Behrens, Timothy E J",
  abstract      = "Learning and interpreting the structure of the environment
                   is an innate feature of biological systems, and is integral
                   to guiding flexible behaviours for evolutionary viability.
                   The concept of a cognitive map has emerged as one of the
                   leading metaphors for these capacities, and unravelling the
                   learning and neural representation of such a map has become
                   a central focus of neuroscience. While experimentalists are
                   providing a detailed picture of the neural substrate of
                   cognitive maps in hippocampus and beyond, theorists have
                   been busy building models to bridge the divide between
                   neurons, computation, and behaviour. These models can
                   account for a variety of known representations and neural
                   phenomena, but often provide a differing understanding of
                   not only the underlying principles of cognitive maps, but
                   also the respective roles of hippocampus and cortex. In this
                   Perspective, we bring many of these models into a common
                   language, distil their underlying principles of constructing
                   cognitive maps, provide novel (re)interpretations for neural
                   phenomena, suggest how the principles can be extended to
                   account for prefrontal cortex representations and, finally,
                   speculate on the role of cognitive maps in higher cognitive
                   capacities.",
  month         =  feb,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2202.01682",
  primaryClass  = "q-bio.NC",
  arxivid       = "2202.01682"
}

@BOOK{Betts2010-yj,
  title     = "Practical methods for optimal control and estimation using
               nonlinear programming",
  author    = "Betts, John T",
  publisher = "Society for Industrial and Applied Mathematics",
  month     =  jan,
  year      =  2010,
  isbn      = "9780898716887, 9780898718577",
  doi       = "10.1137/1.9780898718577"
}

@ARTICLE{Liniger2017-ej,
  title         = "{Optimization-Based} Autonomous Racing of 1:43 Scale {RC}
                   Cars",
  author        = "Liniger, Alexander and Domahidi, Alexander and Morari,
                   Manfred",
  abstract      = "This paper describes autonomous racing of RC race cars based
                   on mathematical optimization. Using a dynamical model of the
                   vehicle, control inputs are computed by receding horizon
                   based controllers, where the objective is to maximize
                   progress on the track subject to the requirement of staying
                   on the track and avoiding opponents. Two different control
                   formulations are presented. The first controller employs a
                   two-level structure, consisting of a path planner and a
                   nonlinear model predictive controller (NMPC) for tracking.
                   The second controller combines both tasks in one nonlinear
                   optimization problem (NLP) following the ideas of contouring
                   control. Linear time varying models obtained by
                   linearization are used to build local approximations of the
                   control NLPs in the form of convex quadratic programs (QPs)
                   at each sampling time. The resulting QPs have a typical MPC
                   structure and can be solved in the range of milliseconds by
                   recent structure exploiting solvers, which is key to the
                   real-time feasibility of the overall control scheme.
                   Obstacle avoidance is incorporated by means of a high-level
                   corridor planner based on dynamic programming, which
                   generates convex constraints for the controllers according
                   to the current position of opponents and the track layout.
                   The control performance is investigated experimentally using
                   1:43 scale RC race cars, driven at speeds of more than 3 m/s
                   and in operating regions with saturated rear tire forces
                   (drifting). The algorithms run at 50 Hz sampling rate on
                   embedded computing platforms, demonstrating the real-time
                   feasibility and high performance of optimization-based
                   approaches for autonomous racing.",
  month         =  nov,
  year          =  2017,
  archivePrefix = "arXiv",
  eprint        = "1711.07300",
  primaryClass  = "math.OC",
  arxivid       = "1711.07300"
}

@ARTICLE{Tyson2022-eg,
  title    = "Accurate determination of marker location within whole-brain
              microscopy images",
  author   = "Tyson, Adam L and V{\'e}lez-Fort, Mateo and Rousseau, Charly V
              and Cossell, Lee and Tsitoura, Chryssanthi and Lenzi, Stephen C
              and Obenhaus, Horst A and Claudi, Federico and Branco, Tiago and
              Margrie, Troy W",
  abstract = "High-resolution whole-brain microscopy provides a means for post
              hoc determination of the location of implanted devices and
              labelled cell populations that are necessary to interpret in vivo
              experiments designed to understand brain function. Here we have
              developed two plugins (brainreg and brainreg-segment) for the
              Python-based image viewer napari, to accurately map any object in
              a common coordinate space. We analysed the position of
              dye-labelled electrode tracks and two-photon imaged cell
              populations expressing fluorescent proteins. The precise location
              of probes and cells were physiologically interrogated and
              revealed accurate segmentation with near-cellular resolution.",
  journal  = "Sci. Rep.",
  volume   =  12,
  number   =  1,
  pages    = "867",
  month    =  jan,
  year     =  2022,
  language = "en",
  issn     = "2045-2322",
  pmid     = "35042882",
  doi      = "10.1038/s41598-021-04676-9",
  pmc      = "PMC8766598"
}

@UNPUBLISHED{Melbaum2022-lg,
  title    = "Conserved structures of neural activity in sensorimotor cortex of
              freely moving rats allow cross-subject decoding",
  author   = "Melbaum, Svenja and Russo, Eleonora and Eriksson, David and
              Schneider, Artur and Durstewitz, Daniel and Brox, Thomas and
              Diester, Ilka",
  abstract = "Our knowledge about neuronal activity in the sensorimotor cortex
              relies primarily on stereotyped movements that are strictly
              controlled in experimental settings. It remains unclear how
              results can be carried over to less constrained behavior like
              that of freely moving subjects. Toward this goal, we developed a
              self-paced behavioral paradigm that encouraged rats to engage in
              different movement types. We employed bilateral
              electrophysiological recordings across the entire sensorimotor
              cortex and simultaneous paw tracking. These techniques revealed
              behavioral coupling of neurons with lateralization and an
              anterior--posterior gradient from the premotor to the primary
              sensory cortex. The structure of population activity patterns was
              conserved across animals despite the severe under-sampling of the
              total number of neurons and variations in electrode positions
              across individuals. We demonstrated cross-subject and
              cross-session generalization in a decoding task through
              alignments of low-dimensional neural manifolds, providing
              evidence of a conserved neuronal code One-sentence summary
              Similarities in neural population structures across the
              sensorimotor cortex enable generalization across animals in the
              decoding of unconstrained behavior. ![Figure][1] Conserved
              structures of neural activity in freely moving rats allow for
              cross-subject decoding. (a) We conducted electrophysiological
              recordings across the bilateral sensorimotor cortex of six freely
              moving rats. Neural activities were projected into a
              low-dimensional space with LEMs ( [22][2] ). (b) In a decoding
              task, points in the aligned low-dimensional neural state space
              were used as input for a classifier that predicted behavioral
              labels. Importantly, training and testing data originated from
              different rats. (c) Our procedure led to successful cross-subject
              generalization for sessions with sufficient numbers of recorded
              units. The rat and brain drawings are adapted from
              scalablebrainatlas.incf.org and SciDraw. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest. [1]: pending:yes [2]: \#ref-22",
  journal  = "bioRxiv",
  pages    = "2021.03.04.433869",
  month    =  feb,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2021.03.04.433869"
}

@UNPUBLISHED{Bachschmid-Romano2022-yc,
  title    = "Interplay between external inputs and recurrent dynamics during
              movement preparation and execution in a network model of motor
              cortex",
  author   = "Bachschmid-Romano, Ludovica and Hatsopoulos, Nicholas G and
              Brunel, Nicolas",
  abstract = "The primary motor cortex has been shown to coordinate movement
              preparation and execution through computations in approximately
              orthogonal subspaces. The underlying network mechanisms, and in
              particular the roles played by external and recurrent
              connectivity, are central open questions that need to be answered
              to understand the neural substrates of motor control. We develop
              a recurrent neural network model that recapitulates the temporal
              evolution of single-unit activity recorded from M1 of a macaque
              monkey during an instructed delayed-reach task. We explore the
              hypothesis that the observed dynamics of neural covariation with
              the direction of motion emerges from a synaptic connectivity
              structure that depends on the preferred directions of neurons in
              both preparatory and movement-related epochs. We constrain the
              strength both of synaptic connectivity and of external input
              parameters by using the data as well as an external input
              minimization cost. Our analysis suggests that the observed
              patterns of covariance are shaped by external inputs that are
              tuned to neurons' preferred directions during movement
              preparation, and they are dominated by strong direction-specific
              recurrent connectivity during movement execution, in agreement
              with recent experimental findings on the relationship between
              motor--cortical and motor--thalamic activity, both before and
              during movement execution. We also demonstrate that the manner in
              which single-neuron tuning properties rearrange over time can
              explain the level of orthogonality of preparatory and
              movement-related subspaces. We predict that the level of
              orthogonality is small enough to prevent premature movement
              initiation during movement preparation; however, it is not zero,
              which allows the network to encode a stable direction of motion
              at the population level without direction-specific external
              inputs during movement execution. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.02.19.481140",
  month    =  feb,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.02.19.481140"
}

@ARTICLE{Page2018-ii,
  title    = "A speed-accurate self-sustaining head direction cell path
              integration model without recurrent excitation",
  author   = "Page, Hector J I and Walters, Daniel and Stringer, Simon M",
  abstract = "The head direction (HD) system signals HD in an allocentric frame
              of reference. The system is able to update firing based on
              internally derived information about self-motion, a process known
              as path integration. Of particular interest is how path
              integration might maintain concordance between true HD and
              internally represented HD. Here we present a self-sustaining
              two-layer model, capable of self-organizing, which produces
              extremely accurate path integration. The implications of this
              work for future investigations of HD system path integration are
              discussed.",
  journal  = "Network",
  volume   =  29,
  number   = "1-4",
  pages    = "37--69",
  year     =  2018,
  keywords = "Spatial cognition; attractor dynamics; continuous attractor
              neural networks; head direction cells; path integration",
  language = "en",
  issn     = "0093-3341",
  pmid     = "30905280",
  doi      = "10.1080/0954898X.2018.1559960"
}

@ARTICLE{Scholz2022-hg,
  title         = "Inference of Affordances and Active Motor Control in
                   Simulated Agents",
  author        = "Scholz, Fedor and Gumbsch, Christian and Otte, Sebastian and
                   Butz, Martin V",
  abstract      = "Flexible, goal-directed behavior is a fundamental aspect of
                   human life. Based on the free energy minimization principle,
                   the theory of active inference formalizes the generation of
                   such behavior from a computational neuroscience perspective.
                   Based on the theory, we introduce an output-probabilistic,
                   temporally predictive, modular artificial neural network
                   architecture, which processes sensorimotor information,
                   infers behavior-relevant aspects of its world, and invokes
                   highly flexible, goal-directed behavior. We show that our
                   architecture, which is trained end-to-end to minimize an
                   approximation of free energy, develops latent states that
                   can be interpreted as affordance maps. That is, the emerging
                   latent states signal which actions lead to which effects
                   dependent on the local context. In combination with active
                   inference, we show that flexible, goal-directed behavior can
                   be invoked, incorporating the emerging affordance maps. As a
                   result, our simulated agent flexibly steers through
                   continuous spaces, avoids collisions with obstacles, and
                   prefers pathways that lead to the goal with high certainty.
                   Additionally, we show that the learned agent is highly
                   suitable for zero-shot generalization across environments:
                   After training the agent in a handful of fixed environments
                   with obstacles and other terrains affecting its behavior, it
                   performs similarly well in procedurally generated
                   environments containing different amounts of obstacles and
                   terrains of various sizes at different locations. To improve
                   and focus model learning further, we plan to invoke active
                   inference-based, information-gain-oriented behavior also
                   while learning the temporally predictive model itself in the
                   near future. Moreover, we intend to foster the development
                   of both deeper event-predictive abstractions and compact,
                   habitual behavioral primitives.",
  month         =  feb,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2202.11532",
  primaryClass  = "cs.AI",
  arxivid       = "2202.11532"
}

@UNPUBLISHED{Barbosa2022-ar,
  title    = "Flexible selection of task-relevant features through across-area
              population gating",
  author   = "Barbosa, Joao and Proville, Remi and Rodgers, Chris C and
              Ostojic, Srdjan and Boubenec, Yves",
  abstract = "Brains can gracefully weed out irrelevant stimuli to guide
              behavior. This feat is believed to rely on a progressive
              selection of task-relevant stimuli across the cortical hierarchy,
              but the specific across-area interactions enabling stimulus
              selection are still unclear. Here, we propose that population
              gating, occurring within A1 but controlled by top-down inputs
              from mPFC, can support across-area stimulus selection. Examining
              single-unit activity recorded while rats performed an auditory
              context-dependent task, we found that A1 encoded relevant and
              irrelevant stimuli along a common dimension of its neural space.
              Yet, the relevant stimulus encoding was enhanced along an extra
              dimension. In turn, mPFC encoded only the stimulus relevant to
              the ongoing context. To identify candidate mechanisms for
              stimulus selection within A1, we reverse-engineered low-rank RNNs
              trained on a similar task. Our analyses predicted that two
              context-modulated neural populations gated their preferred
              stimulus in opposite contexts, which we confirmed in further
              analyses of A1. We finally integrated our within-area
              observations in a two-region RNN and proposed a novel mechanism
              for flexible across-area communication through fixed
              connectivity. \#\#\# Competing Interest Statement The authors
              have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.07.21.500962",
  month    =  jul,
  year     =  2022,
  keywords = "To Read;BCI",
  language = "en",
  doi      = "10.1101/2022.07.21.500962"
}

@ARTICLE{Kim2022-uu,
  title         = "A Neural Programming Language for the Reservoir Computer",
  author        = "Kim, Jason Z and Bassett, Dani S",
  abstract      = "From logical reasoning to mental simulation, biological and
                   artificial neural systems possess an incredible capacity for
                   computation. Such neural computers offer a fundamentally
                   novel computing paradigm by representing data continuously
                   and processing information in a natively parallel and
                   distributed manner. To harness this computation, prior work
                   has developed extensive training techniques to understand
                   existing neural networks. However, the lack of a concrete
                   and low-level programming language for neural networks
                   precludes us from taking full advantage of a neural
                   computing framework. Here, we provide such a programming
                   language using reservoir computing -- a simple recurrent
                   neural network -- and close the gap between how we
                   conceptualize and implement neural computers and silicon
                   computers. By decomposing the reservoir's internal
                   representation and dynamics into a symbolic basis of its
                   inputs, we define a low-level neural machine code that we
                   use to program the reservoir to solve complex equations and
                   store chaotic dynamical systems as random access memory
                   (dRAM). Using this representation, we provide a fully
                   distributed neural implementation of software virtualization
                   and logical circuits, and even program a playable game of
                   pong inside of a reservoir computer. Taken together, we
                   define a concrete, practical, and fully generalizable
                   implementation of neural computation.",
  month         =  mar,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2203.05032",
  primaryClass  = "cond-mat.dis-nn",
  arxivid       = "2203.05032"
}

@ARTICLE{Merel2019-bs,
  title         = "Deep neuroethology of a virtual rodent",
  author        = "Merel, Josh and Aldarondo, Diego and Marshall, Jesse and
                   Tassa, Yuval and Wayne, Greg and {\"O}lveczky, Bence",
  abstract      = "Parallel developments in neuroscience and deep learning have
                   led to mutually productive exchanges, pushing our
                   understanding of real and artificial neural networks in
                   sensory and cognitive systems. However, this interaction
                   between fields is less developed in the study of motor
                   control. In this work, we develop a virtual rodent as a
                   platform for the grounded study of motor activity in
                   artificial models of embodied control. We then use this
                   platform to study motor activity across contexts by training
                   a model to solve four complex tasks. Using methods familiar
                   to neuroscientists, we describe the behavioral
                   representations and algorithms employed by different layers
                   of the network using a neuroethological approach to
                   characterize motor activity relative to the rodent's
                   behavior and goals. We find that the model uses two classes
                   of representations which respectively encode the
                   task-specific behavioral strategies and task-invariant
                   behavioral kinematics. These representations are reflected
                   in the sequential activity and population dynamics of neural
                   subpopulations. Overall, the virtual rodent facilitates
                   grounded collaborations between deep reinforcement learning
                   and motor neuroscience.",
  month         =  nov,
  year          =  2019,
  archivePrefix = "arXiv",
  eprint        = "1911.09451",
  primaryClass  = "q-bio.NC",
  arxivid       = "1911.09451"
}

@UNPUBLISHED{Xing2022-hu,
  title    = "Emergence of distinct neural subspaces in motor cortical dynamics
              during volitional adjustments of ongoing locomotion",
  author   = "Xing, David and Truccolo, Wilson and Borton, David Allenson",
  abstract = "Our ability to modulate our ongoing walking gait with precise,
              voluntary adjustments is what allows us to navigate complex
              terrains. However, how our nervous system generates the signals
              to precisely control our limbs while simultaneously maintaining
              ongoing locomotion is poorly understood. Here, we recorded the
              activity of primary motor cortex in nonhuman primates during
              obstacle avoidance on a treadmill. We found that the same neural
              population was active during both basic unobstructed locomotion
              and volitional obstacle avoidance movements. Additionally, we
              identified the neural modes spanning the subspace of the
              low-dimensional dynamics in M1. We found that motor cortex
              employs a subspace that consistently maintains the same cyclic
              activity throughout obstacle stepping, despite large changes in
              the movement itself. All the variance corresponding to this large
              change in movement during the obstacle avoidance is confined to
              its own distinct subspace. Our findings suggest that M1 utilizes
              separate underlying processes for maintaining ongoing
              locomotor-related neural dynamics and for performing volitional
              gait adjustments during complex locomotion. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest.",
  journal  = "bioRxiv",
  pages    = "2022.04.03.486001",
  month    =  apr,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.04.03.486001"
}

@ARTICLE{Schneider2022-sy,
  title         = "Learnable latent embeddings for joint behavioral and neural
                   analysis",
  author        = "Schneider, Steffen and Lee, Jin Hwa and Mathis, Mackenzie
                   Weygandt",
  abstract      = "Mapping behavioral actions to neural activity is a
                   fundamental goal of neuroscience. As our ability to record
                   large neural and behavioral data increases, there is growing
                   interest in modeling neural dynamics during adaptive
                   behaviors to probe neural representations. In particular,
                   neural latent embeddings can reveal underlying correlates of
                   behavior, yet, we lack non-linear techniques that can
                   explicitly and flexibly leverage joint behavior and neural
                   data. Here, we fill this gap with a novel method, CEBRA,
                   that jointly uses behavioral and neural data in a
                   hypothesis- or discovery-driven manner to produce
                   consistent, high-performance latent spaces. We validate its
                   accuracy and demonstrate our tool's utility for both calcium
                   and electrophysiology datasets, across sensory and motor
                   tasks, and in simple or complex behaviors across species. It
                   allows for single and multi-session datasets to be leveraged
                   for hypothesis testing or can be used label-free. Lastly, we
                   show that CEBRA can be used for the mapping of space,
                   uncovering complex kinematic features, and rapid,
                   high-accuracy decoding of natural movies from visual cortex.",
  month         =  apr,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2204.00673",
  primaryClass  = "cs.LG",
  arxivid       = "2204.00673"
}

@ARTICLE{Dehmamy2021-jq,
  title         = "Automatic Symmetry Discovery with Lie Algebra Convolutional
                   Network",
  author        = "Dehmamy, Nima and Walters, Robin and Liu, Yanchen and Wang,
                   Dashun and Yu, Rose",
  abstract      = "Existing equivariant neural networks require prior knowledge
                   of the symmetry group and discretization for continuous
                   groups. We propose to work with Lie algebras (infinitesimal
                   generators) instead of Lie groups. Our model, the Lie
                   algebra convolutional network (L-conv) can automatically
                   discover symmetries and does not require discretization of
                   the group. We show that L-conv can serve as a building block
                   to construct any group equivariant feedforward architecture.
                   Both CNNs and Graph Convolutional Networks can be expressed
                   as L-conv with appropriate groups. We discover direct
                   connections between L-conv and physics: (1) group invariant
                   loss generalizes field theory (2) Euler-Lagrange equation
                   measures the robustness, and (3) equivariance leads to
                   conservation laws and Noether current.These connections open
                   up new avenues for designing more general equivariant
                   networks and applying them to important problems in physical
                   sciences",
  month         =  sep,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2109.07103",
  primaryClass  = "cs.LG",
  arxivid       = "2109.07103"
}

@ARTICLE{Cueva2021-uc,
  title         = "Recurrent neural network models for working memory of
                   continuous variables: activity manifolds, connectivity
                   patterns, and dynamic codes",
  author        = "Cueva, Christopher J and Ardalan, Adel and Tsodyks, Misha
                   and Qian, Ning",
  abstract      = "Many daily activities and psychophysical experiments involve
                   keeping multiple items in working memory. When items take
                   continuous values (e.g., orientation, contrast, length,
                   loudness) they must be stored in a continuous structure of
                   appropriate dimensions. We investigate how this structure is
                   represented in neural circuits by training recurrent
                   networks to report two previously shown stimulus
                   orientations. We find the activity manifold for the two
                   orientations resembles a Clifford torus. Although a Clifford
                   and standard torus (the surface of a donut) are
                   topologically equivalent, they have important functional
                   differences. A Clifford torus treats the two orientations
                   equally and keeps them in orthogonal subspaces, as demanded
                   by the task, whereas a standard torus does not. We find and
                   characterize the connectivity patterns that support the
                   Clifford torus. Moreover, in addition to attractors that
                   store information via persistent activity, our networks also
                   use a dynamic code where units change their tuning to
                   prevent new sensory input from overwriting the previously
                   stored one. We argue that such dynamic codes are generally
                   required whenever multiple inputs enter a memory system via
                   shared connections. Finally, we apply our framework to a
                   human psychophysics experiment in which subjects reported
                   two remembered orientations. By varying the training
                   conditions of the RNNs, we test and support the hypothesis
                   that human behavior is a product of both neural noise and
                   reliance on the more stable and behaviorally relevant memory
                   of the ordinal relationship between the two orientations.
                   This suggests that suitable inductive biases in RNNs are
                   important for uncovering how the human brain implements
                   working memory. Together, these results offer an
                   understanding of the neural computations underlying a class
                   of visual decoding tasks, bridging the scales from human
                   behavior to synaptic connectivity.",
  month         =  nov,
  year          =  2021,
  keywords      = "To Read;BCI",
  archivePrefix = "arXiv",
  eprint        = "2111.01275",
  primaryClass  = "q-bio.NC",
  arxivid       = "2111.01275"
}

@ARTICLE{Ayzenberg_undated-jc,
  title  = "Topology and geometry of data manifold in deep learning",
  author = "Ayzenberg, German Magai Anton"
}

@ARTICLE{Benhamou2004-nh,
  title    = "How to reliably estimate the tortuosity of an animal's path:
              straightness, sinuosity, or fractal dimension?",
  author   = "Benhamou, Simon",
  abstract = "The tortuosity of an animal's path is a key parameter in
              orientation and searching behaviours. The tortuosity of an
              oriented path is inversely related to the efficiency of the
              orientation mechanism involved, the best mechanism being assumed
              to allow the animal to reach its goal along a straight line
              movement. The tortuosity of a random search path controls the
              local searching intensity, allowing the animal to adjust its
              search effort to the local profitability of the environment. This
              paper shows that (1) the efficiency of an oriented path can be
              reliably estimated by a straightness index computed as the ratio
              between the distance from the starting point to the goal and the
              path length travelled to reach the goal, but such a simple index,
              ranging between 0 and 1, cannot be applied to random search
              paths; (2) the tortuosity of a random search path, ranging
              between straight line movement and Brownian motion, can be
              reliably estimated by a sinuosity index which combines the mean
              cosine of changes of direction with the mean step length; and (3)
              in the current state of the art, the fractal analysis of animals'
              paths, which may appear as an alternative and promising way to
              measure the tortuosity of a random search path as a fractal
              dimension ranging between 1 (straight line movement) and 2
              (Brownian motion), is only liable to generate artifactual
              results. This paper also provides some help for distinguishing
              between oriented and random search paths, and depicts a general,
              comprehensive framework for analysing individual animals' paths
              in a two-dimensional space.",
  journal  = "J. Theor. Biol.",
  volume   =  229,
  number   =  2,
  pages    = "209--220",
  month    =  jul,
  year     =  2004,
  language = "en",
  issn     = "0022-5193",
  pmid     = "15207476",
  doi      = "10.1016/j.jtbi.2004.03.016"
}

@ARTICLE{Wu2020-oa,
  title    = "An effective method to compute the box-counting dimension based
              on the mathematical definition and intervals",
  author   = "Wu, Jiaxin and Jin, Xin and Mi, Shuo and Tang, Jinbo",
  abstract = "Fractal dimension is an appropriate indicator to describe the
              complexity of a certain geometry, and box-counting analysis is
              proved to be an effective and appropriate method for fractal
              dimension estimation which is widely used. However, traditional
              box-counting methods based on images may not always accurate
              especially in small box scale due to the restriction of pixels.
              This paper aims to introduce a method based on generating fractal
              and determining boxes by rigid mathematical definition to
              eliminate the deviation of each box scale and to carry out more
              dependable results. Several samples of the simple and recursive
              fractal are analyzed to verify the accuracy of the box-counting
              method based on mathematical definition and interval in this
              paper.",
  journal  = "Results in Engineering",
  volume   =  6,
  pages    = "100106",
  month    =  jun,
  year     =  2020,
  keywords = "Fractal; Fractal dimension; Box-counting method",
  issn     = "2590-1230",
  doi      = "10.1016/j.rineng.2020.100106"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Van_der_Zouwen2021-yh,
  title    = "Freely Behaving Mice Can Brake and Turn During Optogenetic
              Stimulation of the Mesencephalic Locomotor Region",
  author   = "van der Zouwen, Cornelis Immanuel and Boutin, Jo{\"e}l and
              Foug{\`e}re, Maxime and Flaive, Aur{\'e}lie and Vivancos,
              M{\'e}lanie and Santuz, Alessandro and Akay, Turgay and Sarret,
              Philippe and Ryczko, Dimitri",
  abstract = "A key function of the mesencephalic locomotor region (MLR) is to
              control the speed of forward symmetrical locomotor movements.
              However, the ability of freely moving mammals to integrate
              environmental cues to brake and turn during MLR stimulation is
              poorly documented. Here, we investigated whether freely behaving
              mice could brake or turn, based on environmental cues during MLR
              stimulation. We photostimulated the cuneiform nucleus (part of
              the MLR) in mice expressing channelrhodopsin in Vglut2-positive
              neurons in a Cre-dependent manner (Vglut2-ChR2-EYFP) using
              optogenetics. We detected locomotor movements using deep
              learning. We used patch-clamp recordings to validate the
              functional expression of channelrhodopsin and neuroanatomy to
              visualize the stimulation sites. In the linear corridor, gait
              diagram and limb kinematics were similar during spontaneous and
              optogenetic-evoked locomotion. In the open-field arena,
              optogenetic stimulation of the MLR evoked locomotion, and
              increasing laser power increased locomotor speed. Mice could
              brake and make sharp turns (~90°) when approaching a corner
              during MLR stimulation in the open-field arena. The speed during
              the turn was scaled with the speed before the turn, and with the
              turn angle. Patch-clamp recordings in Vglut2-ChR2-EYFP mice show
              that blue light evoked short-latency spiking in MLR neurons. Our
              results strengthen the idea that different brainstem neurons
              convey braking/turning and MLR speed commands in mammals. Our
              study also shows that Vglut2-positive neurons of the cuneiform
              nucleus are a relevant target to increase locomotor activity
              without impeding the ability to brake and turn when approaching
              obstacles, thus ensuring smooth and adaptable navigation. Our
              observations may have clinical relevance since cuneiform nucleus
              stimulation is increasingly considered to improve locomotion
              function in pathological states such as Parkinson's disease,
              spinal cord injury, or stroke.",
  journal  = "Front. Neural Circuits",
  volume   =  15,
  pages    = "639900",
  month    =  apr,
  year     =  2021,
  keywords = "Vglut2; braking; cuneiform nucleus; locomotion; mesencephalic
              locomotor region; optogenetics; speed; turning",
  language = "en",
  issn     = "1662-5110",
  pmid     = "33897379",
  doi      = "10.3389/fncir.2021.639900",
  pmc      = "PMC8062873"
}

@ARTICLE{Sreenivasan2011-xk,
  title    = "Grid cells generate an analog error-correcting code for
              singularly precise neural computation",
  author   = "Sreenivasan, Sameet and Fiete, Ila",
  abstract = "Entorhinal grid cells in mammals fire as a function of animal
              location, with spatially periodic response patterns. This
              nonlocal periodic representation of location, a local variable,
              is unlike other neural codes. There is no theoretical explanation
              for why such a code should exist. We examined how accurately the
              grid code with noisy neurons allows an ideal observer to estimate
              location and found this code to be a previously unknown type of
              population code with unprecedented robustness to noise. In
              particular, the representational accuracy attained by grid cells
              over the coding range was in a qualitatively different class from
              what is possible with observed sensory and motor population
              codes. We found that a simple neural network can effectively
              correct the grid code. To the best of our knowledge, these
              results are the first demonstration that the brain contains, and
              may exploit, powerful error-correcting codes for analog
              variables.",
  journal  = "Nat. Neurosci.",
  volume   =  14,
  number   =  10,
  pages    = "1330--1337",
  month    =  sep,
  year     =  2011,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "21909090",
  doi      = "10.1038/nn.2901"
}

@ARTICLE{Bubenik2019-jg,
  title         = "Persistent homology detects curvature",
  author        = "Bubenik, Peter and Hull, Michael and Patel, Dhruv and
                   Whittle, Benjamin",
  abstract      = "In topological data analysis, persistent homology is used to
                   study the ``shape of data''. Persistent homology
                   computations are completely characterized by a set of
                   intervals called a bar code. It is often said that the long
                   intervals represent the ``topological signal'' and the short
                   intervals represent ``noise''. We give evidence to dispute
                   this thesis, showing that the short intervals encode
                   geometric information. Specifically, we prove that
                   persistent homology detects the curvature of disks from
                   which points have been sampled. We describe a general
                   computational framework for solving inverse problems using
                   the average persistence landscape, a continuous mapping from
                   metric spaces with a probability measure to a Hilbert space.
                   In the present application, the average persistence
                   landscapes of points sampled from disks of constant
                   curvature results in a path in this Hilbert space which may
                   be learned using standard tools from statistical and machine
                   learning.",
  month         =  may,
  year          =  2019,
  archivePrefix = "arXiv",
  eprint        = "1905.13196",
  primaryClass  = "cs.CG",
  arxivid       = "1905.13196"
}

@UNPUBLISHED{Noorman2022-qm,
  title    = "Accurate angular integration with only a handful of neurons",
  author   = "Noorman, Marcella and Hulse, Brad K and Jayaraman, Vivek and
              Romani, Sandro and Hermundstad, Ann M",
  abstract = "To flexibly navigate, many animals rely on internal spatial
              representations that persist when the animal is standing still in
              darkness, and update accurately by integrating the animal's
              movements in the absence of localizing sensory cues. Theories of
              mammalian head direction cells have proposed that these dynamics
              can be realized in a special class of networks that maintain a
              localized bump of activity via structured recurrent connectivity,
              and that shift this bump of activity via angular velocity input.
              Although there are many different variants of these so-called
              ring attractor networks, they all rely on large numbers of
              neurons to generate representations that persist in the absence
              of input and accurately integrate angular velocity input.
              Surprisingly, in the fly, Drosophila melanogaster , a head
              direction representation is maintained by a much smaller number
              of neurons whose dynamics and connectivity resemble those of a
              ring attractor network. These findings challenge our
              understanding of ring attractors and their putative
              implementation in neural circuits. Here, we analyzed failures of
              angular velocity integration that emerge in small attractor
              networks with only a few computational units. Motivated by the
              peak performance of the fly head direction system in darkness, we
              mathematically derived conditions under which small networks,
              even with as few as 4 neurons, achieve the performance of much
              larger networks. The resulting description reveals that by
              appropriately tuning the network connectivity, the network can
              maintain persistent representations over the continuum of head
              directions, and it can accurately integrate angular velocity
              inputs. We then analytically determined how performance degrades
              as the connectivity deviates from this optimally-tuned setting,
              and we find a trade-off between network size and the tuning
              precision needed to achieve persistence and accurate integration.
              This work shows how even small networks can accurately track an
              animal's movements to guide navigation, and it informs our
              understanding of the functional capabilities of discrete systems
              more broadly. \#\#\# Competing Interest Statement The authors
              have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.05.23.493052",
  month    =  may,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.05.23.493052"
}

@ARTICLE{Brownstone2018-fl,
  title     = "Reticulospinal Systems for Tuning Motor Commands",
  author    = "Brownstone, Robert M and Chopek, Jeremy W",
  abstract  = "The pontomedullary reticular formation (RF) is a key site
               responsible for integrating descending instructions to execute
               particular movements. The indiscrete nature of this region has
               led not only to some inconsistencies in nomenclature, but also
               to difficulties in understanding its role in the control of
               movement. In this review article, we first discuss nomenclature
               of the RF, and then examine the reticulospinal motor command
               system through evolution. These command neurons have direct
               monosynaptic connections with spinal interneurons and
               motoneurons. We next review their roles in postural adjustments,
               walking and sleep atonia, discussing their roles in movement
               activation or inhibition. We propose that knowledge of the
               internal organization of the RF is necessary to understand how
               the nervous system tunes motor commands, and that this knowledge
               will underlie strategies for motor functional recovery following
               neurological injuries or diseases.",
  journal   = "Front. Neural Circuits",
  publisher = "frontiersin.org",
  volume    =  12,
  pages     = "30",
  month     =  apr,
  year      =  2018,
  keywords  = "locomotion; mesencephalic locomotor region; microcircuits;
               reticular formation; sleep atonia",
  language  = "en",
  issn      = "1662-5110",
  pmid      = "29720934",
  doi       = "10.3389/fncir.2018.00030",
  pmc       = "PMC5915564"
}

@UNPUBLISHED{Keshtkaran2022-xw,
  title    = "A large-scale neural network training framework for generalized
              estimation of single-trial population dynamics",
  author   = "Keshtkaran, Mohammad Reza and Sedler, Andrew R and Chowdhury,
              Raeed H and Tandon, Raghav and Basrai, Diya and Nguyen, Sarah L
              and Sohn, Hansem and Jazayeri, Mehrdad and Miller, Lee E and
              Pandarinath, Chethan",
  abstract = "Recent technical advances have enabled recording of increasingly
              large populations of neural activity, even during natural,
              unstructured behavior. Deep learning models are the current
              state-of-the-art for uncovering dynamics from these datasets.
              However, these highly complex models include many non-trainable
              hyperparameters (HPs) that are typically hand tuned with
              reference to supervisory information (e.g., behavioral data).
              This process is cumbersome and time consuming and biases model
              selection toward models with good representations of individual
              supervisory variables. It also completely excludes modeling of
              cognitive areas or unstructured tasks for which supervised
              information is unavailable. Here we demonstrate AutoLFADS, an
              automated model-tuning framework that can characterize dynamics
              using only neural data, without the need for supervisory
              information. This enables inference of dynamics out-of-the-box in
              diverse brain areas and behaviors, which we demonstrate on
              several datasets: motor cortex during free-paced reaching,
              somatosensory cortex during reaching with perturbations, and
              dorsomedial frontal cortex during cognitive timing tasks. We also
              provide a cloud software package and comprehensive tutorials that
              enable new users to apply the method without dedicated computing
              resources. \#\#\# Competing Interest Statement The authors have
              declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2021.01.13.426570",
  month    =  jun,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2021.01.13.426570"
}

@ARTICLE{Mudrik2022-mz,
  title         = "Decomposed Linear Dynamical Systems ({dLDS}) for learning
                   the latent components of neural dynamics",
  author        = "Mudrik, Noga and Chen, Yenho and Yezerets, Eva and Rozell,
                   Christopher J and Charles, Adam S",
  abstract      = "Learning interpretable representations of neural dynamics at
                   a population level is a crucial first step to understanding
                   how neural activity relates to perception and behavior.
                   Models of neural dynamics often focus on either
                   low-dimensional projections of neural activity, or on
                   learning dynamical systems that explicitly relate to the
                   neural state over time. We discuss how these two approaches
                   are interrelated by considering dynamical systems as
                   representative of flows on a low-dimensional manifold.
                   Building on this concept, we propose a new decomposed
                   dynamical system model that represents complex
                   non-stationary and nonlinear dynamics of time-series data as
                   a sparse combination of simpler, more interpretable
                   components. The decomposed nature of the dynamics
                   generalizes over previous switched approaches and enables
                   modeling of overlapping and non-stationary drifts in the
                   dynamics. We further present a dictionary learning-driven
                   approach to model fitting, where we leverage recent results
                   in tracking sparse vectors over time. We demonstrate that
                   our model can learn efficient representations and smooth
                   transitions between dynamical modes in both continuous-time
                   and discrete-time examples. We show results on
                   low-dimensional linear and nonlinear attractors to
                   demonstrate that our decomposed dynamical systems model can
                   well approximate nonlinear dynamics. Additionally, we apply
                   our model to C. elegans data, illustrating a diversity of
                   dynamics that is obscured when classified into discrete
                   states.",
  month         =  jun,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2206.02972",
  primaryClass  = "stat.ML",
  arxivid       = "2206.02972"
}

@UNPUBLISHED{Barreiro2022-ql,
  title    = "Sensory input to cortex encoded on low-dimensional
              periphery-correlated subspaces",
  author   = "Barreiro, Andrea K and Ly, Cheng and Raju, Prashant and Gautam,
              Shree Hari and Shew, Woodrow L",
  abstract = "As information about the world is conveyed from the sensory
              periphery to central neural circuits, it mixes with complex
              ongoing cortical activity. How do neural populations keep track
              of sensory signals, separating them from noisy ongoing activity?
              Here we show that sensory signals are encoded more reliably, with
              less noise in certain low-dimensional subspaces. These coding
              subspaces are defined by correlations between simultaneously
              recorded neural activity in primary sensory cortex and upstream
              sensory brain regions; the most correlated dimensions were best
              for decoding. We analytically predicted and experimentally
              confirmed that coding subspaces can be further improved when
              defined based on populations with lower noise correlations
              between cortex and upstream regions. We show that this principle
              generalizes across diverse sensory stimuli in the olfactory
              system and the visual system of awake mice. Our results suggest
              the cortex may multiplex different functions by executing them in
              different low dimensional subspaces. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.06.15.496327",
  month    =  jun,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.06.15.496327"
}

@ARTICLE{Widloski_undated-xu,
  title    = "Thesis",
  author   = "Widloski, John Eric",
  keywords = "To Read;BCI"
}

@ARTICLE{Downey2018-be,
  title    = "Intracortical recording stability in human brain-computer
              interface users",
  author   = "Downey, John E and Schwed, Nathaniel and Chase, Steven M and
              Schwartz, Andrew B and Collinger, Jennifer L",
  abstract = "OBJECTIVE: Intracortical brain-computer interfaces (BCIs) are
              being developed to assist people with motor disabilities in
              communicating and interacting with the world around them. This
              technology relies on recordings from the primary motor cortex,
              which may vary from day to day. APPROACH: Here we quantify, in
              two long-term BCI subjects, the length of time that action
              potentials from the same neuron, or group of neurons, can be
              recorded from the motor cortex. MAIN RESULTS: These action
              potentials are identified by their extracellular waveforms and
              may change within a single day, although some of these identified
              units can be identified consistently for weeks and even months.
              Features of the extracellular waveforms allowed us to predict
              whether a specific unit was more or less likely to remain stable
              over a prolonged period. SIGNIFICANCE: A greater understanding of
              unit stability and instability can aid the development of motor
              BCIs, where the goal is to maintain a high level of performance
              despite changes in the recorded population. BCIs should be able
              to be operated without technician intervention for hours, and
              hopefully days, to provide the most benefit to the end-users of
              this technology.",
  journal  = "J. Neural Eng.",
  volume   =  15,
  number   =  4,
  pages    = "046016",
  month    =  aug,
  year     =  2018,
  keywords = "To Read;BCI",
  language = "en",
  issn     = "1741-2560, 1741-2552",
  pmid     = "29553484",
  doi      = "10.1088/1741-2552/aab7a0"
}

@ARTICLE{Yoon2013-dr,
  title    = "Specific evidence of low-dimensional continuous attractor
              dynamics in grid cells",
  author   = "Yoon, Kijung and Buice, Michael A and Barry, Caswell and Hayman,
              Robin and Burgess, Neil and Fiete, Ila R",
  abstract = "We examined simultaneously recorded spikes from multiple rat grid
              cells, to explain mechanisms underlying their activity. Among
              grid cells with similar spatial periods, the population activity
              was confined to lie close to a two-dimensional (2D) manifold:
              grid cells differed only along two dimensions of their responses
              and otherwise were nearly identical. Relationships between cell
              pairs were conserved despite extensive deformations of
              single-neuron responses. Results from novel environments suggest
              such structure is not inherited from hippocampal or external
              sensory inputs. Across conditions, cell-cell relationships are
              better conserved than responses of single cells. Finally, the
              system is continually subject to perturbations that, were the 2D
              manifold not attractive, would drive the system to inhabit a
              different region of state space than observed. These findings
              have strong implications for theories of grid-cell activity and
              substantiate the general hypothesis that the brain computes using
              low-dimensional continuous attractors.",
  journal  = "Nat. Neurosci.",
  volume   =  16,
  number   =  8,
  pages    = "1077--1084",
  month    =  aug,
  year     =  2013,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "23852111",
  doi      = "10.1038/nn.3450",
  pmc      = "PMC3797513"
}

@ARTICLE{Lopes2015-ml,
  title     = "Bonsai: an event-based framework for processing and controlling
               data streams",
  author    = "Lopes, Gon{\c c}alo and Bonacchi, Niccol{\`o} and Fraz{\~a}o,
               Jo{\~a}o and Neto, Joana P and Atallah, Bassam V and Soares,
               Sofia and Moreira, Lu{\'\i}s and Matias, Sara and Itskov, Pavel
               M and Correia, Patr{\'\i}cia A and Medina, Roberto E and
               Calcaterra, Lorenza and Dreosti, Elena and Paton, Joseph J and
               Kampff, Adam R",
  abstract  = "The design of modern scientific experiments requires the control
               and monitoring of many different data streams. However, the
               serial execution of programming instructions in a computer makes
               it a challenge to develop software that can deal with the
               asynchronous, parallel nature of scientific data. Here we
               present Bonsai, a modular, high-performance, open-source visual
               programming framework for the acquisition and online processing
               of data streams. We describe Bonsai's core principles and
               architecture and demonstrate how it allows for the rapid and
               flexible prototyping of integrated experimental designs in
               neuroscience. We specifically highlight some applications that
               require the combination of many different hardware and software
               components, including video tracking of behavior,
               electrophysiology and closed-loop control of stimulation.",
  journal   = "Front. Neuroinform.",
  publisher = "frontiersin.org",
  volume    =  9,
  pages     = "7",
  month     =  apr,
  year      =  2015,
  keywords  = "behavior control; data acquisition system; data stream
               processing; electrophysiology; open-source; parallel processing;
               rapid prototyping; video tracking",
  language  = "en",
  issn      = "1662-5196",
  pmid      = "25904861",
  doi       = "10.3389/fninf.2015.00007",
  pmc       = "PMC4389726"
}

@ARTICLE{Wachter2006-wt,
  title    = "On the implementation of an interior-point filter line-search
              algorithm for large-scale nonlinear programming",
  author   = "W{\"a}chter, Andreas and Biegler, Lorenz T",
  abstract = "We present a primal-dual interior-point algorithm with a filter
              line-search method for nonlinear programming. Local and global
              convergence properties of this method were analyzed in previous
              work. Here we provide a comprehensive description of the
              algorithm, including the feasibility restoration phase for the
              filter method, second-order corrections, and inertia correction
              of the KKT matrix. Heuristics are also considered that allow
              faster performance. This method has been implemented in the IPOPT
              code, which we demonstrate in a detailed numerical study based on
              954 problems from the CUTEr test set. An evaluation is made of
              several line-search options, and a comparison is provided with
              two state-of-the-art interior-point codes for nonlinear
              programming.",
  journal  = "Math. Program.",
  volume   =  106,
  number   =  1,
  pages    = "25--57",
  month    =  mar,
  year     =  2006,
  issn     = "0025-5610, 1436-4646",
  doi      = "10.1007/s10107-004-0559-y"
}

@ARTICLE{Neidinger2010-tm,
  title     = "Introduction to Automatic Differentiation and {MATLAB}
               {Object-Oriented} Programming",
  author    = "Neidinger, Richard D",
  abstract  = "An introduction to both automatic differentiation and
               object-oriented programming can enrich a numerical analysis
               course that typically incorporates numerical differentiation and
               basic MATLAB computation. Automatic differentiation consists of
               exact algorithms on floating-point arguments. This
               implementation overloads standard elementary operators and
               functions in MATLAB with a derivative rule in addition to the
               function value; for example, $\sin u$ will also compute $(\cos
               u)\ast u^\{\prime\}$, where u and $u^\{\prime \}$ are numerical
               values. These methods are mostly one-line programs that operate
               on a class of value-and-derivative objects, providing a simple
               example of object-oriented programming in MATLAB using the new
               (as of release 2008a) class definition structure. The resulting
               powerful tool computes derivative values and multivariable
               gradients, and is applied to Newton's method for root-finding in
               both single and multivariable settings. To compute higher-order
               derivatives of a single-variable function, another class of
               series objects keeps Taylor polynomial coefficients up to some
               order. Overloading multiplication on series objects is a
               combination (discrete convolution) of coefficients. This idea
               leads to algorithms for other operations and functions on series
               objects. A survey of more advanced topics in automatic
               differentiation includes an introduction to the reverse mode
               (our implementation is forward mode) and considerations in
               arbitrary-order multivariable series computation.",
  journal   = "SIAM Rev.",
  publisher = "Society for Industrial and Applied Mathematics",
  volume    =  52,
  number    =  3,
  pages     = "545--563",
  month     =  jan,
  year      =  2010,
  issn      = "0036-1445",
  doi       = "10.1137/080743627"
}

@ARTICLE{Dunning2017-ji,
  title     = "{JuMP}: A Modeling Language for Mathematical Optimization",
  author    = "Dunning, Iain and Huchette, Joey and Lubin, Miles",
  abstract  = "JuMP is an open-source modeling language that allows users to
               express a wide range of optimization problems (linear,
               mixed-integer, quadratic, conic-quadratic, semidefinite, and
               nonlinear) in a high-level, algebraic syntax. JuMP takes
               advantage of advanced features of the Julia programming language
               to offer unique functionality while achieving performance on par
               with commercial modeling tools for standard tasks. In this work
               we will provide benchmarks, present the novel aspects of the
               implementation, and discuss how JuMP can be extended to new
               problem classes and composed with state-of-the-art tools for
               visualization and interactivity.",
  journal   = "SIAM Rev.",
  publisher = "Society for Industrial and Applied Mathematics",
  volume    =  59,
  number    =  2,
  pages     = "295--320",
  month     =  jan,
  year      =  2017,
  issn      = "0036-1445",
  doi       = "10.1137/15M1020575"
}

@ARTICLE{Pulsipher2021-cb,
  title         = "A Unifying Modeling Abstraction for {Infinite-Dimensional}
                   Optimization",
  author        = "Pulsipher, Joshua L and Zhang, Weiqi and Hongisto, Tyler J
                   and Zavala, Victor M",
  abstract      = "Infinite-dimensional optimization (InfiniteOpt) problems
                   involve modeling components (variables, objectives, and
                   constraints) that are functions defined over
                   infinite-dimensional domains. Examples include
                   continuous-time dynamic optimization (time is an infinite
                   domain and components are a function of time), PDE
                   optimization problems (space and time are infinite domains
                   and components are a function of space-time), as well as
                   stochastic and semi-infinite optimization (random space is
                   an infinite domain and components are a function of such
                   random space). InfiniteOpt problems also arise from
                   combinations of these problem classes (e.g., stochastic PDE
                   optimization). Given the infinite-dimensional nature of
                   objectives and constraints, one often needs to define
                   appropriate quantities (measures) to properly pose the
                   problem. Moreover, InfiniteOpt problems often need to be
                   transformed into a finite dimensional representation so that
                   they can be solved numerically. In this work, we present a
                   unifying abstraction that facilitates the modeling,
                   analysis, and solution of InfiniteOpt problems. The proposed
                   abstraction enables a general treatment of
                   infinite-dimensional domains and provides a measure-centric
                   paradigm to handle associated variables, objectives, and
                   constraints. This abstraction allows us to transfer
                   techniques across disciplines and with this identify new,
                   interesting, and useful modeling paradigms (e.g., event
                   constraints and risk measures defined over time domains).
                   Our abstraction serves as the backbone of an intuitive
                   Julia-based modeling package that we call InfiniteOpt.jl. We
                   demonstrate the developments using diverse case studies
                   arising in engineering.",
  month         =  jun,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2106.12689",
  primaryClass  = "math.OC",
  arxivid       = "2106.12689"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Astrom2008-si,
  title     = "Feedback systems",
  author    = "{{\AA}str{\"o}m} and {Murray}",
  abstract  = "… the feedback loop using the algebra for a feedback … the
               feedback ). This type of rule can be used to compute transfer
               functions by inspection, although for systems with multiple
               feedback …",
  journal   = "Princeton Univ. Libr. Chron.",
  publisher = "cds.caltech.edu",
  year      =  2008,
  issn      = "0032-8456"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Bishop2001-iv,
  title     = "An introduction to the kalman filter",
  author    = "{Bishop} and {Welch}",
  abstract  = "… Kalman filter is offered in Chapter 1 of (Maybeck
               1979)---which is available from the above Kalman filter …
               maintained a web site dedicated to the Kalman filter . This site
               contains links to …",
  journal   = "Proc of SIGGRAPH, Course",
  publisher = "academia.edu",
  year      =  2001
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Claudi2022-gn,
  title     = "Innate heuristics and fast learning support escape route
               selection in mice",
  author    = "Claudi, Federico and Campagner, Dario and Branco, Tiago",
  abstract  = "When faced with imminent danger, animals must rapidly take
               defensive actions to reach safety. Mice can react to threatening
               stimuli in ∼250 milliseconds1 and, in simple environments, use
               spatial memory to quickly escape to shelter.2,3 Natural
               habitats, however, often offer multiple routes to safety that
               animals must identify and choose from.4 This is challenging
               because although rodents can learn to navigate complex mazes,5,6
               learning the value of different routes through trial and error
               during escape could be deadly. Here, we investigated how mice
               learn to choose between different escape routes. Using
               environments with paths to shelter of varying length and
               geometry, we find that mice prefer options that minimize path
               distance and angle relative to the shelter. This strategy is
               already present during the first threat encounter and after only
               ∼10 minutes of exploration in a novel environment, indicating
               that route selection does not require experience of escaping.
               Instead, an innate heuristic assigns survival value to each path
               after rapidly learning the spatial environment. This route
               selection process is flexible and allows quick adaptation to
               arenas with dynamic geometries. Computational modeling shows
               that model-based reinforcement learning agents replicate the
               observed behavior in environments where the shelter location is
               rewarding during exploration. These results show that mice
               combine fast spatial learning with innate heuristics to choose
               escape routes with the highest survival value. The results
               further suggest that integrating prior knowledge acquired
               through evolution with knowledge learned from experience
               supports adaptation to changing environments and minimizes the
               need for trial and error when the errors are costly.",
  journal   = "Curr. Biol.",
  publisher = "Elsevier",
  month     =  may,
  year      =  2022,
  keywords  = "escape; fast learning; innate behavior; mouse; reinforcement
               learning; route selection; shelter",
  language  = "en",
  issn      = "0960-9822, 1879-0445",
  pmid      = "35617953",
  doi       = "10.1016/j.cub.2022.05.020"
}

@ARTICLE{Gomez-Marin2014-ni,
  title     = "Big behavioral data: psychology, ethology and the foundations of
               neuroscience",
  author    = "Gomez-Marin, Alex and Paton, Joseph J and Kampff, Adam R and
               Costa, Rui M and Mainen, Zachary F",
  abstract  = "Behavior is a unifying organismal process where genes, neural
               function, anatomy and environment converge and interrelate. Here
               we review the current state and discuss the future effect of
               accelerating advances in technology for behavioral studies,
               focusing on rodents as an example. We frame our perspective in
               three dimensions: the degree of experimental constraint,
               dimensionality of data and level of description. We argue that
               'big behavioral data' presents challenges proportionate to its
               promise and describe how these challenges might be met through
               opportunities afforded by the two rival conceptual legacies of
               twentieth century behavioral science, ethology and psychology.
               We conclude that, although 'more is not necessarily better',
               copious, quantitative and open behavioral data has the potential
               to transform and unify these two disciplines and to solidify the
               foundations of others, including neuroscience, but only if the
               development of new theoretical frameworks and improved
               experimental designs matches the technological progress.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  17,
  number    =  11,
  pages     = "1455--1462",
  month     =  nov,
  year      =  2014,
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "25349912",
  doi       = "10.1038/nn.3812"
}

@ARTICLE{Carpentier2021-yh,
  title     = "Recent Progress in Legged Robots Locomotion Control",
  author    = "Carpentier, Justin and Wieber, Pierre-Brice",
  abstract  = "In recent years, legged robots locomotion has been transitioning
               from mostly flat ground in controlled settings to generic indoor
               and outdoor environments, approaching now real industrial
               scenarios. This paper aims at documenting some of the key
               progress made in legged locomotion control that enabled this
               transition.",
  journal   = "Current Robotics Reports",
  publisher = "Springer",
  volume    =  2,
  number    =  3,
  pages     = "231--238",
  month     =  sep,
  year      =  2021,
  issn      = "2662-4087",
  doi       = "10.1007/s43154-021-00059-0"
}

@ARTICLE{Buschmann2015-gv,
  title     = "Controlling legs for locomotion---insights from robotics and
               neurobiology",
  author    = "Buschmann, Thomas and Ewald, Alexander and von Twickel, Arndt
               and B{\"u}schges, Ansgar",
  abstract  = "Walking is the most common terrestrial form of locomotion in
               animals. Its great versatility and flexibility has led to many
               attempts at building walking machines with similar capabilities.
               The control of walking is an active research area both in
               neurobiology and robotics, with a large and growing body of
               work. This paper gives an overview of the current knowledge on
               the control of legged locomotion in animals and machines and
               attempts to give walking control researchers from biology and
               robotics an overview of the current knowledge in both fields. We
               try to summarize the knowledge on the neurobiological basis of
               walking control in animals, emphasizing common principles seen
               in different species. In a section on walking robots, we review
               common approaches to walking controller design with a slight
               emphasis on biped walking control. We show where parallels
               between robotic and neurobiological walking controllers exist
               and how robotics and biology may benefit from each other.
               Finally, we discuss where research in the two fields diverges
               and suggest ways to bridge these gaps.",
  journal   = "Bioinspir. Biomim.",
  publisher = "IOP Publishing",
  volume    =  10,
  number    =  4,
  pages     = "041001",
  month     =  jun,
  year      =  2015,
  language  = "en",
  issn      = "1748-3182, 1748-3190",
  doi       = "10.1088/1748-3190/10/4/041001"
}

@ARTICLE{Saibene2003-am,
  title     = "Biomechanical and physiological aspects of legged locomotion in
               humans",
  author    = "Saibene, Franco and Minetti, Alberto E",
  abstract  = "Walking and running, the two basic gaits used by man, are very
               complex movements. They can, however, be described using two
               simple models: an inverted pendulum and a spring. Muscles must
               contract at each step to move the body segments in the proper
               sequence but the work done is, in part, relieved by the
               interplay of mechanical energies, potential and kinetic in
               walking, and elastic in running. This explains why there is an
               optimal speed of walking (minimal metabolic cost of about 2
               J.kg(-1).m(-1) at about 1.11 m.s(-1)) and why the cost of
               running is constant and independent of speed (about 4
               J.kg(-1).m(-1)). Historically, the mechanical work of locomotion
               has been divided into external and internal work. The former is
               the work done to raise and accelerate the body centre of mass
               (m) within the environment, the latter is the work done to
               accelerate the body segments with respect to the centre of m.
               The total work has been calculated, somewhat arbitrarily, as the
               sum of the two. While the changes of potential and kinetic
               energies can be accurately measured, the contribution of the
               elastic energy cannot easily be assessed, nor can the true work
               performed by the muscles. Many factors can affect the work of
               locomotion--the gradient of the terrain, body size (height and
               body m), and gravity. The partitioning of positive and negative
               work and their different efficiencies explain why the most
               economical gradient is about -10\% (1.1 J.kg(-1).m(-1) at 1.3
               m.s(-1) for walking, and 3.1 J.kg(-1).m(-1) at between 3 and 4
               m.s(-1) for running). The mechanics of walking of children,
               pigmies and dwarfs, in particular the recovery of energy at each
               step, is not different from that of taller (normal sized)
               individuals when the speed is expressed in dynamically
               equivalent terms (Froude number). An extra load, external or
               internal (obesity) affects internal and external work according
               to the distribution of the added m. Different gravitational
               environments determine the optimal speed of walking and the
               speed of transition from walking to running: at more than 1 g it
               is easier to walk than to run, and it is the opposite at less
               than 1 g. Passive aids, such as skis or skates, allow an
               increase in the speed of progression, but the mechanics of the
               locomotion cannot be simply described using the models for
               walking and running because step frequency, the proportion of
               step duration during which the foot is in contact with the
               ground, the position of the limbs, the force exerted on the
               ground and the time of its application are all different.",
  journal   = "Eur. J. Appl. Physiol.",
  publisher = "Springer",
  volume    =  88,
  number    = "4-5",
  pages     = "297--316",
  month     =  jan,
  year      =  2003,
  language  = "en",
  issn      = "1439-6319",
  pmid      = "12527959",
  doi       = "10.1007/s00421-002-0654-9"
}

@ARTICLE{Claudi2021-tn,
  title     = "Visualizing anatomically registered data with brainrender",
  author    = "Claudi, Federico and Tyson, Adam L and Petrucco, Luigi and
               Margrie, Troy W and Portugues, Ruben and Branco, Tiago",
  abstract  = "Three-dimensional (3D) digital brain atlases and high-throughput
               brain-wide imaging techniques generate large multidimensional
               datasets that can be registered to a common reference frame.
               Generating insights from such datasets depends critically on
               visualization and interactive data exploration, but this a
               challenging task. Currently available software is dedicated to
               single atlases, model species or data types, and generating 3D
               renderings that merge anatomically registered data from diverse
               sources requires extensive development and programming skills.
               Here, we present brainrender: an open-source Python package for
               interactive visualization of multidimensional datasets
               registered to brain atlases. Brainrender facilitates the
               creation of complex renderings with different data types in the
               same visualization and enables seamless use of different atlas
               sources. High-quality visualizations can be used interactively
               and exported as high-resolution figures and animated videos. By
               facilitating the visualization of anatomically registered data,
               brainrender should accelerate the analysis, interpretation, and
               dissemination of brain-wide multidimensional data.",
  journal   = "Elife",
  publisher = "elifesciences.org",
  volume    =  10,
  month     =  mar,
  year      =  2021,
  keywords  = "anatomy; data visualization; neuroscience; none; open source;
               software",
  language  = "en",
  issn      = "2050-084X",
  pmid      = "33739286",
  doi       = "10.7554/eLife.65751",
  pmc       = "PMC8079143"
}

@ARTICLE{LeCun2015-ex,
  title     = "Deep learning",
  author    = "LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey",
  abstract  = "Deep learning allows computational models that are composed of
               multiple processing layers to learn representations of data with
               multiple levels of abstraction. These methods have dramatically
               improved the state-of-the-art in speech recognition, visual
               object recognition, object detection and many other domains such
               as drug discovery and genomics. Deep learning discovers
               intricate structure in large data sets by using the
               backpropagation algorithm to indicate how a machine should
               change its internal parameters that are used to compute the
               representation in each layer from the representation in the
               previous layer. Deep convolutional nets have brought about
               breakthroughs in processing images, video, speech and audio,
               whereas recurrent nets have shone light on sequential data such
               as text and speech.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  521,
  number    =  7553,
  pages     = "436--444",
  month     =  may,
  year      =  2015,
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "26017442",
  doi       = "10.1038/nature14539"
}

@BOOK{Goodfellow2016-sd,
  title     = "Deep Learning",
  author    = "Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron",
  abstract  = "An introduction to a broad range of topics in deep learning,
               covering mathematical and conceptual background, deep learning
               techniques used in industry, and research perspectives.``Written
               by three experts in the field, Deep Learning is the only
               comprehensive book on the subject.''---Elon Musk, cochair of
               OpenAI; cofounder and CEO of Tesla and SpaceXDeep learning is a
               form of machine learning that enables computers to learn from
               experience and understand the world in terms of a hierarchy of
               concepts. Because the computer gathers knowledge from
               experience, there is no need for a human computer operator to
               formally specify all the knowledge that the computer needs. The
               hierarchy of concepts allows the computer to learn complicated
               concepts by building them out of simpler ones; a graph of these
               hierarchies would be many layers deep. This book introduces a
               broad range of topics in deep learning. The text offers
               mathematical and conceptual background, covering relevant
               concepts in linear algebra, probability theory and information
               theory, numerical computation, and machine learning. It
               describes deep learning techniques used by practitioners in
               industry, including deep feedforward networks, regularization,
               optimization algorithms, convolutional networks, sequence
               modeling, and practical methodology; and it surveys such
               applications as natural language processing, speech recognition,
               computer vision, online recommendation systems, bioinformatics,
               and videogames. Finally, the book offers research perspectives,
               covering such theoretical topics as linear factor models,
               autoencoders, representation learning, structured probabilistic
               models, Monte Carlo methods, the partition function, approximate
               inference, and deep generative models. Deep Learning can be used
               by undergraduate or graduate students planning careers in either
               industry or research, and by software engineers who want to
               begin using deep learning in their products or platforms. A
               website offers supplementary material for both readers and
               instructors.",
  publisher = "MIT Press",
  month     =  nov,
  year      =  2016,
  language  = "en",
  isbn      = "9780262337373"
}

@ARTICLE{Mirhoseini2020-jf,
  title         = "Chip Placement with Deep Reinforcement Learning",
  author        = "Mirhoseini, Azalia and Goldie, Anna and Yazgan, Mustafa and
                   Jiang, Joe and Songhori, Ebrahim and Wang, Shen and Lee,
                   Young-Joon and Johnson, Eric and Pathak, Omkar and Bae,
                   Sungmin and Nazi, Azade and Pak, Jiwoo and Tong, Andy and
                   Srinivasa, Kavya and Hang, William and Tuncer, Emre and
                   Babu, Anand and Le, Quoc V and Laudon, James and Ho, Richard
                   and Carpenter, Roger and Dean, Jeff",
  abstract      = "In this work, we present a learning-based approach to chip
                   placement, one of the most complex and time-consuming stages
                   of the chip design process. Unlike prior methods, our
                   approach has the ability to learn from past experience and
                   improve over time. In particular, as we train over a greater
                   number of chip blocks, our method becomes better at rapidly
                   generating optimized placements for previously unseen chip
                   blocks. To achieve these results, we pose placement as a
                   Reinforcement Learning (RL) problem and train an agent to
                   place the nodes of a chip netlist onto a chip canvas. To
                   enable our RL policy to generalize to unseen blocks, we
                   ground representation learning in the supervised task of
                   predicting placement quality. By designing a neural
                   architecture that can accurately predict reward across a
                   wide variety of netlists and their placements, we are able
                   to generate rich feature embeddings of the input netlists.
                   We then use this architecture as the encoder of our policy
                   and value networks to enable transfer learning. Our
                   objective is to minimize PPA (power, performance, and area),
                   and we show that, in under 6 hours, our method can generate
                   placements that are superhuman or comparable on modern
                   accelerator netlists, whereas existing baselines require
                   human experts in the loop and take several weeks.",
  month         =  apr,
  year          =  2020,
  archivePrefix = "arXiv",
  eprint        = "2004.10746",
  primaryClass  = "cs.LG",
  arxivid       = "2004.10746"
}

@ARTICLE{Mirhoseini2021-eb,
  title    = "A graph placement methodology for fast chip design",
  author   = "Mirhoseini, Azalia and Goldie, Anna and Yazgan, Mustafa and
              Jiang, Joe Wenjie and Songhori, Ebrahim and Wang, Shen and Lee,
              Young-Joon and Johnson, Eric and Pathak, Omkar and Nazi, Azade
              and Pak, Jiwoo and Tong, Andy and Srinivasa, Kavya and Hang,
              William and Tuncer, Emre and Le, Quoc V and Laudon, James and Ho,
              Richard and Carpenter, Roger and Dean, Jeff",
  abstract = "Chip floorplanning is the engineering task of designing the
              physical layout of a computer chip. Despite five decades of
              research1, chip floorplanning has defied automation, requiring
              months of intense effort by physical design engineers to produce
              manufacturable layouts. Here we present a deep reinforcement
              learning approach to chip floorplanning. In under six hours, our
              method automatically generates chip floorplans that are superior
              or comparable to those produced by humans in all key metrics,
              including power consumption, performance and chip area. To
              achieve this, we pose chip floorplanning as a reinforcement
              learning problem, and develop an edge-based graph convolutional
              neural network architecture capable of learning rich and
              transferable representations of the chip. As a result, our method
              utilizes past experience to become better and faster at solving
              new instances of the problem, allowing chip design to be
              performed by artificial agents with more experience than any
              human designer. Our method was used to design the next generation
              of Google's artificial intelligence (AI) accelerators, and has
              the potential to save thousands of hours of human effort for each
              new generation. Finally, we believe that more powerful
              AI-designed hardware will fuel advances in AI, creating a
              symbiotic relationship between the two fields.",
  journal  = "Nature",
  volume   =  594,
  number   =  7862,
  pages    = "207--212",
  month    =  jun,
  year     =  2021,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "34108699",
  doi      = "10.1038/s41586-021-03544-w"
}

@ARTICLE{Jumper2021-lt,
  title    = "Highly accurate protein structure prediction with {AlphaFold}",
  author   = "Jumper, John and Evans, Richard and Pritzel, Alexander and Green,
              Tim and Figurnov, Michael and Ronneberger, Olaf and
              Tunyasuvunakool, Kathryn and Bates, Russ and {\v Z}{\'\i}dek,
              Augustin and Potapenko, Anna and Bridgland, Alex and Meyer,
              Clemens and Kohl, Simon A A and Ballard, Andrew J and Cowie,
              Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and
              Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig
              and Reiman, David and Clancy, Ellen and Zielinski, Michal and
              Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas
              and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol
              and Senior, Andrew W and Kavukcuoglu, Koray and Kohli, Pushmeet
              and Hassabis, Demis",
  abstract = "Proteins are essential to life, and understanding their structure
              can facilitate a mechanistic understanding of their function.
              Through an enormous experimental effort1-4, the structures of
              around 100,000 unique proteins have been determined5, but this
              represents a small fraction of the billions of known protein
              sequences6,7. Structural coverage is bottlenecked by the months
              to years of painstaking effort required to determine a single
              protein structure. Accurate computational approaches are needed
              to address this gap and to enable large-scale structural
              bioinformatics. Predicting the three-dimensional structure that a
              protein will adopt based solely on its amino acid sequence-the
              structure prediction component of the 'protein folding
              problem'8-has been an important open research problem for more
              than 50 years9. Despite recent progress10-14, existing methods
              fall far short of atomic accuracy, especially when no homologous
              structure is available. Here we provide the first computational
              method that can regularly predict protein structures with atomic
              accuracy even in cases in which no similar structure is known. We
              validated an entirely redesigned version of our neural
              network-based model, AlphaFold, in the challenging 14th Critical
              Assessment of protein Structure Prediction (CASP14)15,
              demonstrating accuracy competitive with experimental structures
              in a majority of cases and greatly outperforming other methods.
              Underpinning the latest version of AlphaFold is a novel machine
              learning approach that incorporates physical and biological
              knowledge about protein structure, leveraging multi-sequence
              alignments, into the design of the deep learning algorithm.",
  journal  = "Nature",
  volume   =  596,
  number   =  7873,
  pages    = "583--589",
  month    =  aug,
  year     =  2021,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "34265844",
  doi      = "10.1038/s41586-021-03819-2",
  pmc      = "PMC8371605"
}

@ARTICLE{Schultz1997-ve,
  title     = "Dopamine neurons and their role in reward mechanisms",
  author    = "Schultz, W",
  abstract  = "Information related to rewards is processed by a limited number
               of brain structures. Recent studies have demonstrated that
               dopamine neurons respond to appetitive events, such as primary
               rewards and reward-predicting stimuli. Rather than responding
               unconditionally, these neurons signal deviations from the
               prediction of future appetitive events. These reward-related
               responses correspond formally to concepts of behavioral and
               computational learning theories and may thus constitute teaching
               signals for appetitive learning.",
  journal   = "Curr. Opin. Neurobiol.",
  publisher = "Elsevier",
  volume    =  7,
  number    =  2,
  pages     = "191--197",
  month     =  apr,
  year      =  1997,
  language  = "en",
  issn      = "0959-4388",
  pmid      = "9142754",
  doi       = "10.1016/s0959-4388(97)80007-4"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Schultz1998-vt,
  title     = "The phasic reward signal of primate dopamine neurons",
  author    = "Schultz, W",
  abstract  = "Publisher Summary A majority of dopamine neurons are activated
               by phasically occurring, primary appetitive stimuli, such as
               foods and liquids, whereas the remaining neurons are not …",
  journal   = "Adv. Pharmacol.",
  publisher = "Elsevier",
  volume    =  42,
  pages     = "686--690",
  year      =  1998,
  language  = "en",
  issn      = "0568-0123, 1054-3589",
  pmid      = "9327992",
  doi       = "10.1016/s1054-3589(08)60841-8"
}

@ARTICLE{Rosenblatt1958-in,
  title     = "The perceptron: a probabilistic model for information storage
               and organization in the brain",
  author    = "Rosenblatt, F",
  abstract  = "This article will be concerned primarily with the second and
               third questions, which are still subject to a vast amount of
               speculation, and where the few relevant facts currently supplied
               by neurophysiology have not yet been integrated into an
               acceptable theory. The first of these questions is in the
               province of sensory physiology, and is the only one for which
               appreciable understanding has been achieved. This article will
               be concerned primarily with the second and third questions,
               which are still subject to a vast amount of speculation, and
               where the few relevant facts currently supplied by
               neurophysiology have not yet been integrated into an acceptable
               theory. With regard to the second question, two alternative
               positions have been maintained. The first suggests that storage
               of sensory information is in the form of coded representations
               or images, with some sort of one-to-one mapping between the
               sensory stimulus",
  journal   = "Psychol. Rev.",
  publisher = "American Psychological Association (APA)",
  volume    =  65,
  number    =  6,
  pages     = "386--408",
  month     =  nov,
  year      =  1958,
  keywords  = "PERCEPTION",
  language  = "en",
  issn      = "0033-295X, 1939-1471",
  pmid      = "13602029",
  doi       = "10.1037/h0042519"
}

@ARTICLE{Garcia-Martin2019-et,
  title    = "Estimation of energy consumption in machine learning",
  author   = "Garc{\'\i}a-Mart{\'\i}n, Eva and Rodrigues, Crefeda Faviola and
              Riley, Graham and Grahn, H{\aa}kan",
  abstract = "Energy consumption has been widely studied in the computer
              architecture field for decades. While the adoption of energy as a
              metric in machine learning is emerging, the majority of research
              is still primarily focused on obtaining high levels of accuracy
              without any computational constraint. We believe that one of the
              reasons for this lack of interest is due to their lack of
              familiarity with approaches to evaluate energy consumption. To
              address this challenge, we present a review of the different
              approaches to estimate energy consumption in general and machine
              learning applications in particular. Our goal is to provide
              useful guidelines to the machine learning community giving them
              the fundamental knowledge to use and build specific energy
              estimation methods for machine learning algorithms. We also
              present the latest software tools that give energy estimation
              values, together with two use cases that enhance the study of
              energy consumption in machine learning.",
  journal  = "J. Parallel Distrib. Comput.",
  volume   =  134,
  pages    = "75--88",
  month    =  dec,
  year     =  2019,
  keywords = "Machine learning; GreenAI; Energy consumption; Deep learning;
              High performance computing",
  issn     = "0743-7315",
  doi      = "10.1016/j.jpdc.2019.07.007"
}

@ARTICLE{Patterson2021-ss,
  title         = "Carbon Emissions and Large Neural Network Training",
  author        = "Patterson, David and Gonzalez, Joseph and Le, Quoc and
                   Liang, Chen and Munguia, Lluis-Miquel and Rothchild, Daniel
                   and So, David and Texier, Maud and Dean, Jeff",
  abstract      = "The computation demand for machine learning (ML) has grown
                   rapidly recently, which comes with a number of costs.
                   Estimating the energy cost helps measure its environmental
                   impact and finding greener strategies, yet it is challenging
                   without detailed information. We calculate the energy use
                   and carbon footprint of several recent large models-T5,
                   Meena, GShard, Switch Transformer, and GPT-3-and refine
                   earlier estimates for the neural architecture search that
                   found Evolved Transformer. We highlight the following
                   opportunities to improve energy efficiency and CO2
                   equivalent emissions (CO2e): Large but sparsely activated
                   DNNs can consume <1/10th the energy of large, dense DNNs
                   without sacrificing accuracy despite using as many or even
                   more parameters. Geographic location matters for ML workload
                   scheduling since the fraction of carbon-free energy and
                   resulting CO2e vary ~5X-10X, even within the same country
                   and the same organization. We are now optimizing where and
                   when large models are trained. Specific datacenter
                   infrastructure matters, as Cloud datacenters can be ~1.4-2X
                   more energy efficient than typical datacenters, and the
                   ML-oriented accelerators inside them can be ~2-5X more
                   effective than off-the-shelf systems. Remarkably, the choice
                   of DNN, datacenter, and processor can reduce the carbon
                   footprint up to ~100-1000X. These large factors also make
                   retroactive estimates of energy cost difficult. To avoid
                   miscalculations, we believe ML papers requiring large
                   computational resources should make energy consumption and
                   CO2e explicit when practical. We are working to be more
                   transparent about energy use and CO2e in our future
                   research. To help reduce the carbon footprint of ML, we
                   believe energy usage and CO2e should be a key metric in
                   evaluating models, and we are collaborating with MLPerf
                   developers to include energy usage during training and
                   inference in this industry standard benchmark.",
  month         =  apr,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2104.10350",
  primaryClass  = "cs.LG",
  arxivid       = "2104.10350"
}

@BOOK{McNeill_Alexander2003-dh,
  title     = "Principles of Animal Locomotion",
  author    = "McNeill Alexander, R",
  abstract  = "How can geckoes walk on the ceiling and basilisk lizards run
               over water? What are the aerodynamic effects that enable small
               insects to fly? What are the relative merits of squids'
               jet-propelled swimming and fishes' tail-powered swimming? Why do
               horses change gait as they increase speed? What determines our
               own vertical leap? Recent technical advances have greatly
               increased researchers' ability to answer these questions with
               certainty and in detail. This text provides an up-to-date
               overview of how animals run, walk, jump, crawl, swim, soar,
               hover, and fly. Excluding only the tiny creatures that use
               cilia, it covers all animals that power their movements with
               muscle--from roundworms to whales, clams to elephants, and gnats
               to albatrosses. The introduction sets out the general rules
               governing all modes of animal locomotion and considers the
               performance criteria--such as speed, endurance, and
               economy--that have shaped their selection. It introduces
               energetics and optimality as basic principles. The text then
               tackles each of the major modes by which animals move on land,
               in water, and through air. It explains the mechanisms involved
               and the physical and biological forces shaping those mechanisms,
               paying particular attention to energy costs. Focusing on general
               principles but extensively discussing a wide variety of
               individual cases, this is a superb synthesis of current
               knowledge about animal locomotion. It will be enormously useful
               to advanced undergraduates, graduate students, and a range of
               professional biologists, physicists, and engineers.",
  publisher = "Princeton University Press",
  year      =  2003,
  language  = "en",
  isbn      = "9780691086781"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@BOOK{Knudson2007-ez,
  title     = "Fundamentals of Biomechanics",
  author    = "Knudson, Duane",
  abstract  = "… 7 Chapter 3 will introduce you to qualitative diagnosis of …
               Noninvasive imaging techniques have begun to expand our … ensure
               they find all the most relevant biomechanics publications to …",
  publisher = "Springer International Publishing",
  year      =  2007,
  doi       = "10.1007/978-3-030-51838-7"
}

@BOOK{Nigg2000-gu,
  title     = "Biomechanics and Biology of Movement",
  author    = "Nigg, Benno Maurus and MacIntosh, Brian R and Mester, Joachim",
  abstract  = "Drawing on the expertise of 31 international researchers in
               biomechanics, exercise physiology, and motor behavior,
               Biomechanics and Biology of Movementprovides an integrated,
               multidisciplinary, scientific approach to understanding human
               movement. As a text, it uses an integrated scientific approach
               to explore solutions to problems in human movement. As a
               complete reference volume, it provides an overview of how energy
               and work, balance and control, load factors, fatigue, and
               exercise interact to affect performance. Edited by three
               renowned specialists in the field--Benno M. Nigg, Brian R.
               MacIntosh, and Joachim Mester--the text contains over 130
               mathematical equations to illustrate and increase understanding
               of its concepts. The editors defined the important components of
               topics such as work and energy, balance and motor control, load
               and excessive load, and fatigue and invited world-renowned
               experts in these areas to contribute from their viewpoints.
               Following an introduction highlighting the necessity of an
               interdisciplinary approach incorporating biology, biomechanics,
               biochemistry, physics, physiology, and other sciences,
               Biomechanics and Biology of Movement provides a four-part
               approach to problem solving arising from various movement,
               exercise, and sport sciences. Each part opens with a chronology
               of major events in research history and ends with a summary and
               a glossary of key terms. Part Iexamines chemical, mechanical,
               physiological, electrical, thermal, and other energy forms, and
               their interrelationship and transformation in order to produce
               optimal performance. Sport shoes, the pole used in pole
               vaulting, and specialized surfaces that allow storage and return
               of energy to the athlete serve as examples of how these energy
               factors work together and affect an athlete's performance. Part
               IIdiscusses how balance, motor control systems, and, most
               importantly, gravity interact to produce all human movement.
               This section also includes methods for applying these insights
               to individual performance situations. Part IIIexplores the
               importance of mechanical load and force as well as their impact,
               both internal and external, on specific physical structures and
               systems, activities, and overall health. Strategies for
               preventing or reducing injuries and enhancing performance are
               also included. Finally, Part IV explores the interplay among
               exercise, muscle fatigue, and methods for its detection as well
               as some results of muscle fatigue such as impaired mobility and
               the potential for injury. Readers will also learn how to apply
               integrated scientific research to -optimize muscle function,
               -enhance energy balance for physical activities, -prevent
               injuries in athletes, -prolong physical ability in active, older
               adults, -rehabilitate joint instability, -increase muscular
               endurance, -discover limits of performance due to fatigue, and
               -resolve other problems in human movement. Whatever your
               situation--biomechanist, physiologist, therapist, trainer, or
               student--Biomechanics and Biology of Movementoffers you a
               thorough overview of biomechanics, exercise physiology, and
               motor behavior; how they impact human movement; and how an
               increased appreciation of their importance can enhance
               performance.",
  publisher = "Human Kinetics",
  year      =  2000,
  language  = "en",
  isbn      = "9780736003315"
}

@ARTICLE{Glad2000-ks,
  title     = "Control Theory. Multivariable and Nonlinear Methods Taylor and
               Francis, London, 2000",
  author    = "Glad, T and Ljung, L",
  abstract  = "The book is divided into three parts: linear systems, linear
               control theory, nonlinear control theory. All aspects of
               continuous and discrete systems are covered, including the
               theory and the methodology. The book is intended for readers
               already familiar with linear time-invariant systems with one
               input and one output. However, I am sure it can easily be
               understood without this prerequisite.",
  journal   = "Numer. Algorithms",
  publisher = "Springer Nature",
  volume    =  23,
  number    =  4,
  pages     = "407--408",
  year      =  2000,
  issn      = "1017-1398, 1572-9265",
  doi       = "10.1023/a:1019124722555"
}

@ARTICLE{Sutton1992-bc,
  title     = "Reinforcement learning is direct adaptive optimal control",
  author    = "Sutton, R S and Barto, A G and Williams, R J",
  abstract  = "Neural network reinforcement learning methods are described and
               considered as a direct approach to adaptive optimal control of
               nonlinear systems. These methods have their roots in studies of
               animal learning and in early learning control work. An emerging
               deeper understanding of these methods is summarized that is
               obtained by viewing them as a synthesis of dynamic programming
               and stochastic approximation methods. The focus is on Q-learning
               systems, which maintain estimates of utilities for all
               state-action pairs and make use of these estimates to select
               actions. The use of hybrid direct/indirect methods is briefly
               discussed.>",
  journal   = "IEEE Control Syst. Mag.",
  publisher = "ieeexplore.ieee.org",
  volume    =  12,
  number    =  2,
  pages     = "19--22",
  month     =  apr,
  year      =  1992,
  keywords  = "Learning;Programmable control;Adaptive control;Optimal
               control;State estimation;Neural networks;Nonlinear
               systems;Animals;Control system synthesis;Dynamic programming",
  issn      = "1941-000X",
  doi       = "10.1109/37.126844"
}

@BOOK{Bertsekas2019-as,
  title     = "Reinforcement Learning and Optimal Control",
  author    = "Bertsekas, Dimitri",
  abstract  = "This book considers large and challenging multistage decision
               problems, which can be solved in principle by dynamic
               programming (DP), but their exact solution is computationally
               intractable. We discuss solution methods that rely on
               approximations to produce suboptimal policies with adequate
               performance. These methods are collectively known by several
               essentially equivalent names: reinforcement learning,
               approximate dynamic programming, neuro-dynamic programming. They
               have been at the forefront of research for the last 25 years,
               and they underlie, among others, the recent impressive successes
               of self-learning in the context of games such as chess and
               Go.Our subject has benefited greatly from the interplay of ideas
               from optimal control and from artificial intelligence, as it
               relates to reinforcement learning and simulation-based neural
               network methods. One of the aims of the book is to explore the
               common boundary between these two fields and to form a bridge
               that is accessible by workers with background in either field.
               Another aim is to organize coherently the broad mosaic of
               methods that have proved successful in practice while having a
               solid theoretical and/or logical foundation. This may help
               researchers and practitioners to find their way through the maze
               of competing ideas that constitute the current state of the
               art.This book relates to several of our other books:
               Neuro-Dynamic Programming (Athena Scientific, 1996), Dynamic
               Programming and Optimal Control (4th edition, Athena Scientific,
               2017), Abstract Dynamic Programming (2nd edition, Athena
               Scientific, 2018), and Nonlinear Programming (Athena Scientific,
               2016). However, the mathematical style of this book is somewhat
               different. While we provide a rigorous, albeit short,
               mathematical account of the theory of finite and infinite
               horizon dynamic programming, and some fundamental approximation
               methods, we rely more on intuitive explanations and less on
               proof-based insights. Moreover, our mathematical requirements
               are quite modest: calculus, a minimal use of matrix-vector
               algebra, and elementary probability (mathematically complicated
               arguments involving laws of large numbers and stochastic
               convergence are bypassed in favor of intuitive explanations).The
               book illustrates the methodology with many examples and
               illustrations, and uses a gradual expository approach, which
               proceeds along four directions:(a) From exact DP to approximate
               DP: We first discuss exact DP algorithms, explain why they may
               be difficult to implement, and then use them as the basis for
               approximations.(b) From finite horizon to infinite horizon
               problems: We first discuss finite horizon exact and approximate
               DP methodologies, which are intuitive and mathematically simple,
               and then progress to infinite horizon problems.(c) From
               deterministic to stochastic models: We often discuss separately
               deterministic and stochastic problems, since deterministic
               problems are simpler and offer special advantages for some of
               our methods.(d) From model-based to model-free implementations:
               We first discuss model-based implementations, and then we
               identify schemes that can be appropriately modified to work with
               a simulator.The book is related and supplemented by the
               companion research monograph Rollout, Policy Iteration, and
               Distributed Reinforcement Learning (Athena Scientific, 2020),
               which focuses more closely on several topics related to rollout,
               approximate policy iteration, multiagent problems, discrete and
               Bayesian optimization, and distributed computation, which are
               either discussed in less detail or not covered at all in the
               present book.The author's website contains class notes, and a
               series of videolectures and slides from a 2021 course at ASU,
               which address a selection of topics from both books.",
  publisher = "Athena Scientific",
  month     =  jul,
  year      =  2019,
  language  = "en",
  isbn      = "9781886529397"
}

@ARTICLE{Tyson2022-rc,
  title    = "Accurate determination of marker location within whole-brain
              microscopy images",
  author   = "Tyson, Adam L and V{\'e}lez-Fort, Mateo and Rousseau, Charly V
              and Cossell, Lee and Tsitoura, Chryssanthi and Lenzi, Stephen C
              and Obenhaus, Horst A and Claudi, Federico and Branco, Tiago and
              Margrie, Troy W",
  abstract = "High-resolution whole-brain microscopy provides a means for post
              hoc determination of the location of implanted devices and
              labelled cell populations that are necessary to interpret in vivo
              experiments designed to understand brain function. Here we have
              developed two plugins (brainreg and brainreg-segment) for the
              Python-based image viewer napari, to accurately map any object in
              a common coordinate space. We analysed the position of
              dye-labelled electrode tracks and two-photon imaged cell
              populations expressing fluorescent proteins. The precise location
              of probes and cells were physiologically interrogated and
              revealed accurate segmentation with near-cellular resolution.",
  journal  = "Sci. Rep.",
  volume   =  12,
  number   =  1,
  pages    = "867",
  month    =  jan,
  year     =  2022,
  language = "en",
  issn     = "2045-2322",
  pmid     = "35042882",
  doi      = "10.1038/s41598-021-04676-9",
  pmc      = "PMC8766598"
}

@ARTICLE{Tyson2022-bp,
  title    = "Mesoscale microscopy and image analysis tools for understanding
              the brain",
  author   = "Tyson, Adam L and Margrie, Troy W",
  abstract = "Over the last ten years, developments in whole-brain microscopy
              now allow for high-resolution imaging of intact brains of small
              animals such as mice. These complex images contain a wealth of
              information, but many neuroscience laboratories do not have all
              of the computational knowledge and tools needed to process these
              data. We review recent open source tools for registration of
              images to atlases, and the segmentation, visualisation and
              analysis of brain regions and labelled structures such as
              neurons. Since the field lacks fully integrated analysis
              pipelines for all types of whole-brain microscopy analysis, we
              propose a pathway for tool developers to work together to meet
              this challenge.",
  journal  = "Prog. Biophys. Mol. Biol.",
  volume   =  168,
  pages    = "81--93",
  month    =  jan,
  year     =  2022,
  keywords = "Image registration; Neuroscience; Segmentation; Visualisation;
              whole Brain microscopy",
  language = "en",
  issn     = "0079-6107, 1873-1732",
  pmid     = "34216639",
  doi      = "10.1016/j.pbiomolbio.2021.06.013",
  pmc      = "PMC8786668"
}

@ARTICLE{Tyson2021-sk,
  title    = "A deep learning algorithm for {3D} cell detection in whole mouse
              brain image datasets",
  author   = "Tyson, Adam L and Rousseau, Charly V and Niedworok, Christian J
              and Keshavarzi, Sepiedeh and Tsitoura, Chryssanthi and Cossell,
              Lee and Strom, Molly and Margrie, Troy W",
  abstract = "Understanding the function of the nervous system necessitates
              mapping the spatial distributions of its constituent cells
              defined by function, anatomy or gene expression. Recently,
              developments in tissue preparation and microscopy allow cellular
              populations to be imaged throughout the entire rodent brain.
              However, mapping these neurons manually is prone to bias and is
              often impractically time consuming. Here we present an
              open-source algorithm for fully automated 3D detection of
              neuronal somata in mouse whole-brain microscopy images using
              standard desktop computer hardware. We demonstrate the
              applicability and power of our approach by mapping the brain-wide
              locations of large populations of cells labeled with cytoplasmic
              fluorescent proteins expressed via retrograde trans-synaptic
              viral infection.",
  journal  = "PLoS Comput. Biol.",
  volume   =  17,
  number   =  5,
  pages    = "e1009074",
  month    =  may,
  year     =  2021,
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "34048426",
  doi      = "10.1371/journal.pcbi.1009074",
  pmc      = "PMC8191998"
}

@UNPUBLISHED{Uhlrich2022-fl,
  title    = "{OpenCap}: {3D} human movement dynamics from smartphone videos",
  author   = "Uhlrich, Scott D and Falisse, Antoine and Kidzi{\'n}ski,
              {\L}ukasz and Muccini, Julie and Ko, Michael and Chaudhari,
              Akshay S and Hicks, Jennifer L and Delp, Scott L",
  abstract = "Measures of human movement dynamics can predict outcomes like
              injury risk or musculoskeletal disease progression. However,
              these measures are rarely quantified in clinical practice due to
              the prohibitive cost, time, and expertise required. Here we
              present and validate OpenCap, an open-source platform for
              computing movement dynamics using videos captured from
              smartphones. OpenCap's web application enables users to collect
              synchronous videos and visualize movement data that is
              automatically processed in the cloud, thereby eliminating the
              need for specialized hardware, software, and expertise. We show
              that OpenCap accurately predicts dynamic measures, like muscle
              activations, joint loads, and joint moments, which can be used to
              screen for disease risk, evaluate intervention efficacy, assess
              between-group movement differences, and inform rehabilitation
              decisions. Additionally, we demonstrate OpenCap's practical
              utility through a 100-subject field study, where a clinician
              using OpenCap estimated movement dynamics 25 times faster than a
              laboratory-based approach at less than 1\% of the cost. By
              democratizing access to human movement analysis, OpenCap can
              accelerate the incorporation of biomechanical metrics into
              large-scale research studies, clinical trials, and clinical
              practice. \#\#\# Competing Interest Statement Stanford University
              has filed for a patent related to the work, titled ``OpenCap:
              open-source software for estimating the kinematics and kinetics
              of human movement from smartphone videos'' on behalf of A.F.,
              S.D.U., {\L}.K., J.L.H, and S.L.D. These authors have no other
              competing interests. J.M., M.K., and A.S.C. have no competing
              interests.",
  journal  = "bioRxiv",
  pages    = "2022.07.07.499061",
  month    =  jul,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.07.07.499061"
}

@PHDTHESIS{Pollock2022-di,
  title     = "Understanding computation through low-dimensional dynamics with
               recurrent neural networks",
  author    = "Pollock, Eli Barton",
  abstract  = "One way to understand the brain is in terms of the computations
               it performs that allow an organism to survive in the world.
               Models of cognition and behavior can be useful for describing
               the computations that might be performed, but often provide
               little insight into how they are realized in neural network
               models. Addressing this disconnect requires tools for better
               understanding neural representations and how they are used for
               cognitive computations. Here, I present work towards developing
               a dynamical systems framework for neural computation, using a
               recurrent neural network (RNN) model. To begin, I propose an
               analysis-by-synthesis method that uses local constraints on
               population activity to create RNNs that can solve a task. I
               demonstrate this method by creating networks that implement
               variations of a ring attractor, a classic model of
               representation in neural circuits. The first variation produces
               a specific drift-diffusion process over the attractor, similar
               to that proposed in a working memory model. As a second
               variation, I introduce an input that controls the speed of the
               network's dynamics, creating a model for how contextual inputs
               can enable flexible behavior. Third, I explore ring attractor
               networks with dynamics of varying complexity. Next, I provide a
               more detailed analysis of the relationship between neural
               representations and network connectivity. Again using a network
               synthesis technique, I show that RNNs with a wide variety of
               synaptic weight configurations can produce nearly identical ring
               attractors. To define the theoretical boundaries of the space
               containing all such networks, I identify underlying sources of
               variability as well as common features. In doing so, I develop a
               framework for relating the geometry and dynamics of constrained
               network states to the features of network connectivity.",
  publisher = "Massachusetts Institute of Technology",
  month     =  may,
  year      =  2022,
  school    = "Massachusetts Institute of Technology",
  keywords  = "Thesis"
}

@UNPUBLISHED{Markov2020-ns,
  title    = "A cerebellar internal model calibrates a feedback controller
              involved in sensorimotor control",
  author   = "Markov, Daniil A and Petrucco, Luigi and Kist, Andreas M and
              Portugues, Ruben",
  abstract = "Abstract Animals must adapt their behavior to survive in a
              changing environment. Behavioral adaptations can be evoked by two
              mechanisms: feedback control and internal-model-based control.
              Feedback controllers can maintain the sensory state of the animal
              at a desired level under different environmental conditions. In
              turn, internal models learn the relationship between behavior and
              resulting sensory consequences in order to modify the behavior
              when this relationship changes. Here, we present multiple
              perturbations in visual feedback to larval zebrafish performing
              the optomotor response and show that they react to these
              perturbations through a feedback control mechanism. In contrast,
              if a perturbation is long-lasting, fish adapt their behavior by
              updating a cerebellum-dependent internal model. We use modelling
              and functional imaging to show that neuronal requirements for
              these mechanisms are met in the larval zebrafish brain. Our
              results illustrate the role of the cerebellum in encoding
              internal models and how these can calibrate neuronal circuits
              involved in reactive behaviors depending on the interactions
              between animal and environment.Highlights Behavioral reactions to
              unexpected changes in visual feedback are implemented by a
              feedback control mechanismA long-lasting change in visual
              feedback updates the state of the neuronal controllerThe
              cerebellar internal model mediates this recalibration",
  journal  = "bioRxiv",
  pages    = "2020.02.12.945956",
  month    =  sep,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.02.12.945956"
}

@UNPUBLISHED{Cowley2022-ig,
  title    = "One-to-one mapping between deep network units and real neurons
              uncovers a visual population code for social behavior",
  author   = "Cowley, Benjamin R and Calhoun, Adam J and Rangarajan, Nivedita
              and Pillow, Jonathan W and Murthy, Mala",
  abstract = "The rich variety of behaviors observed in animals arises through
              the complex interplay between sensory processing and motor
              control [[1][1], [2][2], [3][3], [4][4], [5][5]]. To understand
              these sensorimotor transformations, it is useful to build models
              that predict not only neural responses to sensory input [[6][6],
              [7][7], [8][8], [9][9], [10][10]] but also how each neuron
              causally contributes to behavior [[11][11], [12][12]]. Here we
              demonstrate a novel modeling approach to identify a one-to-one
              mapping between internal units in a deep neural network and real
              neurons by predicting the behavioral changes arising from
              systematic perturbations of more than a dozen neuron types. A key
              ingredient we introduce is ``knockout training'', which involves
              perturbing the network during training to match the perturbations
              of the real neurons during behavioral experiments. We apply this
              approach to model the sensorimotor transformation of Drosophila
              melanogaster males during a complex, visually-guided social
              behavior [[13][13], [14][14], [15][15], [16][16]]. Contrary to
              prevailing views [[17][17], [18][18], [19][19]], our model
              suggests that visual projection neurons at the interface between
              the eye and brain form a distributed population code that
              collectively sculpts social behavior. Overall, our framework
              consolidates behavioral effects elicited from various neural
              perturbations into a single, unified model, providing a detailed
              map from stimulus to neuron to behavior. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest. [1]: \#ref-1 [2]: \#ref-2 [3]: \#ref-3 [4]: \#ref-4
              [5]: \#ref-5 [6]: \#ref-6 [7]: \#ref-7 [8]: \#ref-8 [9]: \#ref-9
              [10]: \#ref-10 [11]: \#ref-11 [12]: \#ref-12 [13]: \#ref-13 [14]:
              \#ref-14 [15]: \#ref-15 [16]: \#ref-16 [17]: \#ref-17 [18]:
              \#ref-18 [19]: \#ref-19",
  journal  = "bioRxiv",
  pages    = "2022.07.18.500505",
  month    =  jul,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.07.18.500505"
}

@UNPUBLISHED{Schafer2022-ow,
  title    = "Hippocampal Place-like Signal in Latent Social Space",
  author   = "Schafer, Matthew and Kamilar-Britt, Philip and Sahani, Vyoma and
              Bachi, Keren and Schiller, Daniela",
  abstract = "During navigation, the hippocampus represents physical places
              like coordinates on a map; similar location-like signals have
              been seen in sensory and concept spaces. It is unclear just how
              general this hippocampal place code is, however: does it map
              places in wholly non-perceivable spaces, without locations being
              instructed or reinforced and during navigation-like behavior? To
              search for such a signal, we imaged participants' brains while
              they played a naturalistic, narrative-based social interaction
              game, and modeled their relationships as a kind of navigation
              through social space. Two independent samples showed hippocampal
              place-like signals in both region-based and whole-brain
              representational similarity analyses, as well as decoding and
              average pattern similarity analyses; the effects were not
              explained by other measures of the behavior or task information.
              We also replicated and extended previous findings of hippocampal
              tracking of the egocentric angle in social space. These results
              are the first demonstration of complete domain generality in
              hippocampal place representation. One-Sentence Summary
              hippocampal place-like signal in non-perceivable and unreinforced
              space during naturalistic navigational behavior. Significance
              statement The hippocampus is a brain structure known to encode
              maps of physical spaces; this study shows that it also maps fully
              abstract, latent and uninstructed spaces. People played a
              naturalistic social interaction game while their brains were
              scanned. Hippocampal brain activity correlated with the fictional
              characters' locations in an abstract social space framed by axes
              of affiliation and power, despite the participants never being
              exposed to a perceivable spatial representation. This mapping was
              present across multiple analyses and two samples, demonstrating
              that the brain system responsible for spatial mapping maps our
              social interactions too. \#\#\# Competing Interest Statement The
              authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.07.15.499827",
  month    =  jul,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.07.15.499827"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Hoelzel1991-xj,
  title     = "Killer whale predation on marine mammals at Punta Norte,
               Argentina; food sharing, provisioning and foraging strategy",
  author    = "Hoelzel, A Rus",
  abstract  = "… /prey interaction and foraging strategy for the Punta Norte
               killer whale population. This study … recognizable killer whales
               . The results indicate that killer whales at Punta Norte hunt …",
  journal   = "Behav. Ecol. Sociobiol.",
  publisher = "Springer Nature",
  volume    =  29,
  number    =  3,
  pages     = "197--204",
  month     =  oct,
  year      =  1991,
  language  = "en",
  issn      = "0340-5443, 1432-0762",
  doi       = "10.1007/bf00166401"
}

@ARTICLE{Gire2016-ib,
  title     = "Mice Develop Efficient Strategies for Foraging and Navigation
               Using Complex Natural Stimuli",
  author    = "Gire, David H and Kapoor, Vikrant and Arrighi-Allisan, Annie and
               Seminara, Agnese and Murthy, Venkatesh N",
  abstract  = "The ability to shift between multiple decision-making strategies
               during natural behavior allows animals to strike a balance
               between flexibility and efficiency. We investigated odor-guided
               navigation by mice to understand how decision-making strategies
               are balanced during a complex natural behavior. Mice navigated
               to odor sources in an open arena using naturally fluctuating
               airborne odor cues as their positions were recorded precisely in
               real time. When mice had limited prior experience of source
               locations, their search behavior was consistent with a gradient
               ascent algorithm that utilized directional cues in the plume to
               navigate to the odor source. Gradient climbing was effective
               because the arena size allowed animals to conduct their search
               mainly within the odor plume, with frequent odor contacts. With
               increased experience, mice shifted their strategy from this
               flexible, sensory-driven search behavior to a more efficient and
               stereotyped foraging approach that varied little in response to
               odor plumes. This study demonstrates that mice use prior
               knowledge to adaptively balance flexibility and efficiency
               during complex behavior guided by dynamic natural stimuli.",
  journal   = "Curr. Biol.",
  publisher = "Elsevier",
  volume    =  26,
  number    =  10,
  pages     = "1261--1273",
  month     =  may,
  year      =  2016,
  language  = "en",
  issn      = "0960-9822, 1879-0445",
  pmid      = "27112299",
  doi       = "10.1016/j.cub.2016.03.040",
  pmc       = "PMC4951102"
}

@ARTICLE{Morris2000-jb,
  title     = "Optimally foraging mice match patch use with habitat differences
               in fitness",
  author    = "Morris, D W and Davidson, D L",
  abstract  = "We tested the fundamental assumption of the ``optimality
               paradigm'' that the foraging behavior of individual organisms
               corresponds to what we would expect if it had been honed by
               natural selection to match habitat differences in reproductive
               success. First, we used long-term studies of life history and
               habitat selection in white-footed mice to illustrate that the
               fitness of females living in the forest is greater than that of
               females living in forest-edge habitat. Second, we used
               short-term foraging studies to evaluate whether food patches
               located in the forest provided more value to foragers than did
               those in the edge. Third, we used foraging studies and data on
               the occurrence of predators to demonstrate that animals foraging
               in areas with little cover face higher risks than when they
               forage in areas with more cover. We confirmed three a priori
               predictions: (1) Individual mice abandoned foraging patches at
               higher harvest rates in edge habitat than they did in forest.
               (2) Individuals harvested resource patches to lower quitting
               harvest rates under cover than they did when patches were
               located in the open. (3) The difference in quitting-harvest rate
               between ``open'' and ``covered'' patches was less in the safe
               forest habitat than it was in the risky edge habitat. Our
               results yield an impressive fit with our previous knowledge of
               habitat differences in reproductive success and substantiate the
               premise that short-duration strategic decisions by individuals
               match habitat differences in fitness.",
  journal   = "Ecology",
  publisher = "Wiley Online Library",
  year      =  2000,
  issn      = "0012-9658",
  doi       = "10.1890/0012-9658(2000)081[2061:OFMMPU]2.0.CO;2"
}

@ARTICLE{DeAngelis2019-dr,
  title     = "{Decision-Making} in {Agent-Based} Modeling: A Current Review
               and Future Prospectus",
  author    = "DeAngelis, Donald L and Diaz, Stephanie G",
  abstract  = "All basic processes of ecological populations involve decisions;
               when and where to move, when and what to eat, and whether to
               fight or flee. Yet decisions and the underlying principles of
               decision-making have been difficult to integrate into the
               classical population-level models of ecology. Certainly, there
               is a long history of modeling individuals' searching behavior,
               diet selection, or conflict dynamics within social interactions.
               When all the individuals are given certain simple rules to
               govern their decision-making processes, the resultant
               population--level models have yielded important generalizations
               and theory. But it is also recognized that such models do not
               represent the way real individuals decide on actions. Factors
               that influence a decision include the organism's environment
               with its dynamic rewards and risks, the complex internal state
               of the organism, and its imperfect knowledge of the environment.
               In the case of animals, it may also involve complex social
               factors, and experience and learning, which vary among
               individuals. The way that all factors are weighed and processed
               to lead to decisions is a major area of behavioral theory.While
               classic population-level modeling is limited in its ability to
               integrate decision-making in its actual complexity, the
               development of individual- or agent-based models (IBM/ABMs) (we
               use ABM throughout to designate both ``agent-based modeling''
               and an ``agent-based model'') has opened the possibility of
               describing the way that decisions are made, and their effects,
               in minute detail. Over the years, these models have increased in
               size and complexity. Current ABMs can simulate thousands of
               individuals in realistic environments, and with highly detailed
               internal physiology, perception and ability to process the
               perceptions and make decisions based on those and their internal
               states. The implementation of decision-making in ABMs ranges
               from fairly simple to highly complex; the process of an
               individual deciding on an action can occur through the use of
               logical and simple (if-then) rules to more sophisticated neural
               networks and genetic algorithms. The purpose of this paper is to
               give an overview of the ways in which decisions are integrated
               into a variety of ABMs and to give a prospectus on the future of
               modeling of decisions in ABMs.",
  journal   = "Frontiers in Ecology and Evolution",
  publisher = "frontiersin.org",
  volume    =  6,
  year      =  2019,
  issn      = "2296-701X",
  doi       = "10.3389/fevo.2018.00237"
}

@ARTICLE{Stimberg2019-cy,
  title    = "Brian 2, an intuitive and efficient neural simulator",
  author   = "Stimberg, Marcel and Brette, Romain and Goodman, Dan Fm",
  abstract = "Brian 2 allows scientists to simply and efficiently simulate
              spiking neural network models. These models can feature novel
              dynamical equations, their interactions with the environment, and
              experimental protocols. To preserve high performance when
              defining new models, most simulators offer two options: low-level
              programming or description languages. The first option requires
              expertise, is prone to errors, and is problematic for
              reproducibility. The second option cannot describe all aspects of
              a computational experiment, such as the potentially complex logic
              of a stimulation protocol. Brian addresses these issues using
              runtime code generation. Scientists write code with simple and
              concise high-level descriptions, and Brian transforms them into
              efficient low-level code that can run interleaved with their
              code. We illustrate this with several challenging examples: a
              plastic model of the pyloric network, a closed-loop sensorimotor
              model, a programmatic exploration of a neuron model, and an
              auditory model with real-time input.",
  journal  = "Elife",
  volume   =  8,
  month    =  aug,
  year     =  2019,
  keywords = "computational neuroscience; neuroscience; none; simulation;
              software",
  language = "en",
  issn     = "2050-084X",
  pmid     = "31429824",
  doi      = "10.7554/eLife.47314",
  pmc      = "PMC6786860"
}

@BOOK{Gerstner2014-mf,
  title     = "Neuronal dynamics: From single neurons to networks and models of
               cognition",
  author    = "Gerstner, Wulfram and Kistler, Werner M and Naud, Richard and
               Paninski, Liam",
  abstract  = "What happens in our brain when we make a decision? What triggers
               a neuron to send out a signal? What is the neural code? This
               textbook for advanced undergraduate and beginning graduate
               students provides a thorough and up-to-date introduction to the
               fields of computational and theoretical neuroscience. It covers
               classical topics, including the Hodgkin-Huxley equations and
               Hopfield model, as well as modern developments in the field such
               as Generalized Linear Models and decision theory. Concepts are
               introduced using clear step-by-step explanations suitable for
               readers with only a basic knowledge of differential equations
               and probabilities, and are richly illustrated by figures and
               worked-out examples. End-of-chapter summaries and
               classroom-tested exercises make the book ideal for courses or
               for self-study. The authors also give pointers to the literature
               and an extensive bibliography, which will prove invaluable to
               readers interested in further study.",
  publisher = "Cambridge University Press",
  month     =  jul,
  year      =  2014,
  address   = "Cambridge, England",
  isbn      = "9781107060838, 9781107635197",
  doi       = "10.1017/cbo9781107447615"
}

@ARTICLE{Pontes-Filho2022-yy,
  title         = "Towards the Neuroevolution of Low-level Artificial General
                   Intelligence",
  author        = "Pontes-Filho, Sidney and Olsen, Kristoffer and Yazidi, Anis
                   and Riegler, Michael A and Halvorsen, P{\aa}l and Nichele,
                   Stefano",
  abstract      = "In this work, we argue that the search for Artificial
                   General Intelligence (AGI) should start from a much lower
                   level than human-level intelligence. The circumstances of
                   intelligent behavior in nature resulted from an organism
                   interacting with its surrounding environment, which could
                   change over time and exert pressure on the organism to allow
                   for learning of new behaviors or environment models. Our
                   hypothesis is that learning occurs through interpreting
                   sensory feedback when an agent acts in an environment. For
                   that to happen, a body and a reactive environment are
                   needed. We evaluate a method to evolve a
                   biologically-inspired artificial neural network that learns
                   from environment reactions named Neuroevolution of
                   Artificial General Intelligence (NAGI), a framework for
                   low-level AGI. This method allows the evolutionary
                   complexification of a randomly-initialized spiking neural
                   network with adaptive synapses, which controls agents
                   instantiated in mutable environments. Such a configuration
                   allows us to benchmark the adaptivity and generality of the
                   controllers. The chosen tasks in the mutable environments
                   are food foraging, emulation of logic gates, and cart-pole
                   balancing. The three tasks are successfully solved with
                   rather small network topologies and therefore it opens up
                   the possibility of experimenting with more complex tasks and
                   scenarios where curriculum learning is beneficial.",
  month         =  jul,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2207.13583",
  primaryClass  = "cs.AI",
  arxivid       = "2207.13583"
}

@ARTICLE{Osanlou2022-ht,
  title         = "Planning and Learning: A Review of Methods involving
                   {Path-Planning} for Autonomous Vehicles",
  author        = "Osanlou, Kevin and Guettier, Christophe and Cazenave,
                   Tristan and Jacopin, Eric",
  abstract      = "This short review aims to make the reader familiar with
                   state-of-the-art works relating to planning, scheduling and
                   learning. First, we study state-of-the-art planning
                   algorithms. We give a brief introduction of neural networks.
                   Then we explore in more detail graph neural networks, a
                   recent variant of neural networks suited for processing
                   graph-structured inputs. We describe briefly the concept of
                   reinforcement learning algorithms and some approaches
                   designed to date. Next, we study some successful approaches
                   combining neural networks for path-planning. Lastly, we
                   focus on temporal planning problems with uncertainty.",
  month         =  jul,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2207.13181",
  primaryClass  = "cs.AI",
  arxivid       = "2207.13181"
}

@ARTICLE{Valente2022-bq,
  title    = "Probing the Relationship Between Latent Linear Dynamical Systems
              and {Low-Rank} Recurrent Neural Network Models",
  author   = "Valente, Adrian and Ostojic, Srdjan and Pillow, Jonathan",
  abstract = "A large body of work has suggested that neural populations
              exhibit low-dimensional dynamics during behavior. However, there
              are a variety of different approaches for modeling
              low-dimensional neural population activity. One approach involves
              latent linear dynamical system (LDS) models, in which population
              activity is described by a projection of low-dimensional latent
              variables with linear dynamics. A second approach involves
              low-rank recurrent neural networks (RNNs), in which population
              activity arises directly from a low-dimensional projection of
              past activity. Although these two modeling approaches have strong
              similarities, they arise in different contexts and tend to have
              different domains of application. Here we examine the precise
              relationship between latent LDS models and linear low-rank RNNs.
              When can one model class be converted to the other, and vice
              versa? We show that latent LDS models can only be converted to
              RNNs in specific limit cases, due to the non-Markovian property
              of latent LDS models. Conversely, we show that linear RNNs can be
              mapped onto LDS models, with latent dimensionality at most twice
              the rank of the RNN. A surprising consequence of our results is
              that a partially observed RNN is better represented by an LDS
              model than by an RNN consisting of only observed units.",
  journal  = "Neural Comput.",
  pages    = "1--22",
  month    =  jul,
  year     =  2022,
  language = "en",
  issn     = "0899-7667, 1530-888X",
  pmid     = "35896161",
  doi      = "10.1162/neco\_a\_01522"
}

@ARTICLE{Khona2022-or,
  title         = "Winning the lottery with neurobiology: faster learning on
                   many cognitive tasks with fixed sparse {RNNs}",
  author        = "Khona, Mikail and Chandra, Sarthak and Ma, Joy J and Fiete,
                   Ila",
  abstract      = "RNNs are often used as models of biological brain circuits
                   and can solve a variety of difficult problems requiring
                   memory, error-correction, or selection
                   \textbackslashcite\{hopfield1982neural,
                   maass2002real,maass2011liquid\}. However, fully-connected
                   RNNs contrast structurally with their biological
                   counterparts, which are extremely sparse ($\sim 0.1$\%).
                   Practical deployment of large RNNs is often limited due to
                   requirements of long training times and large memory
                   requirements. Motivated by brains, where neural connectivity
                   is constrained by distance along cortical sheets and other
                   synaptic wiring costs, we introduce locality masked RNNs
                   (LM-RNNs) that utilize task-agnostic predetermined graphs
                   with sparsity as low as 4\%. We make three contributions:
                   First, we show that LM-RNNs can perform as well as their
                   fully-connected counterparts, without \textbackslashemph\{a
                   posteriori\} construction of the best sparse subnetwork.
                   Second, we find that LM-RNNs train faster with more
                   data-efficiency in a multitask setting relevant to cognitive
                   systems neuroscience, often achieving better asymptotic
                   performance. Third, we contribute a new cognitive multi-task
                   battery, Mod-Cog, consisting of 132 tasks that expands by
                   $\sim 7$-fold the number of tasks and task-complexity of an
                   existing commonly used set of tasks
                   \textbackslashcite\{yang2019task\}, showing that while
                   LM-RNNs can solve the simple
                   \textbackslashcite\{yang2019task\} tasks with a small pool
                   of unconnected autapses, the expanded task-set produces
                   richer solutions.",
  month         =  jul,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2207.03523",
  primaryClass  = "q-bio.NC",
  arxivid       = "2207.03523"
}

@INPROCEEDINGS{Boopathy2022-mo,
  title     = "How to Train Your Wide Neural Network Without Backprop: An
               {Input-Weight} Alignment Perspective",
  booktitle = "Proceedings of the 39th International Conference on Machine
               Learning",
  author    = "Boopathy, Akhilan and Fiete, Ila",
  editor    = "Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and
               Szepesvari, Csaba and Niu, Gang and Sabato, Sivan",
  abstract  = "Recent works have examined theoretical and empirical properties
               of wide neural networks trained in the Neural Tangent Kernel
               (NTK) regime. Given that biological neural networks are much
               wider than their artificial counterparts, we consider NTK regime
               wide neural networks as a possible model of biological neural
               networks. Leveraging NTK theory, we show theoretically that
               gradient descent drives layerwise weight updates that are
               aligned with their input activity correlations weighted by
               error, and demonstrate empirically that the result also holds in
               finite-width wide networks. The alignment result allows us to
               formulate a family of biologically-motivated,
               backpropagation-free learning rules that are theoretically
               equivalent to backpropagation in infinite-width networks. We
               test these learning rules on benchmark problems in feedforward
               and recurrent neural networks and demonstrate, in wide networks,
               comparable performance to backpropagation. The proposed rules
               are particularly effective in low data regimes, which are common
               in biological learning settings.",
  publisher = "PMLR",
  volume    =  162,
  pages     = "2178--2205",
  series    = "Proceedings of Machine Learning Research",
  year      =  2022
}

@ARTICLE{Fiete2021-kp,
  title    = "Ila Fiete",
  author   = "Fiete, Ila",
  abstract = "Interview with Ila Fiete, who studies the microscopic cellular
              and synaptic processes responsible for behaviors of memory and
              cognition in the brain at Massachusetts Institute of Technology.",
  journal  = "Curr. Biol.",
  volume   =  31,
  number   =  24,
  pages    = "R1552--R1555",
  month    =  dec,
  year     =  2021,
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "34932958",
  doi      = "10.1016/j.cub.2021.11.041"
}

@UNPUBLISHED{Pattadkal2022-cx,
  title    = "Primate neocortex performs balanced sensory amplification",
  author   = "Pattadkal, Jagruti J and Zemelman, Boris V and Fiete, Ila and
              Priebe, Nicholas J",
  abstract = "Sensory cortex amplifies relevant features of external stimuli.
              This sensitivity and selectivity arise through the transformation
              of inputs by cortical circuitry. We characterize the circuit
              mechanisms and dynamics of cortical amplification by making
              large-scale simultaneous measurements of single cells in awake
              primates and by testing computational models. By comparing
              network activity in both driven and spontaneous states with
              models, we identify the circuit as operating in a regime of
              balanced amplification. Incoming inputs are strongly but
              transiently amplified by recurrent excitation. Inhibition acts to
              counterbalance this excitation by rapidly quenching responses,
              thereby permitting tracking of time-varying stimuli. One-Sentence
              Summary Sensory cortex uses balanced excitatory and inhibitory
              circuitry to boost weak signals while maintaining fast sensory
              dynamics in a changing environment. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.06.23.497220",
  month    =  jun,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.06.23.497220"
}

@INPROCEEDINGS{Schaeffer2022-ug,
  title     = "Streaming Inference for Infinite Feature Models",
  booktitle = "Proceedings of the 39th International Conference on Machine
               Learning",
  author    = "Schaeffer, Rylan and Du, Yilun and Liu, Gabrielle K and Fiete,
               Ila",
  editor    = "Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and
               Szepesvari, Csaba and Niu, Gang and Sabato, Sivan",
  abstract  = "Unsupervised learning from a continuous stream of data is
               arguably one of the most common and most challenging problems
               facing intelligent agents. One class of unsupervised models,
               collectively termed feature models, attempts unsupervised
               discovery of latent features underlying the data and includes
               common models such as PCA, ICA, and NMF. However, if the data
               arrives in a continuous stream, determining the number of
               features is a significant challenge and the number may grow with
               time. In this work, we make feature models significantly more
               applicable to streaming data by imbuing them with the ability to
               create new features, online, in a probabilistic and principled
               manner. To achieve this, we derive a novel recursive form of the
               Indian Buffet Process, which we term the Recursive IBP (R-IBP).
               We demonstrate that R-IBP can be be used as a prior for feature
               models to efficiently infer a posterior over an unbounded number
               of latent features, with quasilinear average time complexity and
               logarithmic average space complexity. We compare R-IBP to
               existing offline sampling and variational baselines in two
               feature models (Linear Gaussian and Factor Analysis) and
               demonstrate on synthetic and real data that R-IBP achieves
               comparable or better performance in significantly less time.",
  publisher = "PMLR",
  volume    =  162,
  pages     = "19366--19387",
  series    = "Proceedings of Machine Learning Research",
  year      =  2022
}

@UNPUBLISHED{Voigts2022-vb,
  title    = "Spatial reasoning via recurrent neural dynamics in mouse
              retrosplenial cortex",
  author   = "Voigts, Jakob and Kanitscheider, Ingmar and Miller, Nicholas J
              and Toloza, Enrique H S and Newman, Jonathan P and Fiete, Ila R
              and Harnett, Mark T",
  abstract = "From visual perception to language, sensory stimuli change their
              meaning depending on prior experience. Recurrent neural dynamics
              can interpret stimuli based on externally cued context, but it is
              unknown whether similar dynamics can compute and employ internal
              hypotheses to resolve ambiguities. Here, we show that mouse
              retrosplenial cortex (RSC) can form hypotheses over time and
              perform spatial reasoning through recurrent dynamics. In our
              task, mice navigated using ambiguous landmarks that are
              identified through their mutual spatial relationship, requiring
              sequential refinement of hypotheses. Neurons in RSC and in
              artificial neural networks encoded mixtures of hypotheses,
              location, and sensory information, and were constrained by robust
              low dimensional dynamics. RSC encoded hypotheses as locations in
              activity space with divergent trajectories for identical sensory
              inputs, enabling their correct interpretation. Our results
              indicate that interactions between internal hypotheses and
              external sensory data in recurrent circuits can provide a
              substrate for complex sequential cognitive reasoning. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.04.12.488024",
  month    =  apr,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.04.12.488024"
}

@INPROCEEDINGS{Sharma2022-rq,
  title     = "Content Addressable Memory Without Catastrophic Forgetting by
               Heteroassociation with a Fixed Scaffold",
  booktitle = "Proceedings of the 39th International Conference on Machine
               Learning",
  author    = "Sharma, Sugandha and Chandra, Sarthak and Fiete, Ila",
  editor    = "Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and
               Szepesvari, Csaba and Niu, Gang and Sabato, Sivan",
  abstract  = "Content-addressable memory (CAM) networks, so-called because
               stored items can be recalled by partial or corrupted versions of
               the items, exhibit near-perfect recall of a small number of
               information-dense patterns below capacity and a 'memory cliff'
               beyond, such that inserting a single additional pattern results
               in catastrophic loss of all stored patterns. We propose a novel
               CAM architecture, Memory Scaffold with Heteroassociation (MESH),
               that factorizes the problems of internal attractor dynamics and
               association with external content to generate a CAM continuum
               without a memory cliff: Small numbers of patterns are stored
               with complete information recovery matching standard CAMs, while
               inserting more patterns still results in partial recall of every
               pattern, with a graceful trade-off between pattern number and
               pattern richness. Motivated by the architecture of the
               Entorhinal-Hippocampal memory circuit in the brain, MESH is a
               tripartite architecture with pairwise interactions that uses a
               predetermined set of internally stabilized states together with
               heteroassociation between the internal states and arbitrary
               external patterns. We show analytically and experimentally that
               for any number of stored patterns, MESH nearly saturates the
               total information bound (given by the number of synapses) for
               CAM networks, outperforming all existing CAM models.",
  publisher = "PMLR",
  volume    =  162,
  pages     = "19658--19682",
  series    = "Proceedings of Machine Learning Research",
  year      =  2022
}

@UNPUBLISHED{Driscoll2022-ts,
  title    = "Flexible multitask computation in recurrent networks utilizes
              shared dynamical motifs",
  author   = "Driscoll, Laura and Shenoy, Krishna and Sussillo, David",
  abstract = "Flexible computation is a hallmark of intelligent behavior. Yet,
              little is known about how neural networks contextually
              reconfigure for different computations. Humans are able to
              perform a new task without extensive training, presumably through
              the composition of elementary processes that were previously
              learned. Cognitive scientists have long hypothesized the
              possibility of a compositional neural code, where complex neural
              computations are made up of constituent components; however, the
              neural substrate underlying this structure remains elusive in
              biological and artificial neural networks. Here we identified an
              algorithmic neural substrate for compositional computation
              through the study of multitasking artificial recurrent neural
              networks. Dynamical systems analyses of networks revealed learned
              computational strategies that mirrored the modular subtask
              structure of the task-set used for training. Dynamical motifs
              such as attractors, decision boundaries and rotations were reused
              across different task computations. For example, tasks that
              required memory of a continuous circular variable repurposed the
              same ring attractor. We show that dynamical motifs are
              implemented by clusters of units and are reused across different
              contexts, allowing for flexibility and generalization of
              previously learned computation. Lesioning these clusters resulted
              in modular effects on network performance: a lesion that
              destroyed one dynamical motif only minimally perturbed the
              structure of other dynamical motifs. Finally, modular dynamical
              motifs could be reconfigured for fast transfer learning. After
              slow initial learning of dynamical motifs, a subsequent faster
              stage of learning reconfigured motifs to perform novel tasks.
              This work contributes to a more fundamental understanding of
              compositional computation underlying flexible general
              intelligence in neural systems. We present a conceptual framework
              that establishes dynamical motifs as a fundamental unit of
              computation, intermediate between the neuron and the network. As
              more whole brain imaging studies record neural activity from
              multiple specialized systems simultaneously, the framework of
              dynamical motifs will guide questions about specialization and
              generalization across brain regions. \#\#\# Competing Interest
              Statement KS serves on the Scientific Advisory Boards (SABs) of
              MIND-X Inc. (acquired by Blackrock Neurotech, Spring 2022),
              Inscopix Inc. and Heal Inc. He also serves as a consultant /
              advisor (and was on founding SAB) for CTRL-Labs (acquired by
              Facebook Reality Labs in Fall 2019, and is now a part of Meta
              Platform's Reality Labs) and serves as a consultant / advisor
              (and is a co-founder, 2016) for Neuralink. DS works for Meta
              Platform's Reality Labs, but the work presented here was done
              entirely at Stanford. LD has no competing interests.",
  journal  = "bioRxiv",
  pages    = "2022.08.15.503870",
  month    =  aug,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.08.15.503870"
}

@ARTICLE{Crane_undated-gf,
  title  = "{D} {ISCRETE} {D} {IFFERENTIAL} {G} {EOMETRY}: A {N} A {PPLIED} {I}
            {NTRODUCTION}",
  author = "Crane, Keenan"
}

@ARTICLE{Zang2022-ya,
  title         = "Robot Motion Planning as Video Prediction: A
                   {Spatio-Temporal} Neural Network-based Motion Planner",
  author        = "Zang, Xiao and Yin, Miao and Huang, Lingyi and Yu, Jingjin
                   and Zonouz, Saman and Yuan, Bo",
  abstract      = "Neural network (NN)-based methods have emerged as an
                   attractive approach for robot motion planning due to strong
                   learning capabilities of NN models and their inherently high
                   parallelism. Despite the current development in this
                   direction, the efficient capture and processing of important
                   sequential and spatial information, in a direct and
                   simultaneous way, is still relatively under-explored. To
                   overcome the challenge and unlock the potentials of neural
                   networks for motion planning tasks, in this paper, we
                   propose STP-Net, an end-to-end learning framework that can
                   fully extract and leverage important spatio-temporal
                   information to form an efficient neural motion planner. By
                   interpreting the movement of the robot as a video clip,
                   robot motion planning is transformed to a video prediction
                   task that can be performed by STP-Net in both spatially and
                   temporally efficient ways. Empirical evaluations across
                   different seen and unseen environments show that, with
                   nearly 100\% accuracy (aka, success rate), STP-Net
                   demonstrates very promising performance with respect to both
                   planning speed and path cost. Compared with existing
                   NN-based motion planners, STP-Net achieves at least 5x, 2.6x
                   and 1.8x faster speed with lower path cost on 2D Random
                   Forest, 2D Maze and 3D Random Forest environments,
                   respectively. Furthermore, STP-Net can quickly and
                   simultaneously compute multiple near-optimal paths in
                   multi-robot motion planning tasks",
  month         =  aug,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2208.11287",
  primaryClass  = "cs.RO",
  arxivid       = "2208.11287"
}

@UNPUBLISHED{Schaeffer2022-dm,
  title    = "No Free Lunch from Deep Learning in Neuroscience: A Case Study
              through Models of the {Entorhinal-Hippocampal} Circuit",
  author   = "Schaeffer, Rylan and Khona, Mikail and Fiete, Ila Rani",
  abstract = "Research in Neuroscience, as in many scientific disciplines, is
              undergoing a renaissance based on deep learning. Unique to
              Neuroscience, deep learning models can be used not only as a tool
              but interpreted as models of the brain. The central claims of
              recent deep learning-based models of brain circuits are that they
              make novel predictions about neural phenomena or shed light on
              the fundamental functions being optimized. We show, through the
              case-study of grid cells in the entorhinal-hippocampal circuit,
              that one may get neither. We begin by reviewing the principles of
              grid cell mechanism and function obtained from first-principles
              modeling efforts, then rigorously examine the claims of deep
              learning models of grid cells. Using large-scale hyperparameter
              sweeps and theory-driven experimentation, we demonstrate that the
              results of such models may be more strongly driven by particular,
              non-fundamental, and post-hoc implementation choices than
              fundamental truths about neural circuits or the loss function(s)
              they might optimize. We discuss why these models cannot be
              expected to produce accurate models of the brain without the
              addition of substantial amounts of inductive bias, an informal No
              Free Lunch result for Neuroscience. Based on first principles
              work, we provide hypotheses for what additional loss functions
              will produce grid cells more robustly. In conclusion, caution and
              consideration, together with biological knowledge, are warranted
              in building and interpreting deep learning models in
              Neuroscience. \#\#\# Competing Interest Statement The authors
              have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.08.07.503109",
  month    =  aug,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.08.07.503109"
}

@UNPUBLISHED{Sorscher2020-uc,
  title    = "A unified theory for the computational and mechanistic origins of
              grid cells",
  author   = "Sorscher, Ben and Mel, Gabriel C and Ocko, Samuel A and Giocomo,
              Lisa and Ganguli, Surya",
  abstract = "The discovery of entorhinal grid cells has generated considerable
              interest in how and why hexagonal firing fields might
              mechanistically emerge in a generic manner from neural circuits,
              and what their computational significance might be. Here we forge
              an intimate link between the computational problem of
              path-integration and the existence of hexagonal grids, by
              demonstrating that such grids arise generically in biologically
              plausible neural networks trained to path integrate. Moreover, we
              develop a unifying theory for why hexagonal grids are so
              ubiquitous in path-integrator circuits. Such trained networks
              also yield powerful mechanistic hypotheses, exhibiting realistic
              levels of biological variability not captured by hand-designed
              models. We furthermore develop methods to analyze the connectome
              and activity maps of our trained networks to elucidate
              fundamental mechanisms underlying path integration. These methods
              provide an instructive roadmap to go from connectomic and
              physiological measurements to conceptual understanding in a
              manner that might be generalizable to other settings. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2020.12.29.424583",
  month    =  dec,
  year     =  2020,
  language = "en",
  doi      = "10.1101/2020.12.29.424583"
}

@ARTICLE{Banino2018-lu,
  title     = "Vector-based navigation using grid-like representations in
               artificial agents",
  author    = "Banino, Andrea and Barry, Caswell and Uria, Benigno and
               Blundell, Charles and Lillicrap, Timothy and Mirowski, Piotr and
               Pritzel, Alexander and Chadwick, Martin J and Degris, Thomas and
               Modayil, Joseph and Wayne, Greg and Soyer, Hubert and Viola,
               Fabio and Zhang, Brian and Goroshin, Ross and Rabinowitz, Neil
               and Pascanu, Razvan and Beattie, Charlie and Petersen, Stig and
               Sadik, Amir and Gaffney, Stephen and King, Helen and
               Kavukcuoglu, Koray and Hassabis, Demis and Hadsell, Raia and
               Kumaran, Dharshan",
  abstract  = "Deep neural networks have achieved impressive successes in
               fields ranging from object recognition to complex games such as
               Go1,2. Navigation, however, remains a substantial challenge for
               artificial agents, with deep neural networks trained by
               reinforcement learning3--5 failing to rival the proficiency of
               mammalian spatial behaviour, which is underpinned by grid cells
               in the entorhinal cortex6. Grid cells are thought to provide a
               multi-scale periodic representation that functions as a metric
               for coding space7,8 and is critical for integrating self-motion
               (path integration)6,7,9 and planning direct trajectories to
               goals (vector-based navigation)7,10,11. Here we set out to
               leverage the computational functions of grid cells to develop a
               deep reinforcement learning agent with mammal-like navigational
               abilities. We first trained a recurrent network to perform path
               integration, leading to the emergence of representations
               resembling grid cells, as well as other entorhinal cell types12.
               We then showed that this representation provided an effective
               basis for an agent to locate goals in challenging, unfamiliar,
               and changeable environments---optimizing the primary objective
               of navigation through deep reinforcement learning. The
               performance of agents endowed with grid-like representations
               surpassed that of an expert human and comparison agents, with
               the metric quantities necessary for vector-based navigation
               derived from grid-like units within the network. Furthermore,
               grid-like representations enabled agents to conduct shortcut
               behaviours reminiscent of those performed by mammals. Our
               findings show that emergent grid-like representations furnish
               agents with a Euclidean spatial metric and associated vector
               operations, providing a foundation for proficient navigation. As
               such, our results support neuroscientific theories that see grid
               cells as critical for vector-based navigation7,10,11,
               demonstrating that the latter can be combined with path-based
               strategies to support navigation in challenging environments.
               Grid-like representations emerge spontaneously within a neural
               network trained to self-localize, enabling the agent to take
               shortcuts to destinations using vector-based navigation.",
  journal   = "Nature",
  publisher = "Nature Publishing Group",
  volume    =  557,
  number    =  7705,
  pages     = "429--433",
  month     =  may,
  year      =  2018,
  language  = "en",
  issn      = "0028-0836",
  doi       = "10.1038/s41586-018-0102-6"
}

@ARTICLE{Cueva2018-tn,
  title         = "Emergence of grid-like representations by training recurrent
                   neural networks to perform spatial localization",
  author        = "Cueva, Christopher J and Wei, Xue-Xin",
  abstract      = "Decades of research on the neural code underlying spatial
                   navigation have revealed a diverse set of neural response
                   properties. The Entorhinal Cortex (EC) of the mammalian
                   brain contains a rich set of spatial correlates, including
                   grid cells which encode space using tessellating patterns.
                   However, the mechanisms and functional significance of these
                   spatial representations remain largely mysterious. As a new
                   way to understand these neural representations, we trained
                   recurrent neural networks (RNNs) to perform navigation tasks
                   in 2D arenas based on velocity inputs. Surprisingly, we find
                   that grid-like spatial response patterns emerge in trained
                   networks, along with units that exhibit other spatial
                   correlates, including border cells and band-like cells. All
                   these different functional types of neurons have been
                   observed experimentally. The order of the emergence of
                   grid-like and border cells is also consistent with
                   observations from developmental studies. Together, our
                   results suggest that grid cells, border cells and others as
                   observed in EC may be a natural solution for representing
                   space efficiently given the predominant recurrent
                   connections in the neural circuits.",
  month         =  mar,
  year          =  2018,
  archivePrefix = "arXiv",
  eprint        = "1803.07770",
  primaryClass  = "q-bio.NC",
  arxivid       = "1803.07770"
}

@ARTICLE{Gardner2022-vq,
  title    = "Toroidal topology of population activity in grid cells",
  author   = "Gardner, Richard J and Hermansen, Erik and Pachitariu, Marius and
              Burak, Yoram and Baas, Nils A and Dunn, Benjamin A and Moser,
              May-Britt and Moser, Edvard I",
  abstract = "The medial entorhinal cortex is part of a neural system for
              mapping the position of an individual within a physical
              environment1. Grid cells, a key component of this system, fire in
              a characteristic hexagonal pattern of locations2, and are
              organized in modules3 that collectively form a population code
              for the animal's allocentric position1. The invariance of the
              correlation structure of this population code across
              environments4,5 and behavioural states6,7, independent of
              specific sensory inputs, has pointed to intrinsic, recurrently
              connected continuous attractor networks (CANs) as a possible
              substrate of the grid pattern1,8-11. However, whether grid cell
              networks show continuous attractor dynamics, and how they
              interface with inputs from the environment, has remained unclear
              owing to the small samples of cells obtained so far. Here, using
              simultaneous recordings from many hundreds of grid cells and
              subsequent topological data analysis, we show that the joint
              activity of grid cells from an individual module resides on a
              toroidal manifold, as expected in a two-dimensional CAN.
              Positions on the torus correspond to positions of the moving
              animal in the environment. Individual cells are preferentially
              active at singular positions on the torus. Their positions are
              maintained between environments and from wakefulness to sleep, as
              predicted by CAN models for grid cells but not by alternative
              feedforward models12. This demonstration of network dynamics on a
              toroidal manifold provides a population-level visualization of
              CAN dynamics in grid cells.",
  journal  = "Nature",
  volume   =  602,
  number   =  7895,
  pages    = "123--128",
  month    =  feb,
  year     =  2022,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "35022611",
  doi      = "10.1038/s41586-021-04268-7",
  pmc      = "PMC8810387"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Finkelstein2015-oc,
  title     = "Three-dimensional head-direction coding in the bat brain",
  author    = "Finkelstein, Arseny and Derdikman, Dori and Rubin, Alon and
               Foerster, Jakob N and Las, Liora and Ulanovsky, Nachum",
  abstract  = "Navigation requires a sense of direction ('compass'), which in
               mammals is thought to be provided by head-direction cells,
               neurons that discharge when the animal's head points to a
               specific azimuth. However, it remains unclear whether a
               three-dimensional (3D) compass exists in the brain. Here we
               conducted neural recordings in bats, mammals well-adapted to 3D
               spatial behaviours, and found head-direction cells tuned to
               azimuth, pitch or roll, or to conjunctive combinations of 3D
               angles, in both crawling and flying bats. Head-direction cells
               were organized along a functional-anatomical gradient in the
               presubiculum, transitioning from 2D to 3D representations. In
               inverted bats, the azimuth-tuning of neurons shifted by 180°,
               suggesting that 3D head direction is represented in azimuth
               $\times$ pitch toroidal coordinates. Consistent with our
               toroidal model, pitch-cell tuning was unimodal, circular, and
               continuous within the available 360° of pitch. Taken together,
               these results demonstrate a 3D head-direction mechanism in
               mammals, which could support navigation in 3D space.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  517,
  number    =  7533,
  pages     = "159--164",
  month     =  jan,
  year      =  2015,
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "25470055",
  doi       = "10.1038/nature14031"
}

@UNPUBLISHED{Schoyen2022-ge,
  title    = "Coherently Remapping Toroidal Cells But Not Grid Cells are
              Responsible for Path Integration in Virtual Agents",
  author   = "Sch{\o}yen, Vemund and Pettersen, Markus Borud and Holzhausen,
              Konstantin and Malthe-S{\o}renssen, Anders and Lepper{\o}d,
              Mikkel Elle",
  abstract = "Animals employ a neural system to map physical environmental
              position to neural activity and encode allocentric location. Grid
              cells, proposedly a vital component of this system, form a
              population code of space by firing in characteristic tessellated
              triangles of locations. This population code remaps across
              environments and behavioural states, independent of specific
              sensory inputs, pointing to a substrate of standard computation
              across environments, which many speculate to be path integration.
              However, testing whether these cells are crucial for path
              integration is out of scope in today's experimental settings and
              calls for complementary methods, possibly given by computational
              models. Recently, normative artificial neural network models have
              shown that path integration and grid-cell-like activity can be
              found in recurrent neural networks (RNNs) trained to navigate in
              a simulated two-dimensional environment. Remarkably, the emergent
              spatial profile of these grid-like cells is similar to biological
              cell responses in that they set up a toroidal structure. Here, we
              extend the RNN normative model to multiple environments and show
              that cells that form the toroidal structure are crucial for path
              integration. However, cells selected through the grid cell score,
              a common defining property of grid cells, are much less important
              and comparable to randomly selected cells. Moreover, we show that
              the model can navigate multiple environments where toroidal cells
              remain biologically plausible in how grid cells remap across
              environments. Results demonstrate a causal relation between
              toroidal cells and path integration in virtual agents and propose
              a mechanism of remapping in grid cells based on remapping in
              place cells. The work is anticipated to have a potential parallel
              impact on experimental and computational neuroscience and machine
              learning due to the methods employed and the evaluation of
              results. For example, we propose explicit experiments that can
              evaluate both the model's validity and the role of grid cells in
              navigation. Moreover, the model can be further assessed to
              elucidate how high-dimensional data is mapped to low-dimensional
              structures, possibly providing a substrate for interpolation.
              \#\#\# Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.08.18.504379",
  month    =  aug,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.08.18.504379"
}

@ARTICLE{Rybakken2019-mv,
  title     = "Decoding of Neural Data Using Cohomological Feature Extraction",
  author    = "Rybakken, Erik and Baas, Nils and Dunn, Benjamin",
  abstract  = "We introduce a novel data-driven approach to discover and decode
               features in the neural code coming from large population neural
               recordings with minimal assumptions, using cohomological feature
               extraction. We apply our approach to neural recordings of mice
               moving freely in a box, where we find a circular feature. We
               then observe that the decoded value corresponds well to the head
               direction of the mouse. Thus, we capture head direction cells
               and decode the head direction from the neural population
               activity without having to process the mouse's behavior.
               Interestingly, the decoded values convey more information about
               the neural activity than the tracked head direction does, with
               differences that have some spatial organization. Finally, we
               note that the residual population activity, after the head
               direction has been accounted for, retains some low-dimensional
               structure that is correlated with the speed of the mouse.",
  journal   = "Neural Comput.",
  publisher = "direct.mit.edu",
  volume    =  31,
  number    =  1,
  pages     = "68--93",
  month     =  jan,
  year      =  2019,
  language  = "en",
  issn      = "0899-7667, 1530-888X",
  pmid      = "30462582",
  doi       = "10.1162/neco\_a\_01150"
}

@UNPUBLISHED{Benas2022-pz,
  title    = "Modeled grid cells aligned by a flexible attractor",
  author   = "Benas, Sabrina and Fernandez, Ximena and Kropff, Emilio",
  abstract = "Entorhinal grid cells implement a spatial code with hexagonal
              periodicity, signaling the position of the animal within an
              environment. Grid maps of cells belonging to the same module
              share spacing and orientation, only differing in relative
              two-dimensional spatial phase, which could result from their
              participation in a two-dimensional attractor. Such an
              architecture, however, has the drawbacks of being complex to
              construct and rigid, allowing no degrees of freedom for grid
              cells to deviate from the hexagonal pattern, as happens under a
              variety of experimental manipulations. Here we show that a
              simpler one-dimensional architecture is enough to align grid
              cells equally well. Using topological data analysis, we show that
              the resulting population activity is a sample of a torus, while
              the ensemble of maps preserves features of the network
              architecture. The flexibility of this low dimensional attractor
              allows it to negotiate with the feedforward inputs the geometry
              of the representation manifold, rather than imposing it, finding
              a number of equally viable configurations. Our results represent
              a proof of principle against the intuition that the architecture
              and the representation manifold of an attractor are the same
              topological object, with implications to the study of attractor
              networks across the brain. \#\#\# Competing Interest Statement
              The authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.06.13.495956",
  month    =  jun,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.06.13.495956"
}

@ARTICLE{Widloski2014-an,
  title     = "A model of grid cell development through spatial exploration and
               spike time-dependent plasticity",
  author    = "Widloski, John and Fiete, Ila R",
  abstract  = "Grid cell responses develop gradually after eye opening, but
               little is known about the rules that govern this process. We
               present a biologically plausible model for the formation of a
               grid cell network. An asymmetric spike time-dependent plasticity
               rule acts upon an initially unstructured network of spiking
               neurons that receive inputs encoding animal velocity and
               location. Neurons develop an organized recurrent architecture
               based on the similarity of their inputs, interacting through
               inhibitory interneurons. The mature network can convert velocity
               inputs into estimates of animal location, showing that spatially
               periodic responses and the capacity of path integration can
               arise through synaptic plasticity, acting on inputs that display
               neither. The model provides numerous predictions about the
               necessity of spatial exploration for grid cell development,
               network topography, the maturation of velocity tuning and neural
               correlations, the abrupt transition to stable patterned
               responses, and possible mechanisms to set grid period across
               grid modules.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  83,
  number    =  2,
  pages     = "481--495",
  month     =  jul,
  year      =  2014,
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "25033187",
  doi       = "10.1016/j.neuron.2014.06.018"
}

@UNPUBLISHED{Cogno2022-dy,
  title    = "Minute-scale oscillatory sequences in medial entorhinal cortex",
  author   = "Cogno, Soledad Gonzalo and Obenhaus, Horst A and Irene Jacobsen,
              R and Donato, Flavio and Moser, May-Britt and Moser, Edvard I",
  abstract = "The medial entorhinal cortex (MEC) hosts many of the brain's
              circuit elements for spatial navigation and episodic memory,
              operations that require neural activity to be organized across
              long durations of experience[1][1]. While location is known to be
              encoded by a plethora of spatially tuned cell types in this brain
              region[2][2]--[6][3], little is known about how the activity of
              entorhinal cells is tied together over time. Among the brain's
              most powerful mechanisms for neural coordination are network
              oscillations, which dynamically synchronize neural activity
              across circuit elements[7][4]--[10][5]. In MEC, theta and gamma
              oscillations provide temporal structure to the neural population
              activity at subsecond time scales[1][1],[11][6]--[13][7]. It
              remains an open question, however, whether similarly powerful
              coordination occurs in MEC at behavioural time scales, in the
              second-to-minute regime. Here we show that MEC activity can be
              organized into a minute-scale oscillation that entrains nearly
              the entire cell population, with periods ranging from 10 to 100
              seconds. Throughout this ultraslow oscillation, neural activity
              progresses in periodic and stereotyped sequences. This activity
              was elicited while mice ran at free pace on a rotating wheel in
              darkness, with no change in its location or running direction and
              no scheduled rewards. The oscillation sometimes advanced
              uninterruptedly for tens of minutes, transcending epochs of
              locomotion and immobility. Similar oscillatory sequences were not
              observed in neighboring parasubiculum or in visual cortex. The
              ultraslow oscillation of activity sequences in MEC may have the
              potential to couple its neurons and circuits across extended time
              scales and to serve as a scaffold for processes that unfold at
              behavioural time scales, such as navigation and episodic memory
              formation. \#\#\# Competing Interest Statement The authors have
              declared no competing interest. [1]: \#ref-1 [2]: \#ref-2 [3]:
              \#ref-6 [4]: \#ref-7 [5]: \#ref-10 [6]: \#ref-11 [7]: \#ref-13",
  journal  = "bioRxiv",
  pages    = "2022.05.02.490273",
  month    =  may,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.05.02.490273"
}

@ARTICLE{Knierim2012-eh,
  title     = "Attractor dynamics of spatially correlated neural activity in
               the limbic system",
  author    = "Knierim, James J and Zhang, Kechen",
  abstract  = "Attractor networks are a popular computational construct used to
               model different brain systems. These networks allow elegant
               computations that are thought to represent a number of aspects
               of brain function. Although there is good reason to believe that
               the brain displays attractor dynamics, it has proven difficult
               to test experimentally whether any particular attractor
               architecture resides in any particular brain circuit. We review
               models and experimental evidence for three systems in the rat
               brain that are presumed to be components of the rat's
               navigational and memory system. Head-direction cells have been
               modeled as a ring attractor, grid cells as a plane attractor,
               and place cells both as a plane attractor and as a point
               attractor. Whereas the models have proven to be extremely useful
               conceptual tools, the experimental evidence in their favor,
               although intriguing, is still mostly circumstantial.",
  journal   = "Annu. Rev. Neurosci.",
  publisher = "ncbi.nlm.nih.gov",
  volume    =  35,
  pages     = "267--285",
  month     =  mar,
  year      =  2012,
  language  = "en",
  issn      = "0147-006X, 1545-4126",
  pmid      = "22462545",
  doi       = "10.1146/annurev-neuro-062111-150351",
  pmc       = "PMC5613981"
}

@ARTICLE{Guanella2007-jr,
  title     = "A model of grid cells based on a twisted torus topology",
  author    = "Guanella, Alexis and Kiper, Daniel and Verschure, Paul",
  abstract  = "The grid cells of the rat medial entorhinal cortex (MEC) show an
               increased firing frequency when the position of the animal
               correlates with multiple regions of the environment that are
               arranged in regular triangular grids. Here, we describe an
               artificial neural network based on a twisted torus topology,
               which allows for the generation of regular triangular grids. The
               association of the activity of pre-defined hippocampal place
               cells with entorhinal grid cells allows for a highly
               robust-to-noise calibration mechanism, suggesting a role for the
               hippocampal back-projections to the entorhinal cortex.",
  journal   = "Int. J. Neural Syst.",
  publisher = "World Scientific",
  volume    =  17,
  number    =  4,
  pages     = "231--240",
  month     =  aug,
  year      =  2007,
  language  = "en",
  issn      = "0129-0657",
  pmid      = "17696288",
  doi       = "10.1142/S0129065707001093"
}

@ARTICLE{Kropff2008-lo,
  title     = "The emergence of grid cells: Intelligent design or just
               adaptation?",
  author    = "Kropff, Emilio and Treves, Alessandro",
  abstract  = "Individual medial entorhinal cortex (mEC) 'grid' cells provide a
               representation of space that appears to be essentially invariant
               across environments, modulo simple transformations, in contrast
               to multiple, rapidly acquired hippocampal maps; it may therefore
               be established gradually during rodent development. We explore
               with a simplified mathematical model the possibility that the
               self-organization of multiple grid fields into a triangular grid
               pattern may be a single-cell process, driven by firing rate
               adaptation and slowly varying spatial inputs. A simple
               analytical derivation indicates that triangular grids are
               favored asymptotic states of the self-organizing system, and
               computer simulations confirm that such states are indeed reached
               during a model learning process, provided it is sufficiently
               slow to effectively average out fluctuations. The interactions
               among local ensembles of grid units serve solely to stabilize a
               common grid orientation. Spatial information, in the real mEC
               network, may be provided by any combination of feedforward
               cortical afferents and feedback hippocampal projections from
               place cells, since either input alone is likely sufficient to
               yield grid fields.",
  journal   = "Hippocampus",
  publisher = "Wiley Online Library",
  volume    =  18,
  number    =  12,
  pages     = "1256--1269",
  year      =  2008,
  language  = "en",
  issn      = "1050-9631, 1098-1063",
  pmid      = "19021261",
  doi       = "10.1002/hipo.20520"
}

@ARTICLE{Xie2002-ds,
  title     = "Double-ring network model of the head-direction system",
  author    = "Xie, Xiaohui and Hahnloser, Richard H R and Seung, H Sebastian",
  abstract  = "In the head-direction system, the orientation of an animal's
               head in space is encoded internally by persistent activities of
               a pool of cells whose firing rates are tuned to the animal's
               directional heading. To maintain an accurate representation of
               the heading information when the animal moves, the system
               integrates horizontal angular head-velocity signals from the
               vestibular nuclei and updates the representation of directional
               heading. The integration is a difficult process, given that head
               velocities can vary over a large range and the neural system is
               highly nonlinear. Previous models of integration have relied on
               biologically unrealistic mechanisms, such as instantaneous
               changes in synaptic strength, or very fast synaptic dynamics. In
               this paper, we propose a different integration model with two
               populations of neurons, which performs integration based on the
               differential input of the vestibular nuclei to these two
               populations. We mathematically analyze the dynamics of the model
               and demonstrate that with carefully tuned synaptic connections
               it can accurately integrate a large range of the vestibular
               input, with potentially slow synapses.",
  journal   = "Phys. Rev. E Stat. Nonlin. Soft Matter Phys.",
  publisher = "APS",
  volume    =  66,
  number    = "4 Pt 1",
  pages     = "041902",
  month     =  oct,
  year      =  2002,
  language  = "en",
  issn      = "1539-3755",
  pmid      = "12443230",
  doi       = "10.1103/PhysRevE.66.041902"
}

@ARTICLE{Stringer2002-uc,
  title     = "Self-organizing continuous attractor networks and path
               integration: two-dimensional models of place cells",
  author    = "Stringer, S M and Rolls, E T and Trappenberg, T P and de Araujo,
               I E T",
  abstract  = "Single-neuron recording studies have demonstrated the existence
               of neurons in the hippocampus which appear to encode information
               about the place where a rat is located, and about the place at
               which a macaque is looking. We describe 'continuous attractor'
               neural network models of place cells with Gaussian spatial
               fields in which the recurrent collateral synaptic connections
               between the neurons reflect the distance between two places. The
               networks maintain a localized packet of neuronal activity that
               represents the place where the animal is located. We show for
               two related models how the representation of the two-dimensional
               space in the continuous attractor network of place cells could
               self-organize by modifying the synaptic connections between the
               neurons, and also how the place being represented can be updated
               by idiothetic (self-motion) signals in a neural implementation
               of path integration.",
  journal   = "Network",
  publisher = "Taylor \& Francis",
  volume    =  13,
  number    =  4,
  pages     = "429--446",
  month     =  nov,
  year      =  2002,
  language  = "en",
  issn      = "0093-3341, 0954-898X",
  pmid      = "12463338"
}

@ARTICLE{Nielsen2020-de,
  title    = "An Elementary Introduction to Information Geometry",
  author   = "Nielsen, Frank",
  abstract = "In this survey, we describe the fundamental
              differential-geometric structures of information manifolds, state
              the fundamental theorem of information geometry, and illustrate
              some use cases of these information manifolds in information
              sciences. The exposition is self-contained by concisely
              introducing the necessary concepts of differential geometry.
              Proofs are omitted for brevity.",
  journal  = "Entropy",
  volume   =  22,
  number   =  10,
  month    =  sep,
  year     =  2020,
  keywords = "Bayesian hypothesis testing; Fisher--Rao distance; Hessian
              manifolds; affine connection; conjugate connections; curvature
              and flatness; differential geometry; dual metric-compatible
              parallel transport; dually flat manifolds; exponential family;
              gauge freedom; information manifold; metric compatibility; metric
              tensor; mixed parameterization; mixture clustering; mixture
              family; parameter divergence; separable divergence; statistical
              divergence; statistical invariance; statistical manifold;
              $\alpha$-embeddings",
  language = "en",
  issn     = "1099-4300",
  pmid     = "33286868",
  doi      = "10.3390/e22101100",
  pmc      = "PMC7650632"
}

@UNPUBLISHED{Tuckute2022-rh,
  title    = "Many but not all deep neural network audio models capture brain
              responses and exhibit hierarchical region correspondence",
  author   = "Tuckute, Greta and Feather, Jenelle and Boebinger, Dana and
              McDermott, Josh H",
  abstract = "Deep neural networks are commonly used as models of the visual
              system, but are less explored in audition. Prior work provided
              examples of audio-trained neural networks that produced good
              predictions of auditory cortical fMRI responses and exhibited
              correspondence between model stages and brain regions, but left
              it unclear whether these results generalize to other neural
              network models. We evaluated brain-model correspondence for
              publicly available audio neural network models along with
              in-house models trained on four different tasks. Most tested
              models out-predicted previous filter-bank models of auditory
              cortex, and exhibited systematic model-brain correspondence:
              middle stages best predicted primary auditory cortex while deep
              stages best predicted non-primary cortex. However, some
              state-of-the-art models produced substantially worse brain
              predictions. The training task influenced the prediction quality
              for specific cortical tuning properties, with best overall
              predictions resulting from models trained on multiple tasks. The
              results suggest the importance of task optimization in
              constraining brain representations. \#\#\# Competing Interest
              Statement The authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.09.06.506680",
  month    =  sep,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.09.06.506680"
}

@UNPUBLISHED{Stocker2022-qk,
  title    = "Network controllability measures of subnetworks: implications for
              neurosciences",
  author   = "Stocker, Julia Elina and Nozari, Erfan and van Vugt, Marieke K
              and Jansen, Andreas and Jamalabadi, Hamidreza",
  abstract = "Recent progress in network sciences has made it possible to apply
              key findings from control theory to the study of networks.
              Referred to as network control theory, this framework describes
              how the interactions between interconnected system elements and
              external energy sources, potentially constrained by different
              optimality criteria, result in complex network behavior. A
              typical example is the quantification of the functional role
              certain brain regions or symptoms play in shaping the temporal
              dynamics of brain activity or the clinical course of a disease, a
              property that is quantified in terms of the so-called
              controllability metrics. Critically though, contrary to the
              engineering context in which control theory was originally
              developed, a mathematical understanding of the network nodes and
              connections in neurosciences cannot be assumed. For instance, in
              the case of psychological systems such as those studied to
              understand the psychiatric disorders, a potentially large set
              variables are unknown. As such, while the measures offered by
              network control theory would be mathematically correct, in that
              they can be calculated with high precision, they could have
              little translational values with respect to their putative role
              suggested by controllability metrics. It is therefore critical to
              understand if and how the controllability metrics computer over
              subnetworks would deviate, if access to the complete set of
              variables, as in neurosciences, cannot be taken for granted. In
              this paper, we use a host of simulations based on synthetic as
              well as structural MRI data to study the potential deviation of
              controllability metrics in sub- compared to the full networks.
              Specifically, we estimate average- and modal-controllability, two
              of the most widely used controllability measures in
              neurosciences, in a large number of settings where we
              systematically vary network type, network size, and edge density.
              We find out, across all network types we test, that average and
              modal controllability are systematically, either over- or
              underestimated depending on the number of nodes in the sub- and
              full network and the edge density. Finally, we provide a formal
              theoretical proof that our observations generalize to any network
              type and discuss the ramifications of this systematic bias and
              potential solutions to alleviate the problem. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest.",
  journal  = "bioRxiv",
  pages    = "2022.09.11.507468",
  month    =  sep,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.09.11.507468"
}

@ARTICLE{Ainsworth2022-wv,
  title         = "Git {Re-Basin}: Merging Models modulo Permutation Symmetries",
  author        = "Ainsworth, Samuel K and Hayase, Jonathan and Srinivasa,
                   Siddhartha",
  abstract      = "The success of deep learning is thanks to our ability to
                   solve certain massive non-convex optimization problems with
                   relative ease. Despite non-convex optimization being
                   NP-hard, simple algorithms -- often variants of stochastic
                   gradient descent -- exhibit surprising effectiveness in
                   fitting large neural networks in practice. We argue that
                   neural network loss landscapes contain (nearly) a single
                   basin, after accounting for all possible permutation
                   symmetries of hidden units. We introduce three algorithms to
                   permute the units of one model to bring them into alignment
                   with units of a reference model. This transformation
                   produces a functionally equivalent set of weights that lie
                   in an approximately convex basin near the reference model.
                   Experimentally, we demonstrate the single basin phenomenon
                   across a variety of model architectures and datasets,
                   including the first (to our knowledge) demonstration of
                   zero-barrier linear mode connectivity between independently
                   trained ResNet models on CIFAR-10 and CIFAR-100.
                   Additionally, we identify intriguing phenomena relating
                   model width and training time to mode connectivity across a
                   variety of models and datasets. Finally, we discuss
                   shortcomings of a single basin theory, including a
                   counterexample to the linear mode connectivity hypothesis.",
  month         =  sep,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2209.04836",
  primaryClass  = "cs.LG",
  arxivid       = "2209.04836"
}

@ARTICLE{Bruske1998-ae,
  title     = "Intrinsic dimensionality estimation with optimally topology
               preserving maps",
  author    = "Bruske, J and Sommer, G",
  abstract  = "A new method for analyzing the intrinsic dimensionality (ID) of
               low-dimensional manifolds in high-dimensional feature spaces is
               presented. Compared to a previous approach by Fukunaga and Olsen
               (1971), the method has only linear instead of cubic time
               complexity with respect to the dimensionality of the input
               space. Moreover, it is less sensitive to noise than the former
               approach. Experiments include ID estimation of synthetic data
               for comparison and illustration as well as ID estimation of an
               image sequence.",
  journal   = "IEEE Trans. Pattern Anal. Mach. Intell.",
  publisher = "ieeexplore.ieee.org",
  volume    =  20,
  number    =  5,
  pages     = "572--575",
  month     =  may,
  year      =  1998,
  keywords  = "Topology;Principal component analysis;Data visualization;Image
               sequences;Vector quantization;Fractals;System
               identification;Monitoring;Nonlinear distortion;Neural networks",
  issn      = "0162-8828, 1939-3539",
  doi       = "10.1109/34.682189"
}

@ARTICLE{Kambhatla1997-sp,
  title     = "Dimension reduction by local principal component analysis",
  author    = "Kambhatla, Nandakishore and Leen, Todd K",
  abstract  = "Reducing or eliminating statistical redundancy between the
               components of high-dimensional vector data enables a
               lower-dimensional representation without significant loss of
               information. Recognizing the limitations of principal component
               analysis (PCA), researchers in the statistics and neural network
               communities have developed nonlinear extensions of PCA. This
               article develops a local linear approach to dimension reduction
               that provides accurate representations and is fast to compute.
               We exercise the algorithms on speech and image data, and compare
               performance with PCA and with neural network implementations of
               nonlinear PCA. We find that both nonlinear techniques can
               provide more accurate representations than PCA and show that the
               local linear techniques outperform neural network
               implementations.",
  journal   = "Neural Comput.",
  publisher = "MIT Press - Journals",
  volume    =  9,
  number    =  7,
  pages     = "1493--1516",
  month     =  oct,
  year      =  1997,
  language  = "en",
  issn      = "0899-7667, 1530-888X",
  doi       = "10.1162/neco.1997.9.7.1493"
}

@ARTICLE{Fukunaga1971-ot,
  title     = "An Algorithm for Finding Intrinsic Dimensionality of Data",
  author    = "Fukunaga, K and Olsen, D R",
  abstract  = "An algorithm for the analysis of multivariant data is presented
               along with some experimental results. The basic idea of the
               method is to examine the data in many small subregions, and from
               this determine the number of governing parameters, or intrinsic
               dimensionality. This intrinsic dimensionality is usually much
               lower than the dimensionality that is given by the standard
               Karhunen-Lo{\`e}ve technique. An analysis that demonstrates the
               feasability of this approach is presented.",
  journal   = "IEEE Trans. Comput.",
  publisher = "ieeexplore.ieee.org",
  volume    = "C-20",
  number    =  2,
  pages     = "176--183",
  month     =  feb,
  year      =  1971,
  keywords  = "Data reduction, dimensionality reduction, interactive systems,
               intrinsic dimensionality, Karhunen-Lo{\`e}ve expansion,
               multivariant data analysis, principal component, stochastic
               processes.",
  issn      = "0018-9340, 1557-9956",
  doi       = "10.1109/T-C.1971.223208"
}

@ARTICLE{Bac2021-kt,
  title    = "{Scikit-Dimension}: A Python Package for Intrinsic Dimension
              Estimation",
  author   = "Bac, Jonathan and Mirkes, Evgeny M and Gorban, Alexander N and
              Tyukin, Ivan and Zinovyev, Andrei",
  abstract = "Dealing with uncertainty in applications of machine learning to
              real-life data critically depends on the knowledge of intrinsic
              dimensionality (ID). A number of methods have been suggested for
              the purpose of estimating ID, but no standard package to easily
              apply them one by one or all at once has been implemented in
              Python. This technical note introduces scikit-dimension, an
              open-source Python package for intrinsic dimension estimation.
              The scikit-dimension package provides a uniform implementation of
              most of the known ID estimators based on the scikit-learn
              application programming interface to evaluate the global and
              local intrinsic dimension, as well as generators of synthetic toy
              and benchmark datasets widespread in the literature. The package
              is developed with tools assessing the code quality, coverage,
              unit testing and continuous integration. We briefly describe the
              package and demonstrate its use in a large-scale (more than 500
              datasets) benchmarking of methods for ID estimation for real-life
              and synthetic data.",
  journal  = "Entropy",
  volume   =  23,
  number   =  10,
  month    =  oct,
  year     =  2021,
  keywords = "Python package; effective dimension; intrinsic dimension; method
              benchmarking",
  language = "en",
  issn     = "1099-4300",
  pmid     = "34682092",
  doi      = "10.3390/e23101368",
  pmc      = "PMC8534554"
}

@MISC{Little_undated-cg,
  title        = "Multiscale geometric methods for estimating intrinsic
                  dimension",
  author       = "Little, Anna V and Maggioni, Mauro and Rosasco, Lorenzo",
  abstract     = "We present a novel approach for estimating the intrinsic
                  dimension of certain point clouds: we assume that the points
                  are sampled from a manifold M of dimension k, with k << D,
                  and corrupted by D-dimensional noise. When M is linear, one
                  may analyze this situation by PCA: with no noise one would
                  obtain a rank k matrix, and noise may be treated as a
                  perturbation of the covariance matrix. When M is a nonlinear
                  manifold, global PCA may dramatically overestimate the
                  intrinsic dimension. We discuss a multiscale version of PCA
                  and how one can extract estimators for the intrinsic
                  dimension that are highly robust to noise, and we derive some
                  of their finite-sample-size properties.",
  howpublished = "\url{http://lcsl.mit.edu/papers/lit_mag_ros_2011.pdf}",
  note         = "Accessed: 2022-9-16"
}

@UNPUBLISHED{Karniol-Tambour2022-ak,
  title    = "Modeling communication and switching nonlinear dynamics in
              multi-region neural activity",
  author   = "Karniol-Tambour, Orren and Zoltowski, David M and Mika Diamanti,
              E and Pinto, Lucas and Tank, David W and Brody, Carlos W and
              Pillow, Jonathan W",
  abstract = "Understanding how multiple brain regions interact to produce
              behavior is a major challenge in systems neuroscience, with many
              regions causally implicated in common tasks such as sensory
              processing and decision making. However, a precise description of
              interactions between regions remains an open problem. Moreover,
              neural dynamics are nonlinear, non-stationary, and can vary
              dramatically across sessions, days, and animals. Here, we propose
              multi-region, switching dynamical systems (MR-SDS), a
              probabilistic model of multiple latent interacting systems that
              evolve with switching nonlinear dynamics and communication
              between regions. MR-SDS includes directed interactions between
              brain regions, allowing for estimation of state-dependent
              communication signals, and accounts for sensory inputs effects,
              history effects, and heterogeneity across days and animals. We
              show that our model accurately recovers latent trajectories,
              vector fields underlying switching nonlinear dynamics, and
              cross-region communication profiles in two simulations. We then
              apply our method to two large-scale, multi-region neural datasets
              involving mouse decision making. The first includes hundreds of
              neurons per region, recorded simultaneously at
              single-cell-resolution across 3 distant cortical regions. The
              second is a mesoscale widefield dataset of 8 adjacent cortical
              regions imaged across both hemispheres. On these multi-region
              datasets, our model outperforms existing piece-wise linear
              multi-region models and reveals multiple distinct dynamical
              states and a rich set of cross-region communication profiles.
              \#\#\# Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.09.13.507841",
  month    =  sep,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.09.13.507841"
}

@ARTICLE{Scheler2022-sj,
  title         = "Sketch of a novel approach to a neural model",
  author        = "Scheler, Gabriele",
  abstract      = "In this paper, we lay out a novel model of neuroplasticity
                   in the form of a horizontal-vertical integration model of
                   neural processing. We believe a new approach to neural
                   modeling will benefit the 3rd wave of AI. The horizontal
                   plane consists of an adaptive network of neurons connected
                   by transmission links which generates spatio-temporal spike
                   patterns. This fits with standard computational neuroscience
                   approaches. Additionally for each individual neuron there is
                   a vertical part consisting of internal adaptive parameters
                   steering the external membrane-expressed parameters which
                   are involved in neural transmission. Each neuron has a
                   vertical modular system of parameters corresponding to (a)
                   external parameters at the membrane layer, divided into
                   compartments (spines, boutons) (b) internal parameters in
                   the submembrane zone and the cytoplasm with its protein
                   signaling network and (c) core parameters in the nucleus for
                   genetic and epigenetic information. In such models, each
                   node (=neuron) in the horizontal network has its own
                   internal memory. Neural transmission and information storage
                   are systematically separated, an important conceptual
                   advance over synaptic weight models. We discuss the
                   membrane-based (external) filtering and selection of outside
                   signals for processing vs. signal loss by fast fluctuations
                   and the neuron-internal computing strategies from
                   intracellular protein signaling to the nucleus as the core
                   system. We want to show that the individual neuron has an
                   important role in the computation of signals and that many
                   assumptions derived from the synaptic weight adjustment
                   hypothesis of memory may not hold in a real brain. Not every
                   transmission event leaves a trace and the neuron is a
                   self-programming device, rather than passively determined by
                   current input. Ultimately we strive to build a flexible
                   memory system that processes facts and events automatically.",
  month         =  sep,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2209.06865",
  primaryClass  = "q-bio.NC",
  arxivid       = "2209.06865"
}

@ARTICLE{Dorrell2022-hq,
  title         = "Actionable Neural Representations: Grid Cells from Minimal
                   Constraints",
  author        = "Dorrell, William and Latham, Peter E and Behrens, Timothy E
                   J and Whittington, James C R",
  abstract      = "To afford flexible behaviour, the brain must build internal
                   representations that mirror the structure of variables in
                   the external world. For example, 2D space obeys rules: the
                   same set of actions combine in the same way everywhere (step
                   north, then south, and you won't have moved, wherever you
                   start). We suggest the brain must represent this consistent
                   meaning of actions across space, as it allows you to find
                   new short-cuts and navigate in unfamiliar settings. We term
                   this representation an `actionable representation'. We
                   formulate actionable representations using group and
                   representation theory, and show that, when combined with
                   biological and functional constraints - non-negative firing,
                   bounded neural activity, and precise coding - multiple
                   modules of hexagonal grid cells are the optimal
                   representation of 2D space. We support this claim with
                   intuition, analytic justification, and simulations. Our
                   analytic results normatively explain a set of surprising
                   grid cell phenomena, and make testable predictions for
                   future experiments. Lastly, we highlight the generality of
                   our approach beyond just understanding 2D space. Our work
                   characterises a new principle for understanding and
                   designing flexible internal representations: they should be
                   actionable, allowing animals and machines to predict the
                   consequences of their actions, rather than just encode.",
  month         =  sep,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2209.15563",
  primaryClass  = "q-bio.NC",
  arxivid       = "2209.15563"
}

@MISC{Sorce_undated-fo,
  title        = "Transport on smooth manifolds: Fiber bundles, connections,
                  and covariant derivatives",
  author       = "Sorce, Jonathan",
  abstract     = "In the study of smooth, real manifolds, the most powerful
                  analytical tools available may only be applied locally. It is
                  pertinent, therefore, to consider what global structures may
                  reasonably be imposed on such a manifold, and what analytical
                  tools are gained as a result. In particular, one may ask how
                  local structures at one point of a manifold may be smoothly
                  related to similar structures at a distant point-for example,
                  how the tangent spaces to two distinct points in a manifold
                  may be put in isomorphic correspondence. In this paper, we
                  give an introduction to the study of this problem by
                  developing the basics of the theory of Ehresmann connections
                  on smooth manifolds. To do so, we develop the machinery of
                  fiber bundles, discuss the fiber bundle structure of smooth
                  manifolds, and apply these principles in order to provide a
                  means of globally identifying local structures. Whenever
                  possible, we employ methods that favor geometric intuition
                  and visualization over formalism and computation.",
  howpublished = "\url{http://math.uchicago.edu/~may/REU2015/REUPapers/Sorce.pdf}",
  note         = "Accessed: 2022-9-19"
}

@INCOLLECTION{Casey2016-qo,
  title     = "Kinematical Aspects of {Levi-Civita} Transport of Vectors and
               Tensors Along a Surface Curve",
  booktitle = "The Mechanics of Ribbons and M{\"o}bius Bands",
  author    = "Casey, James",
  editor    = "Fosdick, Roger and Fried, Eliot",
  abstract  = "The concept of parallelism along a surface curve, which was
               introduced by Levi-Civita in the context of n-dimensional
               Riemannian manifolds, is re-examined from a kinematical
               viewpoint. A special type of frame, whose angular velocity is
               determined by the rate at which the tangent plane turns as one
               moves along a surface curve, is defined and is called a
               Levi-Civita frame. The surface may be orientable or not. Vectors
               and tensors fixed on Levi-Civita frames are parallel
               transported. Covariant differentiation of vectors and tensors
               along a surface curve can be expressed in terms of the
               corresponding corotational rates measured on Levi-Civita frames.
               Relevant results on ruled surfaces are also included.",
  publisher = "Springer Netherlands",
  pages     = "213--249",
  year      =  2016,
  address   = "Dordrecht",
  isbn      = "9789401773003",
  doi       = "10.1007/978-94-017-7300-3\_12"
}

@MISC{Grimm_undated-oo,
  title        = "Parameterizing {N} -holed Tori",
  author       = "Grimm, Cindy and Hughes, John",
  abstract     = "We define a parameterization for an n-holed tori based on the
                  hyperbolic polygon. We model the domain using a manifold with
                  2n+ 2 charts, and linear fractional transformations for
                  transition functions. We embed the manifold using standard
                  spline techniques to produce a surface.",
  howpublished = "\url{https://cs.brown.edu/people/jhughes/papers/Grimm-PNT-2003/paper.pdf}",
  note         = "Accessed: 2022-9-21"
}

@ARTICLE{Gu2007-kt,
  title     = "Conformal spherical parametrization for high genus surfaces",
  author    = "Gu, Xianfeng and Li, Xin and Yau, Shing-Tung and Zeng, Wei",
  journal   = "Commun. Inf. Syst.",
  publisher = "International Press of Boston",
  volume    =  7,
  number    =  3,
  pages     = "273--286",
  year      =  2007,
  issn      = "1526-7555, 2163-4548",
  doi       = "10.4310/cis.2007.v7.n3.a4"
}

@MISC{Hormann_undated-tc,
  title        = "Mesh Parameterization: Theory and Practice",
  author       = "Hormann, Kai and L{\'e}vy, Bruno and Sheer, Alla",
  howpublished = "\url{http://alice.loria.fr/publications/papers/2007/SigCourseParam/param-course.pdf}",
  note         = "Accessed: 2022-9-21"
}

@ARTICLE{Crane2020-hc,
  title         = "A Survey of Algorithms for Geodesic Paths and Distances",
  author        = "Crane, Keenan and Livesu, Marco and Puppo, Enrico and Qin,
                   Yipeng",
  abstract      = "Numerical computation of shortest paths or geodesics on
                   curved domains, as well as the associated geodesic distance,
                   arises in a broad range of applications across digital
                   geometry processing, scientific computing, computer
                   graphics, and computer vision. Relative to Euclidean
                   distance computation, these tasks are complicated by the
                   influence of curvature on the behavior of shortest paths, as
                   well as the fact that the representation of the domain may
                   itself be approximate. In spite of the difficulty of this
                   problem, recent literature has developed a wide variety of
                   sophisticated methods that enable rapid queries of geodesic
                   information, even on relatively large models. This survey
                   reviews the major categories of approaches to the
                   computation of geodesic paths and distances, highlighting
                   common themes and opportunities for future improvement.",
  month         =  jul,
  year          =  2020,
  archivePrefix = "arXiv",
  eprint        = "2007.10430",
  primaryClass  = "cs.GR",
  arxivid       = "2007.10430",
  doi           = "10.1145/nnnnnnn.nnnnnnn"
}

@ARTICLE{Adam2022-rm,
  title    = "Dynamic control of visually guided locomotion through
              corticosubthalamic projections",
  author   = "Adam, Elie M and Johns, Taylor and Sur, Mriganka",
  abstract = "Goal-directed locomotion requires control signals that propagate
              from higher order areas to regulate spinal mechanisms. The
              corticosubthalamic hyperdirect pathway offers a short route for
              cortical information to reach locomotor centers in the brainstem.
              We developed a task in which head-fixed mice run to a visual
              landmark and then stop and wait to collect the reward and
              examined the role of secondary motor cortex (M2) projections to
              the subthalamic nucleus (STN) in controlling locomotion. Our
              behavioral modeling, calcium imaging, and optogenetics
              manipulation results suggest that the M2-STN pathway can be
              recruited during visually guided locomotion to rapidly and
              precisely control the pedunculopontine nucleus (PPN) of the
              mesencephalic locomotor region through the basal ganglia. By
              capturing the physiological dynamics through a feedback control
              model and analyzing neuronal signals in M2, PPN, and STN, we find
              that the corticosubthalamic projections potentially control PPN
              activity by differentiating an M2 error signal to ensure fast
              input-output dynamics.",
  journal  = "Cell Rep.",
  volume   =  40,
  number   =  4,
  pages    = "111139",
  month    =  jul,
  year     =  2022,
  keywords = "CP: Neuroscience; controller; dynamical system; hyperdirect
              pathway; landmark; locomotion; mesencephalic locomotor region;
              pedunculopontine nucleus; secondary motor cortex; stopping;
              subthalamic nucleus; visually guided;Locomotion",
  language = "en",
  issn     = "2211-1247",
  pmid     = "35905719",
  doi      = "10.1016/j.celrep.2022.111139",
  pmc      = "PMC9395210"
}

@ARTICLE{David_Redishyx1996-ss,
  title   = "A coupled attractor model of the rodent head direction system",
  author  = "David Redishyx, A and Elgazk, Adam N and Touretzkyy{, David S",
  journal = "Network: Computation in Neural Systems",
  volume  =  7,
  pages   = "671--685",
  year    =  1996
}

@ARTICLE{Whittington2022-bn,
  title    = "How to build a cognitive map",
  author   = "Whittington, James C R and McCaffary, David and Bakermans, Jacob
              J W and Behrens, Timothy E J",
  abstract = "Learning and interpreting the structure of the environment is an
              innate feature of biological systems, and is integral to guiding
              flexible behaviors for evolutionary viability. The concept of a
              cognitive map has emerged as one of the leading metaphors for
              these capacities, and unraveling the learning and neural
              representation of such a map has become a central focus of
              neuroscience. In recent years, many models have been developed to
              explain cellular responses in the hippocampus and other brain
              areas. Because it can be difficult to see how these models
              differ, how they relate and what each model can contribute, this
              Review aims to organize these models into a clear ontology. This
              ontology reveals parallels between existing empirical results,
              and implies new approaches to understand hippocampal-cortical
              interactions and beyond.",
  journal  = "Nat. Neurosci.",
  volume   =  25,
  number   =  10,
  pages    = "1257--1272",
  month    =  oct,
  year     =  2022,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "36163284",
  doi      = "10.1038/s41593-022-01153-y"
}

@ARTICLE{Duan2022-sd,
  title         = "See and Copy: Generation of complex compositional movements
                   from modular and geometric {RNN} representations",
  author        = "Duan, Sunny and Khona, Mikail and Bertagnoli, Adrian and
                   Chandra, Sarthak and Fiete, Ila",
  abstract      = "A hallmark of biological intelligence and control is
                   combinatorial generalization: animals are able to learn
                   various things, then piece them together in new combinations
                   to produce appropriate outputs for new tasks. Inspired by
                   the ability of primates to readily imitate seen movement
                   sequences, we present a model of motor control using a
                   realistic model of arm dynamics, tasked with imitating a
                   guide that makes arbitrary two-segment drawings. We
                   hypothesize that modular organization is one of the keys to
                   such flexible and generalizable control. We construct a
                   modular control model consisting of separate encoding and
                   motor RNNs and a scheduler, which we train end-to-end on the
                   task. We show that the modular structure allows the model to
                   generalize not only to unseen two-segment trajectories, but
                   to new drawings consisting of many more segments than it was
                   trained on, and also allows for rapid adaptation to
                   perturbations. Finally, our model recapitulates experimental
                   observations of the preparatory and execution-related
                   processes unfolding during motor control, providing a
                   normative explanation for functional segregation of
                   preparatory and execution-related activity within the motor
                   cortex.",
  month         =  oct,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2210.02521",
  primaryClass  = "q-bio.NC",
  arxivid       = "2210.02521"
}

@ARTICLE{Xu2022-ge,
  title         = "Conformal Isometry of Lie Group Representation in Recurrent
                   Network of Grid Cells",
  author        = "Xu, Dehong and Gao, Ruiqi and Zhang, Wen-Hao and Wei,
                   Xue-Xin and Wu, Ying Nian",
  abstract      = "The activity of the grid cell population in the medial
                   entorhinal cortex (MEC) of the brain forms a vector
                   representation of the self-position of the animal. Recurrent
                   neural networks have been developed to explain the
                   properties of the grid cells by transforming the vector
                   based on the input velocity, so that the grid cells can
                   perform path integration. In this paper, we investigate the
                   algebraic, geometric, and topological properties of grid
                   cells using recurrent network models. Algebraically, we
                   study the Lie group and Lie algebra of the recurrent
                   transformation as a representation of self-motion.
                   Geometrically, we study the conformal isometry of the Lie
                   group representation of the recurrent network where the
                   local displacement of the vector in the neural space is
                   proportional to the local displacement of the agent in the
                   2D physical space. We then focus on a simple non-linear
                   recurrent model that underlies the continuous attractor
                   neural networks of grid cells. Our numerical experiments
                   show that conformal isometry leads to hexagon periodic
                   patterns of the response maps of grid cells and our model is
                   capable of accurate path integration.",
  month         =  oct,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2210.02684",
  primaryClass  = "q-bio.NC",
  arxivid       = "2210.02684"
}

@ARTICLE{Green2017-zj,
  title    = "A neural circuit architecture for angular integration in
              Drosophila",
  author   = "Green, Jonathan and Adachi, Atsuko and Shah, Kunal K and
              Hirokawa, Jonathan D and Magani, Pablo S and Maimon, Gaby",
  abstract = "Many animals keep track of their angular heading over time while
              navigating through their environment. However, a neural-circuit
              architecture for computing heading has not been experimentally
              defined in any species. Here we describe a set of clockwise- and
              anticlockwise-shifting neurons in the Drosophila central complex
              whose wiring and physiology provide a means to rotate an angular
              heading estimate based on the fly's angular velocity. We show
              that each class of shifting neurons exists in two subtypes, with
              spatiotemporal activity profiles that suggest different roles for
              each subtype at the start and end of tethered-walking turns.
              Shifting neurons are required for the heading system to properly
              track the fly's heading in the dark, and stimulation of these
              neurons induces predictable shifts in the heading signal. The
              central features of this biological circuit are analogous to
              those of computational models proposed for head-direction cells
              in rodents and may shed light on how neural systems, in general,
              perform integration.",
  journal  = "Nature",
  volume   =  546,
  number   =  7656,
  pages    = "101--106",
  month    =  jun,
  year     =  2017,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "28538731",
  doi      = "10.1038/nature22343",
  pmc      = "PMC6320684"
}

@UNPUBLISHED{Fascianelli2022-sh,
  title    = "Neural representational geometry correlates with behavioral
              differences between monkeys",
  author   = "Fascianelli, Valeria and Stefanini, Fabio and Tsujimoto, Satoshi
              and Genovesio, Aldo and Fusi, Stefano",
  abstract = "Animals likely use a variety of strategies to solve laboratory
              tasks. Traditionally, combined analysis of behavioral and neural
              recording data across subjects employing different strategies may
              obscure important signals and give confusing results. Hence it is
              important to develop techniques that can infer strategy at the
              single-subject level. We analyzed an experiment in which two
              monkeys perform a visually cued rule-based task. From the
              analysis of their performance there is no indication that they
              used a different strategy. However, when we examined the geometry
              of stimulus representations in the state space of the neural
              activities recorded in dorsolateral prefrontal cortex, we found
              striking differences. Our purely neural results predict
              behavioral differences that we observed by analyzing the reaction
              times. These analyses provide strong support that the animals
              employed different strategies. Finally, we used a modeling study
              to correlate these strategies with the amount of training that
              the animals received. \#\#\# Competing Interest Statement The
              authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.10.05.511024",
  month    =  oct,
  year     =  2022,
  keywords = "To Read;BCI",
  language = "en",
  doi      = "10.1101/2022.10.05.511024"
}

@ARTICLE{Bjerke2022-vb,
  title         = "Understanding Neural Coding on Latent Manifolds by Sharing
                   Features and Dividing Ensembles",
  author        = "Bjerke, Martin and Schott, Lukas and Jensen, Kristopher T
                   and Battistin, Claudia and Klindt, David A and Dunn,
                   Benjamin A",
  abstract      = "Systems neuroscience relies on two complementary views of
                   neural data, characterized by single neuron tuning curves
                   and analysis of population activity. These two perspectives
                   combine elegantly in neural latent variable models that
                   constrain the relationship between latent variables and
                   neural activity, modeled by simple tuning curve functions.
                   This has recently been demonstrated using Gaussian
                   processes, with applications to realistic and topologically
                   relevant latent manifolds. Those and previous models,
                   however, missed crucial shared coding properties of neural
                   populations. We propose feature sharing across neural tuning
                   curves, which significantly improves performance and leads
                   to better-behaved optimization. We also propose a solution
                   to the problem of ensemble detection, whereby different
                   groups of neurons, i.e., ensembles, can be modulated by
                   different latent manifolds. This is achieved through a soft
                   clustering of neurons during training, thus allowing for the
                   separation of mixed neural populations in an unsupervised
                   manner. These innovations lead to more interpretable models
                   of neural population activity that train well and perform
                   better even on mixtures of complex latent manifolds.
                   Finally, we apply our method on a recently published grid
                   cell dataset, recovering distinct ensembles, inferring
                   toroidal latents and predicting neural tuning curves all in
                   a single integrated modeling framework.",
  month         =  oct,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2210.03155",
  primaryClass  = "stat.ML",
  arxivid       = "2210.03155"
}

@ARTICLE{Stackman2000-zh,
  title    = "Maintenance of rat head direction cell firing during locomotion
              in the vertical plane",
  author   = "Stackman, R W and Tullman, M L and Taube, J S",
  abstract = "Previous studies have identified a subset of neurons in the rat
              anterodorsal thalamus (ADN) that encode head direction (HD) in
              absolute space and may be involved in navigation. These HD cells
              discharge selectively when the rat points its head in a specific
              direction (the preferred firing direction) in the horizontal
              plane. HD cells are typically recorded during free movement about
              a single horizontal surface. The current experiment examined how
              HD cell firing was influenced by 1) locomotion in the vertical
              plane and 2) locomotion on two different horizontal surfaces
              separated in height. Rats were trained in a cylindrical enclosure
              containing a single polarizing cue card attached to the cylinder
              wall, covering approximately 100 degrees of arc. The enclosure
              contained two horizontal surfaces: the cylinder floor and an
              annulus around the cylinder top 76 cm above the floor. A 90
              degrees vertical mesh ladder that could be affixed at any angular
              position on the cylinder wall allowed the rats to locomote back
              and forth between the two horizontal surfaces. Rats were trained
              to retrieve food pellets on the cylinder floor as well as climb
              the mesh ladder to retrieve food pellets on the annulus. HD cell
              activity was monitored as the rat traversed the horizontal and
              vertical surfaces of the apparatus. When the angular position of
              the mesh corresponded to the cell's preferred firing direction,
              the HD cells maintained their peak discharge rate as the rat
              climbed up the mesh, but did not fire when the rat climbed down
              the mesh. In contrast, when the mesh was positioned 180 degrees
              opposite the preferred firing direction, HD cells did not fire
              when the rat climbed up the mesh, but exhibited maximal firing
              when the rat climbed down the mesh. When the mesh was placed 90
              or 270 degrees from the preferred firing direction, HD cells
              exhibited background firing rates during climbing up or down the
              mesh. While preferred firing directions were maintained between
              the two horizontal surfaces, peak firing rate increased
              significantly (approximately 30\%) on the annulus as compared
              with the cylinder floor. These data demonstrate that HD cells
              continue to discharge in the vertical plane if the vertical
              locomotion began with the rat's orientation corresponding to the
              preferred firing direction. One model consistent with these data
              are that HD cells define the horizontal reference frame as the
              animal's plane of locomotion. Further, we propose that HD cell
              firing, as viewed within a three-dimensional coordinate system,
              can be characterized as the surface of a hemitorus.",
  journal  = "J. Neurophysiol.",
  volume   =  83,
  number   =  1,
  pages    = "393--405",
  month    =  jan,
  year     =  2000,
  keywords = "Non-programmatic",
  language = "en",
  issn     = "0022-3077",
  pmid     = "10634882",
  doi      = "10.1152/jn.2000.83.1.393"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Blair1995-in,
  title     = "Simulation of a thalamocortical circuit for computing
               directional heading in the rat",
  author    = "Blair, Hugh",
  abstract  = "… rat brain contain neurons known as head-direction celis, which
               encode the animal's directional heading … suggests that a
               thalamocortical circuit might compute the rat's head direction
               by …",
  journal   = "Adv. Neural Inf. Process. Syst.",
  publisher = "proceedings.neurips.cc",
  volume    =  8,
  year      =  1995,
  issn      = "1049-5258"
}

@ARTICLE{Dorkenwald2022-so,
  title    = "{FlyWire}: online community for whole-brain connectomics",
  author   = "Dorkenwald, Sven and McKellar, Claire E and Macrina, Thomas and
              Kemnitz, Nico and Lee, Kisuk and Lu, Ran and Wu, Jingpeng and
              Popovych, Sergiy and Mitchell, Eric and Nehoran, Barak and Jia,
              Zhen and Bae, J Alexander and Mu, Shang and Ih, Dodam and Castro,
              Manuel and Ogedengbe, Oluwaseun and Halageri, Akhilesh and
              Kuehner, Kai and Sterling, Amy R and Ashwood, Zoe and Zung,
              Jonathan and Brittain, Derrick and Collman, Forrest and
              Schneider-Mizell, Casey and Jordan, Chris and Silversmith,
              William and Baker, Christa and Deutsch, David and
              Encarnacion-Rivera, Lucas and Kumar, Sandeep and Burke, Austin
              and Bland, Doug and Gager, Jay and Hebditch, James and Koolman,
              Selden and Moore, Merlin and Morejohn, Sarah and Silverman, Ben
              and Willie, Kyle and Willie, Ryan and Yu, Szi-Chieh and Murthy,
              Mala and Seung, H Sebastian",
  abstract = "Due to advances in automated image acquisition and analysis,
              whole-brain connectomes with 100,000 or more neurons are on the
              horizon. Proofreading of whole-brain automated reconstructions
              will require many person-years of effort, due to the huge volumes
              of data involved. Here we present FlyWire, an online community
              for proofreading neural circuits in a Drosophila melanogaster
              brain and explain how its computational and social structures are
              organized to scale up to whole-brain connectomics. Browser-based
              three-dimensional interactive segmentation by collaborative
              editing of a spatially chunked supervoxel graph makes it possible
              to distribute proofreading to individuals located virtually
              anywhere in the world. Information in the edit history is
              programmatically accessible for a variety of uses such as
              estimating proofreading accuracy or building incentive systems.
              An open community accelerates proofreading by recruiting more
              participants and accelerates scientific discovery by requiring
              information sharing. We demonstrate how FlyWire enables circuit
              analysis by reconstructing and analyzing the connectome of
              mechanosensory neurons.",
  journal  = "Nat. Methods",
  volume   =  19,
  number   =  1,
  pages    = "119--128",
  month    =  jan,
  year     =  2022,
  language = "en",
  issn     = "1548-7091, 1548-7105",
  pmid     = "34949809",
  doi      = "10.1038/s41592-021-01330-0",
  pmc      = "PMC8903166"
}

@UNPUBLISHED{Cowley2022-js,
  title    = "One-to-one mapping between deep network units and real neurons
              uncovers a visual population code for social behavior",
  author   = "Cowley, Benjamin R and Calhoun, Adam J and Rangarajan, Nivedita
              and Pillow, Jonathan W and Murthy, Mala",
  abstract = "The rich variety of behaviors observed in animals arises through
              the complex interplay between sensory processing and motor
              control [[1][1], [2][2], [3][3], [4][4], [5][5]]. To understand
              these sensorimotor transformations, it is useful to build models
              that predict not only neural responses to sensory input [[6][6],
              [7][7], [8][8], [9][9], [10][10]] but also how each neuron
              causally contributes to behavior [[11][11], [12][12]]. Here we
              demonstrate a novel modeling approach to identify a one-to-one
              mapping between internal units in a deep neural network and real
              neurons by predicting the behavioral changes arising from
              systematic perturbations of more than a dozen neuron types. A key
              ingredient we introduce is ``knockout training'', which involves
              perturbing the network during training to match the perturbations
              of the real neurons during behavioral experiments. We apply this
              approach to model the sensorimotor transformation of Drosophila
              melanogaster males during a complex, visually-guided social
              behavior [[13][13], [14][14], [15][15], [16][16]]. Contrary to
              prevailing views [[17][17], [18][18], [19][19]], our model
              suggests that visual projection neurons at the interface between
              the eye and brain form a distributed population code that
              collectively sculpts social behavior. Overall, our framework
              consolidates behavioral effects elicited from various neural
              perturbations into a single, unified model, providing a detailed
              map from stimulus to neuron to behavior. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest. [1]: \#ref-1 [2]: \#ref-2 [3]: \#ref-3 [4]: \#ref-4
              [5]: \#ref-5 [6]: \#ref-6 [7]: \#ref-7 [8]: \#ref-8 [9]: \#ref-9
              [10]: \#ref-10 [11]: \#ref-11 [12]: \#ref-12 [13]: \#ref-13 [14]:
              \#ref-14 [15]: \#ref-15 [16]: \#ref-16 [17]: \#ref-17 [18]:
              \#ref-18 [19]: \#ref-19",
  journal  = "bioRxiv",
  pages    = "2022.07.18.500505",
  month    =  jul,
  year     =  2022,
  language = "en",
  doi      = "10.1101/2022.07.18.500505"
}

@ARTICLE{Baker2022-kk,
  title    = "Neural network organization for courtship-song feature detection
              in Drosophila",
  author   = "Baker, Christa A and McKellar, Claire and Pang, Rich and Nern,
              Aljoscha and Dorkenwald, Sven and Pacheco, Diego A and Eckstein,
              Nils and Funke, Jan and Dickson, Barry J and Murthy, Mala",
  abstract = "Animals communicate using sounds in a wide range of contexts, and
              auditory systems must encode behaviorally relevant acoustic
              features to drive appropriate reactions. How feature detection
              emerges along auditory pathways has been difficult to solve due
              to challenges in mapping the underlying circuits and
              characterizing responses to behaviorally relevant features. Here,
              we study auditory activity in the Drosophila melanogaster brain
              and investigate feature selectivity for the two main modes of fly
              courtship song, sinusoids and pulse trains. We identify 24 new
              cell types of the intermediate layers of the auditory pathway,
              and using a new connectomic resource, FlyWire, we map all
              synaptic connections between these cell types, in addition to
              connections to known early and higher-order auditory neurons-this
              represents the first circuit-level map of the auditory pathway.
              We additionally determine the sign (excitatory or inhibitory) of
              most synapses in this auditory connectome. We find that auditory
              neurons display a continuum of preferences for courtship song
              modes and that neurons with different song-mode preferences and
              response timescales are highly interconnected in a network that
              lacks hierarchical structure. Nonetheless, we find that the
              response properties of individual cell types within the
              connectome are predictable from their inputs. Our study thus
              provides new insights into the organization of auditory coding
              within the Drosophila brain.",
  journal  = "Curr. Biol.",
  volume   =  32,
  number   =  15,
  pages    = "3317--3333.e7",
  month    =  aug,
  year     =  2022,
  keywords = "acoustic communication; auditory; calcium imaging; connectomics;
              neural network; sensory responses",
  language = "en",
  issn     = "0960-9822, 1879-0445",
  pmid     = "35793679",
  doi      = "10.1016/j.cub.2022.06.019",
  pmc      = "PMC9378594"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Rotman2021-gc,
  title     = "Shuffling recurrent neural networks",
  author    = "Rotman, Michael and Wolf, Lior",
  abstract  = "We propose a novel recurrent neural network model, where the
               hidden state hₜ is obtained by permuting the vector elements of
               the previous hidden state hₜ₋₁ and adding the output of a
               learned function $\beta$(xₜ) of the input xₜ at time t. In our
               model, the prediction is given by a second learned function,
               which is applied to the hidden state s(hₜ). The method is easy
               to implement, extremely efficient, and does not suffer from
               vanishing nor exploding gradients. In an extensive set of
               experiments, the method shows competitive results, in comparison
               to the leading literature baselines. We share our implementation
               at https://github.com/rotmanmi/SRNN.",
  journal   = "Proc. Conf. AAAI Artif. Intell.",
  publisher = "Association for the Advancement of Artificial Intelligence
               (AAAI)",
  volume    =  35,
  number    =  11,
  pages     = "9428--9435",
  month     =  may,
  year      =  2021,
  issn      = "2159-5399, 2374-3468",
  doi       = "10.1609/aaai.v35i11.17136"
}

@ARTICLE{Araujo2019-mx,
  title         = "Understanding and Training Deep Diagonal Circulant Neural
                   Networks",
  author        = "Araujo, Alexandre and Negrevergne, Benjamin and Chevaleyre,
                   Yann and Atif, Jamal",
  abstract      = "In this paper, we study deep diagonal circulant neural
                   networks, that is deep neural networks in which weight
                   matrices are the product of diagonal and circulant ones.
                   Besides making a theoretical analysis of their expressivity,
                   we introduced principled techniques for training these
                   models: we devise an initialization scheme and proposed a
                   smart use of non-linearity functions in order to train deep
                   diagonal circulant networks. Furthermore, we show that these
                   networks outperform recently introduced deep networks with
                   other types of structured layers. We conduct a thorough
                   experimental study to compare the performance of deep
                   diagonal circulant networks with state of the art models
                   based on structured matrices and with dense models. We show
                   that our models achieve better accuracy than other
                   structured approaches while required 2x fewer weights as the
                   next best approach. Finally we train deep diagonal circulant
                   networks to build a compact and accurate models on a real
                   world video classification dataset with over 3.8 million
                   training examples.",
  month         =  jan,
  year          =  2019,
  archivePrefix = "arXiv",
  eprint        = "1901.10255",
  primaryClass  = "cs.LG",
  arxivid       = "1901.10255"
}

@ARTICLE{Li2018-qy,
  title         = "Efficient Recurrent Neural Networks using Structured
                   Matrices in {FPGAs}",
  author        = "Li, Zhe and Wang, Shuo and Ding, Caiwen and Qiu, Qinru and
                   Wang, Yanzhi and Liang, Yun",
  abstract      = "Recurrent Neural Networks (RNNs) are becoming increasingly
                   important for time series-related applications which require
                   efficient and real-time implementations. The recent pruning
                   based work ESE suffers from degradation of
                   performance/energy efficiency due to the irregular network
                   structure after pruning. We propose block-circulant matrices
                   for weight matrix representation in RNNs, thereby achieving
                   simultaneous model compression and acceleration. We aim to
                   implement RNNs in FPGA with highest performance and energy
                   efficiency, with certain accuracy requirement (negligible
                   accuracy degradation). Experimental results on actual FPGA
                   deployments shows that the proposed framework achieves a
                   maximum energy efficiency improvement of 35.7$\times$
                   compared with ESE.",
  month         =  mar,
  year          =  2018,
  archivePrefix = "arXiv",
  eprint        = "1803.07661",
  primaryClass  = "cs.LG",
  arxivid       = "1803.07661"
}

@ARTICLE{Pascanu2013-al,
  title         = "How to Construct Deep Recurrent Neural Networks",
  author        = "Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and
                   Bengio, Yoshua",
  abstract      = "In this paper, we explore different ways to extend a
                   recurrent neural network (RNN) to a
                   \textbackslashtextit\{deep\} RNN. We start by arguing that
                   the concept of depth in an RNN is not as clear as it is in
                   feedforward neural networks. By carefully analyzing and
                   understanding the architecture of an RNN, however, we find
                   three points of an RNN which may be made deeper; (1)
                   input-to-hidden function, (2) hidden-to-hidden transition
                   and (3) hidden-to-output function. Based on this
                   observation, we propose two novel architectures of a deep
                   RNN which are orthogonal to an earlier attempt of stacking
                   multiple recurrent layers to build a deep RNN (Schmidhuber,
                   1992; El Hihi and Bengio, 1996). We provide an alternative
                   interpretation of these deep RNNs using a novel framework
                   based on neural operators. The proposed deep RNNs are
                   empirically evaluated on the tasks of polyphonic music
                   prediction and language modeling. The experimental result
                   supports our claim that the proposed deep RNNs benefit from
                   the depth and outperform the conventional, shallow RNNs.",
  month         =  dec,
  year          =  2013,
  archivePrefix = "arXiv",
  eprint        = "1312.6026",
  primaryClass  = "cs.NE",
  arxivid       = "1312.6026"
}

@ARTICLE{Back1998-xa,
  title     = "A low-sensitivity recurrent neural network",
  author    = "Back, Andrew D and Tsoi, Ah Chung",
  abstract  = "The problem of high sensitivity in modeling is well known. Small
               perturbations in the model parameters may result in large,
               undesired changes in the model behavior. A number of authors
               have considered the issue of sensitivity in feedforward neural
               networks from a probabilistic perspective. Less attention has
               been given to such issues in recurrent neural networks. In this
               article, we present a new recurrent neural network architecture,
               that is capable of significantly improved parameter sensitivity
               properties compared to existing recurrent neural networks. The
               new recurrent neural network generalizes previous architectures
               by employing alternative discrete-time operators in place of the
               shift operator normally used. An analysis of the model
               demonstrates the existence of parameter sensitivity in recurrent
               neural networks and supports the proposed architecture. The new
               architecture performs significantly better than previous
               recurrent neural networks, as shown by a series of simple
               numerical experiments.",
  journal   = "Neural Comput.",
  publisher = "MIT Press - Journals",
  volume    =  10,
  number    =  1,
  pages     = "165--188",
  month     =  jan,
  year      =  1998,
  language  = "en",
  issn      = "0899-7667, 1530-888X",
  doi       = "10.1162/089976698300017935"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Valente2019-ml,
  title        = "Reverse-engineering low-rank recurrent neural networks",
  author       = "Valente, A",
  abstract     = "… , a full- rank and a low rank one, that I will briefly
                  describe. … even when bringing it to an extremely low rank
                  like 1 or 2, it then … low - rank network with a structure
                  taken from a high rank RNN . …",
  publisher    = "adrian-valente.github.io",
  year         =  2019,
  howpublished = "\url{https://adrian-valente.github.io/assets/pdfs/report.pdf}",
  note         = "Accessed: 2022-10-23"
}

@ARTICLE{Lu2016-rn,
  title         = "Learning Compact Recurrent Neural Networks",
  author        = "Lu, Zhiyun and Sindhwani, Vikas and Sainath, Tara N",
  abstract      = "Recurrent neural networks (RNNs), including long short-term
                   memory (LSTM) RNNs, have produced state-of-the-art results
                   on a variety of speech recognition tasks. However, these
                   models are often too large in size for deployment on mobile
                   devices with memory and latency constraints. In this work,
                   we study mechanisms for learning compact RNNs and LSTMs via
                   low-rank factorizations and parameter sharing schemes. Our
                   goal is to investigate redundancies in recurrent
                   architectures where compression can be admitted without
                   losing performance. A hybrid strategy of using structured
                   matrices in the bottom layers and shared low-rank factors on
                   the top layers is found to be particularly effective,
                   reducing the parameters of a standard LSTM by 75\%, at a
                   small cost of 0.3\% increase in WER, on a 2,000-hr English
                   Voice Search task.",
  month         =  apr,
  year          =  2016,
  archivePrefix = "arXiv",
  eprint        = "1604.02594",
  primaryClass  = "cs.LG",
  arxivid       = "1604.02594"
}

@MISC{Yuan2020-xn,
  title        = "Structured deep neural network with low complexity",
  author       = "Yuan, Bo",
  year         =  2020,
  howpublished = "\url{https://rucore.libraries.rutgers.edu/rutgers-lib/64996/PDF/1/play/}",
  note         = "Accessed: 2022-10-23"
}

@INPROCEEDINGS{Tomikawa1995-qj,
  title     = "Convergence analysis of recurrent neural network with self-loops
               based on eigenvalues of a connection matrix",
  booktitle = "Proceedings of {ICNN'95} - International Conference on Neural
               Networks",
  author    = "Tomikawa, Y and Nakayama, K",
  abstract  = "Recurrent neural networks (RNNs) can be applied to solve a
               combinatorial optimization problem. However, the existence of
               the local minima in this model prevents its application to real
               world. In this paper, an analysis method for network dynamics
               based on eigenvalues and eigenvectors of a connection weight
               matrix is proposed. In this analysis, the transition of the
               number of negative eigenvalues and the movement of eigenspaces
               by increasing diagonal elements, which correspond to feedback
               loops of RNNs, are discussed. From this analysis, it is
               confirmed that the number of negative eigenvalues decreases and
               the eigenspaces move toward the ascent side of the energy slope
               at the center point of the state space of RNNs, as increasing
               diagonal elements. These behaviors of RNNs contribute to the
               improvement for searching a solution of a combinatorial
               optimization problem. This analysis method is applied to a
               2-dimensional example and five cities TS problems. From this
               analysis, it is theoretically found that the network performance
               of detecting the optimal solution can be improved by increasing
               the values of diagonal elements of connection matrix.",
  volume    =  5,
  pages     = "2642--2647 vol.5",
  month     =  nov,
  year      =  1995,
  keywords  = "Convergence;Recurrent neural networks;Eigenvalues and
               eigenfunctions;Feedback loop;Electronic mail;State-space
               methods;Cities and towns;Performance analysis;NP-complete
               problem;Optimal control",
  doi       = "10.1109/ICNN.1995.487827"
}

@ARTICLE{Smith2021-ds,
  title         = "Reverse engineering recurrent neural networks with Jacobian
                   switching linear dynamical systems",
  author        = "Smith, Jimmy T H and Linderman, Scott W and Sussillo, David",
  abstract      = "Recurrent neural networks (RNNs) are powerful models for
                   processing time-series data, but it remains challenging to
                   understand how they function. Improving this understanding
                   is of substantial interest to both the machine learning and
                   neuroscience communities. The framework of reverse
                   engineering a trained RNN by linearizing around its fixed
                   points has provided insight, but the approach has
                   significant challenges. These include difficulty choosing
                   which fixed point to expand around when studying RNN
                   dynamics and error accumulation when reconstructing the
                   nonlinear dynamics with the linearized dynamics. We present
                   a new model that overcomes these limitations by co-training
                   an RNN with a novel switching linear dynamical system (SLDS)
                   formulation. A first-order Taylor series expansion of the
                   co-trained RNN and an auxiliary function trained to pick out
                   the RNN's fixed points govern the SLDS dynamics. The results
                   are a trained SLDS variant that closely approximates the
                   RNN, an auxiliary function that can produce a fixed point
                   for each point in state-space, and a trained nonlinear RNN
                   whose dynamics have been regularized such that its
                   first-order terms perform the computation, if possible. This
                   model removes the post-training fixed point optimization and
                   allows us to unambiguously study the learned dynamics of the
                   SLDS at any point in state-space. It also generalizes SLDS
                   models to continuous manifolds of switching points while
                   sharing parameters across switches. We validate the utility
                   of the model on two synthetic tasks relevant to previous
                   work reverse engineering RNNs. We then show that our model
                   can be used as a drop-in in more complex architectures, such
                   as LFADS, and apply this LFADS hybrid to analyze
                   single-trial spiking activity from the motor system of a
                   non-human primate.",
  pages         = "16700--16713",
  month         =  nov,
  year          =  2021,
  copyright     = "http://creativecommons.org/licenses/by/4.0/",
  archivePrefix = "arXiv",
  eprint        = "2111.01256",
  primaryClass  = "cs.LG",
  arxivid       = "2111.01256"
}

@ARTICLE{Scheffer2020-cr,
  title     = "A connectome and analysis of the adult Drosophila central brain",
  author    = "Scheffer, Louis K and Xu, C Shan and Januszewski, Michal and Lu,
               Zhiyuan and Takemura, Shin-Ya and Hayworth, Kenneth J and Huang,
               Gary B and Shinomiya, Kazunori and Maitlin-Shepard, Jeremy and
               Berg, Stuart and Clements, Jody and Hubbard, Philip M and Katz,
               William T and Umayam, Lowell and Zhao, Ting and Ackerman, David
               and Blakely, Tim and Bogovic, John and Dolafi, Tom and
               Kainmueller, Dagmar and Kawase, Takashi and Khairy, Khaled A and
               Leavitt, Laramie and Li, Peter H and Lindsey, Larry and
               Neubarth, Nicole and Olbris, Donald J and Otsuna, Hideo and
               Trautman, Eric T and Ito, Masayoshi and Bates, Alexander S and
               Goldammer, Jens and Wolff, Tanya and Svirskas, Robert and
               Schlegel, Philipp and Neace, Erika and Knecht, Christopher J and
               Alvarado, Chelsea X and Bailey, Dennis A and Ballinger, Samantha
               and Borycz, Jolanta A and Canino, Brandon S and Cheatham,
               Natasha and Cook, Michael and Dreher, Marisa and Duclos, Octave
               and Eubanks, Bryon and Fairbanks, Kelli and Finley, Samantha and
               Forknall, Nora and Francis, Audrey and Hopkins, Gary Patrick and
               Joyce, Emily M and Kim, Sungjin and Kirk, Nicole A and Kovalyak,
               Julie and Lauchie, Shirley A and Lohff, Alanna and Maldonado,
               Charli and Manley, Emily A and McLin, Sari and Mooney, Caroline
               and Ndama, Miatta and Ogundeyi, Omotara and Okeoma, Nneoma and
               Ordish, Christopher and Padilla, Nicholas and Patrick,
               Christopher M and Paterson, Tyler and Phillips, Elliott E and
               Phillips, Emily M and Rampally, Neha and Ribeiro, Caitlin and
               Robertson, Madelaine K and Rymer, Jon Thomson and Ryan, Sean M
               and Sammons, Megan and Scott, Anne K and Scott, Ashley L and
               Shinomiya, Aya and Smith, Claire and Smith, Kelsey and Smith,
               Natalie L and Sobeski, Margaret A and Suleiman, Alia and Swift,
               Jackie and Takemura, Satoko and Talebi, Iris and Tarnogorska,
               Dorota and Tenshaw, Emily and Tokhi, Temour and Walsh, John J
               and Yang, Tansy and Horne, Jane Anne and Li, Feng and Parekh,
               Ruchi and Rivlin, Patricia K and Jayaraman, Vivek and Costa,
               Marta and Jefferis, Gregory Sxe and Ito, Kei and Saalfeld,
               Stephan and George, Reed and Meinertzhagen, Ian A and Rubin,
               Gerald M and Hess, Harald F and Jain, Viren and Plaza, Stephen M",
  abstract  = "The neural circuits responsible for animal behavior remain
               largely unknown. We summarize new methods and present the
               circuitry of a large fraction of the brain of the fruit fly
               Drosophila melanogaster. Improved methods include new procedures
               to prepare, image, align, segment, find synapses in, and
               proofread such large data sets. We define cell types, refine
               computational compartments, and provide an exhaustive atlas of
               cell examples and types, many of them novel. We provide detailed
               circuits consisting of neurons and their chemical synapses for
               most of the central brain. We make the data public and simplify
               access, reducing the effort needed to answer circuit questions,
               and provide procedures linking the neurons defined by our
               analysis with genetic reagents. Biologically, we examine
               distributions of connection strengths, neural motifs on
               different scales, electrical consequences of
               compartmentalization, and evidence that maximizing packing
               density is an important criterion in the evolution of the fly's
               brain.",
  journal   = "Elife",
  publisher = "eLife Sciences Publications, Ltd",
  volume    =  9,
  pages     = "e57443",
  month     =  sep,
  year      =  2020,
  keywords  = "connectome; brain regions; cell types; graph properties;
               connectome reconstuction methods; synapse detecton",
  issn      = "2050-084X",
  doi       = "10.7554/eLife.57443"
}

@ARTICLE{Dubreuil2022-xl,
  title    = "The role of population structure in computations through neural
              dynamics",
  author   = "Dubreuil, Alexis and Valente, Adrian and Beiran, Manuel and
              Mastrogiuseppe, Francesca and Ostojic, Srdjan",
  abstract = "Neural computations are currently investigated using two separate
              approaches: sorting neurons into functional subpopulations or
              examining the low-dimensional dynamics of collective activity.
              Whether and how these two aspects interact to shape computations
              is currently unclear. Using a novel approach to extract
              computational mechanisms from networks trained on neuroscience
              tasks, here we show that the dimensionality of the dynamics and
              subpopulation structure play fundamentally complementary roles.
              Although various tasks can be implemented by increasing the
              dimensionality in networks with fully random population
              structure, flexible input-output mappings instead require a
              non-random population structure that can be described in terms of
              multiple subpopulations. Our analyses revealed that such a
              subpopulation structure enables flexible computations through a
              mechanism based on gain-controlled modulations that flexibly
              shape the collective dynamics. Our results lead to task-specific
              predictions for the structure of neural selectivity, for
              inactivation experiments and for the implication of different
              neurons in multi-tasking.",
  journal  = "Nat. Neurosci.",
  volume   =  25,
  number   =  6,
  pages    = "783--794",
  month    =  jun,
  year     =  2022,
  keywords = "To Read;BCI",
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "35668174",
  doi      = "10.1038/s41593-022-01088-4",
  pmc      = "PMC9284159"
}

@UNPUBLISHED{Cimesa2022-xm,
  title    = "Geometry of population activity in spiking networks with low-rank
              structure",
  author   = "Cimesa, Ljubica and Ostojic, Srdjan and Ciric, Lazar",
  abstract = "Recurrent network models are instrumental in investigating how
              behaviorally-relevant computations emerge from collective neural
              dynamics. A recently developed class of models based on low-rank
              connectivity provides an analytically tractable framework for
              understanding of how connectivity structure determines the
              geometry of low-dimensional dynamics and the ensuing
              computations. Such models however lack some fundamental
              biological constraints, and in particular represent individual
              neurons in terms of abstract units that communicate through
              continuous firing rates rather than discrete action potentials.
              Here we examine how far the theoretical insights obtained from
              low-rank rate networks transfer to more biologically plausible
              networks of spiking neurons. Adding a low-rank structure on top
              of random excitatory-inhibitory connectivity, we systematically
              compare the geometry of activity in networks of
              integrate-and-fire neurons to rate networks with statistically
              equivalent low-rank connectivity. We show that the mean-field
              predictions of rate networks allow us to identify low-dimensional
              dynamics at constant population-average activity in spiking
              networks, as well as novel non-linear regimes of activity such as
              out-of-phase oscillations and slow manifolds. We finally exploit
              these results to directly build spiking networks that perform
              nonlinear computations. \#\#\# Competing Interest Statement The
              authors have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.11.18.517093",
  month    =  nov,
  year     =  2022,
  keywords = "BCI",
  language = "en",
  doi      = "10.1101/2022.11.18.517093"
}

@ARTICLE{Issa2012-af,
  title    = "Universal conditions for exact path integration in neural systems",
  author   = "Issa, John B and Zhang, Kechen",
  abstract = "Animals are capable of navigation even in the absence of
              prominent landmark cues. This behavioral demonstration of path
              integration is supported by the discovery of place cells and
              other neurons that show path-invariant response properties even
              in the dark. That is, under suitable conditions, the activity of
              these neurons depends primarily on the spatial location of the
              animal regardless of which trajectory it followed to reach that
              position. Although many models of path integration have been
              proposed, no known single theoretical framework can formally
              accommodate their diverse computational mechanisms. Here we
              derive a set of necessary and sufficient conditions for a general
              class of systems that performs exact path integration. These
              conditions include multiplicative modulation by velocity inputs
              and a path-invariance condition that limits the structure of
              connections in the underlying neural network. In particular, for
              a linear system to satisfy the path-invariance condition, the
              effective synaptic weight matrices under different velocities
              must commute. Our theory subsumes several existing exact path
              integration models as special cases. We use entorhinal grid cells
              as an example to demonstrate that our framework can provide
              useful guidance for finding unexpected solutions to the path
              integration problem. This framework may help constrain future
              experimental and modeling studies pertaining to a broad class of
              neural integration systems.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  109,
  number   =  17,
  pages    = "6716--6720",
  month    =  apr,
  year     =  2012,
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "22493275",
  doi      = "10.1073/pnas.1119880109",
  pmc      = "PMC3340063"
}

@ARTICLE{Darshan2022-nh,
  title    = "Learning to represent continuous variables in heterogeneous
              neural networks",
  author   = "Darshan, Ran and Rivkind, Alexander",
  abstract = "Animals must monitor continuous variables such as position or
              head direction. Manifold attractor networks-which enable a
              continuum of persistent neuronal states-provide a key framework
              to explain this monitoring ability. Neural networks with
              symmetric synaptic connectivity dominate this framework but are
              inconsistent with the diverse synaptic connectivity and neuronal
              representations observed in experiments. Here, we developed a
              theory for manifold attractors in trained neural networks, which
              approximates a continuum of persistent states, without assuming
              unrealistic symmetry. We exploit the theory to predict how
              asymmetries in the representation and heterogeneity in the
              connectivity affect the formation of the manifold via training,
              shape network response to stimulus, and govern mechanisms that
              possibly lead to destabilization of the manifold. Our work
              suggests that the functional properties of manifold attractors in
              the brain can be inferred from the overlooked asymmetries in
              connectivity and in the low-dimensional representation of the
              encoded variable.",
  journal  = "Cell Rep.",
  volume   =  39,
  number   =  1,
  pages    = "110612",
  month    =  apr,
  year     =  2022,
  keywords = "CP: Neuroscience; continuous attractor; control; low-dimensional
              dynamics; low-rank perturbation; manifold attractor; neural
              computation; recurrent neural networks; training; working memory",
  language = "en",
  issn     = "2211-1247",
  pmid     = "35385721",
  doi      = "10.1016/j.celrep.2022.110612"
}

@ARTICLE{Seelig2015-jg,
  title     = "Neural dynamics for landmark orientation and angular path
               integration",
  author    = "Seelig, Johannes D and Jayaraman, Vivek",
  abstract  = "Many animals navigate using a combination of visual landmarks
               and path integration. In mammalian brains, head direction cells
               integrate these two streams of information by representing an
               animal's heading relative to landmarks, yet maintaining their
               directional tuning in darkness based on self-motion cues. Here
               we use two-photon calcium imaging in head-fixed Drosophila
               melanogaster walking on a ball in a virtual reality arena to
               demonstrate that landmark-based orientation and angular path
               integration are combined in the population responses of neurons
               whose dendrites tile the ellipsoid body, a toroidal structure in
               the centre of the fly brain. The neural population encodes the
               fly's azimuth relative to its environment, tracking visual
               landmarks when available and relying on self-motion cues in
               darkness. When both visual and self-motion cues are absent, a
               representation of the animal's orientation is maintained in this
               network through persistent activity, a potential substrate for
               short-term memory. Several features of the population dynamics
               of these neurons and their circular anatomical arrangement are
               suggestive of ring attractors, network structures that have been
               proposed to support the function of navigational brain circuits.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  521,
  number    =  7551,
  pages     = "186--191",
  month     =  may,
  year      =  2015,
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "25971509",
  doi       = "10.1038/nature14446",
  pmc       = "PMC4704792"
}

@ARTICLE{Lu2022-bb,
  title     = "Transforming representations of movement from body- to
               world-centric space",
  author    = "Lu, Jenny and Behbahani, Amir H and Hamburg, Lydia and
               Westeinde, Elena A and Dawson, Paul M and Lyu, Cheng and Maimon,
               Gaby and Dickinson, Michael H and Druckmann, Shaul and Wilson,
               Rachel I",
  abstract  = "When an animal moves through the world, its brain receives a
               stream of information about the body's translational velocity
               from motor commands and sensory feedback signals. These incoming
               signals are referenced to the body, but ultimately, they must be
               transformed into world-centric coordinates for navigation1,2.
               Here we show that this computation occurs in the fan-shaped body
               in the brain of Drosophila melanogaster. We identify two cell
               types, PFNd and PFNv3-5, that conjunctively encode translational
               velocity and heading as a fly walks. In these cells, velocity
               signals are acquired from locomotor brain regions6 and are
               multiplied with heading signals from the compass system. PFNd
               neurons prefer forward-ipsilateral movement, whereas PFNv
               neurons prefer backward-contralateral movement, and perturbing
               PFNd neurons disrupts idiothetic path integration in walking
               flies7. Downstream, PFNd and PFNv neurons converge onto
               h$\Delta$B neurons, with a connectivity pattern that pools
               together heading and translation direction combinations
               corresponding to the same movement in world-centric space. This
               network motif effectively performs a rotation of the brain's
               representation of body-centric translational velocity according
               to the current heading direction. Consistent with our
               predictions, we observe that h$\Delta$B neurons form a
               representation of translational velocity in world-centric
               coordinates. By integrating this representation over time, it
               should be possible for the brain to form a working memory of the
               path travelled through the environment8-10.",
  journal   = "Nature",
  publisher = "nature.com",
  volume    =  601,
  number    =  7891,
  pages     = "98--104",
  month     =  jan,
  year      =  2022,
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "34912123",
  doi       = "10.1038/s41586-021-04191-x"
}

@ARTICLE{Lyu2022-yg,
  title    = "Building an allocentric travelling direction signal via vector
              computation",
  author   = "Lyu, Cheng and Abbott, L F and Maimon, Gaby",
  abstract = "Many behavioural tasks require the manipulation of mathematical
              vectors, but, outside of computational models1-7, it is not known
              how brains perform vector operations. Here we show how the
              Drosophila central complex, a region implicated in goal-directed
              navigation7-10, performs vector arithmetic. First, we describe a
              neural signal in the fan-shaped body that explicitly tracks the
              allocentric travelling angle of a fly, that is, the travelling
              angle in reference to external cues. Past work has identified
              neurons in Drosophila8,11-13 and mammals14 that track the heading
              angle of an animal referenced to external cues (for example, head
              direction cells), but this new signal illuminates how the sense
              of space is properly updated when travelling and heading angles
              differ (for example, when walking sideways). We then characterize
              a neuronal circuit that performs an egocentric-to-allocentric
              (that is, body-centred to world-centred) coordinate
              transformation and vector addition to compute the allocentric
              travelling direction. This circuit operates by mapping
              two-dimensional vectors onto sinusoidal patterns of activity
              across distinct neuronal populations, with the amplitude of the
              sinusoid representing the length of the vector and its phase
              representing the angle of the vector. The principles of this
              circuit may generalize to other brains and to domains beyond
              navigation where vector operations or reference-frame
              transformations are required.",
  journal  = "Nature",
  volume   =  601,
  number   =  7891,
  pages    = "92--97",
  month    =  jan,
  year     =  2022,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "34912112",
  doi      = "10.1038/s41586-021-04067-0"
}

@ARTICLE{Shiozaki2020-lh,
  title     = "A Multi-regional Network Encoding Heading and Steering Maneuvers
               in Drosophila",
  author    = "Shiozaki, Hiroshi M and Ohta, Kazumi and Kazama, Hokto",
  abstract  = "An internal sense of heading direction is computed from various
               cues, including steering maneuvers of the animal. Although
               neurons encoding heading and steering have been found in
               multiple brain regions, it is unclear whether and how they are
               organized into neural circuits. Here we show that, in flying
               Drosophila, heading and turning behaviors are encoded by
               population dynamics of specific cell types connecting the
               subregions of the central complex (CX), a brain structure
               implicated in navigation. Columnar neurons in the fan-shaped
               body (FB) of the CX exhibit circular dynamics that multiplex
               information about turning behavior and heading. These dynamics
               are coordinated with those in the ellipsoid body, another CX
               subregion containing a heading representation, although only FB
               neurons flip turn preference depending on the visual
               environment. Thus, the navigational system spans multiple
               subregions of the CX, where specific cell types show coordinated
               but distinct context-dependent dynamics.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  106,
  number    =  1,
  pages     = "126--141.e5",
  month     =  apr,
  year      =  2020,
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "32023429",
  doi       = "10.1016/j.neuron.2020.01.009"
}

@ARTICLE{Heinze2018-nb,
  title     = "Principles of Insect Path Integration",
  author    = "Heinze, Stanley and Narendra, Ajay and Cheung, Allen",
  abstract  = "Continuously monitoring its position in space relative to a goal
               is one of the most essential tasks for an animal that moves
               through its environment. Species as diverse as rats, bees, and
               crabs achieve this by integrating all changes of direction with
               the distance covered during their foraging trips, a process
               called path integration. They generate an estimate of their
               current position relative to a starting point, enabling a
               straight-line return, following what is known as a home vector.
               While in theory path integration always leads the animal
               precisely back home, in the real world noise limits the
               usefulness of this strategy when operating in isolation. Noise
               results from stochastic processes in the nervous system and from
               unreliable sensory information, particularly when obtaining
               heading estimates. Path integration, during which angular
               self-motion provides the sole input for encoding heading
               (idiothetic path integration), results in accumulating errors
               that render this strategy useless over long distances. In
               contrast, when using an external compass this limitation is
               avoided (allothetic path integration). Many navigating insects
               indeed rely on external compass cues for estimating body
               orientation, whereas they obtain distance information by
               integration of steps or optic-flow-based speed signals. In the
               insect brain, a region called the central complex plays a key
               role for path integration. Not only does the central complex
               house a ring-attractor network that encodes head directions,
               neurons responding to optic flow also converge with this
               circuit. A neural substrate for integrating direction and
               distance into a memorized home vector has therefore been
               proposed in the central complex. We discuss how behavioral data
               and the theoretical framework of path integration can be aligned
               with these neural data.",
  journal   = "Curr. Biol.",
  publisher = "Elsevier",
  volume    =  28,
  number    =  17,
  pages     = "R1043--R1058",
  month     =  sep,
  year      =  2018,
  language  = "en",
  issn      = "0960-9822, 1879-0445",
  pmid      = "30205054",
  doi       = "10.1016/j.cub.2018.04.058",
  pmc       = "PMC6462409"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Davies_undated-hj,
  title    = "Synthetic morphology via active and agential matter",
  author   = "Davies, J and Levin, M",
  abstract = "Bioengineering can address many critical needs, from
              transformative biomedicine to environmental remediation. Beyond
              its practical uses, constructing novel living systems will …",
  journal  = "osf.io"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Fields2020-gz,
  title     = "{Scale‐Free} Biology: Integrating Evolutionary and Developmental
               Thinking",
  author    = "Fields, C and Levin, M",
  abstract  = "When the history of life on earth is viewed as a history of cell
               division, all of life becomes a single cell lineage. The growth
               and differentiation of this lineage in reciprocal interaction …",
  journal   = "Bioessays",
  publisher = "Wiley Online Library",
  year      =  2020,
  issn      = "0265-9247"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Mordvintsev2020-nw,
  title     = "Growing neural cellular automata",
  author    = "Mordvintsev, A and Randazzo, E and Niklasson, E and Levin, M",
  abstract  = "Growing models were trained to generate patterns, but don't know
               how to persist them. Some patterns explode, some decay, but some
               happen to be almost stable or even …",
  journal   = "Distill",
  publisher = "distill.pub",
  year      =  2020
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Lyon2021-xk,
  title     = "Basal cognition: multicellularity, neurons and the cognitive
               lens",
  author    = "Lyon, P and Keijzer, F and Arendt, D and Levin, M",
  abstract  = "Basal cognition: multicellularity, neurons and the cognitive
               lens --- the University of Groningen research portal Skip to
               main navigation Skip to search Skip to main content the …",
  journal   = "Philosophical Transactions of",
  publisher = "research.rug.nl",
  year      =  2021
}

@ARTICLE{Abramson2021-en,
  title    = "Behaviorist approaches to investigating memory and learning: A
              primer for synthetic biology and bioengineering",
  author   = "Abramson, Charles I and Levin, Michael",
  abstract = "The fields of developmental biology, biomedicine, and artificial
              life are being revolutionized by advances in synthetic
              morphology. The next phase of synthetic biology and
              bioengineering is resulting in the construction of novel
              organisms (biobots), which exhibit not only morphogenesis and
              physiology but functional behavior. It is now essential to begin
              to characterize the behavioral capacity of novel living
              constructs in terms of their ability to make decisions, form
              memories, learn from experience, and anticipate future stimuli.
              These synthetic organisms are highly diverse, and often do not
              resemble familiar model systems used in behavioral science. Thus,
              they represent an important context in which to begin to unify
              and standardize vocabulary and techniques across developmental
              biology, behavioral ecology, and neuroscience. To facilitate the
              study of behavior in novel living systems, we present a primer on
              techniques from the behaviorist tradition that can be used to
              probe the functions of any organism - natural, chimeric, or
              synthetic - regardless of the details of their construction or
              origin. These techniques provide a rich toolkit for advancing the
              fields of synthetic bioengineering, evolutionary developmental
              biology, basal cognition, exobiology, and robotics.",
  journal  = "Commun. Integr. Biol.",
  volume   =  14,
  number   =  1,
  pages    = "230--247",
  month    =  dec,
  year     =  2021,
  keywords = "Behaviorism; basal cognition; biobot; learning; memory; synthetic
              morphology",
  language = "en",
  issn     = "1942-0889",
  pmid     = "34925687",
  doi      = "10.1080/19420889.2021.2005863",
  pmc      = "PMC8677006"
}

@ARTICLE{Cervera2020-dc,
  title    = "Bioelectrical Coupling of {Single-Cell} States in Multicellular
              Systems",
  author   = "Cervera, Javier and Levin, Michael and Mafe, Salvador",
  abstract = "The spatiotemporal distributions of signaling ions and molecules
              that modulate biochemical pathways in nonexcitable cells are
              influenced by multicellular electric potentials. These potentials
              act as distributed controllers encoding instructive spatial
              patterns in development and regeneration. We review experimental
              facts and discuss recent bioelectrical models that provide new
              physical insights and complement biochemical approaches.
              Single-cell states are modulated at the multicellular level
              because of the coupling between neighboring cells, thus allowing
              memories and multicellular patterns. The model is based on (i)
              two generic voltage-gated ion channels that promote the polarized
              and depolarized cell states, (ii) a feedback mechanism for the
              transcriptional and bioelectrical regulations, and (iii)
              voltage-gated intercellular conductances that allow a dynamic
              intercellular connectivity. The simulations provide steady-state
              and oscillatory multicellular states that help explain aspects of
              development and guide experimental procedures attempting to
              establish instructive bioelectrical patterns based on electric
              potentials and currents to regulate cell behavior and
              morphogenesis.",
  journal  = "J. Phys. Chem. Lett.",
  volume   =  11,
  number   =  9,
  pages    = "3234--3241",
  month    =  may,
  year     =  2020,
  language = "en",
  issn     = "1948-7185",
  pmid     = "32243754",
  doi      = "10.1021/acs.jpclett.0c00641"
}

@ARTICLE{Davidian2022-di,
  title    = "Inducing Vertebrate Limb Regeneration: A Review of Past Advances
              and Future Outlook",
  author   = "Davidian, Devon and Levin, Michael",
  abstract = "Limb loss due to traumatic injury or amputation is a major
              biomedical burden. Many vertebrates exhibit the ability to form
              and pattern normal limbs during embryogenesis from amorphous
              clusters of precursor cells, hinting that this process could
              perhaps be activated later in life to rebuild missing or damaged
              limbs. Indeed, some animals, such as salamanders, are proficient
              regenerators of limbs throughout their life span. Thus, research
              over the last century has sought to stimulate regeneration in
              species that do not normally regenerate their appendages.
              Importantly, these efforts are not only a vital aspect of
              regenerative medicine, but also have fundamental implications for
              understanding evolution and the cellular control of growth and
              form throughout the body. Here we review major recent advances in
              augmenting limb regeneration, summarizing the degree of success
              that has been achieved to date in frog and mammalian models using
              genetic, biochemical, and bioelectrical interventions. While the
              degree of whole limb repair in rodent models has been modest to
              date, a number of new technologies and approaches comprise an
              exciting near-term road map for basic and clinical progress in
              regeneration.",
  journal  = "Cold Spring Harb. Perspect. Biol.",
  volume   =  14,
  number   =  4,
  month    =  may,
  year     =  2022,
  language = "en",
  issn     = "1943-0264",
  pmid     = "34400551",
  doi      = "10.1101/cshperspect.a040782",
  pmc      = "PMC9121900"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Kudithipudi2022-nr,
  title     = "Biological underpinnings for lifelong learning machines",
  author    = "Kudithipudi, D and Aguilar-Simon, M and Babb, J and {others}",
  abstract  = "Biological organisms learn from interactions with their
               environment throughout their lifetime. For artificial systems to
               successfully act and adapt in the real world, it is desirable to
               similarly …",
  journal   = "Nature Machine",
  publisher = "nature.com",
  year      =  2022
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Kuchling2022-iv,
  title     = "Metacognition as a consequence of competing evolutionary time
               scales",
  author    = "Kuchling, F and Fields, C and Levin, M",
  abstract  = "Evolution is full of coevolving systems characterized by complex
               spatio-temporal interactions that lead to intertwined processes
               of adaptation. Yet, how adaptation across multiple levels …",
  journal   = "Entropy",
  publisher = "mdpi.com",
  year      =  2022
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Fields_undated-ez,
  title    = "Competency in Navigating Arbitrary Spaces: Intelligence as an
              Invariant for Analyzing Cognition in Diverse Embodiments",
  author   = "Fields, C and Levin, M",
  abstract = "One of the most salient features of life is its capacity to
              handle novelty: to thrive and adapt to new circumstances and
              changes of both environment and internal components. An …",
  journal  = "psyarxiv.com"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Clawson_undated-yc,
  title     = "Endless forms most beautiful 2.0: teleonomy and the
               bioengineering of chimaeric and synthetic organisms",
  author    = "Clawson, W P and Levin, M",
  abstract  = "The rich variety of biological forms and behaviours results from
               one evolutionary history on Earth, via frozen accidents and
               selection in specific environments. This ubiquitous baggage …",
  journal   = "Biol. J. Linn. Soc. Lond.",
  publisher = "academic.oup.com",
  issn      = "0024-4066"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Blackiston2022-yv,
  title     = "Biological Robots: Perspectives on an Emerging Interdisciplinary
               Field",
  author    = "Blackiston, D and Kriegman, S and Bongard, J and {others}",
  abstract  = "Advances in science and engineering often reveal the limitations
               of classical approaches initially used to understand, predict,
               and control phenomena. With progress, conceptual …",
  journal   = "arXiv preprint arXiv",
  publisher = "arxiv.org",
  year      =  2022
}

@ARTICLE{Fields2022-ed,
  title    = "Neurons as hierarchies of quantum reference frames",
  author   = "Fields, Chris and Glazebrook, James F and Levin, Michael",
  abstract = "Conceptual and mathematical models of neurons have lagged behind
              empirical understanding for decades. Here we extend previous work
              in modeling biological systems with fully scale-independent
              quantum information-theoretic tools to develop a uniform,
              scalable representation of synapses, dendritic and axonal
              processes, neurons, and local networks of neurons. In this
              representation, hierarchies of quantum reference frames act as
              hierarchical active-inference systems. The resulting model
              enables specific predictions of correlations between synaptic
              activity, dendritic remodeling, and trophic reward. We summarize
              how the model may be generalized to nonneural cells and tissues
              in developmental and regenerative contexts.",
  journal  = "Biosystems.",
  volume   =  219,
  pages    = "104714",
  month    =  sep,
  year     =  2022,
  keywords = "Activity-dependent remodeling; Bayesian inference;
              Bioelectricity; Computation; Learning; Memory",
  language = "en",
  issn     = "0303-2647, 1872-8324",
  pmid     = "35671840",
  doi      = "10.1016/j.biosystems.2022.104714"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Fields2022-zr,
  title     = "The Free Energy Principle drives neuromorphic development",
  author    = "Fields, C and Friston, K and Glazebrook, J F and Levin, M and
               {others}",
  abstract  = "We show how any system with morphological degrees of freedom and
               locally limited free energy will, under the constraints of the
               free energy principle, evolve toward a neuromorphic …",
  journal   = "arXiv preprint arXiv",
  publisher = "arxiv.org",
  year      =  2022
}

@ARTICLE{McMillen2022-vp,
  title    = "Information Theory as an Experimental Tool for Integrating
              Disparate Biophysical Signaling Modules",
  author   = "McMillen, Patrick and Walker, Sara I and Levin, Michael",
  abstract = "There is a growing appreciation in the fields of cell biology and
              developmental biology that cells collectively process information
              in time and space. While many powerful molecular tools exist to
              observe biophysical dynamics, biologists must find ways to
              quantitatively understand these phenomena at the systems level.
              Here, we present a guide for the application of well-established
              information theory metrics to biological datasets and explain
              these metrics using examples from cell, developmental and
              regenerative biology. We introduce a novel computational tool
              named after its intended purpose, calcium imaging, (CAIM) for
              simple, rigorous application of these metrics to time series
              datasets. Finally, we use CAIM to study calcium and cytoskeletal
              actin information flow patterns between Xenopus laevis embryonic
              animal cap stem cells. The tools that we present here should
              enable biologists to apply information theory to develop a
              systems-level understanding of information processing across a
              diverse array of experimental systems.",
  journal  = "Int. J. Mol. Sci.",
  volume   =  23,
  number   =  17,
  month    =  aug,
  year     =  2022,
  keywords = "calcium; cell biology; embryogenesis; information theory;
              morphogenesis; regeneration",
  language = "en",
  issn     = "1422-0067",
  pmid     = "36076979",
  doi      = "10.3390/ijms23179580",
  pmc      = "PMC9455895"
}

@ARTICLE{Djamgoz2022-jm,
  title     = "Bioelectricity: An Update",
  author    = "Djamgoz, Mustafa B A and Levin, Michael",
  journal   = "Bioelectricity",
  publisher = "Mary Ann Liebert, Inc., publishers",
  volume    =  4,
  number    =  3,
  pages     = "135--135",
  month     =  sep,
  year      =  2022,
  issn      = "2576-3105",
  doi       = "10.1089/bioe.2022.0024"
}

@UNPUBLISHED{Fields2022-us,
  title    = "Regulative development as a model for origin of life and
              artificial life studies",
  author   = "Fields, Chris and Levin, Michael",
  abstract = "Using the formal framework of the Free Energy Principle, we show
              how generic thermodynamic requirements on bidirectional
              information exchange between a system and its environment can
              generate complexity. This leads to the emergence of hierarchical
              computational architectures in systems that operate sufficiently
              far from thermal equilibrium. In this setting, the environment of
              any system increases its ability to predict system behavior by
              ``engineering'' the system towards increased morphological
              complexity and hence larger-scale, more macroscopic behaviors.
              When seen in this light, regulative development becomes an
              environmentally-driven process in which ``parts'' are assembled
              to produce a system with predictable behavior. We suggest on this
              basis that life is thermodynamically favorable and that human
              engineers are acting like a generic ``environment'' when
              designing artificial living systems.",
  month    =  oct,
  year     =  2022,
  keywords = "free energy principle; kinematic replication; learning;
              multicellularity; multiscale competency architecture; target
              morphology",
  doi      = "10.31234/osf.io/rdt7f"
}

@ARTICLE{Grodstein2022-sj,
  title         = "Closing the Loop on Morphogenesis: A Mathematical Model of
                   Morphogenesis by {Closed-Loop} {Reaction-Diffusion}",
  author        = "Grodstein, Joel and Levin, Michael",
  abstract      = "Morphogenesis, the establishment and repair of emergent
                   complex anatomy by groups of cells, is a fascinating and
                   biomedically-relevant problem. One of its most fascinating
                   aspects is that a developing embryo can reliably recover
                   from disturbances, such as splitting into twins. While this
                   reliability implies some type of goal-seeking error
                   minimization over a morphogenic field, there are many gaps
                   with respect to detailed, constructive models of such a
                   process being used to implement the collective intelligence
                   of cellular swarms. We describe a closed-loop
                   negative-feedback system for creating reaction-diffusion
                   (RD) patterns with high reliability. It uses a cellular
                   automaton to characterize a morphogen pattern, then compares
                   it to a goal and adjusts accordingly, providing a framework
                   for modeling anatomical homeostasis and robust generation of
                   target morphologies. Specifically, we create a RD pattern
                   with N repetitions, where N is easily changeable.
                   Furthermore, the individual repetitions of the RD pattern
                   can be easily stretched or shrunk under genetic control to
                   create, e.g., some morphological features larger than
                   others. Finally, the cellular automaton uses a computation
                   wave that scans the morphogen pattern unidirectionally to
                   characterize the features that the negative feedback then
                   controls. By taking advantage of a prior process
                   asymmetrically establishing planar polarity (e.g., head vs.
                   tail), our automaton is greatly simplified. This work
                   contributes to the exciting effort of understanding design
                   principles of morphological computation, which can be used
                   to understand evolved developmental mechanisms, manipulate
                   them in regenerative medicine settings, or embed a degree of
                   synthetic intelligence into novel bioengineered constructs.",
  month         =  nov,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2211.01313",
  primaryClass  = "q-bio.MN",
  arxivid       = "2211.01313"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Levin_undated-rg,
  title    = "Collective Intelligence of Morphogenesis as a Teleonomic Process",
  author   = "Levin, M",
  abstract = "Manuscript v9 Page 1 Collective Intelligence of Morphogenesis as
              a Teleonomic Process Michael Levin1,2 1 Allen Discovery Center at
              Tufts University, Medford, MA, USA 2 Wyss …",
  journal  = "psyarxiv.com"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INPROCEEDINGS{Cavuoti2022-sd,
  title       = "Adversarial Takeover of Neural Cellular Automata",
  booktitle   = "Artificial Life Conference Proceedings 34",
  author      = "Cavuoti, Lorenzo and Sacco, Francesco and Randazzo, Ettore and
                 Levin, Michael",
  volume      =  2022,
  pages       = "38",
  institution = "MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA
                 journals-info …",
  year        =  2022
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Ciaunica2022-mf,
  title     = "The Brain is not Mental! Coupling Neuronal and Immune Cellular
               Processing in Human Organisms",
  author    = "Ciaunica, A and Levin, M",
  abstract  = "… behaviour of the human organism as a whole. We focus
               specifically on the immune cellular processing as key actor in
               complementing neuronal processing in achieving successful self-…",
  publisher = "psyarxiv.com",
  year      =  2022
}

@ARTICLE{Murrugarra2022-nb,
  title  = "The Nonlinearity of Regulation in Biological Networks",
  author = "Murrugarra, David and Manicka, Santosh and Johnson, Kathleen and
            Levin, Michael",
  year   =  2022
}

@UNPUBLISHED{Durstewitz2022-du,
  title    = "Reconstructing Computational Dynamics from Neural Measurements
              with Recurrent Neural Networks",
  author   = "Durstewitz, Daniel and Koppe, Georgia and Thurm, Max Ingo",
  abstract = "Mechanistic and computational models in neuroscience usually take
              the form of systems of differential or time-recursive equations.
              The spatio-temporal behavior of such systems is the subject of
              dynamical systems theory (DST). DST provides a powerful
              mathematical toolbox for describing and analyzing neurobiological
              processes at any level, from molecules to behavior, and has been
              a mainstay of computational neuroscience for decades. Recently,
              recurrent neural networks (RNNs) became a popular machine
              learning tool for studying the nonlinear dynamics underlying
              neural or behavioral observations. By training RNNs on the same
              behavioral tasks as employed for animal subjects and dissecting
              their inner workings, insights and hypotheses about the
              neuro-computational underpinnings of behavior could be generated.
              Alternatively, RNNs may be trained directly on the physiological
              and behavioral time series at hand. Ideally, the once trained RNN
              would then be able to generate data with the same temporal and
              geometrical properties as those observed. This is called
              dynamical systems reconstruction, a burgeoning field in machine
              learning and nonlinear dynamics. Through this more powerful
              approach the trained RNN becomes a surrogate for the
              experimentally probed system, as far as its dynamical and
              computational properties are concerned. The trained system can
              then be systematically analyzed, probed and simulated. Here we
              will review this highly exciting and rapidly expanding field,
              including recent trends in machine learning that may as yet be
              less well known in neuroscience. We will also discuss important
              validation tests, caveats, and requirements of RNN-based
              dynamical systems reconstruction. Concepts and applications will
              be illustrated with various examples from neuroscience. \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.10.31.514408",
  month    =  nov,
  year     =  2022,
  keywords = "To Read;BCI",
  language = "en",
  doi      = "10.1101/2022.10.31.514408"
}

@ARTICLE{Sorscher2022-zt,
  title    = "A unified theory for the computational and mechanistic origins of
              grid cells",
  author   = "Sorscher, Ben and Mel, Gabriel C and Ocko, Samuel A and Giocomo,
              Lisa M and Ganguli, Surya",
  abstract = "The discovery of entorhinal grid cells has generated considerable
              interest in how and why hexagonal firing fields might emerge in a
              generic manner from neural circuits, and what their computational
              significance might be. Here, we forge a link between the problem
              of path integration and the existence of hexagonal grids, by
              demonstrating that such grids arise in neural networks trained to
              path integrate under simple biologically plausible constraints.
              Moreover, we develop a unifying theory for why hexagonal grids
              are ubiquitous in path-integrator circuits. Such trained networks
              also yield powerful mechanistic hypotheses, exhibiting realistic
              levels of biological variability not captured by hand-designed
              models. We furthermore develop methods to analyze the connectome
              and activity maps of our networks to elucidate fundamental
              mechanisms underlying path integration. These methods provide a
              road map to go from connectomic and physiological measurements to
              conceptual understanding in a manner that could generalize to
              other settings.",
  journal  = "Neuron",
  month    =  oct,
  year     =  2022,
  keywords = "grid cells; mechanistic models; medial entorhinal cortex;
              navigation; neural data; neural fitting; neural networks;
              normative models; path integration; pattern formation",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "36306779",
  doi      = "10.1016/j.neuron.2022.10.003"
}

@ARTICLE{Gonzalez2022-ia,
  title    = "From Rats to Humans: how novel behavioral paradigms and
              reinforcement learning can bridge the gap in translation",
  author   = "Gonzalez, Alexander and Giocomo, Lisa M",
  journal  = "Lab Anim.",
  volume   =  51,
  number   =  11,
  pages    = "289--290",
  month    =  nov,
  year     =  2022,
  language = "en",
  issn     = "0093-7355, 1548-4475",
  pmid     = "36258040",
  doi      = "10.1038/s41684-022-01077-x"
}

@ARTICLE{Low2022-qp,
  title    = "Task engagement turns on spatial maps",
  author   = "Low, Isabel I C and Giocomo, Lisa M",
  journal  = "Nat. Neurosci.",
  volume   =  25,
  number   =  5,
  pages    = "534--535",
  month    =  may,
  year     =  2022,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "35449356",
  doi      = "10.1038/s41593-022-01051-3"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Nayebi2021-yf,
  title     = "Explaining heterogeneity in medial entorhinal cortex with
               task-driven neural networks",
  author    = "Nayebi, A and Attinger, A and Campbell, M and {others}",
  abstract  = "Medial entorhinal cortex (MEC) supports a wide range of
               navigational and memory related behaviors. Well-known
               experimental results have revealed specialized cell types in MEC
               …",
  journal   = "Advances in",
  publisher = "proceedings.neurips.cc",
  year      =  2021
}

@ARTICLE{Rueckemann2021-hj,
  title    = "The grid code for ordered experience",
  author   = "Rueckemann, Jon W and Sosa, Marielena and Giocomo, Lisa M and
              Buffalo, Elizabeth A",
  abstract = "Entorhinal cortical grid cells fire in a periodic pattern that
              tiles space, which is suggestive of a spatial coordinate system.
              However, irregularities in the grid pattern as well as responses
              of grid cells in contexts other than spatial navigation have
              presented a challenge to existing models of entorhinal function.
              In this Perspective, we propose that hippocampal input provides a
              key informative drive to the grid network in both spatial and
              non-spatial circumstances, particularly around salient events. We
              build on previous models in which neural activity propagates
              through the entorhinal-hippocampal network in time. This temporal
              contiguity in network activity points to temporal order as a
              necessary characteristic of representations generated by the
              hippocampal formation. We advocate that interactions in the
              entorhinal-hippocampal loop build a topological representation
              that is rooted in the temporal order of experience. In this way,
              the structure of grid cell firing supports a learned topology
              rather than a rigid coordinate frame that is bound to
              measurements of the physical world.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  22,
  number   =  10,
  pages    = "637--649",
  month    =  oct,
  year     =  2021,
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "34453151",
  doi      = "10.1038/s41583-021-00499-9",
  pmc      = "PMC9371942"
}

@ARTICLE{Campbell2021-vl,
  title    = "Distance-tuned neurons drive specialized path integration
              calculations in medial entorhinal cortex",
  author   = "Campbell, Malcolm G and Attinger, Alexander and Ocko, Samuel A
              and Ganguli, Surya and Giocomo, Lisa M",
  abstract = "During navigation, animals estimate their position using path
              integration and landmarks, engaging many brain areas. Whether
              these areas follow specialized or universal cue integration
              principles remains incompletely understood. We combine
              electrophysiology with virtual reality to quantify cue
              integration across thousands of neurons in three
              navigation-relevant areas: primary visual cortex (V1),
              retrosplenial cortex (RSC), and medial entorhinal cortex (MEC).
              Compared with V1 and RSC, path integration influences position
              estimates more in MEC, and conflicts between path integration and
              landmarks trigger remapping more readily. Whereas MEC codes
              position prospectively, V1 codes position retrospectively, and
              RSC is intermediate between the two. Lowered visual contrast
              increases the influence of path integration on position estimates
              only in MEC. These properties are most pronounced in a population
              of MEC neurons, overlapping with grid cells, tuned to distance
              run in darkness. These results demonstrate the specialized role
              that path integration plays in MEC compared with other
              navigation-relevant cortical areas.",
  journal  = "Cell Rep.",
  volume   =  36,
  number   =  10,
  pages    = "109669",
  month    =  sep,
  year     =  2021,
  keywords = "cue integration; grid cells; landmarks; medial entorhinal cortex;
              navigation; path integration; retrosplenial cortex; visual cortex",
  language = "en",
  issn     = "2211-1247",
  pmid     = "34496249",
  doi      = "10.1016/j.celrep.2021.109669",
  pmc      = "PMC8437084"
}

@ARTICLE{Mallory2021-sv,
  title    = "Mouse entorhinal cortex encodes a diverse repertoire of
              self-motion signals",
  author   = "Mallory, Caitlin S and Hardcastle, Kiah and Campbell, Malcolm G
              and Attinger, Alexander and Low, Isabel I C and Raymond, Jennifer
              L and Giocomo, Lisa M",
  abstract = "Neural circuits generate representations of the external world
              from multiple information streams. The navigation system provides
              an exceptional lens through which we may gain insights about how
              such computations are implemented. Neural circuits in the medial
              temporal lobe construct a map-like representation of space that
              supports navigation. This computation integrates multiple sensory
              cues, and, in addition, is thought to require cues related to the
              individual's movement through the environment. Here, we identify
              multiple self-motion signals, related to the position and
              velocity of the head and eyes, encoded by neurons in a key node
              of the navigation circuitry of mice, the medial entorhinal cortex
              (MEC). The representation of these signals is highly integrated
              with other cues in individual neurons. Such information could be
              used to compute the allocentric location of landmarks from visual
              cues and to generate internal representations of space.",
  journal  = "Nat. Commun.",
  volume   =  12,
  number   =  1,
  pages    = "671",
  month    =  jan,
  year     =  2021,
  language = "en",
  issn     = "2041-1723",
  pmid     = "33510164",
  doi      = "10.1038/s41467-021-20936-8",
  pmc      = "PMC7844029"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{York2021-vf,
  title     = "Flexible analysis of animal behavior via time-resolved manifold
               embedding",
  author    = "York, R A and Carreira-Rosario, A and Giocomo, L M and {others}",
  abstract  = "Uncovering relationships between neural activity and behavior
               represents a critical challenge, one that would benefit from
               facile tools that can capture complex structures within …",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  year      =  2021
}

@ARTICLE{Munn2020-rk,
  title    = "Entorhinal velocity signals reflect environmental geometry",
  author   = "Munn, Robert G K and Mallory, Caitlin S and Hardcastle, Kiah and
              Chetkovich, Dane M and Giocomo, Lisa M",
  abstract = "The entorhinal cortex contains neurons that represent
              self-location, including grid cells that fire in periodic
              locations and velocity signals that encode running speed and head
              direction. Although the size and shape of the environment
              influence grid patterns, whether entorhinal velocity signals are
              equally influenced or provide a universal metric for self-motion
              across environments remains unknown. Here we report that speed
              cells rescale after changes to the size and shape of the
              environment. Moreover, head direction cells reorganize in an
              experience-dependent manner to align with the axis of
              environmental change. A knockout mouse model allows dissociation
              of the coordination between cell types, with grid and speed
              cells, but not head direction cells, responding in concert to
              environmental change. These results point to malleability in the
              coding features of multiple entorhinal cell types and have
              implications for which cell types contribute to the velocity
              signal used by computational models of grid cells.",
  journal  = "Nat. Neurosci.",
  volume   =  23,
  number   =  2,
  pages    = "239--251",
  month    =  feb,
  year     =  2020,
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "31932764",
  doi      = "10.1038/s41593-019-0562-5",
  pmc      = "PMC7007349"
}

@ARTICLE{Campbell2019-hp,
  title     = "How a fly's neural compass adapts to an ever-changing world",
  author    = "Campbell, Malcolm G and Giocomo, Lisa M",
  journal   = "Nature",
  publisher = "Springer Science and Business Media LLC",
  volume    =  576,
  number    =  7785,
  pages     = "42--43",
  month     =  dec,
  year      =  2019,
  keywords  = "Neuroscience",
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "31792416",
  doi       = "10.1038/d41586-019-03443-1"
}

@ARTICLE{Campbell2018-rf,
  title    = "Self-motion processing in visual and entorhinal cortices: inputs,
              integration, and implications for position coding",
  author   = "Campbell, Malcolm G and Giocomo, Lisa M",
  abstract = "The sensory signals generated by self-motion are complex and
              multimodal, but the ability to integrate these signals into a
              unified self-motion percept to guide navigation is essential for
              animal survival. Here, we summarize classic and recent work on
              self-motion coding in the visual and entorhinal cortices of the
              rodent brain. We compare motion processing in rodent and primate
              visual cortices, highlighting the strengths of classic primate
              work in establishing causal links between neural activity and
              perception, and discuss the integration of motor and visual
              signals in rodent visual cortex. We then turn to the medial
              entorhinal cortex (MEC), where calculations using self-motion to
              update position estimates are thought to occur. We focus on
              several key sources of self-motion information to MEC: the medial
              septum, which provides locomotor speed information; visual
              cortex, whose input has been increasingly recognized as essential
              to both position and speed-tuned MEC cells; and the head
              direction system, which is a major source of directional
              information for self-motion estimates. These inputs create a
              large and diverse group of self-motion codes in MEC, and great
              interest remains in how these self-motion codes might be
              integrated by MEC grid cells to estimate position. However, which
              signals are used in these calculations and the mechanisms by
              which they are integrated remain controversial. We end by
              proposing future experiments that could further our understanding
              of the interactions between MEC cells that code for self-motion
              and position and clarify the relationship between the activity of
              these cells and spatial perception.",
  journal  = "J. Neurophysiol.",
  volume   =  120,
  number   =  4,
  pages    = "2091--2106",
  month    =  oct,
  year     =  2018,
  language = "en",
  issn     = "0022-3077, 1522-1598",
  pmid     = "30089025",
  doi      = "10.1152/jn.00686.2017",
  pmc      = "PMC6230811"
}

@ARTICLE{Hardcastle2017-au,
  title     = "A Multiplexed, Heterogeneous, and Adaptive Code for Navigation
               in Medial Entorhinal Cortex",
  author    = "Hardcastle, Kiah and Maheswaranathan, Niru and Ganguli, Surya
               and Giocomo, Lisa M",
  abstract  = "Medial entorhinal grid cells display strikingly symmetric
               spatial firing patterns. The clarity of these patterns motivated
               the use of specific activity pattern shapes to classify
               entorhinal cell types. While this approach successfully revealed
               cells that encode boundaries, head direction, and running speed,
               it left a majority of cells unclassified, and its pre-defined
               nature may have missed unconventional, yet important coding
               properties. Here, we apply an unbiased statistical approach to
               search for cells that encode navigationally relevant variables.
               This approach successfully classifies the majority of entorhinal
               cells and reveals unsuspected entorhinal coding principles.
               First, we find a high degree of mixed selectivity and
               heterogeneity in superficial entorhinal neurons. Second, we
               discover a dynamic and remarkably adaptive code for space that
               enables entorhinal cells to rapidly encode navigational
               information accurately at high running speeds. Combined, these
               observations advance our current understanding of the
               mechanistic origins and functional implications of the
               entorhinal code for navigation. VIDEO ABSTRACT.",
  journal   = "Neuron",
  publisher = "Elsevier",
  volume    =  94,
  number    =  2,
  pages     = "375--387.e7",
  month     =  apr,
  year      =  2017,
  keywords  = "Multiplexed-coding; adaptive coding; computational models of
               spatial coding; encoding mode; entorhinal cortex; spatial
               navigation; tuning heterogeneity",
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "28392071",
  doi       = "10.1016/j.neuron.2017.03.025",
  pmc       = "PMC5498174"
}

@ARTICLE{Floryan2022-bj,
  title     = "Data-driven discovery of intrinsic dynamics",
  author    = "Floryan, Daniel and Graham, Michael D",
  abstract  = "Dynamical models underpin our ability to understand and predict
               the behaviour of natural systems. Whether dynamical models are
               developed from first-principles derivations or from
               observational data, they are predicated on our choice of state
               variables. The choice of state variables is driven by
               convenience and intuition, and, in data-driven cases, the
               observed variables are often chosen to be the state variables.
               The dimensionality of these variables (and consequently the
               dynamical models) can be arbitrarily large, obscuring the
               underlying behaviour of the system. In truth these variables are
               often highly redundant and the system is driven by a much
               smaller set of latent intrinsic variables. In this study we
               combine the mathematical theory of manifolds with the
               representational capacity of neural networks to develop a method
               that learns a system's intrinsic state variables directly from
               time-series data, as well as predictive models for their
               dynamics. What distinguishes our method is its ability to reduce
               data to the intrinsic dimensionality of the nonlinear manifold
               they live on. This ability is enabled by the concepts of charts
               and atlases from the theory of manifolds, whereby a manifold is
               represented by a collection of patches that are sewn
               together---a necessary representation to attain intrinsic
               dimensionality. We demonstrate this approach on several
               high-dimensional systems with low-dimensional behaviour. The
               resulting framework provides the ability to develop dynamical
               models of the lowest possible dimension, capturing the essence
               of a system. Learning minimal representations of dynamical
               systems is essential for mathematical modelling and prediction
               in science and engineering. Floryan and Graham propose a deep
               learning framework able to estimate accurate global dynamical
               models by sewing together multiple local representations learnt
               from high-dimensional time-series data.",
  journal   = "Nature Machine Intelligence",
  publisher = "Nature Publishing Group",
  pages     = "1--8",
  month     =  dec,
  year      =  2022,
  keywords  = "to\_read\_for\_review",
  language  = "en",
  issn      = "2522-5839, 2522-5839",
  doi       = "10.1038/s42256-022-00575-4"
}

@ARTICLE{Smiley2022-jh,
  title    = "Competition for finite resources as coordination mechanism for
              morphogenesis: An evolutionary algorithm study of digital
              embryogeny",
  author   = "Smiley, Peter and Levin, Michael",
  abstract = "The standard view of embryogenesis is one of cooperation driven
              by the cells' shared genetics and evolutionary interests.
              However, numerous examples from developmental biology and
              agriculture reveal a surprising amount of competition among body
              cells, tissues, and organs for both metabolic and informational
              resources. To explain the existence of such competition we had
              hypothesized that evolution uses limiting ``reservoirs'' of
              resource molecules as a communication medium - a global
              scratchpad, to enable tissues across the body to coordinate
              growth. Here, we test this hypothesis via an evolutionary
              simulation of embryogeny in silico. Genomes encode state
              transition rules for cells, such as proliferation,
              differentiation, and resource use, enabling virtual embryos to
              develop a specific large-scale morphology. An evolutionary
              algorithm operates over the genomes, with fitness defined as a
              function of specific morphological requirements for the final
              embryo shape. We found that not only does such an algorithm
              rapidly discover rules for cellular behavior that reliably make
              embryos with specific anatomical properties, but that it
              discovers the strategy of using finite resources to coordinate
              development. Given the option of using finite or infinite
              reservoirs (which determine cells' ability to carry out specific
              actions), evolution preferentially uses finite reservoirs, which
              results in higher fitness and increased consistency (without
              needing direct selection for morphological invariance). We report
              aspects of anatomical, physiological/transcriptional, and genomic
              analysis of evolved virtual embryos that help understand how
              evolution can use competition among genetically identical
              subunits within a multicellular body to coordinate reliable,
              complex morphogenesis. Our results suggest that under some
              conditions, composite multi-scale systems will promote conflict
              and artificial scarcity for their components.",
  journal  = "Biosystems.",
  volume   =  221,
  pages    = "104762",
  month    =  nov,
  year     =  2022,
  keywords = "Artificial life; Cell; Competition; Embryonic development;
              Evolution; Morphogenesis; Simulation",
  language = "en",
  issn     = "0303-2647, 1872-8324",
  pmid     = "36064151",
  doi      = "10.1016/j.biosystems.2022.104762"
}

@ARTICLE{Sperry2022-fy,
  title    = "Enhancers of Host Immune Tolerance to Bacterial Infection
              Discovered Using Linked Computational and Experimental Approaches",
  author   = "Sperry, Megan M and Novak, Richard and Keshari, Vishal and Dinis,
              Alexandre L M and Cartwright, Mark J and Camacho, Diogo M and
              Par{\'e}, Jean-Fran{\c c}ois and Super, Michael and Levin,
              Michael and Ingber, Donald E",
  abstract = "Current therapeutic strategies against bacterial infections focus
              on reduction of pathogen load using antibiotics; however,
              stimulation of host tolerance to infection in the presence of
              pathogens might offer an alternative approach. Computational
              transcriptomics and Xenopus laevis embryos are used to discover
              infection response pathways, identify potential tolerance inducer
              drugs, and validate their ability to induce broad tolerance.
              Xenopus exhibits natural tolerance to Acinetobacter baumanii,
              Klebsiella pneumoniae, Staphylococcus aureus, and Streptococcus
              pneumoniae bacteria, whereas Aeromonas hydrophila and Pseudomonas
              aeruginosa produce lethal infections. Transcriptional profiling
              leads to definition of a 20-gene signature that discriminates
              between tolerant and susceptible states, as well as
              identification of a more active tolerance response to gram
              negative compared to gram positive bacteria. Gene pathways
              associated with active tolerance in Xenopus, including some
              involved in metal ion binding and hypoxia, are found to be
              conserved across species, including mammals, and administration
              of a metal chelator (deferoxamine) or a HIF-1$\alpha$ agonist
              (1,4-DPCA) in embryos infected with lethal A. hydrophila
              increased survival despite high pathogen load. These data
              demonstrate the value of combining the Xenopus embryo infection
              model with computational multiomics analyses for mechanistic
              discovery and drug repurposing to induce host tolerance to
              bacterial infections.",
  journal  = "Adv. Sci.",
  volume   =  9,
  number   =  26,
  pages    = "e2200222",
  month    =  sep,
  year     =  2022,
  keywords = "drug repurposing; host response; infection; sepsis; tolerance",
  language = "en",
  issn     = "0001-866X, 2198-3844",
  pmid     = "35706367",
  doi      = "10.1002/advs.202200222",
  pmc      = "PMC9475558"
}

@ARTICLE{Manicka2022-wx,
  title    = "Minimal Developmental Computation: A Causal Network Approach to
              Understand Morphogenetic Pattern Formation",
  author   = "Manicka, Santosh and Levin, Michael",
  abstract = "What information-processing strategies and general principles are
              sufficient to enable self-organized morphogenesis in
              embryogenesis and regeneration? We designed and analyzed a
              minimal model of self-scaling axial patterning consisting of a
              cellular network that develops activity patterns within
              implicitly set bounds. The properties of the cells are determined
              by internal 'genetic' networks with an architecture shared across
              all cells. We used machine-learning to identify models that
              enable this virtual mini-embryo to pattern a typical axial
              gradient while simultaneously sensing the set boundaries within
              which to develop it from homogeneous conditions-a setting that
              captures the essence of early embryogenesis. Interestingly, the
              model revealed several features (such as planar polarity and
              regenerative re-scaling capacity) for which it was not directly
              selected, showing how these common biological design principles
              can emerge as a consequence of simple patterning modes. A novel
              ``causal network'' analysis of the best model furthermore
              revealed that the originally symmetric model dynamically
              integrates into intercellular causal networks characterized by
              broken-symmetry, long-range influence and modularity, offering an
              interpretable macroscale-circuit-based explanation for phenotypic
              patterning. This work shows how computation could occur in
              biological development and how machine learning approaches can
              generate hypotheses and deepen our understanding of how
              featureless tissues might develop sophisticated patterns-an
              essential step towards predictive control of morphogenesis in
              regenerative medicine or synthetic bioengineering contexts. The
              tools developed here also have the potential to benefit machine
              learning via new forms of backpropagation and by leveraging the
              novel distributed self-representation mechanisms to improve
              robustness and generalization.",
  journal  = "Entropy",
  volume   =  24,
  number   =  1,
  month    =  jan,
  year     =  2022,
  keywords = "artificial embryogeny; biological circuits; biological
              computation; causal information flow; collective phenomena;
              developmental patterning; distributed information processing",
  language = "en",
  issn     = "1099-4300",
  pmid     = "35052133",
  doi      = "10.3390/e24010107",
  pmc      = "PMC8774453"
}

@ARTICLE{Stemmler2015-xb,
  title    = "Connecting multiple spatial scales to decode the population
              activity of grid cells",
  author   = "Stemmler, Martin and Mathis, Alexander and Herz, Andreas V M",
  abstract = "Mammalian grid cells fire when an animal crosses the points of an
              imaginary hexagonal grid tessellating the environment. We show
              how animals can navigate by reading out a simple population
              vector of grid cell activity across multiple spatial scales, even
              though neural activity is intrinsically stochastic. This theory
              of dead reckoning explains why grid cells are organized into
              discrete modules within which all cells have the same lattice
              scale and orientation. The lattice scale changes from module to
              module and should form a geometric progression with a scale ratio
              of around 3/2 to minimize the risk of making large-scale errors
              in spatial localization. Such errors should also occur if
              intermediate-scale modules are silenced, whereas knocking out the
              module at the smallest scale will only affect spatial precision.
              For goal-directed navigation, the allocentric grid cell
              representation can be readily transformed into the egocentric
              goal coordinates needed for planning movements. The goal location
              is set by nonlinear gain fields that act on goal vector cells.
              This theory predicts neural and behavioral correlates of grid
              cell readout that transcend the known link between grid cells of
              the medial entorhinal cortex and place cells of the hippocampus.",
  journal  = "Sci Adv",
  volume   =  1,
  number   =  11,
  pages    = "e1500816",
  month    =  dec,
  year     =  2015,
  keywords = "entorhinal cortex; goal-directed navigation; goal-vector cells;
              grid cell; maximum likelihood decoding; nonlinear gain fields;
              population vector; self localization; spatial cognition",
  language = "en",
  issn     = "2375-2548",
  pmid     = "26824061",
  doi      = "10.1126/science.1500816",
  pmc      = "PMC4730856"
}

@ARTICLE{Khona2022-ba,
  title    = "Attractor and integrator networks in the brain",
  author   = "Khona, Mikail and Fiete, Ila R",
  abstract = "In this Review, we describe the singular success of attractor
              neural network models in describing how the brain maintains
              persistent activity states for working memory, corrects errors
              and integrates noisy cues. We consider the mechanisms by which
              simple and forgetful units can organize to collectively generate
              dynamics on the long timescales required for such computations.
              We discuss the myriad potential uses of attractor dynamics for
              computation in the brain, and showcase notable examples of brain
              systems in which inherently low-dimensional continuous-attractor
              dynamics have been concretely and rigorously identified. Thus, it
              is now possible to conclusively state that the brain constructs
              and uses such systems for computation. Finally, we highlight
              recent theoretical advances in understanding how the fundamental
              trade-offs between robustness and capacity and between structure
              and flexibility can be overcome by reusing and recombining the
              same set of modular attractors for multiple functions, so they
              together produce representations that are structurally
              constrained and robust but exhibit high capacity and are
              flexible.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  23,
  number   =  12,
  pages    = "744--766",
  month    =  dec,
  year     =  2022,
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "36329249",
  doi      = "10.1038/s41583-022-00642-0"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@INCOLLECTION{Lee2012-qo,
  title     = "Smooth Manifolds",
  booktitle = "Introduction to Smooth Manifolds",
  author    = "Lee, John M",
  editor    = "Lee, John M",
  abstract  = "In this chapter, we begin by introducing the simplest type of
               manifolds, the topological manifolds, which are topological
               spaces with three special properties that encode what we mean
               when we say that they ``locally look like ℝn.'' We then prove
               some important topological properties of manifolds that we use
               throughout the book. In the second section we introduce an
               additional structure, called a smooth structure, that can be
               added to a topological manifold to enable us to do calculus.
               Following the basic definitions, we introduce a number of
               examples of manifolds, so you can have something concrete in
               mind as you read the general theory. At the end of the chapter
               we introduce the concept of a smooth manifold with boundary, an
               important generalization of smooth manifolds that will have
               numerous applications throughout the book.",
  publisher = "Springer New York",
  pages     = "1--31",
  year      =  2012,
  address   = "New York, NY",
  isbn      = "9781441999825",
  doi       = "10.1007/978-1-4419-9982-5\_1"
}

@ARTICLE{Dabagia2022-rj,
  title    = "Aligning latent representations of neural activity",
  author   = "Dabagia, Max and Kording, Konrad P and Dyer, Eva L",
  journal  = "Nat Biomed Eng",
  month    =  nov,
  year     =  2022,
  language = "en",
  issn     = "2157-846X",
  pmid     = "36443379",
  doi      = "10.1038/s41551-022-00962-7",
  pmc      = "4393644"
}

@ARTICLE{Degenhart2020-nf,
  title    = "Stabilization of a brain-computer interface via the alignment of
              low-dimensional spaces of neural activity",
  author   = "Degenhart, Alan D and Bishop, William E and Oby, Emily R and
              Tyler-Kabara, Elizabeth C and Chase, Steven M and Batista, Aaron
              P and Yu, Byron M",
  abstract = "The instability of neural recordings can render clinical
              brain-computer interfaces (BCIs) uncontrollable. Here, we show
              that the alignment of low-dimensional neural manifolds
              (low-dimensional spaces that describe specific correlation
              patterns between neurons) can be used to stabilize neural
              activity, thereby maintaining BCI performance in the presence of
              recording instabilities. We evaluated the stabilizer with
              non-human primates during online cursor control via intracortical
              BCIs in the presence of severe and abrupt recording
              instabilities. The stabilized BCIs recovered proficient control
              under different instability conditions and across multiple days.
              The stabilizer does not require knowledge of user intent and can
              outperform supervised recalibration. It stabilized BCIs even when
              neural activity contained little information about the direction
              of cursor movement. The stabilizer may be applicable to other
              neural interfaces and may improve the clinical viability of BCIs.",
  journal  = "Nat Biomed Eng",
  volume   =  4,
  number   =  7,
  pages    = "672--685",
  month    =  jul,
  year     =  2020,
  keywords = "To Read;BCI",
  language = "en",
  issn     = "2157-846X",
  pmid     = "32313100",
  doi      = "10.1038/s41551-020-0542-9",
  pmc      = "PMC7822646"
}

@ARTICLE{Pfau2020-xi,
  title         = "Disentangling by Subspace Diffusion",
  author        = "Pfau, David and Higgins, Irina and Botev, Aleksandar and
                   Racani{\`e}re, S{\'e}bastien",
  abstract      = "We present a novel nonparametric algorithm for
                   symmetry-based disentangling of data manifolds, the
                   Geometric Manifold Component Estimator (GEOMANCER).
                   GEOMANCER provides a partial answer to the question posed by
                   Higgins et al. (2018): is it possible to learn how to
                   factorize a Lie group solely from observations of the orbit
                   of an object it acts on? We show that fully unsupervised
                   factorization of a data manifold is possible if the true
                   metric of the manifold is known and each factor manifold has
                   nontrivial holonomy -- for example, rotation in 3D. Our
                   algorithm works by estimating the subspaces that are
                   invariant under random walk diffusion, giving an
                   approximation to the de Rham decomposition from differential
                   geometry. We demonstrate the efficacy of GEOMANCER on
                   several complex synthetic manifolds. Our work reduces the
                   question of whether unsupervised disentangling is possible
                   to the question of whether unsupervised metric learning is
                   possible, providing a unifying insight into the geometric
                   nature of representation learning.",
  month         =  jun,
  year          =  2020,
  archivePrefix = "arXiv",
  eprint        = "2006.12982",
  primaryClass  = "stat.ML",
  arxivid       = "2006.12982"
}

@ARTICLE{Cohen2019-wr,
  title         = "Gauge Equivariant Convolutional Networks and the Icosahedral
                   {CNN}",
  author        = "Cohen, Taco S and Weiler, Maurice and Kicanaoglu, Berkay and
                   Welling, Max",
  abstract      = "The principle of equivariance to symmetry transformations
                   enables a theoretically grounded approach to neural network
                   architecture design. Equivariant networks have shown
                   excellent performance and data efficiency on vision and
                   medical imaging problems that exhibit symmetries. Here we
                   show how this principle can be extended beyond global
                   symmetries to local gauge transformations. This enables the
                   development of a very general class of convolutional neural
                   networks on manifolds that depend only on the intrinsic
                   geometry, and which includes many popular methods from
                   equivariant and geometric deep learning. We implement gauge
                   equivariant CNNs for signals defined on the surface of the
                   icosahedron, which provides a reasonable approximation of
                   the sphere. By choosing to work with this very regular
                   manifold, we are able to implement the gauge equivariant
                   convolution using a single conv2d call, making it a highly
                   scalable and practical alternative to Spherical CNNs. Using
                   this method, we demonstrate substantial improvements over
                   previous methods on the task of segmenting omnidirectional
                   images and global climate patterns.",
  month         =  feb,
  year          =  2019,
  archivePrefix = "arXiv",
  eprint        = "1902.04615",
  primaryClass  = "cs.LG",
  arxivid       = "1902.04615"
}

@ARTICLE{Vafidis2022-sv,
  title    = "Learning accurate path integration in ring attractor models of
              the head direction system",
  author   = "Vafidis, Pantelis and Owald, David and D'Albis, Tiziano and
              Kempter, Richard",
  abstract = "Ring attractor models for angular path integration have received
              strong experimental support. To function as integrators, head
              direction circuits require precisely tuned connectivity, but it
              is currently unknown how such tuning could be achieved. Here, we
              propose a network model in which a local, biologically plausible
              learning rule adjusts synaptic efficacies during development,
              guided by supervisory allothetic cues. Applied to the Drosophila
              head direction system, the model learns to path-integrate
              accurately and develops a connectivity strikingly similar to the
              one reported in experiments. The mature network is a
              quasi-continuous attractor and reproduces key experiments in
              which optogenetic stimulation controls the internal
              representation of heading in flies, and where the network remaps
              to integrate with different gains in rodents. Our model predicts
              that path integration requires self-supervised learning during a
              developmental phase, and proposes a general framework to learn to
              path-integrate with gain-1 even in architectures that lack the
              physical topography of a ring.",
  journal  = "Elife",
  volume   =  11,
  month    =  jun,
  year     =  2022,
  keywords = "compartmentalized neuron; neuroscience; none; path integration;
              predictive coding; recurrent neural networks; self-supervised
              learning; synaptic plasticity",
  language = "en",
  issn     = "2050-084X",
  pmid     = "35723252",
  doi      = "10.7554/eLife.69841",
  pmc      = "PMC9286743"
}

@ARTICLE{Ma2022-fe,
  title         = "Dynamics of bump attractors in neural circuits with emergent
                   spatial correlations",
  author        = "Ma, Hengyuan and Qi, Yang and Gong, Pulin and Lu, Wenlian
                   and Feng, Jianfeng",
  abstract      = "Neural activity in the brain exhibits correlated
                   fluctuations that may strongly influence the properties of
                   neural population coding. However, how such correlated
                   neural fluctuations may arise from the intrinsic neural
                   circuit dynamics and subsequently impact the computational
                   properties of neural population activity remains poorly
                   understood. The main difficulty lies in resolving the
                   nonlinear coupling between correlated fluctuations with the
                   overall dynamics of the system. In this study, we develop a
                   neural circuit model that captures the nonlinear noise
                   coupling of realistic neurons to investigate the dynamics of
                   bump attractors, a type of spatially localized persistent
                   states implicated in a host of cognitive processes in the
                   brain. We show that a rich repertoire of spatial correlation
                   patterns naturally emerge from the intrinsic dynamics of the
                   neural circuit model and further reveal how the interplay
                   between differential and noise correlations influences the
                   accuracy of neural population codes of bump attractors under
                   different dynamical regimes. Moreover, we find that negative
                   correlations may induce stable bound states between two
                   bumps, a phenomenon previously unobserved in firing rate
                   models. These noise-induced effects of bump attractors lead
                   to a number of computational advantages including enhanced
                   working memory capacity and efficient codes through
                   spatiotemporal multiplexing, and can account for a range of
                   cognitive and behavioral phenomena related to working
                   memory. This study offers a dynamical approach to
                   investigating realistic correlated neural fluctuations and
                   insights to their roles in cortical computations.",
  month         =  dec,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2212.01663",
  primaryClass  = "physics.bio-ph",
  arxivid       = "2212.01663"
}

@UNPUBLISHED{Herrero-Vidal2021-jo,
  title       = "Across-animal odor decoding by probabilistic manifold
                 alignment",
  author      = "Herrero-Vidal, Pedro and Rinberg, Dmitry and Savin, Cristina",
  abstract    = "AbstractIdentifying the common structure of neural dynamics
                 across subjects is key for extracting unifying principles of
                 brain computation and for many brain machine interface
                 applications. Here, we propose a novel probabilistic approach
                 for aligning stimulus-evoked responses from multiple animals
                 in a common low dimensional manifold and use hierarchical
                 inference to identify which stimulus drives neural activity in
                 any given trial. Our probabilistic decoder is robust to a
                 range of features of the neural responses and significantly
                 outperforms existing neural alignment procedures. When applied
                 to recordings from the mouse olfactory bulb, our approach
                 reveals low-dimensional population dynamics that are odor
                 specific and have consistent structure across animals. Thus,
                 our decoder can be used for increasing the robustness and
                 scalability of neural-based chemical detection.",
  journal     = "bioRxiv",
  pages       = "20360--20372",
  institution = "bioRxiv",
  month       =  jun,
  year        =  2021,
  keywords    = "To Read;BCI",
  doi         = "10.1101/2021.06.06.447279"
}

@UNPUBLISHED{Humphreys2022-at,
  title    = "{BCI} learning phenomena can be explained by gradient-based
              optimization",
  author   = "Humphreys, Peter C and Daie, Kayvon and Svoboda, Karel and
              Botvinick, Matthew and Lillicrap, Timothy P",
  abstract = "Brain-computer interface (BCI) experiments have shown that
              animals are able to adapt their recorded neural activity in order
              to receive reward. Recent studies have highlighted two phenomena.
              First, the speed at which a BCI task can be learned is dependent
              on how closely the required neural activity aligns with
              pre-existing activity patterns: learning ``out-of-manifold''
              tasks is slower than ``in-manifold'' tasks. Second, learning
              happens by ``re-association'': the overall distribution of neural
              activity patterns does not change significantly during task
              learning. These phenomena have been presented as distinctive
              aspects of BCI learning. Here we show, using simulations and
              theoretical analysis, that both phenomena result from the simple
              assumption that behaviour and representations are improved via
              gradient-based algorithms. We invoke Occam's Razor to suggest
              that this straightforward explanation should be pre-ferred when
              accounting for these experimental observations. \#\#\# Competing
              Interest Statement The authors have declared no competing
              interest.",
  journal  = "bioRxiv",
  pages    = "2022.12.08.519453",
  month    =  dec,
  year     =  2022,
  keywords = "To Read;BCI",
  language = "en",
  doi      = "10.1101/2022.12.08.519453"
}

@UNPUBLISHED{OShea2022-kp,
  title    = "Direct neural perturbations reveal a dynamical mechanism for
              robust computation",
  author   = "O'Shea, Daniel J and Duncker, Lea and Goo, Werapong and Sun, Xulu
              and Vyas, Saurabh and Trautmann, Eric M and Diester, Ilka and
              Ramakrishnan, Charu and Deisseroth, Karl and Sahani, Maneesh and
              Shenoy, Krishna V",
  abstract = "The rich repertoire of skilled mammalian behavior is the product
              of neural circuits that generate robust and flexible patterns of
              activity distributed across populations of neurons. Decades of
              associative studies have linked many behaviors to specific
              patterns of population activity, but association alone cannot
              reveal the dynamical mechanisms that shape those patterns. Are
              local neural circuits high- dimensional dynamical reservoirs able
              to generate arbitrary superpositions of patterns with appropriate
              excitation? Or might circuit dynamics be shaped in response to
              behavioral context so as to generate only the low-dimensional
              patterns needed for the task at hand? Here, we address these
              questions within primate motor cortex by delivering optogenetic
              and electrical microstimulation perturbations during reaching
              behavior. We develop a novel analytic approach that relates
              measured activity to theoretically tractable, dynamical models of
              excitatory and inhibitory neurons. This computational model
              captures the dynamical effects of these perturbations and
              demonstrates that motor cortical activity during reaching is
              shaped by a self-contained, low-dimensional dynamical system. The
              subspace containing task-relevant dynamics proves to be oriented
              so as to be robust to strong non-normal amplification within
              cortical circuits. This task dynamics space exhibits a privileged
              causal relationship with behavior, in that stimulation in motor
              cortex perturb reach kinematics only to the extent that it alters
              neural states within this subspace. Our results resolve
              long-standing questions about the dynamical structure of cortical
              activity associated with movement, and illuminate the dynamical
              perturbation experiments needed to understand how neural circuits
              throughout the brain generate complex behavior. \#\#\# Competing
              Interest Statement Prof. Shenoy serves on the Scientific Advisory
              Boards (SABs) of MIND-X Inc. (acquired by Blackrock Neurotech,
              Spring 2022), Inscopix Inc. (acquired by Bruker Nano, Fall 2022)
              and Heal Inc. He also serves as a consultant / advisor (and was
              on founding SAB) for CTRL-Labs (acquired by Facebook Reality Labs
              in Fall 2019, and is now a part of Meta Platform's Reality Labs)
              and serves as a consultant / advisor (and is a co-founder, 2016)
              for Neuralink.",
  journal  = "bioRxiv",
  pages    = "2022.12.16.520768",
  month    =  dec,
  year     =  2022,
  keywords = "To Read;BCI",
  language = "en",
  doi      = "10.1101/2022.12.16.520768"
}

@ARTICLE{Lemos2022-ck,
  title         = "Rediscovering orbital mechanics with machine learning",
  author        = "Lemos, Pablo and Jeffrey, Niall and Cranmer, Miles and Ho,
                   Shirley and Battaglia, Peter",
  abstract      = "We present an approach for using machine learning to
                   automatically discover the governing equations and hidden
                   properties of real physical systems from observations. We
                   train a ``graph neural network'' to simulate the dynamics of
                   our solar system's Sun, planets, and large moons from 30
                   years of trajectory data. We then use symbolic regression to
                   discover an analytical expression for the force law
                   implicitly learned by the neural network, which our results
                   showed is equivalent to Newton's law of gravitation. The key
                   assumptions that were required were translational and
                   rotational equivariance, and Newton's second and third laws
                   of motion. Our approach correctly discovered the form of the
                   symbolic force law. Furthermore, our approach did not
                   require any assumptions about the masses of planets and
                   moons or physical constants. They, too, were accurately
                   inferred through our methods. Though, of course, the
                   classical law of gravitation has been known since Isaac
                   Newton, our result serves as a validation that our method
                   can discover unknown laws and hidden properties from
                   observed data. More broadly this work represents a key step
                   toward realizing the potential of machine learning for
                   accelerating scientific discovery.",
  month         =  feb,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2202.02306",
  primaryClass  = "astro-ph.EP",
  arxivid       = "2202.02306"
}

@ARTICLE{Daigavane2022-ah,
  title         = "Learning Integrable Dynamics with {Action-Angle} Networks",
  author        = "Daigavane, Ameya and Kosmala, Arthur and Cranmer, Miles and
                   Smidt, Tess and Ho, Shirley",
  abstract      = "Machine learning has become increasingly popular for
                   efficiently modelling the dynamics of complex physical
                   systems, demonstrating a capability to learn effective
                   models for dynamics which ignore redundant degrees of
                   freedom. Learned simulators typically predict the evolution
                   of the system in a step-by-step manner with numerical
                   integration techniques. However, such models often suffer
                   from instability over long roll-outs due to the accumulation
                   of both estimation and integration error at each prediction
                   step. Here, we propose an alternative construction for
                   learned physical simulators that are inspired by the concept
                   of action-angle coordinates from classical mechanics for
                   describing integrable systems. We propose Action-Angle
                   Networks, which learn a nonlinear transformation from input
                   coordinates to the action-angle space, where evolution of
                   the system is linear. Unlike traditional learned simulators,
                   Action-Angle Networks do not employ any higher-order
                   numerical integration methods, making them extremely
                   efficient at modelling the dynamics of integrable physical
                   systems.",
  month         =  nov,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2211.15338",
  primaryClass  = "cs.LG",
  arxivid       = "2211.15338"
}

@ARTICLE{Acosta2022-ip,
  title         = "Quantifying Local Extrinsic Curvature in Neural Manifolds",
  author        = "Acosta, Francisco E and Sanborn, Sophia and Duc, Khanh Dao
                   and Madhav, Manu and Miolane, Nina",
  abstract      = "The neural manifold hypothesis postulates that the activity
                   of a neural population forms a low-dimensional manifold
                   within the larger neural state space, whose structure
                   reflects the structure of the encoded task variables. Many
                   dimensionality reduction techniques have been used to study
                   the structure of neural manifolds, but these methods do not
                   provide an explicit parameterization of the manifold, and
                   fail to capture the global structure of topologically
                   nontrivial manifolds. Topological data analysis methods can
                   reveal the shared topological structure between neural
                   manifolds and the task variables they represent, but fail to
                   capture much of the geometric information including
                   distance, angles, and curvature. In this work, we leverage
                   tools from Riemannian geometry and topologically-aware deep
                   generative models to introduce a novel approach for studying
                   the geometry of neural manifolds. This approach (1) computes
                   an explicit parameterization of the manifolds and (2)
                   estimates their local extrinsic curvature. Our approach
                   correctly estimates the geometry of synthetic neural
                   manifolds generated from smooth deformations of circles,
                   spheres, and tori. We expect this approach to open new
                   avenues of inquiry exploring geometric neural correlates of
                   perception and behavior, and provide a new means to compare
                   representations in biological and artificial neural systems.",
  month         =  dec,
  year          =  2022,
  archivePrefix = "arXiv",
  eprint        = "2212.10414",
  primaryClass  = "q-bio.NC",
  arxivid       = "2212.10414"
}

@ARTICLE{Conklin2005-ge,
  title    = "A controlled attractor network model of path integration in the
              rat",
  author   = "Conklin, John and Eliasmith, Chris",
  abstract = "Cells in several areas of the hippocampal formation show place
              specific firing patterns, and are thought to form a distributed
              representation of an animal's current location in an environment.
              Experimental results suggest that this representation is
              continually updated even in complete darkness, indicating the
              presence of a path integration mechanism in the rat. Adopting the
              Neural Engineering Framework (NEF) presented by Eliasmith and
              Anderson (2003) we derive a novel attractor network model of path
              integration, using heterogeneous spiking neurons. The network we
              derive incorporates representation and updating of position into
              a single layer of neurons, eliminating the need for a large
              external control population, and without making use of
              multiplicative synapses. An efficient and biologically plausible
              control mechanism results directly from applying the principles
              of the NEF. We simulate the network for a variety of inputs,
              analyze its performance, and give three testable predictions of
              our model.",
  journal  = "J. Comput. Neurosci.",
  volume   =  18,
  number   =  2,
  pages    = "183--203",
  year     =  2005,
  language = "en",
  issn     = "0929-5313",
  pmid     = "15714269",
  doi      = "10.1007/s10827-005-6558-z"
}

@ARTICLE{Claudi2022-xs,
  title     = "Differential Geometry Methods for Constructing
               {Manifold-Targeted} Recurrent Neural Networks",
  author    = "Claudi, Federico and Branco, Tiago",
  abstract  = "Neural computations can be framed as dynamical processes,
               whereby the structure of the dynamics within a neural network is
               a direct reflection of the computations that the network
               performs. A key step in generating mechanistic interpretations
               within this computation through dynamics framework is to
               establish the link among network connectivity, dynamics, and
               computation. This link is only partly understood. Recent work
               has focused on producing algorithms for engineering artificial
               recurrent neural networks (RNN) with dynamics targeted to a
               specific goal manifold. Some of these algorithms require only a
               set of vectors tangent to the target manifold to be computed and
               thus provide a general method that can be applied to a diverse
               set of problems. Nevertheless, computing such vectors for an
               arbitrary manifold in a high-dimensional state space remains
               highly challenging, which in practice limits the applicability
               of this approach. Here we demonstrate how topology and
               differential geometry can be leveraged to simplify this task by
               first computing tangent vectors on a low-dimensional topological
               manifold and then embedding these in state space. The simplicity
               of this procedure greatly facilitates the creation of
               manifold-targeted RNNs, as well as the process of designing
               task-solving, on-manifold dynamics. This new method should
               enable the application of network engineering-based approaches
               to a wide set of problems in neuroscience and machine learning.
               Our description of how fundamental concepts from differential
               geometry can be mapped onto different aspects of neural dynamics
               is a further demonstration of how the language of differential
               geometry can enrich the conceptual framework for describing
               neural dynamics and computation.",
  journal   = "Neural Comput.",
  publisher = "direct.mit.edu",
  volume    =  34,
  number    =  8,
  pages     = "1790--1811",
  month     =  jul,
  year      =  2022,
  language  = "en",
  issn      = "0899-7667, 1530-888X",
  pmid      = "35798324",
  doi       = "10.1162/neco\_a\_01511"
}

@ARTICLE{Machens2008-df,
  title    = "Design of continuous attractor networks with monotonic tuning
              using a symmetry principle",
  author   = "Machens, Christian K and Brody, Carlos D",
  abstract = "Neurons that sustain elevated firing in the absence of stimuli
              have been found in many neural systems. In graded persistent
              activity, neurons can sustain firing at many levels, suggesting a
              widely found type of network dynamics in which networks can relax
              to any one of a continuum of stationary states. The reproduction
              of these findings in model networks of nonlinear neurons has
              turned out to be nontrivial. A particularly insightful model has
              been the ``bump attractor,'' in which a continuous attractor
              emerges through an underlying symmetry in the network
              connectivity matrix. This model, however, cannot account for data
              in which the persistent firing of neurons is a monotonic --
              rather than a bell-shaped -- function of a stored variable. Here,
              we show that the symmetry used in the bump attractor network can
              be employed to create a whole family of continuous attractor
              networks, including those with monotonic tuning. Our design is
              based on tuning the external inputs to networks that have a
              connectivity matrix with Toeplitz symmetry. In particular, we
              provide a complete analytical solution of a line attractor
              network with monotonic tuning and show that for many other
              networks, the numerical tuning of synaptic weights reduces to the
              computation of a single parameter.",
  journal  = "Neural Comput.",
  volume   =  20,
  number   =  2,
  pages    = "452--485",
  month    =  feb,
  year     =  2008,
  language = "en",
  issn     = "0899-7667",
  pmid     = "18047414",
  doi      = "10.1162/neco.2007.07-06-297"
}

@ARTICLE{Kang2019-oi,
  title    = "A geometric attractor mechanism for self-organization of
              entorhinal grid modules",
  author   = "Kang, Louis and Balasubramanian, Vijay",
  abstract = "Grid cells in the medial entorhinal cortex (MEC) respond when an
              animal occupies a periodic lattice of 'grid fields' in the
              environment. The grids are organized in modules with spatial
              periods, or scales, clustered around discrete values separated on
              average by ratios in the range 1.4-1.7. We propose a mechanism
              that produces this modular structure through dynamical
              self-organization in the MEC. In attractor network models of grid
              formation, the grid scale of a single module is set by the
              distance of recurrent inhibition between neurons. We show that
              the MEC forms a hierarchy of discrete modules if a smooth
              increase in inhibition distance along its dorso-ventral axis is
              accompanied by excitatory interactions along this axis. Moreover,
              constant scale ratios between successive modules arise through
              geometric relationships between triangular grids and have values
              that fall within the observed range. We discuss how interactions
              required by our model might be tested experimentally.",
  journal  = "Elife",
  volume   =  8,
  month    =  aug,
  year     =  2019,
  keywords = "continuous attractor; entorhinal cortex; geometry; grid cell;
              grid module; neuroscience; none; physics of living systems;
              self-organization;to\_read\_for\_review",
  language = "en",
  issn     = "2050-084X",
  pmid     = "31373556",
  doi      = "10.7554/eLife.46687",
  pmc      = "PMC6776444"
}

@ARTICLE{Ebitz2021-bd,
  title    = "The population doctrine in cognitive neuroscience",
  author   = "Ebitz, R Becket and Hayden, Benjamin Y",
  abstract = "A major shift is happening within neurophysiology: a population
              doctrine is drawing level with the single-neuron doctrine that
              has long dominated the field. Population-level ideas have so far
              had their greatest impact in motor neuroscience, but they hold
              great promise for resolving open questions in cognition as well.
              Here, we codify the population doctrine and survey recent work
              that leverages this view to specifically probe cognition. Our
              discussion is organized around five core concepts that provide a
              foundation for population-level thinking: (1) state spaces, (2)
              manifolds, (3) coding dimensions, (4) subspaces, and (5)
              dynamics. The work we review illustrates the progress and promise
              that population-level thinking holds for cognitive
              neuroscience-for delivering new insight into attention, working
              memory, decision-making, executive function, learning, and reward
              processing.",
  journal  = "Neuron",
  volume   =  109,
  number   =  19,
  pages    = "3055--3068",
  month    =  oct,
  year     =  2021,
  keywords = "to\_read\_for\_review",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "34416170",
  doi      = "10.1016/j.neuron.2021.07.011",
  pmc      = "PMC8725976"
}

@ARTICLE{Yuste2015-qb,
  title    = "From the neuron doctrine to neural networks",
  author   = "Yuste, Rafael",
  abstract = "For over a century, the neuron doctrine--which states that the
              neuron is the structural and functional unit of the nervous
              system--has provided a conceptual foundation for neuroscience.
              This viewpoint reflects its origins in a time when the use of
              single-neuron anatomical and physiological techniques was
              prominent. However, newer multineuronal recording methods have
              revealed that ensembles of neurons, rather than individual cells,
              can form physiological units and generate emergent functional
              properties and states. As a new paradigm for neuroscience, neural
              network models have the potential to incorporate knowledge
              acquired with single-neuron approaches to help us understand how
              emergent functional states generate behaviour, cognition and
              mental disease.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  16,
  number   =  8,
  pages    = "487--497",
  month    =  aug,
  year     =  2015,
  keywords = "to\_read\_for\_review",
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "26152865",
  doi      = "10.1038/nrn3962"
}

@ARTICLE{Cranmer2020-bs,
  title         = "Discovering Symbolic Models from Deep Learning with
                   Inductive Biases",
  author        = "Cranmer, Miles and Sanchez-Gonzalez, Alvaro and Battaglia,
                   Peter and Xu, Rui and Cranmer, Kyle and Spergel, David and
                   Ho, Shirley",
  abstract      = "We develop a general approach to distill symbolic
                   representations of a learned deep model by introducing
                   strong inductive biases. We focus on Graph Neural Networks
                   (GNNs). The technique works as follows: we first encourage
                   sparse latent representations when we train a GNN in a
                   supervised setting, then we apply symbolic regression to
                   components of the learned model to extract explicit physical
                   relations. We find the correct known equations, including
                   force laws and Hamiltonians, can be extracted from the
                   neural network. We then apply our method to a non-trivial
                   cosmology example-a detailed dark matter simulation-and
                   discover a new analytic formula which can predict the
                   concentration of dark matter from the mass distribution of
                   nearby cosmic structures. The symbolic expressions extracted
                   from the GNN using our technique also generalized to
                   out-of-distribution data better than the GNN itself. Our
                   approach offers alternative directions for interpreting
                   neural networks and discovering novel physical principles
                   from the representations they learn.",
  month         =  jun,
  year          =  2020,
  archivePrefix = "arXiv",
  eprint        = "2006.11287",
  primaryClass  = "cs.LG",
  arxivid       = "2006.11287"
}

@ARTICLE{Landau2018-xf,
  title     = "Coherent chaos in a recurrent neural network with structured
               connectivity",
  author    = "Landau, Itamar Daniel and Sompolinsky, Haim",
  abstract  = "We present a simple model for coherent, spatially correlated
               chaos in a recurrent neural network. Networks of randomly
               connected neurons exhibit chaotic fluctuations and have been
               studied as a model for capturing the temporal variability of
               cortical activity. The dynamics generated by such networks,
               however, are spatially uncorrelated and do not generate coherent
               fluctuations, which are commonly observed across spatial scales
               of the neocortex. In our model we introduce a structured
               component of connectivity, in addition to random connections,
               which effectively embeds a feedforward structure via
               unidirectional coupling between a pair of orthogonal modes.
               Local fluctuations driven by the random connectivity are summed
               by an output mode and drive coherent activity along an input
               mode. The orthogonality between input and output mode preserves
               chaotic fluctuations by preventing feedback loops. In the regime
               of weak structured connectivity we apply a perturbative approach
               to solve the dynamic mean-field equations, showing that in this
               regime coherent fluctuations are driven passively by the chaos
               of local residual fluctuations. When we introduce a row balance
               constraint on the random connectivity, stronger structured
               connectivity puts the network in a distinct dynamical regime of
               self-tuned coherent chaos. In this regime the coherent component
               of the dynamics self-adjusts intermittently to yield periods of
               slow, highly coherent chaos. The dynamics display longer
               time-scales and switching-like activity. We show how in this
               regime the dynamics depend qualitatively on the particular
               realization of the connectivity matrix: a complex leading
               eigenvalue can yield coherent oscillatory chaos while a real
               leading eigenvalue can yield chaos with broken symmetry. The
               level of coherence grows with increasing strength of structured
               connectivity until the dynamics are almost entirely constrained
               to a single spatial mode. We examine the effects of network-size
               scaling and show that these results are not finite-size effects.
               Finally, we show that in the regime of weak structured
               connectivity, coherent chaos emerges also for a generalized
               structured connectivity with multiple input-output modes.",
  journal   = "PLoS Comput. Biol.",
  publisher = "journals.plos.org",
  volume    =  14,
  number    =  12,
  pages     = "e1006309",
  month     =  dec,
  year      =  2018,
  language  = "en",
  issn      = "1553-734X, 1553-7358",
  pmid      = "30543634",
  doi       = "10.1371/journal.pcbi.1006309",
  pmc       = "PMC6307850"
}

@ARTICLE{Herbert2022-vz,
  title    = "The impact of sparsity in low-rank recurrent neural networks",
  author   = "Herbert, Elizabeth and Ostojic, Srdjan",
  abstract = "Neural population dynamics are often highly coordinated, allowing
              task-related computations to be understood as neural trajectories
              through low-dimensional subspaces. How the network connectivity
              and input structure give rise to such activity can be
              investigated with the aid of low-rank recurrent neural networks,
              a recently-developed class of computational models which offer a
              rich theoretical framework linking the underlying connectivity
              structure to emergent low-dimensional dynamics. This framework
              has so far relied on the assumption of all-to-all connectivity,
              yet cortical networks are known to be highly sparse. Here we
              investigate the dynamics of low-rank recurrent networks in which
              the connections are randomly sparsified, which makes the network
              connectivity formally full-rank. We first analyse the impact of
              sparsity on the eigenvalue spectrum of low-rank connectivity
              matrices, and use this to examine the implications for the
              dynamics. We find that in the presence of sparsity, the
              eigenspectra in the complex plane consist of a continuous bulk
              and isolated outliers, a form analogous to the eigenspectra of
              connectivity matrices composed of a low-rank and a full-rank
              random component. This analogy allows us to characterise distinct
              dynamical regimes of the sparsified low-rank network as a
              function of key network parameters. Altogether, we find that the
              low-dimensional dynamics induced by low-rank connectivity
              structure are preserved even at high levels of sparsity, and can
              therefore support rich and robust computations even in networks
              sparsified to a biologically-realistic extent.",
  journal  = "PLoS Comput. Biol.",
  volume   =  18,
  number   =  8,
  pages    = "e1010426",
  month    =  aug,
  year     =  2022,
  keywords = "To Read;BCI",
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "35944030",
  doi      = "10.1371/journal.pcbi.1010426",
  pmc      = "PMC9390915"
}

@ARTICLE{Valente2022-xu,
  title    = "Probing the Relationship Between Latent Linear Dynamical Systems
              and {Low-Rank} Recurrent Neural Network Models",
  author   = "Valente, Adrian and Ostojic, Srdjan and Pillow, Jonathan W",
  abstract = "A large body of work has suggested that neural populations
              exhibit low-dimensional dynamics during behavior. However, there
              are a variety of different approaches for modeling
              low-dimensional neural population activity. One approach involves
              latent linear dynamical system (LDS) models, in which population
              activity is described by a projection of low-dimensional latent
              variables with linear dynamics. A second approach involves
              low-rank recurrent neural networks (RNNs), in which population
              activity arises directly from a low-dimensional projection of
              past activity. Although these two modeling approaches have strong
              similarities, they arise in different contexts and tend to have
              different domains of application. Here we examine the precise
              relationship between latent LDS models and linear low-rank RNNs.
              When can one model class be converted to the other, and vice
              versa? We show that latent LDS models can only be converted to
              RNNs in specific limit cases, due to the non-Markovian property
              of latent LDS models. Conversely, we show that linear RNNs can be
              mapped onto LDS models, with latent dimensionality at most twice
              the rank of the RNN. A surprising consequence of our results is
              that a partially observed RNN is better represented by an LDS
              model than by an RNN consisting of only observed units.",
  journal  = "Neural Comput.",
  volume   =  34,
  number   =  9,
  pages    = "1871--1892",
  month    =  aug,
  year     =  2022,
  keywords = "To Read;BCI",
  language = "en",
  issn     = "0899-7667, 1530-888X",
  pmid     = "35896161",
  doi      = "10.1162/neco\_a\_01522"
}

@ARTICLE{Ben-Yishai1995-ex,
  title    = "Theory of orientation tuning in visual cortex",
  author   = "Ben-Yishai, R and Bar-Or, R L and Sompolinsky, H",
  abstract = "The role of intrinsic cortical connections in processing sensory
              input and in generating behavioral output is poorly understood.
              We have examined this issue in the context of the tuning of
              neuronal responses in cortex to the orientation of a visual
              stimulus. We analytically study a simple network model that
              incorporates both orientation-selective input from the lateral
              geniculate nucleus and orientation-specific cortical
              interactions. Depending on the model parameters, the network
              exhibits orientation selectivity that originates from within the
              cortex, by a symmetry-breaking mechanism. In this case, the width
              of the orientation tuning can be sharp even if the lateral
              geniculate nucleus inputs are only weakly anisotropic. By using
              our model, several experimental consequences of this cortical
              mechanism of orientation tuning are derived. The tuning width is
              relatively independent of the contrast and angular anisotropy of
              the visual stimulus. The transient population response to
              changing of the stimulus orientation exhibits a slow ``virtual
              rotation.'' Neuronal cross-correlations exhibit long time tails,
              the sign of which depends on the preferred orientations of the
              cells and the stimulus orientation.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  92,
  number   =  9,
  pages    = "3844--3848",
  month    =  apr,
  year     =  1995,
  language = "en",
  issn     = "0027-8424",
  pmid     = "7731993",
  doi      = "10.1073/pnas.92.9.3844",
  pmc      = "PMC42058"
}

@ARTICLE{Hopfield1982-ov,
  title    = "Neural networks and physical systems with emergent collective
              computational abilities",
  author   = "Hopfield, J J",
  abstract = "Computational properties of use of biological organisms or to the
              construction of computers can emerge as collective properties of
              systems having a large number of simple equivalent components (or
              neurons). The physical meaning of content-addressable memory is
              described by an appropriate phase space flow of the state of a
              system. A model of such a system is given, based on aspects of
              neurobiology but readily adapted to integrated circuits. The
              collective properties of this model produce a content-addressable
              memory which correctly yields an entire memory from any subpart
              of sufficient size. The algorithm for the time evolution of the
              state of the system is based on asynchronous parallel processing.
              Additional emergent collective properties include some capacity
              for generalization, familiarity recognition, categorization,
              error correction, and time sequence retention. The collective
              properties are only weakly sensitive to details of the modeling
              or the failure of individual devices.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  79,
  number   =  8,
  pages    = "2554--2558",
  month    =  apr,
  year     =  1982,
  language = "en",
  issn     = "0027-8424",
  pmid     = "6953413",
  doi      = "10.1073/pnas.79.8.2554",
  pmc      = "PMC346238"
}

@INPROCEEDINGS{Stockel2020-bd,
  title     = "A Biologically Plausible Spiking Neural Model of Eyeblink
               Conditioning in the Cerebellum",
  booktitle = "{CogSci}",
  author    = "St{\"o}ckel, Andreas and Stewart, Terrence C and Eliasmith,
               Chris",
  year      =  2020,
  keywords  = "To Read;BCI"
}

@MISC{Dumont_undated-kz,
  title        = "Accurate representation for spatial cognition using grid
                  cells",
  author       = "Dumont, Nicole Sandra-Yaffa and Eliasmith, Chris",
  howpublished = "\url{https://www.cognitivesciencesociety.org/cogsci20/papers/0562/0562.pdf}",
  note         = "Accessed: 2023-1-11",
  keywords     = "To Read;BCI"
}

@ARTICLE{Sompolinsky1988-tl,
  title     = "Chaos in random neural networks",
  author    = "Sompolinsky, H and Crisanti, A and Sommers, H J",
  abstract  = "A continuous-time dynamic model of a network of N nonlinear
               elements interacting via random asymmetric couplings is studied.
               A self-consistent mean-field theory, exact in the
               N$\rightarrow$$\infty$ limit, predicts a transition from a
               stationary phase to a chaotic phase occurring at a critical
               value of the gain parameter. The autocorrelations of the chaotic
               flow as well as the maximal Lyapunov exponent are calculated.",
  journal   = "Phys. Rev. Lett.",
  publisher = "APS",
  volume    =  61,
  number    =  3,
  pages     = "259--262",
  month     =  jul,
  year      =  1988,
  language  = "en",
  issn      = "0031-9007, 1079-7114",
  pmid      = "10039285",
  doi       = "10.1103/PhysRevLett.61.259"
}

@ARTICLE{Beiran2021-qz,
  title    = "Shaping Dynamics With Multiple Populations in {Low-Rank}
              Recurrent Networks",
  author   = "Beiran, Manuel and Dubreuil, Alexis and Valente, Adrian and
              Mastrogiuseppe, Francesca and Ostojic, Srdjan",
  abstract = "An emerging paradigm proposes that neural computations can be
              understood at the level of dynamic systems that govern
              low-dimensional trajectories of collective neural activity. How
              the connectivity structure of a network determines the emergent
              dynamical system, however, remains to be clarified. Here we
              consider a novel class of models, gaussian-mixture, low-rank
              recurrent networks in which the rank of the connectivity matrix
              and the number of statistically defined populations are
              independent hyperparameters. We show that the resulting
              collective dynamics form a dynamical system, where the rank sets
              the dimensionality and the population structure shapes the
              dynamics. In particular, the collective dynamics can be described
              in terms of a simplified effective circuit of interacting latent
              variables. While having a single global population strongly
              restricts the possible dynamics, we demonstrate that if the
              number of populations is large enough, a rank R network can
              approximate any R-dimensional dynamical system.",
  journal  = "Neural Comput.",
  volume   =  33,
  number   =  6,
  pages    = "1572--1615",
  month    =  may,
  year     =  2021,
  keywords = "To Read;BCI",
  language = "en",
  issn     = "0899-7667, 1530-888X",
  pmid     = "34496384",
  doi      = "10.1162/neco\_a\_01381"
}

@ARTICLE{Ahmadian2015-qb,
  title    = "Properties of networks with partially structured and partially
              random connectivity",
  author   = "Ahmadian, Yashar and Fumarola, Francesco and Miller, Kenneth D",
  abstract = "Networks studied in many disciplines, including neuroscience and
              mathematical biology, have connectivity that may be stochastic
              about some underlying mean connectivity represented by a
              non-normal matrix. Furthermore, the stochasticity may not be
              independent and identically distributed (iid) across elements of
              the connectivity matrix. More generally, the problem of
              understanding the behavior of stochastic matrices with nontrivial
              mean structure and correlations arises in many settings. We
              address this by characterizing large random N$\times$N matrices
              of the form A=M+LJR, where M,L, and R are arbitrary deterministic
              matrices and J is a random matrix of zero-mean iid elements. M
              can be non-normal, and L and R allow correlations that have
              separable dependence on row and column indices. We first provide
              a general formula for the eigenvalue density of A. For A
              non-normal, the eigenvalues do not suffice to specify the
              dynamics induced by A, so we also provide general formulas for
              the transient evolution of the magnitude of activity and
              frequency power spectrum in an N-dimensional linear dynamical
              system with a coupling matrix given by A. These quantities can
              also be thought of as characterizing the stability and the
              magnitude of the linear response of a nonlinear network to small
              perturbations about a fixed point. We derive these formulas and
              work them out analytically for some examples of M,L, and R
              motivated by neurobiological models. We also argue that the
              persistence as N$\rightarrow$$\infty$ of a finite number of
              randomly distributed outlying eigenvalues outside the support of
              the eigenvalue density of A, as previously observed, arises in
              regions of the complex plane $\Omega$ where there are nonzero
              singular values of L(-1)(z1-M)R(-1) (for z$\in$$\Omega$) that
              vanish as N$\rightarrow$$\infty$. When such singular values do
              not exist and L and R are equal to the identity, there is a
              correspondence in the normalized Frobenius norm (but not in the
              operator norm) between the support of the spectrum of A for J of
              norm $\sigma$ and the $\sigma$ pseudospectrum of M.",
  journal  = "Phys. Rev. E Stat. Nonlin. Soft Matter Phys.",
  volume   =  91,
  number   =  1,
  pages    = "012820",
  month    =  jan,
  year     =  2015,
  keywords = "To Read;BCI",
  language = "en",
  issn     = "1539-3755, 1550-2376",
  pmid     = "25679669",
  doi      = "10.1103/PhysRevE.91.012820",
  pmc      = "PMC4745946"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Redish1996-ew,
  title     = "A coupled attractor model of the rodent head direction system",
  author    = "Redish, A and Elga, Adam and Touretzky, David",
  abstract  = "Head direction (HD) cells, abundant in the rat postsubiculum and
               anterior thalamic nuclei, fire maximally when the rat's head is
               facing a particular direction. The activity of a population of
               these cells forms a distributed representation of the animal's
               current heading. We describe a neural network model that creates
               a stable, distributed representation of head direction and
               updates that representation in response to angular velocity
               information. In contrast to earlier models, our model of the
               head direction system accurately tracks a series of actual rat …",
  journal   = "Network",
  publisher = "Informa UK Limited",
  volume    =  7,
  number    =  4,
  pages     = "671--685",
  month     =  nov,
  year      =  1996,
  keywords  = "To Read;BCI",
  issn      = "0093-3341",
  doi       = "10.1088/0954-898x/7/4/004"
}

@ARTICLE{Burak2012-jc,
  title    = "Fundamental limits on persistent activity in networks of noisy
              neurons",
  author   = "Burak, Yoram and Fiete, Ila R",
  abstract = "Neural noise limits the fidelity of representations in the brain.
              This limitation has been extensively analyzed for sensory coding.
              However, in short-term memory and integrator networks, where
              noise accumulates and can play an even more prominent role, much
              less is known about how neural noise interacts with neural and
              network parameters to determine the accuracy of the computation.
              Here we analytically derive how the stored memory in continuous
              attractor networks of probabilistically spiking neurons will
              degrade over time through diffusion. By combining statistical and
              dynamical approaches, we establish a fundamental limit on the
              network's ability to maintain a persistent state: The
              noise-induced drift of the memory state over time within the
              network is strictly lower-bounded by the accuracy of estimation
              of the network's instantaneous memory state by an ideal external
              observer. This result takes the form of an information-diffusion
              inequality. We derive some unexpected consequences: Despite the
              persistence time of short-term memory networks, it does not pay
              to accumulate spikes for longer than the cellular time-constant
              to read out their contents. For certain neural transfer
              functions, the conditions for optimal sensory coding coincide
              with those for optimal storage, implying that short-term memory
              may be co-localized with sensory representation.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  109,
  number   =  43,
  pages    = "17645--17650",
  month    =  oct,
  year     =  2012,
  keywords = "To Read;BCI",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "23047704",
  doi      = "10.1073/pnas.1117386109",
  pmc      = "PMC3491496"
}

@ARTICLE{Gallego2020-ee,
  title     = "Long-term stability of cortical population dynamics underlying
               consistent behavior",
  author    = "Gallego, Juan A and Perich, Matthew G and Chowdhury, Raeed H and
               Solla, Sara A and Miller, Lee E",
  abstract  = "Animals readily execute learned behaviors in a consistent manner
               over long periods of time, and yet no equally stable neural
               correlate has been demonstrated. How does the cortex achieve
               this stable control? Using the sensorimotor system as a model of
               cortical processing, we investigated the hypothesis that the
               dynamics of neural latent activity, which captures the dominant
               co-variation patterns within the neural population, must be
               preserved across time. We recorded from populations of neurons
               in premotor, primary motor and somatosensory cortices as monkeys
               performed a reaching task, for up to 2 years. Intriguingly,
               despite a steady turnover in the recorded neurons, the
               low-dimensional latent dynamics remained stable. The stability
               allowed reliable decoding of behavioral features for the entire
               timespan, while fixed decoders based directly on the recorded
               neural activity degraded substantially. We posit that stable
               latent cortical dynamics within the manifold are the fundamental
               building blocks underlying consistent behavioral execution.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  23,
  number    =  2,
  pages     = "260--270",
  month     =  feb,
  year      =  2020,
  keywords  = "To Read;BCI",
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "31907438",
  doi       = "10.1038/s41593-019-0555-4",
  pmc       = "PMC7007364"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Gallego2018-dp,
  title     = "Cortical population activity within a preserved neural manifold
               underlies multiple motor behaviors",
  author    = "Gallego, Juan A and Perich, Matthew G and Naufel, Stephanie N
               and Ethier, Christian and Solla, Sara A and Miller, Lee E",
  abstract  = "Populations of cortical neurons flexibly perform different
               functions; for the primary motor cortex (M1) this means a rich
               repertoire of motor behaviors. We investigate the flexibility of
               M1 …",
  journal   = "Nat. Commun.",
  publisher = "Nature Publishing Group",
  volume    =  9,
  number    =  1,
  pages     = "1--13",
  year      =  2018,
  keywords  = "To Read;BCI"
}

@UNPUBLISHED{Safaie2022-og,
  title    = "Preserved neural population dynamics across animals performing
              similar behaviour",
  author   = "Safaie, Mostafa and Chang, Joanna C and Park, Junchol and Miller,
              Lee E and Dudman, Joshua T and Perich, Matthew G and Gallego,
              Juan A",
  abstract = "Animals of the same species often exhibit similar behaviours that
              are advantageously adapted to their body and their environment.
              These behaviours are shaped by selection pressures over
              evolutionary timescales at the species level, yet each individual
              produces these behaviours using a different, uniquely constructed
              brain. It remains unclear how these common behavioural
              adaptations emerge from the idiosyncratic neural circuitry of a
              given individual. Here, we hypothesised that the adaptive
              behaviour of a species requires specific neural population
              `latent dynamics'. These latent dynamics should thus be preserved
              and identifiable across individuals within a species, regardless
              of the idiosyncratic aspects of each individual's brain. Using
              recordings of neural populations from monkey and mouse motor
              cortex, we show that individuals from the same species share
              surprisingly similar neural dynamics when they perform the same
              behaviour. The similarity in neural population dynamics extends
              beyond cortical regions to the dorsal striatum, an evolutionarily
              older structure, and also holds when animals con-sciously plan
              future movements without overt behaviour. These preserved
              dynamics are behaviourally-relevant, allowing decoding of
              intended and ongoing movements across individuals. We posit that
              these emergent neural population dynamics result from
              evolutionarily-imposed constraints on brain development, and
              reflect a fundamental property of the neural basis of behaviour.
              \#\#\# Competing Interest Statement J.A.G. receives funding from
              Meta Platform Technologies, LLC.",
  journal  = "bioRxiv",
  pages    = "2022.09.26.509498",
  month    =  sep,
  year     =  2022,
  keywords = "To Read;BCI",
  language = "en",
  doi      = "10.1101/2022.09.26.509498"
}

@ARTICLE{Lopez1997-av,
  title     = "Complete nonorientable minimal surfaces with the highest
               symmetry group",
  author    = "L{\'o}pez, Francisco J and Mart{\'\i}n, Francisco",
  abstract  = "ARRAY(0x5579b99e60e8)",
  journal   = "Amer. J. Math.",
  publisher = "Johns Hopkins University Press",
  volume    =  119,
  number    =  1,
  pages     = "55--81",
  year      =  1997,
  keywords  = "To Read;BCI",
  issn      = "0002-9327, 1080-6377",
  doi       = "10.1353/ajm.1997.0004"
}

@UNPUBLISHED{Ye2021-di,
  title    = "Representation learning for neural population activity with
              Neural Data Transformers",
  author   = "Ye, Joel and Pandarinath, Chethan",
  abstract = "Neural population activity is theorized to reflect an underlying
              dynamical structure. This structure can be accurately captured
              using state space models with explicit dynamics, such as those
              based on recurrent neural networks (RNNs). However, using
              recurrence to explicitly model dynamics necessitates sequential
              processing of data, slowing real-time applications such as
              brain-computer interfaces. Here we introduce the Neural Data
              Transformer (NDT), a non-recurrent alternative. We test the NDT's
              ability to capture autonomous dynamical systems by applying it to
              synthetic datasets with known dynamics and data from monkey motor
              cortex during a reaching task well-modeled by RNNs. The NDT
              models these datasets as well as state-of-the-art recurrent
              models. Further, its non-recurrence enables 3.9ms inference, well
              within the loop time of real-time applications and more than 6
              times faster than recurrent baselines on the monkey reaching
              dataset. These results suggest that an explicit dynamics model is
              not necessary to model autonomous neural population dynamics.
              Code [github.com/snel-repo/neural-data-transformers][1] . \#\#\#
              Competing Interest Statement The authors have declared no
              competing interest. [1]:
              http://github.com/snel-repo/neural-data-transformers",
  journal  = "bioRxiv",
  pages    = "2021.01.16.426955",
  month    =  jul,
  year     =  2021,
  keywords = "To Read;BCI",
  language = "en",
  doi      = "10.1101/2021.01.16.426955"
}

@ARTICLE{Wen2021-zs,
  title    = "Rapid adaptation of brain-computer interfaces to new neuronal
              ensembles or participants via generative modelling",
  author   = "Wen, Shixian and Yin, Allen and Furlanello, Tommaso and Perich, M
              G and Miller, L E and Itti, Laurent",
  abstract = "For brain-computer interfaces (BCIs), obtaining sufficient
              training data for algorithms that map neural signals onto actions
              can be difficult, expensive or even impossible. Here we report
              the development and use of a generative model-a model that
              synthesizes a virtually unlimited number of new data
              distributions from a learned data distribution-that learns
              mappings between hand kinematics and the associated neural spike
              trains. The generative spike-train synthesizer is trained on data
              from one recording session with a monkey performing a reaching
              task and can be rapidly adapted to new sessions or monkeys by
              using limited additional neural data. We show that the model can
              be adapted to synthesize new spike trains, accelerating the
              training and improving the generalization of BCI decoders. The
              approach is fully data-driven, and hence, applicable to
              applications of BCIs beyond motor control.",
  journal  = "Nat Biomed Eng",
  month    =  nov,
  year     =  2021,
  keywords = "To Read;BCI",
  language = "en",
  issn     = "2157-846X",
  pmid     = "34795394",
  doi      = "10.1038/s41551-021-00811-z",
  pmc      = "PMC9114171"
}

@ARTICLE{Muhl2014-oh,
  title     = "A survey of affective brain computer interfaces: principles,
               state-of-the-art, and challenges",
  author    = "M{\"u}hl, Christian and Allison, Brendan and Nijholt, Anton and
               Chanel, Guillaume",
  abstract  = "Affective states, moods and emotions, are an integral part of
               human nature: they shape our thoughts, govern the behavior of
               the individual, and influence our interpersonal relationships.
               The last decades have seen a growing interest in the automatic
               detection of such states from voice, facial expression, and
               physiological signals, primarily with the goal of enhancing
               human-computer interaction with an affective component. With the
               advent of brain-computer interface research, the idea of
               affective brain-computer interfaces (aBCI), enabling affect
               detection from brain signals, arose. In this article, we set out
               to survey the field of neurophysiology-based affect detection.
               We outline possible applications of aBCI in a general taxonomy
               of brain-computer interface approaches and introduce the core
               concepts of affect and their neurophysiological fundamentals. We
               show that there is a growing body of literature that evidences
               the capabilities, but also the limitations and challenges of
               affect detection from neurophysiological activity.",
  journal   = "Brain-Computer Interfaces",
  publisher = "Taylor \& Francis",
  volume    =  1,
  number    =  2,
  pages     = "66--84",
  month     =  apr,
  year      =  2014,
  keywords  = "BCI;To Read",
  issn      = "2326-263X",
  doi       = "10.1080/2326263X.2014.912881"
}

@ARTICLE{Kao2017-pp,
  title    = "Leveraging neural dynamics to extend functional lifetime of
              brain-machine interfaces",
  author   = "Kao, Jonathan C and Ryu, Stephen I and Shenoy, Krishna V",
  abstract = "Intracortical brain-machine interfaces (BMIs) aim to restore lost
              motor function to people with neurological deficits by decoding
              neural activity into control signals for guiding prostheses. An
              important challenge facing BMIs is that, over time, the number of
              neural signals recorded from implanted multielectrode arrays will
              decline and result in a concomitant decrease of BMI performance.
              We sought to extend BMI lifetime by developing an algorithmic
              technique, implemented entirely in software, to improve
              performance over state-of-the-art algorithms as the number of
              recorded neural signals decline. Our approach augments the
              decoder by incorporating neural population dynamics remembered
              from an earlier point in the array lifetime. We demonstrate, in
              closed-loop experiments with two rhesus macaques, that after the
              loss of approximately 60\% of recording electrodes, our approach
              outperforms state-of-the-art decoders by a factor of 3.2$\times$
              and 1.7$\times$ (corresponding to a 46\% and 22\% recovery of
              maximal performance). Further, our results suggest that neural
              population dynamics in motor cortex are invariant to the number
              of recorded neurons. By extending functional BMI lifetime, this
              approach increases the clinical viability of BMIs.",
  journal  = "Sci. Rep.",
  volume   =  7,
  number   =  1,
  pages    = "7395",
  month    =  aug,
  year     =  2017,
  keywords = "BCI",
  language = "en",
  issn     = "2045-2322",
  pmid     = "28784984",
  doi      = "10.1038/s41598-017-06029-x",
  pmc      = "PMC5547077"
}

@ARTICLE{Altan2021-xd,
  title    = "Estimating the dimensionality of the manifold underlying
              multi-electrode neural recordings",
  author   = "Altan, Ege and Solla, Sara A and Miller, Lee E and Perreault,
              Eric J",
  abstract = "It is generally accepted that the number of neurons in a given
              brain area far exceeds the number of neurons needed to carry any
              specific function controlled by that area. For example, motor
              areas of the human brain contain tens of millions of neurons that
              control the activation of tens or at most hundreds of muscles.
              This massive redundancy implies the covariation of many neurons,
              which constrains the population activity to a low-dimensional
              manifold within the space of all possible patterns of neural
              activity. To gain a conceptual understanding of the complexity of
              the neural activity within a manifold, it is useful to estimate
              its dimensionality, which quantifies the number of degrees of
              freedom required to describe the observed population activity
              without significant information loss. While there are many
              algorithms for dimensionality estimation, we do not know which
              are well suited for analyzing neural activity. The objective of
              this study was to evaluate the efficacy of several representative
              algorithms for estimating the dimensionality of linearly and
              nonlinearly embedded data. We generated synthetic neural
              recordings with known intrinsic dimensionality and used them to
              test the algorithms' accuracy and robustness. We emulated some of
              the important challenges associated with experimental data by
              adding noise, altering the nature of the embedding of the
              low-dimensional manifold within the high-dimensional recordings,
              varying the dimensionality of the manifold, and limiting the
              amount of available data. We demonstrated that linear algorithms
              overestimate the dimensionality of nonlinear, noise-free data. In
              cases of high noise, most algorithms overestimated the
              dimensionality. We thus developed a denoising algorithm based on
              deep learning, the ``Joint Autoencoder'', which significantly
              improved subsequent dimensionality estimation. Critically, we
              found that all algorithms failed when the intrinsic
              dimensionality was high (above 20) or when the amount of data
              used for estimation was low. Based on the challenges we observed,
              we formulated a pipeline for estimating the dimensionality of
              experimental neural data.",
  journal  = "PLoS Comput. Biol.",
  volume   =  17,
  number   =  11,
  pages    = "e1008591",
  month    =  nov,
  year     =  2021,
  keywords = "To Read;BCI",
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "34843461",
  doi      = "10.1371/journal.pcbi.1008591",
  pmc      = "PMC8659648"
}

@ARTICLE{Downey2018-pl,
  title     = "Intracortical recording stability in human brain-computer
               interface users",
  author    = "Downey, John E and Schwed, Nathaniel and Chase, Steven M and
               Schwartz, Andrew B and Collinger, Jennifer L",
  abstract  = "OBJECTIVE: Intracortical brain-computer interfaces (BCIs) are
               being developed to assist people with motor disabilities in
               communicating and interacting with the world around them. This
               technology relies on recordings from the primary motor cortex,
               which may vary from day to day. APPROACH: Here we quantify, in
               two long-term BCI subjects, the length of time that action
               potentials from the same neuron, or group of neurons, can be
               recorded from the motor cortex. MAIN RESULTS: These action
               potentials are identified by their extracellular waveforms and
               may change within a single day, although some of these
               identified units can be identified consistently for weeks and
               even months. Features of the extracellular waveforms allowed us
               to predict whether a specific unit was more or less likely to
               remain stable over a prolonged period. SIGNIFICANCE: A greater
               understanding of unit stability and instability can aid the
               development of motor BCIs, where the goal is to maintain a high
               level of performance despite changes in the recorded population.
               BCIs should be able to be operated without technician
               intervention for hours, and hopefully days, to provide the most
               benefit to the end-users of this technology.",
  journal   = "J. Neural Eng.",
  publisher = "iopscience.iop.org",
  volume    =  15,
  number    =  4,
  pages     = "046016",
  month     =  aug,
  year      =  2018,
  keywords  = "brain-computer interface; intracortical; motor cortex;
               stability;BCI",
  language  = "en",
  issn      = "1741-2560, 1741-2552",
  pmid      = "29553484",
  doi       = "10.1088/1741-2552/aab7a0"
}

@UNPUBLISHED{Karpowicz2022-dq,
  title    = "Stabilizing brain-computer interfaces through alignment of latent
              dynamics",
  author   = "Karpowicz, Brianna M and Ali, Yahia H and Wimalasena, Lahiru N
              and Sedler, Andrew R and Keshtkaran, Mohammad Reza and Bodkin,
              Kevin and Ma, Xuan and Miller, Lee E and Pandarinath, Chethan",
  abstract = "Intracortical brain-computer interfaces (iBCIs) restore motor
              function to people with paralysis by translating brain activity
              into control signals for external devices. In current iBCIs,
              instabilities at the neural interface result in a degradation of
              decoding performance, which necessitates frequent supervised
              recalibration using new labeled data. One potential solution is
              to use the latent manifold structure that underlies neural
              population activity to facilitate a stable mapping between brain
              activity and behavior. Recent efforts using unsupervised
              approaches have improved iBCI stability using this principle;
              however, existing methods treat each time step as an independent
              sample and do not account for latent dynamics. Dynamics have been
              used to enable high performance prediction of movement intention,
              and may also help improve stabilization. Here, we present a
              platform for Nonlinear Manifold Alignment with Dynamics (NoMAD),
              which stabilizes iBCI decoding using recurrent neural network
              models of dynamics. NoMAD uses unsupervised distribution
              alignment to update the mapping of nonstationary neural data to a
              consistent set of neural dynamics, thereby providing stable input
              to the iBCI decoder. In applications to data from monkey motor
              cortex collected during motor tasks, NoMAD enables accurate
              behavioral decoding with unparalleled stability over weeks-to
              months-long timescales without any supervised recalibration.
              \#\#\# Competing Interest Statement C.P. is a consultant to
              Synchron and Meta (Reality Labs).",
  journal  = "bioRxiv",
  pages    = "2022.04.06.487388",
  month    =  nov,
  year     =  2022,
  keywords = "To Read;BCI",
  language = "en",
  doi      = "10.1101/2022.04.06.487388"
}

@ARTICLE{Mitchell-Heggs2023-kn,
  title    = "Neural manifold analysis of brain circuit dynamics in health and
              disease",
  author   = "Mitchell-Heggs, Rufus and Prado, Seigfred and Gava, Giuseppe P
              and Go, Mary Ann and Schultz, Simon R",
  abstract = "Recent developments in experimental neuroscience make it possible
              to simultaneously record the activity of thousands of neurons.
              However, the development of analysis approaches for such
              large-scale neural recordings have been slower than those
              applicable to single-cell experiments. One approach that has
              gained recent popularity is neural manifold learning. This
              approach takes advantage of the fact that often, even though
              neural datasets may be very high dimensional, the dynamics of
              neural activity tends to traverse a much lower-dimensional space.
              The topological structures formed by these low-dimensional neural
              subspaces are referred to as ``neural manifolds'', and may
              potentially provide insight linking neural circuit dynamics with
              cognitive function and behavioral performance. In this paper we
              review a number of linear and non-linear approaches to neural
              manifold learning, including principal component analysis (PCA),
              multi-dimensional scaling (MDS), Isomap, locally linear embedding
              (LLE), Laplacian eigenmaps (LEM), t-SNE, and uniform manifold
              approximation and projection (UMAP). We outline these methods
              under a common mathematical nomenclature, and compare their
              advantages and disadvantages with respect to their use for neural
              data analysis. We apply them to a number of datasets from
              published literature, comparing the manifolds that result from
              their application to hippocampal place cells, motor cortical
              neurons during a reaching task, and prefrontal cortical neurons
              during a multi-behavior task. We find that in many circumstances
              linear algorithms produce similar results to non-linear methods,
              although in particular cases where the behavioral complexity is
              greater, non-linear methods tend to find lower-dimensional
              manifolds, at the possible expense of interpretability. We
              demonstrate that these methods are applicable to the study of
              neurological disorders through simulation of a mouse model of
              Alzheimer's Disease, and speculate that neural manifold analysis
              may help us to understand the circuit-level consequences of
              molecular and cellular neuropathology.",
  journal  = "J. Comput. Neurosci.",
  volume   =  51,
  number   =  1,
  pages    = "1--21",
  month    =  feb,
  year     =  2023,
  keywords = "Dimensionality reduction; Manifold learning; Neural manifolds;
              Neural population analysis; Neurological disorders;To Read;BCI",
  language = "en",
  issn     = "0929-5313, 1573-6873",
  pmid     = "36522604",
  doi      = "10.1007/s10827-022-00839-3",
  pmc      = "PMC9840597"
}

@ARTICLE{Yadav2020-qc,
  title     = "A comprehensive assessment of Brain Computer Interfaces: Recent
               trends and challenges",
  author    = "Yadav, Drishti and Yadav, Shilpee and Veer, Karan",
  abstract  = "BACKGROUND: An uninterrupted channel of communication and
               control between the human brain and electronic processing units
               has led to an increased use of Brain Computer Interfaces (BCIs).
               This article attempts to present an all-encompassing review on
               BCI and the scientific advancements associated with it. The
               ultimate goal of this review is to provide a general overview of
               the BCI technology and to shed light on different aspects of
               BCIs. This review also underscores the applications, practical
               challenges and opportunities associated with BCI technology,
               which can be used to accelerate future developments in this
               field. METHODS: This review is based on a systematic literature
               search for tracking down the relevant research annals and
               proceedings. Using a methodical search strategy, the search was
               carried out across major technical databases. The retrieved
               records were screened for their relevance and a total of 369
               research chronicles were engulfed in this review based on the
               inclusion criteria. RESULTS: This review describes the present
               scenario and recent advancements in BCI technology. It also
               identifies several application areas of BCI technology. This
               comprehensive review provides evidence that, while we are
               getting ever closer, significant challenges still exist for the
               development of BCIs that can seamlessly integrate with the
               user's biological system. CONCLUSION: The findings of this
               review confirm the importance of BCI technology in various
               applications. It is concluded that BCI technology, still in its
               sprouting phase, requires significant explorations for further
               development.",
  journal   = "J. Neurosci. Methods",
  publisher = "Elsevier",
  volume    =  346,
  pages     = "108918",
  month     =  dec,
  year      =  2020,
  keywords  = "BCI applications; BCI challenges; BCI technology; Brain-Computer
               Interface;To Read;BCI",
  language  = "en",
  issn      = "0165-0270, 1872-678X",
  pmid      = "32853592",
  doi       = "10.1016/j.jneumeth.2020.108918"
}

@ARTICLE{Millan2010-un,
  title     = "Combining brain-computer interfaces and assistive technologies:
               State-of-the-art and challenges",
  author    = "Mill{\'a}n, J D R and Rupp, R and M{\"u}ller-Putz, G R and
               Murray-Smith, R and Giugliemma, C and Tangermann, M and
               Vidaurre, C and Cincotti, F and K{\"u}bler, A and Leeb, R and
               Neuper, C and M{\"u}ller, K-R and Mattia, D",
  abstract  = "In recent years, new research has brought the field of
               electroencephalogram (EEG)-based brain-computer interfacing
               (BCI) out of its infancy and into a phase of relative maturity
               through many demonstrated prototypes such as brain-controlled
               wheelchairs, keyboards, and computer games. With this
               proof-of-concept phase in the past, the time is now ripe to
               focus on the development of practical BCI technologies that can
               be brought out of the lab and into real-world applications. In
               particular, we focus on the prospect of improving the lives of
               countless disabled individuals through a combination of BCI
               technology with existing assistive technologies (AT). In pursuit
               of more practical BCIs for use outside of the lab, in this
               paper, we identify four application areas where disabled
               individuals could greatly benefit from advancements in BCI
               technology, namely, ``Communication and Control'', ``Motor
               Substitution'', ``Entertainment'', and ``Motor Recovery''. We
               review the current state of the art and possible future
               developments, while discussing the main research issues in these
               four areas. In particular, we expect the most progress in the
               development of technologies such as hybrid BCI architectures,
               user-machine adaptation algorithms, the exploitation of users'
               mental states for BCI reliability and confidence measures, the
               incorporation of principles in human-computer interaction (HCI)
               to improve BCI usability, and the development of novel BCI
               technology including better EEG devices.",
  journal   = "Front. Neurosci.",
  publisher = "Frontiers Media SA",
  volume    =  4,
  month     =  sep,
  year      =  2010,
  keywords  = "BCI; assistive technology; communication and control;
               entertainment; motor recovery; motor substitution;BCI;To Read",
  language  = "en",
  issn      = "1662-4548, 1662-453X",
  pmid      = "20877434",
  doi       = "10.3389/fnins.2010.00161",
  pmc       = "PMC2944670"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Willett2023-py,
  title     = "A high-performance speech neuroprosthesis",
  author    = "Willett, Francis and Kunz, Erin and Fan, Chaofei and Avansino,
               Donald and Wilson, Guy and Choi, Eun Young and Kamdar, Foram and
               Hochberg, Leigh R and Druckmann, Shaul and Shenoy, Krishna V and
               Henderson, Jaimie M",
  abstract  = "Speech brain-computer interfaces (BCIs) have the potential to
               restore rapid communication to people with paralysis by decoding
               neural activity evoked by attempted speaking movements into text
               1,2 or sound 3,4 .Early demonstrations, while promising, have
               not yet achieved accuracies high enough for communication of
               unconstrainted sentences from a large vocabulary 1{\^a}€``5 .
               Here, we demonstrate the first speech-to-text BCI that records
               spiking activity from intracortical microelectrode arrays.
               Enabled by these high-resolution recordings, our study
               participant, who can no longer speak intelligibly due
               amyotrophic lateral sclerosis (ALS), achieved a 9.1\% word error
               rate on a 50 word vocabulary (2.7 times fewer errors than the
               prior state of the art speech BCI 2 ) and a 23.8\% word error
               rate on a 125,000 word vocabulary (the first successful
               demonstration of large-vocabulary decoding). Our BCI decoded
               speech at 62 words per minute, which is 3.4 times faster than
               the prior record for any kind of BCI 6 and begins to approach
               the speed of natural conversation (160 words per minute 7 ).
               Finally, we highlight two aspects of the neural code for speech
               that are encouraging for speech BCIs: spatially intermixed
               tuning to speech articulators that makes accurate decoding
               possible from only a small region of cortex, and a detailed
               articulatory representation of phonemes that persists years
               after paralysis. These results show a feasible path forward for
               using intracortical speech BCIs to restore rapid communication
               to people with paralysis who can no longer speak.",
  journal   = "bioRxiv",
  publisher = "biorxiv.org",
  month     =  jan,
  year      =  2023,
  keywords  = "BCI;To Read",
  language  = "en",
  pmid      = "36711591",
  doi       = "10.1101/2023.01.21.524489",
  pmc       = "PMC9882398"
}

@ARTICLE{Dong2023-xw,
  title     = "Decoder calibration framework for intracortical brain-computer
               interface system via domain adaptation",
  author    = "Dong, Yuanrui and Hu, Dingyin and Wang, Shirong and He, Jiping",
  abstract  = "Intracortical brain-computer interface (iBCI) systems have
               evolved into a clinical approach to assist people with
               disabilities and paralysis. The decoder is one of the most
               crucial parts of iBCI systems. In reality, it is difficult to
               maintain efficient performance with a fixed decoder due to
               frequent changes in the distribution of data recorded over time.
               To improve the reliability of iBCI systems, usually, it is
               necessary to recalibrate decoders every time with a large amount
               of current data. However, it is difficult to obtain enough
               current data for recalibration. To reduce the recalibration
               data, we propose a domain adaptation-based decoder calibration
               framework (DA-DCF) for decoding reach-and grasp movements, which
               utilizes a small amount of current data and robustly achieves
               good performance. In the DA-DCF, a source convolutional neural
               network (CNN) learned representation from source data to
               initialize the target CNN. Secondly, the target CNN was trained
               through a confusing domain discriminator until it would not
               distinguish between the source and target domains. Thirdly, the
               features transformed by the target CNN were classified by the
               classifier for movements in the target domain. Finally, the
               practicality and efficiency of the DA-DCF were evaluated with
               other comparative frameworks. The comparative experiments were
               conducted on the data from a male rhesus monkey, which was
               trained to perform three categories of reach-and-grasp tasks
               across two sessions. Our results showed that DA-DCF diminished
               the disparity between source and target data, and significantly
               reduced the amount of recalibration data while improving the
               decoding accuracy. It is plausible to utilize DA-DCF in
               real-time iBCI systems of the forelimb movement control.",
  journal   = "Biomed. Signal Process. Control",
  publisher = "Elsevier",
  volume    =  81,
  pages     = "104453",
  month     =  mar,
  year      =  2023,
  keywords  = "Intracortical brain-computer interface (iBCI); Decoder
               calibration; Domain adaptation; Transfer learning; Small amounts
               of current data;To Read;BCI",
  issn      = "1746-8094",
  doi       = "10.1016/j.bspc.2022.104453"
}

@ARTICLE{Sussillo2016-td,
  title     = "Making brain--machine interfaces robust to future neural
               variability",
  author    = "Sussillo, David and Stavisky, Sergey D and Kao, Jonathan C and
               Ryu, Stephen I and Shenoy, Krishna V",
  abstract  = "A major hurdle to clinical translation of brain--machine
               interfaces (BMIs) is that current decoders, which are trained
               from a small quantity of recent data, become ineffective when
               neural recording conditions subsequently change. We tested
               whether a decoder could be made more robust to future neural
               variability by training it to handle a variety of recording
               conditions sampled from months of previously collected data as
               well as synthetic training data perturbations. We developed a
               new multiplicative recurrent neural network BMI decoder that
               successfully learned a large variety of neural-to-kinematic
               mappings and became more robust with larger training data sets.
               Here we demonstrate that when tested with a non-human primate
               preclinical BMI model, this decoder is robust under conditions
               that disabled a state-of-the-art Kalman filter-based decoder.
               These results validate a new BMI strategy in which accumulated
               data history are effectively harnessed, and may facilitate
               reliable BMI use by reducing decoder retraining downtime.
               Brain-machine interfaces (BMI) depend on algorithms to decode
               neural signals, but these decoders cope poorly with signal
               variability. Here, authors report a BMI decoder which
               circumvents these problems by using a large and perturbed
               training dataset to improve performance with variable neural
               signals.",
  journal   = "Nat. Commun.",
  publisher = "Nature Publishing Group",
  volume    =  7,
  number    =  1,
  pages     = "1--13",
  month     =  dec,
  year      =  2016,
  keywords  = "To Read;BCI",
  language  = "en",
  issn      = "2041-1723, 2041-1723",
  doi       = "10.1038/ncomms13749"
}

@ARTICLE{Jarosiewicz2015-xl,
  title     = "Virtual typing by people with tetraplegia using a
               self-calibrating intracortical brain-computer interface",
  author    = "Jarosiewicz, Beata and Sarma, Anish A and Bacher, Daniel and
               Masse, Nicolas Y and Simeral, John D and Sorice, Brittany and
               Oakley, Erin M and Blabe, Christine and Pandarinath, Chethan and
               Gilja, Vikash and Cash, Sydney S and Eskandar, Emad N and
               Friehs, Gerhard and Henderson, Jaimie M and Shenoy, Krishna V
               and Donoghue, John P and Hochberg, Leigh R",
  abstract  = "Brain-computer interfaces (BCIs) promise to restore independence
               for people with severe motor disabilities by translating decoded
               neural activity directly into the control of a computer.
               However, recorded neural signals are not stationary (that is,
               can change over time), degrading the quality of decoding.
               Requiring users to pause what they are doing whenever signals
               change to perform decoder recalibration routines is
               time-consuming and impractical for everyday use of BCIs. We
               demonstrate that signal nonstationarity in an intracortical BCI
               can be mitigated automatically in software, enabling long
               periods (hours to days) of self-paced point-and-click typing by
               people with tetraplegia, without degradation in neural control.
               Three key innovations were included in our approach: tracking
               the statistics of the neural activity during self-timed pauses
               in neural control, velocity bias correction during neural
               control, and periodically recalibrating the decoder using data
               acquired during typing by mapping neural activity to movement
               intentions that are inferred retrospectively based on the user's
               self-selected targets. These methods, which can be extended to a
               variety of neurally controlled applications, advance the
               potential for intracortical BCIs to help restore independent
               communication and assistive device control for people with
               paralysis.",
  journal   = "Sci. Transl. Med.",
  publisher = "science.org",
  volume    =  7,
  number    =  313,
  pages     = "313ra179",
  month     =  nov,
  year      =  2015,
  keywords  = "To Read;BCI",
  language  = "en",
  issn      = "1946-6234, 1946-6242",
  pmid      = "26560357",
  doi       = "10.1126/scitranslmed.aac7328",
  pmc       = "PMC4765319"
}

@ARTICLE{Chestek2011-nv,
  title    = "Long-term stability of neural prosthetic control signals from
              silicon cortical arrays in rhesus macaque motor cortex",
  author   = "Chestek, Cynthia A and Gilja, Vikash and Nuyujukian, Paul and
              Foster, Justin D and Fan, Joline M and Kaufman, Matthew T and
              Churchland, Mark M and Rivera-Alvidrez, Zuley and Cunningham,
              John P and Ryu, Stephen I and Shenoy, Krishna V",
  abstract = "Cortically-controlled prosthetic systems aim to help disabled
              patients by translating neural signals from the brain into
              control signals for guiding prosthetic devices. Recent reports
              have demonstrated reasonably high levels of performance and
              control of computer cursors and prosthetic limbs, but to achieve
              true clinical viability, the long-term operation of these systems
              must be better understood. In particular, the quality and
              stability of the electrically-recorded neural signals require
              further characterization. Here, we quantify action potential
              changes and offline neural decoder performance over 382 days of
              recording from four intracortical arrays in three animals. Action
              potential amplitude decreased by 2.4\% per month on average over
              the course of 9.4, 10.4, and 31.7 months in three animals. During
              most time periods, decoder performance was not well correlated
              with action potential amplitude (p > 0.05 for three of four
              arrays). In two arrays from one animal, action potential
              amplitude declined by an average of 37\% over the first 2 months
              after implant. However, when using simple threshold-crossing
              events rather than well-isolated action potentials, no
              corresponding performance loss was observed during this time
              using an offline decoder. One of these arrays was effectively
              used for online prosthetic experiments over the following year.
              Substantial short-term variations in waveforms were quantified
              using a wireless system for contiguous recording in one animal,
              and compared within and between days for all three animals.
              Overall, this study suggests that action potential amplitude
              declines more slowly than previously supposed, and performance
              can be maintained over the course of multiple years when decoding
              from threshold-crossing events rather than isolated action
              potentials. This suggests that neural prosthetic systems may
              provide high performance over multiple years in human clinical
              trials.",
  journal  = "J. Neural Eng.",
  volume   =  8,
  number   =  4,
  pages    = "045005",
  month    =  aug,
  year     =  2011,
  keywords = "To Read;BCI",
  language = "en",
  issn     = "1741-2560, 1741-2552",
  pmid     = "21775782",
  doi      = "10.1088/1741-2560/8/4/045005",
  pmc      = "PMC3644617"
}

@ARTICLE{Christie2015-lw,
  title    = "Comparison of spike sorting and thresholding of voltage waveforms
              for intracortical brain-machine interface performance",
  author   = "Christie, Breanne P and Tat, Derek M and Irwin, Zachary T and
              Gilja, Vikash and Nuyujukian, Paul and Foster, Justin D and Ryu,
              Stephen I and Shenoy, Krishna V and Thompson, David E and
              Chestek, Cynthia A",
  abstract = "OBJECTIVE: For intracortical brain-machine interfaces (BMIs),
              action potential voltage waveforms are often sorted to separate
              out individual neurons. If these neurons contain independent
              tuning information, this process could increase BMI performance.
              However, the sorting of action potentials ('spikes') requires
              high sampling rates and is computationally expensive. To
              explicitly define the difference between spike sorting and
              alternative methods, we quantified BMI decoder performance when
              using threshold-crossing events versus sorted action potentials.
              APPROACH: We used data sets from 58 experimental sessions from
              two rhesus macaques implanted with Utah arrays. Data were
              recorded while the animals performed a center-out reaching task
              with seven different angles. For spike sorting, neural signals
              were sorted into individual units by using a mixture of Gaussians
              to cluster the first four principal components of the waveforms.
              For thresholding events, spikes that simply crossed a set
              threshold were retained. We decoded the data offline using both a
              Na{\"\i}ve Bayes classifier for reaching direction and a linear
              regression to evaluate hand position. MAIN RESULTS: We found the
              highest performance for thresholding when placing a threshold
              between -3 and -4.5 $\times$ Vrms. Spike sorted data outperformed
              thresholded data for one animal but not the other. The mean
              Na{\"\i}ve Bayes classification accuracy for sorted data was
              88.5\% and changed by 5\% on average when data were thresholded.
              The mean correlation coefficient for sorted data was 0.92, and
              changed by 0.015 on average when thresholded. SIGNIFICANCE: For
              prosthetics applications, these results imply that when
              thresholding is used instead of spike sorting, only a small
              amount of performance may be lost. The utilization of
              threshold-crossing events may significantly extend the lifetime
              of a device because these events are often still detectable once
              single neurons are no longer isolated.",
  journal  = "J. Neural Eng.",
  volume   =  12,
  number   =  1,
  pages    = "016009",
  month    =  feb,
  year     =  2015,
  keywords = "BCI;To Read",
  language = "en",
  issn     = "1741-2560, 1741-2552",
  pmid     = "25504690",
  doi      = "10.1088/1741-2560/12/1/016009",
  pmc      = "PMC4332592"
}

@ARTICLE{Gilja2012-ed,
  title     = "A high-performance neural prosthesis enabled by control
               algorithm design",
  author    = "Gilja, Vikash and Nuyujukian, Paul and Chestek, Cindy A and
               Cunningham, John P and Yu, Byron M and Fan, Joline M and
               Churchland, Mark M and Kaufman, Matthew T and Kao, Jonathan C
               and Ryu, Stephen I and Shenoy, Krishna V",
  abstract  = "Neural prostheses translate neural activity from the brain into
               control signals for guiding prosthetic devices, such as computer
               cursors and robotic limbs, and thus offer individuals with
               disabilities greater interaction with the world. However,
               relatively low performance remains a critical barrier to
               successful clinical translation; current neural prostheses are
               considerably slower, with less accurate control, than the native
               arm. Here we present a new control algorithm, the recalibrated
               feedback intention-trained Kalman filter (ReFIT-KF) that
               incorporates assumptions about the nature of closed-loop neural
               prosthetic control. When tested in rhesus monkeys implanted with
               motor cortical electrode arrays, the ReFIT-KF algorithm
               outperformed existing neural prosthetic algorithms in all
               measured domains and halved target acquisition time. This
               control algorithm permits sustained, uninterrupted use for hours
               and generalizes to more challenging tasks without retraining.
               Using this algorithm, we demonstrate repeatable high performance
               for years after implantation in two monkeys, thereby increasing
               the clinical viability of neural prostheses.",
  journal   = "Nat. Neurosci.",
  publisher = "nature.com",
  volume    =  15,
  number    =  12,
  pages     = "1752--1757",
  month     =  dec,
  year      =  2012,
  keywords  = "To Read;BCI",
  language  = "en",
  issn      = "1097-6256, 1546-1726",
  pmid      = "23160043",
  doi       = "10.1038/nn.3265",
  pmc       = "PMC3638087"
}

@ARTICLE{Todorova2014-qq,
  title     = "To sort or not to sort: the impact of spike-sorting on neural
               decoding performance",
  author    = "Todorova, Sonia and Sadtler, Patrick and Batista, Aaron and
               Chase, Steven and Ventura, Val{\'e}rie",
  abstract  = "OBJECTIVE: Brain-computer interfaces (BCIs) are a promising
               technology for restoring motor ability to paralyzed patients.
               Spiking-based BCIs have successfully been used in clinical
               trials to control multi-degree-of-freedom robotic devices.
               Current implementations of these devices require a lengthy
               spike-sorting step, which is an obstacle to moving this
               technology from the lab to the clinic. A viable alternative is
               to avoid spike-sorting, treating all threshold crossings of the
               voltage waveform on an electrode as coming from one putative
               neuron. It is not known, however, how much decoding information
               might be lost by ignoring spike identity. APPROACH: We present a
               full analysis of the effects of spike-sorting schemes on
               decoding performance. Specifically, we compare how well two
               common decoders, the optimal linear estimator and the Kalman
               filter, reconstruct the arm movements of non-human primates
               performing reaching tasks, when receiving input from various
               sorting schemes. The schemes we tested included: using threshold
               crossings without spike-sorting; expert-sorting discarding the
               noise; expert-sorting, including the noise as if it were another
               neuron; and automatic spike-sorting using waveform features. We
               also decoded from a joint statistical model for the waveforms
               and tuning curves, which does not involve an explicit
               spike-sorting step. MAIN RESULTS: Discarding the threshold
               crossings that cannot be assigned to neurons degrades decoding:
               no spikes should be discarded. Decoding based on spike-sorted
               units outperforms decoding based on electrodes voltage
               crossings: spike-sorting is useful. The four waveform based
               spike-sorting methods tested here yield similar decoding
               efficiencies: a fast and simple method is competitive. Decoding
               using the joint waveform and tuning model shows promise but is
               not consistently superior. SIGNIFICANCE: Our results indicate
               that simple automated spike-sorting performs as well as the more
               computationally or manually intensive methods used here. Even
               basic spike-sorting adds value to the low-threshold
               waveform-crossing methods often employed in BCI decoding.",
  journal   = "J. Neural Eng.",
  publisher = "iopscience.iop.org",
  volume    =  11,
  number    =  5,
  pages     = "056005",
  month     =  oct,
  year      =  2014,
  keywords  = "BCI;To Read",
  language  = "en",
  issn      = "1741-2560, 1741-2552",
  pmid      = "25082508",
  doi       = "10.1088/1741-2560/11/5/056005",
  pmc       = "PMC4454741"
}

@ARTICLE{Flint2016-xe,
  title    = "{Long-Term} Stability of Motor Cortical Activity: Implications
              for Brain Machine Interfaces and Optimal Feedback Control",
  author   = "Flint, Robert D and Scheid, Michael R and Wright, Zachary A and
              Solla, Sara A and Slutzky, Marc W",
  abstract = "UNLABELLED: The human motor system is capable of remarkably
              precise control of movements--consider the skill of professional
              baseball pitchers or surgeons. This precise control relies upon
              stable representations of movements in the brain. Here, we
              investigated the stability of cortical activity at multiple
              spatial and temporal scales by recording local field potentials
              (LFPs) and action potentials (multiunit spikes, MSPs) while two
              monkeys controlled a cursor either with their hand or directly
              from the brain using a brain-machine interface. LFPs and some
              MSPs were remarkably stable over time periods ranging from 3 d to
              over 3 years; overall, LFPs were significantly more stable than
              spikes. We then assessed whether the stability of all neural
              activity, or just a subset of activity, was necessary to achieve
              stable behavior. We showed that projections of neural activity
              into the subspace relevant to the task (the ``task-relevant
              space'') were significantly more stable than were projections
              into the task-irrelevant (or ``task-null'') space. This provides
              cortical evidence in support of the minimum intervention
              principle, which proposes that optimal feedback control (OFC)
              allows the brain to tightly control only activity in the
              task-relevant space while allowing activity in the
              task-irrelevant space to vary substantially from trial to trial.
              We found that the brain appears capable of maintaining stable
              movement representations for extremely long periods of time,
              particularly so for neural activity in the task-relevant space,
              which agrees with OFC predictions. SIGNIFICANCE STATEMENT: It is
              unknown whether cortical signals are stable for more than a few
              weeks. Here, we demonstrate that motor cortical signals can
              exhibit high stability over several years. This result is
              particularly important to brain-machine interfaces because it
              could enable stable performance with infrequent recalibration.
              Although we can maintain movement accuracy over time, movement
              components that are unrelated to the goals of a task (such as
              elbow position during reaching) often vary from trial to trial.
              This is consistent with the minimum intervention principle of
              optimal feedback control. We provide evidence that the motor
              cortex acts according to this principle: cortical activity is
              more stable in the task-relevant space and more variable in the
              task-irrelevant space.",
  journal  = "J. Neurosci.",
  volume   =  36,
  number   =  12,
  pages    = "3623--3632",
  month    =  mar,
  year     =  2016,
  keywords = "LFPs; brain--machine interface; minimum intervention; motor
              cortex; optimal feedback control; stability;To Read;BCI",
  language = "en",
  issn     = "0270-6474, 1529-2401",
  pmid     = "27013690",
  doi      = "10.1523/JNEUROSCI.2339-15.2016",
  pmc      = "PMC4804017"
}

@ARTICLE{Farshchian2018-ed,
  title         = "Adversarial Domain Adaptation for Stable {Brain-Machine}
                   Interfaces",
  author        = "Farshchian, Ali and Gallego, Juan A and Cohen, Joseph P and
                   Bengio, Yoshua and Miller, Lee E and Solla, Sara A",
  abstract      = "Brain-Machine Interfaces (BMIs) have recently emerged as a
                   clinically viable option to restore voluntary movements
                   after paralysis. These devices are based on the ability to
                   extract information about movement intent from neural
                   signals recorded using multi-electrode arrays chronically
                   implanted in the motor cortices of the brain. However, the
                   inherent loss and turnover of recorded neurons requires
                   repeated recalibrations of the interface, which can
                   potentially alter the day-to-day user experience. The
                   resulting need for continued user adaptation interferes with
                   the natural, subconscious use of the BMI. Here, we introduce
                   a new computational approach that decodes movement intent
                   from a low-dimensional latent representation of the neural
                   data. We implement various domain adaptation methods to
                   stabilize the interface over significantly long times. This
                   includes Canonical Correlation Analysis used to align the
                   latent variables across days; this method requires prior
                   point-to-point correspondence of the time series across
                   domains. Alternatively, we match the empirical probability
                   distributions of the latent variables across days through
                   the minimization of their Kullback-Leibler divergence. These
                   two methods provide a significant and comparable improvement
                   in the performance of the interface. However, implementation
                   of an Adversarial Domain Adaptation Network trained to match
                   the empirical probability distribution of the residuals of
                   the reconstructed neural signals outperforms the two methods
                   based on latent variables, while requiring remarkably few
                   data points to solve the domain adaptation problem.",
  month         =  sep,
  year          =  2018,
  keywords      = "BCI",
  archivePrefix = "arXiv",
  eprint        = "1810.00045",
  primaryClass  = "cs.LG",
  arxivid       = "1810.00045"
}

@ARTICLE{Trautmann2019-aq,
  title    = "Accurate Estimation of Neural Population Dynamics without Spike
              Sorting",
  author   = "Trautmann, Eric M and Stavisky, Sergey D and Lahiri, Subhaneil
              and Ames, Katherine C and Kaufman, Matthew T and O'Shea, Daniel J
              and Vyas, Saurabh and Sun, Xulu and Ryu, Stephen I and Ganguli,
              Surya and Shenoy, Krishna V",
  abstract = "A central goal of systems neuroscience is to relate an organism's
              neural activity to behavior. Neural population analyses often
              reduce the data dimensionality to focus on relevant activity
              patterns. A major hurdle to data analysis is spike sorting, and
              this problem is growing as the number of recorded neurons
              increases. Here, we investigate whether spike sorting is
              necessary to estimate neural population dynamics. The theory of
              random projections suggests that we can accurately estimate the
              geometry of low-dimensional manifolds from a small number of
              linear projections of the data. We recorded data using
              Neuropixels probes in motor cortex of nonhuman primates and
              reanalyzed data from three previous studies and found that neural
              dynamics and scientific conclusions are quite similar using
              multiunit threshold crossings rather than sorted neurons. This
              finding unlocks existing data for new analyses and informs the
              design and use of new electrode arrays for laboratory and
              clinical use.",
  journal  = "Neuron",
  volume   =  103,
  number   =  2,
  pages    = "292--308.e4",
  month    =  jul,
  year     =  2019,
  keywords = "brain computer interface; dimensionality reduction; neural
              dynamics; neural implant; neural signal processing; neural
              trajectories; neurophysiology; random projections; spike
              sorting;To Read;BCI",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "31171448",
  doi      = "10.1016/j.neuron.2019.05.003",
  pmc      = "PMC7002296"
}

@ARTICLE{Jarosiewicz2015-jr,
  title    = "Virtual typing by people with tetraplegia using a
              self-calibrating intracortical brain-computer interface",
  author   = "Jarosiewicz, Beata and Sarma, Anish A and Bacher, Daniel and
              Masse, Nicolas Y and Simeral, John D and Sorice, Brittany and
              Oakley, Erin M and Blabe, Christine and Pandarinath, Chethan and
              Gilja, Vikash and Cash, Sydney S and Eskandar, Emad N and Friehs,
              Gerhard and Henderson, Jaimie M and Shenoy, Krishna V and
              Donoghue, John P and Hochberg, Leigh R",
  abstract = "Brain-computer interfaces (BCIs) promise to restore independence
              for people with severe motor disabilities by translating decoded
              neural activity directly into the control of a computer. However,
              recorded neural signals are not stationary (that is, can change
              over time), degrading the quality of decoding. Requiring users to
              pause what they are doing whenever signals change to perform
              decoder recalibration routines is time-consuming and impractical
              for everyday use of BCIs. We demonstrate that signal
              nonstationarity in an intracortical BCI can be mitigated
              automatically in software, enabling long periods (hours to days)
              of self-paced point-and-click typing by people with tetraplegia,
              without degradation in neural control. Three key innovations were
              included in our approach: tracking the statistics of the neural
              activity during self-timed pauses in neural control, velocity
              bias correction during neural control, and periodically
              recalibrating the decoder using data acquired during typing by
              mapping neural activity to movement intentions that are inferred
              retrospectively based on the user's self-selected targets. These
              methods, which can be extended to a variety of neurally
              controlled applications, advance the potential for intracortical
              BCIs to help restore independent communication and assistive
              device control for people with paralysis.",
  journal  = "Sci. Transl. Med.",
  volume   =  7,
  number   =  313,
  pages    = "313ra179",
  month    =  nov,
  year     =  2015,
  keywords = "To Read;BCI",
  language = "en",
  issn     = "1946-6234, 1946-6242",
  pmid     = "26560357",
  doi      = "10.1126/scitranslmed.aac7328",
  pmc      = "PMC4765319"
}

@ARTICLE{Brandman2018-ge,
  title    = "Rapid calibration of an intracortical brain-computer interface
              for people with tetraplegia",
  author   = "Brandman, David M and Hosman, Tommy and Saab, Jad and Burkhart,
              Michael C and Shanahan, Benjamin E and Ciancibello, John G and
              Sarma, Anish A and Milstein, Daniel J and Vargas-Irwin, Carlos E
              and Franco, Brian and Kelemen, Jessica and Blabe, Christine and
              Murphy, Brian A and Young, Daniel R and Willett, Francis R and
              Pandarinath, Chethan and Stavisky, Sergey D and Kirsch, Robert F
              and Walter, Benjamin L and Bolu Ajiboye, A and Cash, Sydney S and
              Eskandar, Emad N and Miller, Jonathan P and Sweet, Jennifer A and
              Shenoy, Krishna V and Henderson, Jaimie M and Jarosiewicz, Beata
              and Harrison, Matthew T and Simeral, John D and Hochberg, Leigh R",
  abstract = "OBJECTIVE: Brain-computer interfaces (BCIs) can enable
              individuals with tetraplegia to communicate and control external
              devices. Though much progress has been made in improving the
              speed and robustness of neural control provided by intracortical
              BCIs, little research has been devoted to minimizing the amount
              of time spent on decoder calibration. APPROACH: We investigated
              the amount of time users needed to calibrate decoders and achieve
              performance saturation using two markedly different decoding
              algorithms: the steady-state Kalman filter, and a novel technique
              using Gaussian process regression (GP-DKF). MAIN RESULTS: Three
              people with tetraplegia gained rapid closed-loop neural cursor
              control and peak, plateaued decoder performance within 3 min of
              initializing calibration. We also show that a BCI-na{\"\i}ve user
              (T5) was able to rapidly attain closed-loop neural cursor control
              with the GP-DKF using self-selected movement imagery on his
              first-ever day of closed-loop BCI use, acquiring a target 37 s
              after initiating calibration. SIGNIFICANCE: These results
              demonstrate the potential for an intracortical BCI to be used
              immediately after deployment by people with paralysis, without
              the need for user learning or extensive system calibration.",
  journal  = "J. Neural Eng.",
  volume   =  15,
  number   =  2,
  pages    = "026007",
  month    =  apr,
  year     =  2018,
  keywords = "To Read;BCI",
  language = "en",
  issn     = "1741-2560, 1741-2552",
  pmid     = "29363625",
  doi      = "10.1088/1741-2552/aa9ee7",
  pmc      = "PMC5823702"
}

@INPROCEEDINGS{Chase2019-lb,
  title     = "Neural manifolds: from basic science to practical improvements
               in brain-computer intefaces",
  booktitle = "2019 7th International Winter Conference on {Brain-Computer}
               Interface ({BCI})",
  author    = "Chase, Steven M",
  abstract  = "Intracortical brain-computer interfaces hold the potential to
               improve the quality of life for patients living with motor
               control disorders. However, a critical barrier to the successful
               clinical translation of these devices is recording instability,
               which, if unmitigated, can quickly cause control to deteriorate.
               Recent findings have indicated that high-dimensional neural
               population activity resides in a low-dimensional ``neural
               manifold''. Here I will introduce the concept of neural
               manifolds and briefly recap recent findings showing that neural
               manifolds constrain the types of brain-computer interface
               mappings that can be easily learned. Finally, I will show how
               these neural manifolds can be leveraged to mitigate the effects
               of neural recording instability, enabling stable control in the
               presence of even severe recording instabilities.",
  publisher = "ieeexplore.ieee.org",
  pages     = "1--2",
  month     =  feb,
  year      =  2019,
  keywords  = "Manifolds;Sociology;Statistics;Neurons;Decoding;Brain-computer
               interfaces;Neural activity;BMI;neural
               recording;decoding;instability;BCI",
  issn      = "2572-7672",
  doi       = "10.1109/IWW-BCI.2019.8737339"
}

@ARTICLE{Xu2020-ws,
  title     = "{Cross-Dataset} Variability Problem in {EEG} Decoding With Deep
               Learning",
  author    = "Xu, Lichao and Xu, Minpeng and Ke, Yufeng and An, Xingwei and
               Liu, Shuang and Ming, Dong",
  abstract  = "Cross-subject variability problems hinder practical usages of
               Brain-Computer Interfaces. Recently, deep learning has been
               introduced into the BCI community due to its better
               generalization and feature representation abilities. However,
               most studies currently only have validated deep learning models
               for single datasets, and the generalization ability for other
               datasets still needs to be further verified. In this paper, we
               validated deep learning models for eight MI datasets and
               demonstrated that the cross-dataset variability problem weakened
               the generalization ability of models. To alleviate the impact of
               cross-dataset variability, we proposed an online pre-alignment
               strategy for aligning the EEG distributions of different
               subjects before training and inference processes. The results of
               this study show that deep learning models with online
               pre-alignment strategies could significantly improve the
               generalization ability across datasets without any additional
               calibration data.",
  journal   = "Front. Hum. Neurosci.",
  publisher = "frontiersin.org",
  volume    =  14,
  pages     = "103",
  month     =  apr,
  year      =  2020,
  keywords  = "EEG; brain-computer interface; cross-dataset variability;
               cross-subject variability; deep learning; transfer learning;To
               Read;BCI",
  language  = "en",
  issn      = "1662-5161",
  pmid      = "32372929",
  doi       = "10.3389/fnhum.2020.00103",
  pmc       = "PMC7188358"
}

@ARTICLE{Feulner2021-un,
  title     = "Neural manifold under plasticity in a goal driven learning
               behaviour",
  author    = "Feulner, Barbara and Clopath, Claudia",
  abstract  = "Neural activity is often low dimensional and dominated by only a
               few prominent neural covariation patterns. It has been
               hypothesised that these covariation patterns could form the
               building blocks used for fast and flexible motor control.
               Supporting this idea, recent experiments have shown that monkeys
               can learn to adapt their neural activity in motor cortex on a
               timescale of minutes, given that the change lies within the
               original low-dimensional subspace, also called neural manifold.
               However, the neural mechanism underlying this within-manifold
               adaptation remains unknown. Here, we show in a computational
               model that modification of recurrent weights, driven by a
               learned feedback signal, can account for the observed
               behavioural difference between within- and outside-manifold
               learning. Our findings give a new perspective, showing that
               recurrent weight changes do not necessarily lead to change in
               the neural manifold. On the contrary, successful learning is
               naturally constrained to a common subspace.",
  journal   = "PLoS Comput. Biol.",
  publisher = "journals.plos.org",
  volume    =  17,
  number    =  2,
  pages     = "e1008621",
  month     =  feb,
  year      =  2021,
  keywords  = "To Read;BCI",
  language  = "en",
  issn      = "1553-734X, 1553-7358",
  pmid      = "33544700",
  doi       = "10.1371/journal.pcbi.1008621",
  pmc       = "PMC7864452"
}

@ARTICLE{Jude2022-bn,
  title         = "Robust alignment of cross-session recordings of neural
                   population activity by behaviour via unsupervised domain
                   adaptation",
  author        = "Jude, Justin and Perich, Matthew G and Miller, Lee E and
                   Hennig, Matthias H",
  abstract      = "Neural population activity relating to behaviour is assumed
                   to be inherently low-dimensional despite the observed high
                   dimensionality of data recorded using multi-electrode
                   arrays. Therefore, predicting behaviour from neural
                   population recordings has been shown to be most effective
                   when using latent variable models. Over time however, the
                   activity of single neurons can drift, and different neurons
                   will be recorded due to movement of implanted neural probes.
                   This means that a decoder trained to predict behaviour on
                   one day performs worse when tested on a different day. On
                   the other hand, evidence suggests that the latent dynamics
                   underlying behaviour may be stable even over months and
                   years. Based on this idea, we introduce a model capable of
                   inferring behaviourally relevant latent dynamics from
                   previously unseen data recorded from the same animal,
                   without any need for decoder recalibration. We show that
                   unsupervised domain adaptation combined with a sequential
                   variational autoencoder, trained on several sessions, can
                   achieve good generalisation to unseen data and correctly
                   predict behaviour where conventional methods fail. Our
                   results further support the hypothesis that
                   behaviour-related neural dynamics are low-dimensional and
                   stable over time, and will enable more effective and
                   flexible use of brain computer interface technologies.",
  month         =  feb,
  year          =  2022,
  keywords      = "To Read;BCI",
  archivePrefix = "arXiv",
  eprint        = "2202.06159",
  primaryClass  = "q-bio.NC",
  arxivid       = "2202.06159"
}

@ARTICLE{Bleuze2022-dt,
  title     = "Tangent space alignment: Transfer learning for {Brain-Computer}
               Interface",
  author    = "Bleuz{\'e}, Alexandre and Mattout, J{\'e}r{\'e}mie and Congedo,
               Marco",
  abstract  = "Statistical variability of electroencephalography (EEG) between
               subjects and between sessions is a common problem faced in the
               field of Brain-Computer Interface (BCI). Such variability
               prevents the usage of pre-trained machine learning models and
               requires the use of a calibration for every new session. This
               paper presents a new transfer learning (TL) method that deals
               with this variability. This method aims to reduce calibration
               time and even improve accuracy of BCI systems by aligning EEG
               data from one subject to the other in the tangent space of the
               positive definite matrices Riemannian manifold. We tested the
               method on 18 BCI databases comprising a total of 349 subjects
               pertaining to three BCI paradigms, namely, event related
               potentials (ERP), motor imagery (MI), and steady state visually
               evoked potentials (SSVEP). We employ a support vector classifier
               for feature classification. The results demonstrate a
               significant improvement of classification accuracy, as compared
               to a classical training-test pipeline, in the case of the ERP
               paradigm, whereas for both the MI and SSVEP paradigm no
               deterioration of performance is observed. A global 2.7\%
               accuracy improvement is obtained compared to a previously
               published Riemannian method, Riemannian Procrustes Analysis
               (RPA). Interestingly, tangent space alignment has an intrinsic
               ability to deal with transfer learning for sets of data that
               have different number of channels, naturally applying to
               inter-dataset transfer learning.",
  journal   = "Front. Hum. Neurosci.",
  publisher = "hal.science",
  volume    =  16,
  pages     = "1049985",
  month     =  dec,
  year      =  2022,
  keywords  = "Brain-Computer Interface; ERP; Riemannian geometry; SSVEP;
               domain adaptation; motor imagery; transfer learning;To Read;BCI",
  language  = "en",
  issn      = "1662-5161",
  pmid      = "36530202",
  doi       = "10.3389/fnhum.2022.1049985",
  pmc       = "PMC9755175"
}

@INPROCEEDINGS{Li2019-ad,
  title     = "Motor Imagery Classification based on Local Isometric Embedding
               of Riemannian Manifold",
  booktitle = "2019 14th {IEEE} Conference on Industrial Electronics and
               Applications ({ICIEA})",
  author    = "Li, Shaofeng and Xie, Xiaofeng and Gu, Zhenghui and Yu, Zhu
               Liang and Li, Yuanqing",
  abstract  = "Since the spatial covariance matrices of EEG lie on a Riemannian
               manifold, it is potential to exploit Riemannian geometry to
               decode the motor imagery EEG signal. However, high
               dimensionality on Riemannian manifold limits the application of
               existing techniques. In this paper, taking advantage of the
               locality preserving on Riemannian manifold, we propose a novel
               dimensionality reduction method, named local isometric embedding
               (LIE), to learn a low-dimensional embedding from Riemannian
               manifold. Further with a support vector machine (SVM) classifier
               performed on the embedding, we obtain a efficient decoding
               method for motor imagery classification. Experimental evaluation
               on Dataset IIa of BCI Competition IV reveals that the proposed
               method outperforms other competing methods.",
  publisher = "ieeexplore.ieee.org",
  pages     = "2368--2372",
  month     =  jun,
  year      =  2019,
  keywords  = "Manifolds;Decoding;Electroencephalography;Dimensionality
               reduction;Support vector machines;Covariance matrices;Symmetric
               matrices;Motor imagery;Electroencephalogram(EEG);Dimensionality
               reduction;Riemannian manifold;Decoding;To Read;BCI",
  issn      = "2158-2297",
  doi       = "10.1109/ICIEA.2019.8833878"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Oby2020-wy,
  title     = "Intracortical brain--machine interfaces",
  author    = "Oby, E R and Hennig, J A and Batista, A P and Yu, B M and Chase,
               S M",
  abstract  = "A brain--machine interface, or BMI, directly connects the brain
               to the external world, bypassing damaged biological pathways. It
               replaces the impaired parts of the nervous …",
  journal   = "Neural Engineering",
  publisher = "Springer",
  year      =  2020,
  keywords  = "To Read;BCI"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Perge2013-sb,
  title     = "Intra-day signal instabilities affect decoding performance in an
               intracortical neural interface system",
  author    = "Perge, J{\'a}nos A and Homer, Mark L and Malik, Wasim Q and
               Cash, Sydney and Eskandar, Emad and Friehs, Gerhard and
               Donoghue, John P and Hochberg, Leigh R",
  abstract  = "OBJECTIVE: Motor neural interface systems (NIS) aim to convert
               neural signals into motor prosthetic or assistive device
               control, allowing people with paralysis to regain movement or
               control over their immediate environment. Effector or prosthetic
               control can degrade if the relationship between recorded neural
               signals and intended motor behavior changes. Therefore,
               characterizing both biological and technological sources of
               signal variability is important for a reliable NIS. APPROACH: To
               address the frequency and causes of neural signal variability in
               a spike-based NIS, we analyzed within-day fluctuations in
               spiking activity and action potential amplitude recorded with
               silicon microelectrode arrays implanted in the motor cortex of
               three people with tetraplegia (BrainGate pilot clinical trial,
               IDE). MAIN RESULTS: 84\% of the recorded units showed a
               statistically significant change in apparent firing rate (3.8
               $\pm$ 8.71 Hz or 49\% of the mean rate) across several-minute
               epochs of tasks performed on a single session, and 74\% of the
               units showed a significant change in spike amplitude (3.7 $\pm$
               6.5 µV or 5.5\% of mean spike amplitude). 40\% of the recording
               sessions showed a significant correlation in the occurrence of
               amplitude changes across electrodes, suggesting array
               micro-movement. Despite the relatively frequent amplitude
               changes, only 15\% of the observed within-day rate changes
               originated from recording artifacts such as spike amplitude
               change or electrical noise, while 85\% of the rate changes most
               likely emerged from physiological mechanisms. Computer
               simulations confirmed that systematic rate changes of individual
               neurons could produce a directional 'bias' in the decoded neural
               cursor movements. Instability in apparent neuronal spike rates
               indeed yielded a directional bias in 56\% of all performance
               assessments in participant cursor control (n = 2 participants,
               108 and 20 assessments over two years), resulting in suboptimal
               performance in these sessions. SIGNIFICANCE: We anticipate that
               signal acquisition and decoding methods that can adapt to the
               reported instabilities will further improve the performance of
               intracortically-based NISs.",
  journal   = "J. Neural Eng.",
  publisher = "iopscience.iop.org",
  volume    =  10,
  number    =  3,
  pages     = "036004",
  month     =  jun,
  year      =  2013,
  keywords  = "To Read;BCI",
  language  = "en",
  issn      = "1741-2560, 1741-2552",
  pmid      = "23574741",
  doi       = "10.1088/1741-2560/10/3/036004",
  pmc       = "PMC3693851"
}

@ARTICLE{Ran2022-ir,
  title     = "A hybrid autoencoder framework of dimensionality reduction for
               brain-computer interface decoding",
  author    = "Ran, Xingchen and Chen, Weidong and Yvert, Blaise and Zhang,
               Shaomin",
  abstract  = "OBJECTIVE: As the scale of neural recording increases,
               Brain-computer interfaces (BCIs) are restrained by
               high-dimensional neural features, so dimensionality reduction is
               required as a preprocess of neural features. In this context, we
               propose a novel framework based on deep learning to reduce the
               dimensionality of neural features that are typically extracted
               from electrocorticography (ECoG) or local field potential (LFP).
               APPROACH: A high-performance autoencoder was implemented by
               chaining convolutional layers to deal with spatial and frequency
               dimensions with bottleneck long short-term memory (LSTM) layers
               to deal with the temporal dimension of the features.
               Furthermore, this autoencoder is combined with a fully connected
               layer to regularize the training. MAIN RESULTS: By applying the
               proposed method to two different datasets, we found that this
               dimensionality reduction method largely outperforms kernel
               principal component analysis (KPCA), partial least square (PLS),
               preferential subspace identification (PSID), and latent factor
               analysis via dynamical systems (LFADS). Besides, the new
               features obtained by our method can be applied to various BCI
               decoders, without significant differences in decoding
               performance. SIGNIFICANCE: A novel method is proposed as a
               reliable tool for efficient dimensionality reduction of neural
               signals. Its high performance and robustness are promising to
               enhance the decoding accuracy and long-term stability of online
               BCI systems based on large-scale neural recordings.",
  journal   = "Comput. Biol. Med.",
  publisher = "Elsevier",
  volume    =  148,
  pages     = "105871",
  month     =  sep,
  year      =  2022,
  keywords  = "Autoencoder; Brain-computer interface; Dimensionality reduction;
               Neural decoding;To Read;BCI",
  language  = "en",
  issn      = "0010-4825, 1879-0534",
  pmid      = "35933960",
  doi       = "10.1016/j.compbiomed.2022.105871"
}

@ARTICLE{Valencia2019-az,
  title     = "Frameworks for Efficient {Brain-Computer} Interfacing",
  author    = "Valencia, Daniel and Thies, Jameson and Alimohammad, Amirhossein",
  abstract  = "One challenge present in brain-computer interface (BCI) circuits
               is finding a balance between real-time on-chip processing
               in-vivo and wireless transmission of neural signals for off-chip
               in-silico processing. This article presents three potential
               frameworks for investigating an area- and energy-efficient
               realization of BCI circuits. The first framework performs spike
               detection on the filtered neural signal on a brain-implantable
               chip and only transmits detected spikes wirelessly for offline
               classification and decoding. The second framework performs
               in-vivo compression of the on-chip detected spikes prior to
               wireless transmission for substantially reducing wireless
               transmission overhead. The third framework performs spike
               sorting in-vivo on the brain-implantable chip to classify
               detected spikes on-chip and hence, even further reducing
               wireless data transmission rate at the expense of more signal
               processing. To alleviate the on-chip computation of spike
               sorting and also utilizing a more area- and energy-effective
               design, this work employs, for the first time, to the best of
               our knowledge, an artificial neural network (ANN) instead of
               using relatively computationally-intensive conventional spike
               sorting algorithms. The ASIC implementation results of the
               designed frameworks are presented and their feasibility for
               efficient in-vivo processing of neural signals is discussed.
               Compared to the previously-published BCI systems, the presented
               frameworks reduce the area and power consumption of implantable
               circuits.",
  journal   = "IEEE Trans. Biomed. Circuits Syst.",
  publisher = "ieeexplore.ieee.org",
  volume    =  13,
  number    =  6,
  pages     = "1714--1722",
  month     =  dec,
  year      =  2019,
  keywords  = "To Read;BCI",
  language  = "en",
  issn      = "1932-4545, 1940-9990",
  pmid      = "31613780",
  doi       = "10.1109/TBCAS.2019.2947130"
}

@INPROCEEDINGS{Shaeri2022-hr,
  title     = "Challenges and Opportunities of Edge {AI} for {Next-Generation}
               Implantable {BMIs}",
  booktitle = "2022 {IEEE} 4th International Conference on Artificial
               Intelligence Circuits and Systems ({AICAS})",
  author    = "Shaeri, Mohammadali and Afzal, Arshia and Shoaran, Mahsa",
  abstract  = "Neuroscience and neurotechnology are currently being
               revolutionized by artificial intelligence (AI) and machine
               learning. AI is widely used to study and interpret neural
               signals (analytical applications), assist people with
               disabilities (prosthetic applications), and treat underlying
               neurological symptoms (ther-apeutic applications). In this
               brief, we will review the emerging opportunities of on-chip AI
               for the next-generation implantable brain machine interfaces
               (BMIs), with a focus on state-of-the-art prosthetic BMIs. Major
               technological challenges for the effectiveness of AI models will
               be discussed. Finally, we will present algorithmic and IC design
               solutions to enable a new generation of AI-enhanced and
               high-channel-count BMIs.",
  publisher = "ieeexplore.ieee.org",
  pages     = "190--193",
  month     =  jun,
  year      =  2022,
  keywords  = "Neuroscience;Machine
               learning;System-on-chip;Trajectory;Artificial
               intelligence;Integrated circuit modeling;Next generation
               networking;Artificial Intelligence (AI);Machine Learning
               (ML);Brain Machine Interface (BMI);hardware efficiency;To
               Read;BCI",
  doi       = "10.1109/AICAS54282.2022.9870008"
}

@ARTICLE{Tam2019-ql,
  title     = "Human motor decoding from neural signals: a review",
  author    = "Tam, Wing-Kin and Wu, Tong and Zhao, Qi and Keefer, Edward and
               Yang, Zhi",
  abstract  = "Many people suffer from movement disability due to amputation or
               neurological diseases. Fortunately, with modern neurotechnology
               now it is possible to intercept motor control signals at various
               points along the neural transduction pathway and use that to
               drive external devices for communication or control. Here we
               will review the latest developments in human motor decoding. We
               reviewed the various strategies to decode motor intention from
               human and their respective advantages and challenges. Neural
               control signals can be intercepted at various points in the
               neural signal transduction pathway, including the brain
               (electroencephalography, electrocorticography, intracortical
               recordings), the nerves (peripheral nerve recordings) and the
               muscles (electromyography). We systematically discussed the
               sites of signal acquisition, available neural features, signal
               processing techniques and decoding algorithms in each of these
               potential interception points. Examples of applications and the
               current state-of-the-art performance were also reviewed.
               Although great strides have been made in human motor decoding,
               we are still far away from achieving naturalistic and dexterous
               control like our native limbs. Concerted efforts from material
               scientists, electrical engineers, and healthcare professionals
               are needed to further advance the field and make the technology
               widely available in clinical use.",
  journal   = "BMC Biomed Eng",
  publisher = "Springer",
  volume    =  1,
  pages     = "22",
  month     =  sep,
  year      =  2019,
  keywords  = "Brain-machine interfaces; Motor decoding; Neural signal
               processing; Neuroprosthesis;To Read;BCI",
  language  = "en",
  issn      = "2524-4426",
  pmid      = "32903354",
  doi       = "10.1186/s42490-019-0022-z",
  pmc       = "PMC7422484"
}

@ARTICLE{Degenhart2020-lg,
  title     = "Stabilization of a brain--computer interface via the alignment
               of low-dimensional spaces of neural activity",
  author    = "Degenhart, Alan D and Bishop, William E and Oby, Emily R and
               Tyler-Kabara, Elizabeth C and Chase, Steven M and Batista, Aaron
               P and Yu, Byron M",
  abstract  = "The instability of neural recordings can render clinical
               brain--computer interfaces (BCIs) uncontrollable. Here, we show
               that the alignment of low-dimensional neural manifolds
               (low-dimensional spaces that describe specific correlation
               patterns between neurons) can be used to stabilize neural
               activity, thereby maintaining BCI performance in the presence of
               recording instabilities. We evaluated the stabilizer with
               non-human primates during online cursor control via
               intracortical BCIs in the presence of severe and abrupt
               recording instabilities. The stabilized BCIs recovered
               proficient control under different instability conditions and
               across multiple days. The stabilizer does not require knowledge
               of user intent and can outperform supervised recalibration. It
               stabilized BCIs even when neural activity contained little
               information about the direction of cursor movement. The
               stabilizer may be applicable to other neural interfaces and may
               improve the clinical viability of BCIs. Neural activity residing
               in a low-dimensional space that reflects specific correlation
               patterns among neurons can be used to maintain the performance
               of brain--computer interfaces in the presence of recording
               instabilities.",
  journal   = "Nature Biomedical Engineering",
  publisher = "Nature Publishing Group",
  volume    =  4,
  number    =  7,
  pages     = "672--685",
  month     =  apr,
  year      =  2020,
  keywords  = "BCI;To Read",
  language  = "en",
  issn      = "2157-846X, 2157-846X",
  doi       = "10.1038/s41551-020-0542-9"
}

@ARTICLE{Cai2022-ph,
  title     = "Motor imagery {EEG} decoding using manifold embedded transfer
               learning",
  author    = "Cai, Yinhao and She, Qingshan and Ji, Jiyue and Ma, Yuliang and
               Zhang, Jianhai and Zhang, Yingchun",
  abstract  = "BACKGROUND: Brain computer interface (BCI) utilizes brain
               signals to help users interact with external devices directly.
               EEG is one of the most commonly used techniques for brain signal
               acquisition in BCI. However, it is notoriously difficult to
               build a generic EEG recognition model due to significant
               non-stationarity and subject-to-subject variations, and the
               requirement for long time training. Transfer learning (TL) is
               particularly useful because it can alleviate the calibration
               requirement in EEG-based BCI applications by transferring the
               calibration information from existing subjects to new subject.
               To take advantage of geometric properties in Riemann manifold
               and joint distribution adaptation, a manifold embedded transfer
               learning (METL) framework was proposed for motor imagery (MI)
               EEG decoding. NEW METHOD: First, the covariance matrices of the
               EEG trials are first aligned on the SPD manifold. Then the
               features are extracted from both the symmetric positive definite
               (SPD) manifold and Grassmann manifold. Finally, the
               classification model is learned by combining the structural risk
               minimization (SRM) of source domain and joint distribution
               alignment of source and target domains. RESULT: Experimental
               results on two MI EEG datasets verify the effectiveness of the
               proposed METL. In particular, when there are a small amount of
               labeled samples in the target domain, METL demonstrated a more
               accurate and stable classification performance than conventional
               methods. COMPARISON WITH EXISTING METHODS: Compared with several
               state-of-the-art methods, METL has achieved better
               classification accuracy, 71.81\% and 69.06\% in single-to-single
               (STS), 83.14\% and 76.00\% in multi-to-single (MTS) transfer
               tasks, respectively. CONCLUSIONS: METL can cope with single
               source domain or multi-source domains and compared with
               single-source transfer learning, multi-source transfer learning
               can improve the performance effectively due to the data
               expansion. It is effective enough to achieve superior
               performance for classification of EEG signals.",
  journal   = "J. Neurosci. Methods",
  publisher = "Elsevier",
  volume    =  370,
  pages     = "109489",
  month     =  mar,
  year      =  2022,
  keywords  = "Brain-computer interface; Distribution alignment; Multiple
               source domains; Riemannian manifold; Transfer learning;To
               Read;BCI",
  language  = "en",
  issn      = "0165-0270, 1872-678X",
  pmid      = "35090904",
  doi       = "10.1016/j.jneumeth.2022.109489"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Wimalasena2020-nm,
  title     = "From unstable input to robust output",
  author    = "Wimalasena, Lahiru N and Miller, Lee E and Pandarinath, Chethan",
  abstract  = "… recovery of BCI cursor control via manifold alignment (which …
               ' method is that the alignment of successive windows of … ,
               which may allow the manifold alignment and thus the decoder 's …",
  journal   = "Nat Biomed Eng",
  publisher = "nature.com",
  volume    =  4,
  number    =  7,
  pages     = "665--667",
  month     =  jul,
  year      =  2020,
  keywords  = "BCI",
  language  = "en",
  issn      = "2157-846X",
  pmid      = "32661304",
  doi       = "10.1038/s41551-020-0587-9"
}

@UNPUBLISHED{Ma2022-vw,
  title    = "Using adversarial networks to extend brain computer interface
              decoding accuracy over time",
  author   = "Ma, Xuan and Rizzoglio, Fabio and Perreault, Eric J and Miller,
              Lee E and Kennedy, Ann",
  abstract = "Existing intracortical brain computer interfaces (iBCIs)
              transform neural activity into control signals capable of
              restoring movement to persons with paralysis. However, the
              accuracy of the ``decoder'' at the heart of the iBCI typically
              degrades over time due to turnover of recorded neurons. To
              compensate, decoders can be recalibrated, but this requires the
              user to spend extra time and effort to provide the necessary
              data, then learn the new dynamics. As the recorded neurons
              change, one can think of the underlying movement intent signal
              being expressed in changing coordinates. If a mapping can be
              computed between the different coordinate systems, it may be
              possible to stabilize the original decoder's mapping from brain
              to behavior without recalibration. We previously proposed a
              method based on Generalized Adversarial Networks (GANs), called
              ``Adversarial Domain Adaptation Network'' (ADAN), which aligns
              the distributions of latent signals within underlying
              low-dimensional neural manifolds. However, ADAN was tested on
              only a very limited dataset. Here we propose a method based on
              Cycle-Consistent Adversarial Networks (Cycle-GAN), which aligns
              the distributions of the full-dimensional neural recordings. We
              tested both Cycle-GAN and ADAN on data from multiple monkeys and
              behaviors and compared them to a linear method based on
              Procrustes Alignment of axes provided by Factor Analysis (PAF).
              Both GAN-based methods outperformed PAF. Cycle-GAN and ADAN (like
              PAF) are unsupervised and require little data, making them
              practical in real life. Overall, Cycle-GAN had the best
              performance and was easier to train and more robust than ADAN,
              making it ideal for stabilizing iBCI systems over time.
              Significance Statement The inherent instabilities in the neural
              signals acquired by intracortical microelectrode arrays cause the
              performance of an intracortical brain computer interface (iBCI)
              decoder to drop over time, as the movement intent signal must
              essentially be recorded from neurons representing an
              ever-changing coordinate system. Here, we address this problem
              using Generative Adversarial Networks (GANs) to align these
              coordinates and compare their success to another, recently
              proposed linear method that uses Factor Analysis and Procrustes
              alignment. Our proposed methods are fully unsupervised, can be
              trained quickly, and require remarkably little new data. These
              methods should give iBCI users access to decoders with unchanging
              dynamics, and without the need for periodic supervised
              recalibration. \#\#\# Competing Interest Statement The authors
              have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2022.08.26.504777",
  month    =  aug,
  year     =  2022,
  keywords = "BCI",
  language = "en",
  doi      = "10.1101/2022.08.26.504777"
}
